INFO:root:Backdoor type: single-character-common
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 49.411764705882355
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [595, 500, 859, 383, 1838, 1939, 1125, 353, 1260, 1834]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :595
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695054
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697550
INFO:root:FL Epoch: 1 Norm Difference for worker 595 is 0.318258
INFO:root:FL Epoch: 1 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :500
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693981
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690362
INFO:root:FL Epoch: 1 Norm Difference for worker 500 is 0.305986
INFO:root:FL Epoch: 1 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :859
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696468
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670782
INFO:root:FL Epoch: 1 Norm Difference for worker 859 is 0.307247
INFO:root:FL Epoch: 1 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :383
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690619
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689030
INFO:root:FL Epoch: 1 Norm Difference for worker 383 is 0.290591
INFO:root:FL Epoch: 1 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1838
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688133
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680265
INFO:root:FL Epoch: 1 Norm Difference for worker 1838 is 0.276971
INFO:root:FL Epoch: 1 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1939
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682560
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694945
INFO:root:FL Epoch: 1 Norm Difference for worker 1939 is 0.293944
INFO:root:FL Epoch: 1 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1125
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687419
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689854
INFO:root:FL Epoch: 1 Norm Difference for worker 1125 is 0.289756
INFO:root:FL Epoch: 1 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :353
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693567
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683620
INFO:root:FL Epoch: 1 Norm Difference for worker 353 is 0.270315
INFO:root:FL Epoch: 1 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1260
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690472
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688392
INFO:root:FL Epoch: 1 Norm Difference for worker 1260 is 0.405649
INFO:root:FL Epoch: 1 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1834
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683985
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699399
INFO:root:FL Epoch: 1 Norm Difference for worker 1834 is 0.264058
INFO:root:FL Epoch: 1 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1125
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 1 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 1 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6923948701690225 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6543356279532114                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1016
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696072
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699696
INFO:root:FL Epoch: 2 Norm Difference for worker 1016 is 0.354551
INFO:root:FL Epoch: 2 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :543
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716037
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660384
INFO:root:FL Epoch: 2 Norm Difference for worker 543 is 0.389179
INFO:root:FL Epoch: 2 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1103
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707855
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690230
INFO:root:FL Epoch: 2 Norm Difference for worker 1103 is 0.334593
INFO:root:FL Epoch: 2 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1820
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683555
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684954
INFO:root:FL Epoch: 2 Norm Difference for worker 1820 is 0.307925
INFO:root:FL Epoch: 2 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :768
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694474
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652975
INFO:root:FL Epoch: 2 Norm Difference for worker 768 is 0.389887
INFO:root:FL Epoch: 2 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1316
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695294
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679136
INFO:root:FL Epoch: 2 Norm Difference for worker 1316 is 0.274574
INFO:root:FL Epoch: 2 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682882
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693307
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.33657
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :276
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 276 is 0.358441
INFO:root:FL Epoch: 2 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :207
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 207 is 0.296349
INFO:root:FL Epoch: 2 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :159
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 159 is 0.31863
INFO:root:FL Epoch: 2 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 159
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 2 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 2 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6880842622588662 and Test Accuracy:53.8235294117647 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.712280680735906                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 3 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :263
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 263 is 0.298923
INFO:root:FL Epoch: 3 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1554
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693596
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682703
INFO:root:FL Epoch: 3 Norm Difference for worker 1554 is 0.540959
INFO:root:FL Epoch: 3 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1266
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680773
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691184
INFO:root:FL Epoch: 3 Norm Difference for worker 1266 is 0.367003
INFO:root:FL Epoch: 3 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :982
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687586
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684998
INFO:root:FL Epoch: 3 Norm Difference for worker 982 is 0.344523
INFO:root:FL Epoch: 3 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674156
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671733
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.33549
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :475
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691355
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696559
INFO:root:FL Epoch: 3 Norm Difference for worker 475 is 0.334379
INFO:root:FL Epoch: 3 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1357
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701708
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692149
INFO:root:FL Epoch: 3 Norm Difference for worker 1357 is 0.3554
INFO:root:FL Epoch: 3 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :684
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690284
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685235
INFO:root:FL Epoch: 3 Norm Difference for worker 684 is 0.340088
INFO:root:FL Epoch: 3 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1506
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687936
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683095
INFO:root:FL Epoch: 3 Norm Difference for worker 1506 is 0.317843
INFO:root:FL Epoch: 3 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1238
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682405
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682321
INFO:root:FL Epoch: 3 Norm Difference for worker 1238 is 0.323627
INFO:root:FL Epoch: 3 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 3 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 3 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6831657606012681 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.717783639828364                             and Backdoor Test Accuracy:26.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :979
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672630
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702998
INFO:root:FL Epoch: 4 Norm Difference for worker 979 is 0.49258
INFO:root:FL Epoch: 4 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :915
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691645
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724700
INFO:root:FL Epoch: 4 Norm Difference for worker 915 is 0.481295
INFO:root:FL Epoch: 4 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1324
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676704
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701578
INFO:root:FL Epoch: 4 Norm Difference for worker 1324 is 0.472124
INFO:root:FL Epoch: 4 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1034
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675046
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681738
INFO:root:FL Epoch: 4 Norm Difference for worker 1034 is 0.442539
INFO:root:FL Epoch: 4 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :360
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680187
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670382
INFO:root:FL Epoch: 4 Norm Difference for worker 360 is 0.461832
INFO:root:FL Epoch: 4 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1751
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674132
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666827
INFO:root:FL Epoch: 4 Norm Difference for worker 1751 is 0.393751
INFO:root:FL Epoch: 4 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1025
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664101
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717371
INFO:root:FL Epoch: 4 Norm Difference for worker 1025 is 0.395452
INFO:root:FL Epoch: 4 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :153
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673150
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 153 is 0.397176
INFO:root:FL Epoch: 4 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1482
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675417
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690187
INFO:root:FL Epoch: 4 Norm Difference for worker 1482 is 0.399932
INFO:root:FL Epoch: 4 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :274
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.709506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 274 is 0.363952
INFO:root:FL Epoch: 4 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 915
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.7017259527655209 and Test Accuracy:51.76470588235294 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.5175132950146993                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 5 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :786
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670238
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652606
INFO:root:FL Epoch: 5 Norm Difference for worker 786 is 0.390284
INFO:root:FL Epoch: 5 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :115
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719730
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 115 is 0.43512
INFO:root:FL Epoch: 5 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :329
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694107
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 329 is 0.421378
INFO:root:FL Epoch: 5 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :440
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646702
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715802
INFO:root:FL Epoch: 5 Norm Difference for worker 440 is 0.431325
INFO:root:FL Epoch: 5 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1220
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730188
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717440
INFO:root:FL Epoch: 5 Norm Difference for worker 1220 is 0.52221
INFO:root:FL Epoch: 5 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :622
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697813
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682219
INFO:root:FL Epoch: 5 Norm Difference for worker 622 is 0.636768
INFO:root:FL Epoch: 5 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1865
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680899
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674695
INFO:root:FL Epoch: 5 Norm Difference for worker 1865 is 0.556146
INFO:root:FL Epoch: 5 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1868
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680776
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692883
INFO:root:FL Epoch: 5 Norm Difference for worker 1868 is 0.622286
INFO:root:FL Epoch: 5 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1776
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728301
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609430
INFO:root:FL Epoch: 5 Norm Difference for worker 1776 is 0.422312
INFO:root:FL Epoch: 5 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1316
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652980
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686260
INFO:root:FL Epoch: 5 Norm Difference for worker 1316 is 0.518401
INFO:root:FL Epoch: 5 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 329
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 5 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 5 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.680676495327669 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.6236344675223032                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 6 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :1197
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627972
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673230
INFO:root:FL Epoch: 6 Norm Difference for worker 1197 is 0.543224
INFO:root:FL Epoch: 6 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1507
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719508
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679635
INFO:root:FL Epoch: 6 Norm Difference for worker 1507 is 0.561626
INFO:root:FL Epoch: 6 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1435
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635485
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670338
INFO:root:FL Epoch: 6 Norm Difference for worker 1435 is 0.491667
INFO:root:FL Epoch: 6 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1040
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695132
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663514
INFO:root:FL Epoch: 6 Norm Difference for worker 1040 is 0.423478
INFO:root:FL Epoch: 6 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1420
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722262
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674815
INFO:root:FL Epoch: 6 Norm Difference for worker 1420 is 0.59278
INFO:root:FL Epoch: 6 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :361
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691737
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698573
INFO:root:FL Epoch: 6 Norm Difference for worker 361 is 0.457823
INFO:root:FL Epoch: 6 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1002
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666635
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695000
INFO:root:FL Epoch: 6 Norm Difference for worker 1002 is 0.505294
INFO:root:FL Epoch: 6 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :327
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 327 is 0.42648
INFO:root:FL Epoch: 6 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :674
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678865
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654825
INFO:root:FL Epoch: 6 Norm Difference for worker 674 is 0.569477
INFO:root:FL Epoch: 6 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1021
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648847
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652017
INFO:root:FL Epoch: 6 Norm Difference for worker 1021 is 0.526284
INFO:root:FL Epoch: 6 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1002
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6754996320780586 and Test Accuracy:55.294117647058826 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7725062867005666                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 7 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :1809
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700984
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668008
INFO:root:FL Epoch: 7 Norm Difference for worker 1809 is 0.493917
INFO:root:FL Epoch: 7 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :835
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669521
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643028
INFO:root:FL Epoch: 7 Norm Difference for worker 835 is 0.536668
INFO:root:FL Epoch: 7 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :972
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688321
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707479
INFO:root:FL Epoch: 7 Norm Difference for worker 972 is 0.54569
INFO:root:FL Epoch: 7 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1512
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670589
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683672
INFO:root:FL Epoch: 7 Norm Difference for worker 1512 is 0.568885
INFO:root:FL Epoch: 7 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1161
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624256
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743009
INFO:root:FL Epoch: 7 Norm Difference for worker 1161 is 0.545278
INFO:root:FL Epoch: 7 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1280
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705794
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634441
INFO:root:FL Epoch: 7 Norm Difference for worker 1280 is 0.598767
INFO:root:FL Epoch: 7 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1341
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691708
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598436
INFO:root:FL Epoch: 7 Norm Difference for worker 1341 is 0.582983
INFO:root:FL Epoch: 7 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :243
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.621100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 243 is 0.584196
INFO:root:FL Epoch: 7 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1257
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639326
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640021
INFO:root:FL Epoch: 7 Norm Difference for worker 1257 is 0.568276
INFO:root:FL Epoch: 7 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :863
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640916
INFO:root:FL Epoch: 7 Norm Difference for worker 863 is 0.584362
INFO:root:FL Epoch: 7 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 835
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 7 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 7 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6711651682853699 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.6397924323876699                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1434
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671064
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679807
INFO:root:FL Epoch: 8 Norm Difference for worker 1434 is 0.57475
INFO:root:FL Epoch: 8 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :721
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698003
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686272
INFO:root:FL Epoch: 8 Norm Difference for worker 721 is 0.552589
INFO:root:FL Epoch: 8 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :363
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699957
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646183
INFO:root:FL Epoch: 8 Norm Difference for worker 363 is 0.615359
INFO:root:FL Epoch: 8 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :467
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647561
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683706
INFO:root:FL Epoch: 8 Norm Difference for worker 467 is 0.660641
INFO:root:FL Epoch: 8 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1443
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670012
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667478
INFO:root:FL Epoch: 8 Norm Difference for worker 1443 is 0.61225
INFO:root:FL Epoch: 8 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1573
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678212
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651987
INFO:root:FL Epoch: 8 Norm Difference for worker 1573 is 0.627108
INFO:root:FL Epoch: 8 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712017
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.568706
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :475
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682697
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638685
INFO:root:FL Epoch: 8 Norm Difference for worker 475 is 0.561414
INFO:root:FL Epoch: 8 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1216
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676105
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707573
INFO:root:FL Epoch: 8 Norm Difference for worker 1216 is 0.531957
INFO:root:FL Epoch: 8 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :521
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663346
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620349
INFO:root:FL Epoch: 8 Norm Difference for worker 521 is 0.54686
INFO:root:FL Epoch: 8 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 269
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6727078451829798 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7943882842858633                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1154
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701017
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692754
INFO:root:FL Epoch: 9 Norm Difference for worker 1154 is 0.582451
INFO:root:FL Epoch: 9 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :257
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654742
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 257 is 0.612739
INFO:root:FL Epoch: 9 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1894
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642232
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672233
INFO:root:FL Epoch: 9 Norm Difference for worker 1894 is 0.683602
INFO:root:FL Epoch: 9 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :729
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630422
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667353
INFO:root:FL Epoch: 9 Norm Difference for worker 729 is 0.638276
INFO:root:FL Epoch: 9 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1361
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633083
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646847
INFO:root:FL Epoch: 9 Norm Difference for worker 1361 is 0.648407
INFO:root:FL Epoch: 9 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :634
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664308
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640076
INFO:root:FL Epoch: 9 Norm Difference for worker 634 is 0.598991
INFO:root:FL Epoch: 9 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648609
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613025
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.636801
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :657
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703149
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675650
INFO:root:FL Epoch: 9 Norm Difference for worker 657 is 0.629309
INFO:root:FL Epoch: 9 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :28
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.661576
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 28 is 0.61058
INFO:root:FL Epoch: 9 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :344
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718196
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748697
INFO:root:FL Epoch: 9 Norm Difference for worker 344 is 0.583285
INFO:root:FL Epoch: 9 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1154
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6689383878427393 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.7150585452715555                             and Backdoor Test Accuracy:43.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :322
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 322 is 0.628561
INFO:root:FL Epoch: 10 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1069
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702391
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653435
INFO:root:FL Epoch: 10 Norm Difference for worker 1069 is 0.625585
INFO:root:FL Epoch: 10 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655413
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642458
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.642107
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :716
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659071
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662785
INFO:root:FL Epoch: 10 Norm Difference for worker 716 is 0.661045
INFO:root:FL Epoch: 10 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1613
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682003
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595452
INFO:root:FL Epoch: 10 Norm Difference for worker 1613 is 0.668736
INFO:root:FL Epoch: 10 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1184
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663185
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703348
INFO:root:FL Epoch: 10 Norm Difference for worker 1184 is 0.575606
INFO:root:FL Epoch: 10 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1191
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675888
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672138
INFO:root:FL Epoch: 10 Norm Difference for worker 1191 is 0.718013
INFO:root:FL Epoch: 10 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :27
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 27 is 0.620703
INFO:root:FL Epoch: 10 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1904
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650893
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702538
INFO:root:FL Epoch: 10 Norm Difference for worker 1904 is 0.715363
INFO:root:FL Epoch: 10 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :291
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 291 is 0.620987
INFO:root:FL Epoch: 10 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1184
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6690563489409054 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.7683854897816976                             and Backdoor Test Accuracy:29.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [1409, 1122, 467, 247, 1802, 1801, 1139, 1528, 498, 594]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :1409
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657431
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626084
INFO:root:FL Epoch: 11 Norm Difference for worker 1409 is 0.694122
INFO:root:FL Epoch: 11 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1122
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649899
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642810
INFO:root:FL Epoch: 11 Norm Difference for worker 1122 is 0.747113
INFO:root:FL Epoch: 11 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :467
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682441
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619877
INFO:root:FL Epoch: 11 Norm Difference for worker 467 is 0.713202
INFO:root:FL Epoch: 11 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :247
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672239
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 247 is 0.736218
INFO:root:FL Epoch: 11 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1802
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596898
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646976
INFO:root:FL Epoch: 11 Norm Difference for worker 1802 is 0.707067
INFO:root:FL Epoch: 11 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1801
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713850
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657896
INFO:root:FL Epoch: 11 Norm Difference for worker 1801 is 0.712387
INFO:root:FL Epoch: 11 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1139
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694629
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711767
INFO:root:FL Epoch: 11 Norm Difference for worker 1139 is 0.694197
INFO:root:FL Epoch: 11 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1528
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618894
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605710
INFO:root:FL Epoch: 11 Norm Difference for worker 1528 is 0.814299
INFO:root:FL Epoch: 11 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :498
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686485
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641288
INFO:root:FL Epoch: 11 Norm Difference for worker 498 is 0.687831
INFO:root:FL Epoch: 11 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :594
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655470
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674635
INFO:root:FL Epoch: 11 Norm Difference for worker 594 is 0.687748
INFO:root:FL Epoch: 11 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6707168572089252 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.5981289347012838                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1405
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659738
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559081
INFO:root:FL Epoch: 12 Norm Difference for worker 1405 is 0.857925
INFO:root:FL Epoch: 12 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1244
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577180
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622914
INFO:root:FL Epoch: 12 Norm Difference for worker 1244 is 0.79236
INFO:root:FL Epoch: 12 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :380
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623753
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717606
INFO:root:FL Epoch: 12 Norm Difference for worker 380 is 0.775325
INFO:root:FL Epoch: 12 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :125
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659674
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.767234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 125 is 0.799914
INFO:root:FL Epoch: 12 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :802
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737927
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667662
INFO:root:FL Epoch: 12 Norm Difference for worker 802 is 0.848639
INFO:root:FL Epoch: 12 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :840
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627852
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531409
INFO:root:FL Epoch: 12 Norm Difference for worker 840 is 0.858512
INFO:root:FL Epoch: 12 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1334
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647858
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576542
INFO:root:FL Epoch: 12 Norm Difference for worker 1334 is 0.865258
INFO:root:FL Epoch: 12 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746568
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660310
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.803506
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :689
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618816
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622544
INFO:root:FL Epoch: 12 Norm Difference for worker 689 is 0.813025
INFO:root:FL Epoch: 12 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1036
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607450
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669461
INFO:root:FL Epoch: 12 Norm Difference for worker 1036 is 0.77388
INFO:root:FL Epoch: 12 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 125
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6694679540746352 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.8496211667855581                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1930
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688000
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618826
INFO:root:FL Epoch: 13 Norm Difference for worker 1930 is 0.958474
INFO:root:FL Epoch: 13 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1474
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650597
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576376
INFO:root:FL Epoch: 13 Norm Difference for worker 1474 is 0.850265
INFO:root:FL Epoch: 13 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :442
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781286
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613456
INFO:root:FL Epoch: 13 Norm Difference for worker 442 is 0.781145
INFO:root:FL Epoch: 13 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :232
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682342
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 232 is 0.871207
INFO:root:FL Epoch: 13 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :116
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692426
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 116 is 0.857709
INFO:root:FL Epoch: 13 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :202
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.721693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 202 is 0.816063
INFO:root:FL Epoch: 13 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1081
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703283
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512894
INFO:root:FL Epoch: 13 Norm Difference for worker 1081 is 0.856424
INFO:root:FL Epoch: 13 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :606
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610176
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579695
INFO:root:FL Epoch: 13 Norm Difference for worker 606 is 0.823335
INFO:root:FL Epoch: 13 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1303
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633173
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594439
INFO:root:FL Epoch: 13 Norm Difference for worker 1303 is 0.850255
INFO:root:FL Epoch: 13 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :945
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677028
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633447
INFO:root:FL Epoch: 13 Norm Difference for worker 945 is 0.849196
INFO:root:FL Epoch: 13 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 442
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6610666057642769 and Test Accuracy:57.35294117647059 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.7457867860794067                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1163
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640868
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682681
INFO:root:FL Epoch: 14 Norm Difference for worker 1163 is 0.805067
INFO:root:FL Epoch: 14 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1460
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656280
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610137
INFO:root:FL Epoch: 14 Norm Difference for worker 1460 is 0.855397
INFO:root:FL Epoch: 14 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :409
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674766
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651502
INFO:root:FL Epoch: 14 Norm Difference for worker 409 is 0.889312
INFO:root:FL Epoch: 14 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1123
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672285
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628160
INFO:root:FL Epoch: 14 Norm Difference for worker 1123 is 0.870729
INFO:root:FL Epoch: 14 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :604
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647043
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712449
INFO:root:FL Epoch: 14 Norm Difference for worker 604 is 0.900418
INFO:root:FL Epoch: 14 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :200
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 200 is 0.855961
INFO:root:FL Epoch: 14 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :551
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692232
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599293
INFO:root:FL Epoch: 14 Norm Difference for worker 551 is 0.847367
INFO:root:FL Epoch: 14 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1222
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651384
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582633
INFO:root:FL Epoch: 14 Norm Difference for worker 1222 is 0.868938
INFO:root:FL Epoch: 14 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1589
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638140
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700214
INFO:root:FL Epoch: 14 Norm Difference for worker 1589 is 0.823996
INFO:root:FL Epoch: 14 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :746
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614049
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646138
INFO:root:FL Epoch: 14 Norm Difference for worker 746 is 0.784098
INFO:root:FL Epoch: 14 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 746
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6554806933683508 and Test Accuracy:58.529411764705884 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:0.817481130361557                             and Backdoor Test Accuracy:30.0 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 15 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :1506
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598618
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561610
INFO:root:FL Epoch: 15 Norm Difference for worker 1506 is 1.016835
INFO:root:FL Epoch: 15 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :196
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 196 is 0.989314
INFO:root:FL Epoch: 15 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1478
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614982
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531782
INFO:root:FL Epoch: 15 Norm Difference for worker 1478 is 0.957015
INFO:root:FL Epoch: 15 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659898
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597022
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 0.997446
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1923
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656313
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638388
INFO:root:FL Epoch: 15 Norm Difference for worker 1923 is 0.907571
INFO:root:FL Epoch: 15 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :91
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 91 is 0.953192
INFO:root:FL Epoch: 15 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :242
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.661674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 242 is 0.927393
INFO:root:FL Epoch: 15 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1709
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706571
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621275
INFO:root:FL Epoch: 15 Norm Difference for worker 1709 is 0.937277
INFO:root:FL Epoch: 15 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1297
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637359
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670223
INFO:root:FL Epoch: 15 Norm Difference for worker 1297 is 0.957004
INFO:root:FL Epoch: 15 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1000
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642380
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541450
INFO:root:FL Epoch: 15 Norm Difference for worker 1000 is 0.995889
INFO:root:FL Epoch: 15 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1923
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6537317738813513 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:0.7926214039325714                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :639
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599258
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616670
INFO:root:FL Epoch: 16 Norm Difference for worker 639 is 1.086058
INFO:root:FL Epoch: 16 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :327
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 327 is 1.079908
INFO:root:FL Epoch: 16 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :503
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591424
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577252
INFO:root:FL Epoch: 16 Norm Difference for worker 503 is 1.087954
INFO:root:FL Epoch: 16 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1110
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672780
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617801
INFO:root:FL Epoch: 16 Norm Difference for worker 1110 is 1.060872
INFO:root:FL Epoch: 16 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :839
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556547
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645292
INFO:root:FL Epoch: 16 Norm Difference for worker 839 is 1.063892
INFO:root:FL Epoch: 16 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :472
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654876
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613935
INFO:root:FL Epoch: 16 Norm Difference for worker 472 is 1.136545
INFO:root:FL Epoch: 16 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :274
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564666
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 274 is 1.069872
INFO:root:FL Epoch: 16 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :481
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585689
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520563
INFO:root:FL Epoch: 16 Norm Difference for worker 481 is 1.067545
INFO:root:FL Epoch: 16 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :805
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532219
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584925
INFO:root:FL Epoch: 16 Norm Difference for worker 805 is 1.088292
INFO:root:FL Epoch: 16 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1606
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621322
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578178
INFO:root:FL Epoch: 16 Norm Difference for worker 1606 is 1.08289
INFO:root:FL Epoch: 16 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 503
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6633008157505709 and Test Accuracy:60.0 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.020702342192332                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :116
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 116 is 1.213657
INFO:root:FL Epoch: 17 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1658
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651987
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609420
INFO:root:FL Epoch: 17 Norm Difference for worker 1658 is 1.185869
INFO:root:FL Epoch: 17 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :988
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605118
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570124
INFO:root:FL Epoch: 17 Norm Difference for worker 988 is 1.244728
INFO:root:FL Epoch: 17 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1655
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741353
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535849
INFO:root:FL Epoch: 17 Norm Difference for worker 1655 is 1.208484
INFO:root:FL Epoch: 17 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :62
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787996
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 62 is 1.202241
INFO:root:FL Epoch: 17 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :870
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745831
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740190
INFO:root:FL Epoch: 17 Norm Difference for worker 870 is 1.171558
INFO:root:FL Epoch: 17 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :955
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670187
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605791
INFO:root:FL Epoch: 17 Norm Difference for worker 955 is 1.311959
INFO:root:FL Epoch: 17 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :304
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 304 is 1.192135
INFO:root:FL Epoch: 17 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1427
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762187
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586471
INFO:root:FL Epoch: 17 Norm Difference for worker 1427 is 1.13428
INFO:root:FL Epoch: 17 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :652
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628546
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458871
INFO:root:FL Epoch: 17 Norm Difference for worker 652 is 1.255945
INFO:root:FL Epoch: 17 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 652
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6616577944334816 and Test Accuracy:60.0 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:0.8500720163186392                             and Backdoor Test Accuracy:43.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1037
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633888
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606151
INFO:root:FL Epoch: 18 Norm Difference for worker 1037 is 1.217499
INFO:root:FL Epoch: 18 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1375
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713977
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667896
INFO:root:FL Epoch: 18 Norm Difference for worker 1375 is 1.257867
INFO:root:FL Epoch: 18 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :637
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640667
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565265
INFO:root:FL Epoch: 18 Norm Difference for worker 637 is 1.345377
INFO:root:FL Epoch: 18 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :293
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689112
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 293 is 1.247642
INFO:root:FL Epoch: 18 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1435
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578477
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644692
INFO:root:FL Epoch: 18 Norm Difference for worker 1435 is 1.254764
INFO:root:FL Epoch: 18 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1294
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718905
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631598
INFO:root:FL Epoch: 18 Norm Difference for worker 1294 is 1.276756
INFO:root:FL Epoch: 18 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :712
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671836
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731664
INFO:root:FL Epoch: 18 Norm Difference for worker 712 is 1.421395
INFO:root:FL Epoch: 18 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :440
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577277
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730663
INFO:root:FL Epoch: 18 Norm Difference for worker 440 is 1.262051
INFO:root:FL Epoch: 18 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1768
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692658
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547696
INFO:root:FL Epoch: 18 Norm Difference for worker 1768 is 1.226298
INFO:root:FL Epoch: 18 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1805
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603555
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630146
INFO:root:FL Epoch: 18 Norm Difference for worker 1805 is 1.263321
INFO:root:FL Epoch: 18 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1037
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6581977185081033 and Test Accuracy:59.705882352941174 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.0045347015062969                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 19 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :772
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596358
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549365
INFO:root:FL Epoch: 19 Norm Difference for worker 772 is 1.017782
INFO:root:FL Epoch: 19 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :212
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 212 is 1.080392
INFO:root:FL Epoch: 19 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :407
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591958
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556476
INFO:root:FL Epoch: 19 Norm Difference for worker 407 is 1.009595
INFO:root:FL Epoch: 19 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :782
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778683
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588201
INFO:root:FL Epoch: 19 Norm Difference for worker 782 is 1.060526
INFO:root:FL Epoch: 19 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1093
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650377
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527316
INFO:root:FL Epoch: 19 Norm Difference for worker 1093 is 1.064872
INFO:root:FL Epoch: 19 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1764
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694386
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647304
INFO:root:FL Epoch: 19 Norm Difference for worker 1764 is 1.031642
INFO:root:FL Epoch: 19 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 1.026493
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :351
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797043
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692276
INFO:root:FL Epoch: 19 Norm Difference for worker 351 is 1.003659
INFO:root:FL Epoch: 19 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1391
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674193
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643278
INFO:root:FL Epoch: 19 Norm Difference for worker 1391 is 1.053503
INFO:root:FL Epoch: 19 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :334
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 334 is 1.097651
INFO:root:FL Epoch: 19 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 351
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6729085480465609 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.092368483543396                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :697
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706639
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580187
INFO:root:FL Epoch: 20 Norm Difference for worker 697 is 1.049589
INFO:root:FL Epoch: 20 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1059
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609891
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510376
INFO:root:FL Epoch: 20 Norm Difference for worker 1059 is 1.010931
INFO:root:FL Epoch: 20 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :940
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803311
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610752
INFO:root:FL Epoch: 20 Norm Difference for worker 940 is 1.028328
INFO:root:FL Epoch: 20 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1796
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720568
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582290
INFO:root:FL Epoch: 20 Norm Difference for worker 1796 is 0.933791
INFO:root:FL Epoch: 20 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1162
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710034
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655756
INFO:root:FL Epoch: 20 Norm Difference for worker 1162 is 1.018042
INFO:root:FL Epoch: 20 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1765
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673888
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504142
INFO:root:FL Epoch: 20 Norm Difference for worker 1765 is 0.977072
INFO:root:FL Epoch: 20 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :469
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659014
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566671
INFO:root:FL Epoch: 20 Norm Difference for worker 469 is 0.942151
INFO:root:FL Epoch: 20 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1470
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591830
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607164
INFO:root:FL Epoch: 20 Norm Difference for worker 1470 is 0.961157
INFO:root:FL Epoch: 20 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :442
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558364
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597973
INFO:root:FL Epoch: 20 Norm Difference for worker 442 is 0.944884
INFO:root:FL Epoch: 20 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1373
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740461
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588480
INFO:root:FL Epoch: 20 Norm Difference for worker 1373 is 0.999142
INFO:root:FL Epoch: 20 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 469
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6575507241136888 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.0573597153027852                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [188, 485, 797, 1233, 876, 159, 811, 1592, 1089, 1895]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :188
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 188 is 1.04585
INFO:root:FL Epoch: 21 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :485
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726358
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486458
INFO:root:FL Epoch: 21 Norm Difference for worker 485 is 1.132462
INFO:root:FL Epoch: 21 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :797
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531103
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465565
INFO:root:FL Epoch: 21 Norm Difference for worker 797 is 1.056835
INFO:root:FL Epoch: 21 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1233
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668382
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652274
INFO:root:FL Epoch: 21 Norm Difference for worker 1233 is 1.203663
INFO:root:FL Epoch: 21 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :876
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694495
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502080
INFO:root:FL Epoch: 21 Norm Difference for worker 876 is 1.049327
INFO:root:FL Epoch: 21 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :159
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 159 is 1.023187
INFO:root:FL Epoch: 21 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :811
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651485
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679704
INFO:root:FL Epoch: 21 Norm Difference for worker 811 is 1.090231
INFO:root:FL Epoch: 21 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1592
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783901
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545428
INFO:root:FL Epoch: 21 Norm Difference for worker 1592 is 1.088779
INFO:root:FL Epoch: 21 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1089
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692198
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551140
INFO:root:FL Epoch: 21 Norm Difference for worker 1089 is 1.037913
INFO:root:FL Epoch: 21 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1895
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712410
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703200
INFO:root:FL Epoch: 21 Norm Difference for worker 1895 is 1.074239
INFO:root:FL Epoch: 21 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 876
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6687815259484684 and Test Accuracy:60.0 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:0.9210933645566305                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 22 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :1716
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604451
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644107
INFO:root:FL Epoch: 22 Norm Difference for worker 1716 is 0.975292
INFO:root:FL Epoch: 22 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :910
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602161
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534665
INFO:root:FL Epoch: 22 Norm Difference for worker 910 is 1.064253
INFO:root:FL Epoch: 22 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1098
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541724
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507401
INFO:root:FL Epoch: 22 Norm Difference for worker 1098 is 1.00816
INFO:root:FL Epoch: 22 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1721
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551903
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763859
INFO:root:FL Epoch: 22 Norm Difference for worker 1721 is 0.949367
INFO:root:FL Epoch: 22 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :576
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571151
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623158
INFO:root:FL Epoch: 22 Norm Difference for worker 576 is 1.005111
INFO:root:FL Epoch: 22 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :104
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 104 is 0.972241
INFO:root:FL Epoch: 22 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1834
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668193
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631191
INFO:root:FL Epoch: 22 Norm Difference for worker 1834 is 0.996949
INFO:root:FL Epoch: 22 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1178
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547060
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637419
INFO:root:FL Epoch: 22 Norm Difference for worker 1178 is 1.063385
INFO:root:FL Epoch: 22 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :810
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668043
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632524
INFO:root:FL Epoch: 22 Norm Difference for worker 810 is 0.994198
INFO:root:FL Epoch: 22 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1047
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633378
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631696
INFO:root:FL Epoch: 22 Norm Difference for worker 1047 is 0.955712
INFO:root:FL Epoch: 22 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1047
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6862867088878856 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:0.8642102777957916                             and Backdoor Test Accuracy:32.5 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1150
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625197
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693022
INFO:root:FL Epoch: 23 Norm Difference for worker 1150 is 1.053322
INFO:root:FL Epoch: 23 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :703
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723668
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687979
INFO:root:FL Epoch: 23 Norm Difference for worker 703 is 1.037403
INFO:root:FL Epoch: 23 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1942
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517314
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735589
INFO:root:FL Epoch: 23 Norm Difference for worker 1942 is 1.060686
INFO:root:FL Epoch: 23 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :362
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532502
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545802
INFO:root:FL Epoch: 23 Norm Difference for worker 362 is 1.150447
INFO:root:FL Epoch: 23 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1475
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633417
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536440
INFO:root:FL Epoch: 23 Norm Difference for worker 1475 is 1.090688
INFO:root:FL Epoch: 23 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :742
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798498
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581453
INFO:root:FL Epoch: 23 Norm Difference for worker 742 is 1.084699
INFO:root:FL Epoch: 23 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705374
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670383
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 1.005368
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :355
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833875
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715454
INFO:root:FL Epoch: 23 Norm Difference for worker 355 is 1.088394
INFO:root:FL Epoch: 23 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :747
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613672
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596349
INFO:root:FL Epoch: 23 Norm Difference for worker 747 is 1.056128
INFO:root:FL Epoch: 23 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :802
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690049
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700798
INFO:root:FL Epoch: 23 Norm Difference for worker 802 is 1.126314
INFO:root:FL Epoch: 23 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6715695156770594 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:0.8972673813501993                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678233
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711213
INFO:root:FL Epoch: 24 Norm Difference for worker 858 is 0.994827
INFO:root:FL Epoch: 24 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :699
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609938
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648323
INFO:root:FL Epoch: 24 Norm Difference for worker 699 is 0.965496
INFO:root:FL Epoch: 24 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :206
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 206 is 0.97925
INFO:root:FL Epoch: 24 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1820
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605997
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665031
INFO:root:FL Epoch: 24 Norm Difference for worker 1820 is 0.958715
INFO:root:FL Epoch: 24 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1414
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582912
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617636
INFO:root:FL Epoch: 24 Norm Difference for worker 1414 is 0.954772
INFO:root:FL Epoch: 24 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :474
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703269
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703998
INFO:root:FL Epoch: 24 Norm Difference for worker 474 is 0.890181
INFO:root:FL Epoch: 24 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :7
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 7 is 0.970697
INFO:root:FL Epoch: 24 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1914
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518358
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703193
INFO:root:FL Epoch: 24 Norm Difference for worker 1914 is 0.968307
INFO:root:FL Epoch: 24 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :865
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631862
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622300
INFO:root:FL Epoch: 24 Norm Difference for worker 865 is 0.964194
INFO:root:FL Epoch: 24 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :249
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653804
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 249 is 1.024163
INFO:root:FL Epoch: 24 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 474
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6641720358063193 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:0.9896289110183716                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1399
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600294
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631552
INFO:root:FL Epoch: 25 Norm Difference for worker 1399 is 0.896107
INFO:root:FL Epoch: 25 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :693
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665027
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604658
INFO:root:FL Epoch: 25 Norm Difference for worker 693 is 0.881818
INFO:root:FL Epoch: 25 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1217
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771262
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533772
INFO:root:FL Epoch: 25 Norm Difference for worker 1217 is 0.997073
INFO:root:FL Epoch: 25 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :70
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621093
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 70 is 0.872076
INFO:root:FL Epoch: 25 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :496
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626253
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540370
INFO:root:FL Epoch: 25 Norm Difference for worker 496 is 0.843612
INFO:root:FL Epoch: 25 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :407
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517461
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555121
INFO:root:FL Epoch: 25 Norm Difference for worker 407 is 0.859991
INFO:root:FL Epoch: 25 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :317
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 317 is 0.872845
INFO:root:FL Epoch: 25 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :98
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 98 is 0.888185
INFO:root:FL Epoch: 25 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1286
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661422
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646898
INFO:root:FL Epoch: 25 Norm Difference for worker 1286 is 0.875239
INFO:root:FL Epoch: 25 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1251
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644862
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614846
INFO:root:FL Epoch: 25 Norm Difference for worker 1251 is 0.936761
INFO:root:FL Epoch: 25 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6871877978829777 and Test Accuracy:58.23529411764706 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.25543212890625                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 26 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :1748
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711394
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674642
INFO:root:FL Epoch: 26 Norm Difference for worker 1748 is 1.003916
INFO:root:FL Epoch: 26 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1403
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448763
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502190
INFO:root:FL Epoch: 26 Norm Difference for worker 1403 is 0.989469
INFO:root:FL Epoch: 26 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1456
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820158
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593188
INFO:root:FL Epoch: 26 Norm Difference for worker 1456 is 0.993918
INFO:root:FL Epoch: 26 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1021
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694218
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640936
INFO:root:FL Epoch: 26 Norm Difference for worker 1021 is 0.976435
INFO:root:FL Epoch: 26 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1824
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640676
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657043
INFO:root:FL Epoch: 26 Norm Difference for worker 1824 is 1.011903
INFO:root:FL Epoch: 26 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :311
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549289
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 311 is 1.057518
INFO:root:FL Epoch: 26 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :906
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558974
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604342
INFO:root:FL Epoch: 26 Norm Difference for worker 906 is 1.053431
INFO:root:FL Epoch: 26 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1618
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937414
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464984
INFO:root:FL Epoch: 26 Norm Difference for worker 1618 is 0.971594
INFO:root:FL Epoch: 26 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :900
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600912
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614991
INFO:root:FL Epoch: 26 Norm Difference for worker 900 is 1.099292
INFO:root:FL Epoch: 26 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1277
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642050
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597266
INFO:root:FL Epoch: 26 Norm Difference for worker 1277 is 1.038034
INFO:root:FL Epoch: 26 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1618
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 26 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 26 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6555818880305571 and Test Accuracy:62.94117647058823 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:0.9500959813594818                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 27 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1930
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455070
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589989
INFO:root:FL Epoch: 27 Norm Difference for worker 1930 is 1.098384
INFO:root:FL Epoch: 27 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1641
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804119
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593525
INFO:root:FL Epoch: 27 Norm Difference for worker 1641 is 1.009946
INFO:root:FL Epoch: 27 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :786
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623108
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723701
INFO:root:FL Epoch: 27 Norm Difference for worker 786 is 1.036036
INFO:root:FL Epoch: 27 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1944
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495324
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679393
INFO:root:FL Epoch: 27 Norm Difference for worker 1944 is 1.025929
INFO:root:FL Epoch: 27 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :949
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594320
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641221
INFO:root:FL Epoch: 27 Norm Difference for worker 949 is 1.031541
INFO:root:FL Epoch: 27 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507322
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494782
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 0.983861
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1024
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580641
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549400
INFO:root:FL Epoch: 27 Norm Difference for worker 1024 is 1.055543
INFO:root:FL Epoch: 27 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :860
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736799
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710041
INFO:root:FL Epoch: 27 Norm Difference for worker 860 is 1.172506
INFO:root:FL Epoch: 27 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :79
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446181
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 79 is 1.040241
INFO:root:FL Epoch: 27 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1497
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672313
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619368
INFO:root:FL Epoch: 27 Norm Difference for worker 1497 is 1.016034
INFO:root:FL Epoch: 27 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.668555266716901 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:0.9761598408222198                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :533
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687473
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699648
INFO:root:FL Epoch: 28 Norm Difference for worker 533 is 1.102932
INFO:root:FL Epoch: 28 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1370
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634083
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580401
INFO:root:FL Epoch: 28 Norm Difference for worker 1370 is 1.077297
INFO:root:FL Epoch: 28 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1778
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656907
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592696
INFO:root:FL Epoch: 28 Norm Difference for worker 1778 is 1.195617
INFO:root:FL Epoch: 28 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :376
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638506
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483875
INFO:root:FL Epoch: 28 Norm Difference for worker 376 is 1.15094
INFO:root:FL Epoch: 28 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1688
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419052
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375425
INFO:root:FL Epoch: 28 Norm Difference for worker 1688 is 1.085409
INFO:root:FL Epoch: 28 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1791
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516202
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559156
INFO:root:FL Epoch: 28 Norm Difference for worker 1791 is 1.128612
INFO:root:FL Epoch: 28 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :744
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448382
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723694
INFO:root:FL Epoch: 28 Norm Difference for worker 744 is 1.098359
INFO:root:FL Epoch: 28 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :605
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794500
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576978
INFO:root:FL Epoch: 28 Norm Difference for worker 605 is 1.125202
INFO:root:FL Epoch: 28 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1458
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702036
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432191
INFO:root:FL Epoch: 28 Norm Difference for worker 1458 is 1.100345
INFO:root:FL Epoch: 28 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :452
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756585
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735302
INFO:root:FL Epoch: 28 Norm Difference for worker 452 is 1.125089
INFO:root:FL Epoch: 28 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1688
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6720647952135872 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:0.9520962635676066                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :173
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 173 is 1.19867
INFO:root:FL Epoch: 29 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1917
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743210
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556339
INFO:root:FL Epoch: 29 Norm Difference for worker 1917 is 1.101368
INFO:root:FL Epoch: 29 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1341
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613016
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546154
INFO:root:FL Epoch: 29 Norm Difference for worker 1341 is 1.127476
INFO:root:FL Epoch: 29 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :789
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712525
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638763
INFO:root:FL Epoch: 29 Norm Difference for worker 789 is 1.271014
INFO:root:FL Epoch: 29 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :961
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463366
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630382
INFO:root:FL Epoch: 29 Norm Difference for worker 961 is 1.162205
INFO:root:FL Epoch: 29 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1601
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626156
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511623
INFO:root:FL Epoch: 29 Norm Difference for worker 1601 is 1.133214
INFO:root:FL Epoch: 29 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1755
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405024
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618956
INFO:root:FL Epoch: 29 Norm Difference for worker 1755 is 1.128405
INFO:root:FL Epoch: 29 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1597
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698569
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597656
INFO:root:FL Epoch: 29 Norm Difference for worker 1597 is 1.173678
INFO:root:FL Epoch: 29 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1906
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586759
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651725
INFO:root:FL Epoch: 29 Norm Difference for worker 1906 is 1.200942
INFO:root:FL Epoch: 29 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :545
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416564
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623975
INFO:root:FL Epoch: 29 Norm Difference for worker 545 is 1.201713
INFO:root:FL Epoch: 29 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1917
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6607084134045769 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.9407508869965872                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :97
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678289
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570586
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 97 is 1.025122
INFO:root:FL Epoch: 30 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577056
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513499
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 1.007372
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1598
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661645
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518664
INFO:root:FL Epoch: 30 Norm Difference for worker 1598 is 0.945768
INFO:root:FL Epoch: 30 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1172
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857959
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647916
INFO:root:FL Epoch: 30 Norm Difference for worker 1172 is 0.995986
INFO:root:FL Epoch: 30 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :189
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 189 is 1.03166
INFO:root:FL Epoch: 30 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1585
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543038
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445916
INFO:root:FL Epoch: 30 Norm Difference for worker 1585 is 1.078569
INFO:root:FL Epoch: 30 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1215
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614151
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653384
INFO:root:FL Epoch: 30 Norm Difference for worker 1215 is 0.936866
INFO:root:FL Epoch: 30 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :439
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727565
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643280
INFO:root:FL Epoch: 30 Norm Difference for worker 439 is 0.988563
INFO:root:FL Epoch: 30 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :573
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724772
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593790
INFO:root:FL Epoch: 30 Norm Difference for worker 573 is 1.00973
INFO:root:FL Epoch: 30 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1311
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653024
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524361
INFO:root:FL Epoch: 30 Norm Difference for worker 1311 is 1.034155
INFO:root:FL Epoch: 30 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1598
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 30 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 30 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6519122123718262 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:0.9271735350290934                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [1693, 599, 1613, 1374, 698, 1310, 1539, 786, 1330, 1413]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 31 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :1693
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577911
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524426
INFO:root:FL Epoch: 31 Norm Difference for worker 1693 is 1.064636
INFO:root:FL Epoch: 31 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :599
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726213
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610588
INFO:root:FL Epoch: 31 Norm Difference for worker 599 is 1.104034
INFO:root:FL Epoch: 31 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1613
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674351
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589621
INFO:root:FL Epoch: 31 Norm Difference for worker 1613 is 1.117243
INFO:root:FL Epoch: 31 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1374
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529212
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472150
INFO:root:FL Epoch: 31 Norm Difference for worker 1374 is 1.075567
INFO:root:FL Epoch: 31 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :698
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574206
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690297
INFO:root:FL Epoch: 31 Norm Difference for worker 698 is 1.032073
INFO:root:FL Epoch: 31 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1310
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496414
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545091
INFO:root:FL Epoch: 31 Norm Difference for worker 1310 is 1.106649
INFO:root:FL Epoch: 31 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1539
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731906
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576851
INFO:root:FL Epoch: 31 Norm Difference for worker 1539 is 1.100646
INFO:root:FL Epoch: 31 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :786
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653765
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692454
INFO:root:FL Epoch: 31 Norm Difference for worker 786 is 1.024649
INFO:root:FL Epoch: 31 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1330
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632639
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440534
INFO:root:FL Epoch: 31 Norm Difference for worker 1330 is 1.115074
INFO:root:FL Epoch: 31 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1413
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619651
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548840
INFO:root:FL Epoch: 31 Norm Difference for worker 1413 is 1.057225
INFO:root:FL Epoch: 31 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 786
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 31 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 31 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6471662521362305 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:0.8533410330613455                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :1528
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655242
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426269
INFO:root:FL Epoch: 32 Norm Difference for worker 1528 is 1.094191
INFO:root:FL Epoch: 32 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :546
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580514
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648042
INFO:root:FL Epoch: 32 Norm Difference for worker 546 is 1.05639
INFO:root:FL Epoch: 32 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1315
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659942
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471677
INFO:root:FL Epoch: 32 Norm Difference for worker 1315 is 1.037295
INFO:root:FL Epoch: 32 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.755497
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 1.029453
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :504
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660093
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588324
INFO:root:FL Epoch: 32 Norm Difference for worker 504 is 0.999242
INFO:root:FL Epoch: 32 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :250
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.740772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 250 is 0.994188
INFO:root:FL Epoch: 32 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :655
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656220
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571929
INFO:root:FL Epoch: 32 Norm Difference for worker 655 is 1.009954
INFO:root:FL Epoch: 32 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1640
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611731
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526029
INFO:root:FL Epoch: 32 Norm Difference for worker 1640 is 0.99908
INFO:root:FL Epoch: 32 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1386
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577278
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767288
INFO:root:FL Epoch: 32 Norm Difference for worker 1386 is 0.995951
INFO:root:FL Epoch: 32 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :46
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605298
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 46 is 1.044034
INFO:root:FL Epoch: 32 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1640
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6602080218932208 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.149759034315745                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1149
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651952
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507822
INFO:root:FL Epoch: 33 Norm Difference for worker 1149 is 1.067981
INFO:root:FL Epoch: 33 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :529
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781681
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696105
INFO:root:FL Epoch: 33 Norm Difference for worker 529 is 0.983242
INFO:root:FL Epoch: 33 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :986
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711883
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516316
INFO:root:FL Epoch: 33 Norm Difference for worker 986 is 1.108429
INFO:root:FL Epoch: 33 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :911
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526242
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610252
INFO:root:FL Epoch: 33 Norm Difference for worker 911 is 1.02801
INFO:root:FL Epoch: 33 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :260
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462618
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 260 is 0.954626
INFO:root:FL Epoch: 33 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :855
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642716
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.806149
INFO:root:FL Epoch: 33 Norm Difference for worker 855 is 1.112228
INFO:root:FL Epoch: 33 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :478
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706791
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485899
INFO:root:FL Epoch: 33 Norm Difference for worker 478 is 1.053759
INFO:root:FL Epoch: 33 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1001
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774572
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600906
INFO:root:FL Epoch: 33 Norm Difference for worker 1001 is 0.974736
INFO:root:FL Epoch: 33 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :407
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440600
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515114
INFO:root:FL Epoch: 33 Norm Difference for worker 407 is 1.01692
INFO:root:FL Epoch: 33 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1886
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879443
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639450
INFO:root:FL Epoch: 33 Norm Difference for worker 1886 is 1.009878
INFO:root:FL Epoch: 33 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1001
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.6389011986115399 and Test Accuracy:65.0 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:0.7774730523427328                             and Backdoor Test Accuracy:42.5 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1640
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496235
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549643
INFO:root:FL Epoch: 34 Norm Difference for worker 1640 is 0.988916
INFO:root:FL Epoch: 34 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :942
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674109
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571988
INFO:root:FL Epoch: 34 Norm Difference for worker 942 is 0.928769
INFO:root:FL Epoch: 34 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :389
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658843
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550211
INFO:root:FL Epoch: 34 Norm Difference for worker 389 is 0.910273
INFO:root:FL Epoch: 34 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :907
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566668
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537425
INFO:root:FL Epoch: 34 Norm Difference for worker 907 is 0.989515
INFO:root:FL Epoch: 34 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1081
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778959
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559989
INFO:root:FL Epoch: 34 Norm Difference for worker 1081 is 0.937103
INFO:root:FL Epoch: 34 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1797
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660689
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603911
INFO:root:FL Epoch: 34 Norm Difference for worker 1797 is 0.915907
INFO:root:FL Epoch: 34 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1890
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633041
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566695
INFO:root:FL Epoch: 34 Norm Difference for worker 1890 is 0.936581
INFO:root:FL Epoch: 34 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :922
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548381
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507824
INFO:root:FL Epoch: 34 Norm Difference for worker 922 is 0.893338
INFO:root:FL Epoch: 34 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1593
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693340
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584845
INFO:root:FL Epoch: 34 Norm Difference for worker 1593 is 0.922491
INFO:root:FL Epoch: 34 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1411
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696998
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575260
INFO:root:FL Epoch: 34 Norm Difference for worker 1411 is 0.862165
INFO:root:FL Epoch: 34 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6611939475816839 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.1951219042142232                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1678
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616647
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474970
INFO:root:FL Epoch: 35 Norm Difference for worker 1678 is 1.078731
INFO:root:FL Epoch: 35 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1654
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775844
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686844
INFO:root:FL Epoch: 35 Norm Difference for worker 1654 is 1.124369
INFO:root:FL Epoch: 35 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1413
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783861
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716637
INFO:root:FL Epoch: 35 Norm Difference for worker 1413 is 1.147744
INFO:root:FL Epoch: 35 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :547
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652320
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559252
INFO:root:FL Epoch: 35 Norm Difference for worker 547 is 1.154022
INFO:root:FL Epoch: 35 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1443
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665150
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659762
INFO:root:FL Epoch: 35 Norm Difference for worker 1443 is 1.168746
INFO:root:FL Epoch: 35 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :144
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.733897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 144 is 1.080708
INFO:root:FL Epoch: 35 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :892
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684060
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488115
INFO:root:FL Epoch: 35 Norm Difference for worker 892 is 1.105941
INFO:root:FL Epoch: 35 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :191
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 191 is 1.177346
INFO:root:FL Epoch: 35 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :340
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514952
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664136
INFO:root:FL Epoch: 35 Norm Difference for worker 340 is 1.153467
INFO:root:FL Epoch: 35 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1558
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688445
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537662
INFO:root:FL Epoch: 35 Norm Difference for worker 1558 is 1.138883
INFO:root:FL Epoch: 35 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 144
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6417943852789262 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.0975040594736736                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1323
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625921
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721956
INFO:root:FL Epoch: 36 Norm Difference for worker 1323 is 1.005968
INFO:root:FL Epoch: 36 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1216
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712218
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615620
INFO:root:FL Epoch: 36 Norm Difference for worker 1216 is 0.961627
INFO:root:FL Epoch: 36 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597967
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645946
INFO:root:FL Epoch: 36 Norm Difference for worker 1937 is 0.992983
INFO:root:FL Epoch: 36 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :432
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715713
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579885
INFO:root:FL Epoch: 36 Norm Difference for worker 432 is 0.885491
INFO:root:FL Epoch: 36 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1511
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668109
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629760
INFO:root:FL Epoch: 36 Norm Difference for worker 1511 is 0.943263
INFO:root:FL Epoch: 36 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :669
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524231
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622388
INFO:root:FL Epoch: 36 Norm Difference for worker 669 is 1.069004
INFO:root:FL Epoch: 36 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1891
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439218
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550268
INFO:root:FL Epoch: 36 Norm Difference for worker 1891 is 0.950073
INFO:root:FL Epoch: 36 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1824
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603718
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722220
INFO:root:FL Epoch: 36 Norm Difference for worker 1824 is 1.024842
INFO:root:FL Epoch: 36 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :228
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 228 is 1.012364
INFO:root:FL Epoch: 36 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :447
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649916
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643520
INFO:root:FL Epoch: 36 Norm Difference for worker 447 is 0.994572
INFO:root:FL Epoch: 36 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6446977678467246 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.2373002370198567                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 37 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :400
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604409
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654511
INFO:root:FL Epoch: 37 Norm Difference for worker 400 is 0.999085
INFO:root:FL Epoch: 37 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :3
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 3 is 0.98369
INFO:root:FL Epoch: 37 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1265
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618035
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724286
INFO:root:FL Epoch: 37 Norm Difference for worker 1265 is 1.013968
INFO:root:FL Epoch: 37 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :532
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710514
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582732
INFO:root:FL Epoch: 37 Norm Difference for worker 532 is 1.036159
INFO:root:FL Epoch: 37 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1836
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570456
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598498
INFO:root:FL Epoch: 37 Norm Difference for worker 1836 is 0.975134
INFO:root:FL Epoch: 37 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :270
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565741
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 270 is 1.034571
INFO:root:FL Epoch: 37 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1792
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610614
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605546
INFO:root:FL Epoch: 37 Norm Difference for worker 1792 is 0.980768
INFO:root:FL Epoch: 37 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1318
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699436
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566497
INFO:root:FL Epoch: 37 Norm Difference for worker 1318 is 0.996563
INFO:root:FL Epoch: 37 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :159
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 159 is 1.023743
INFO:root:FL Epoch: 37 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :894
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686761
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621552
INFO:root:FL Epoch: 37 Norm Difference for worker 894 is 1.063577
INFO:root:FL Epoch: 37 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1265
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.6318218392484328 and Test Accuracy:65.0 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.2078287601470947                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 38 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :91
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419335
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 91 is 1.088959
INFO:root:FL Epoch: 38 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :406
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669509
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679529
INFO:root:FL Epoch: 38 Norm Difference for worker 406 is 1.117602
INFO:root:FL Epoch: 38 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1341
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852871
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574891
INFO:root:FL Epoch: 38 Norm Difference for worker 1341 is 1.083656
INFO:root:FL Epoch: 38 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1142
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739110
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611626
INFO:root:FL Epoch: 38 Norm Difference for worker 1142 is 1.133614
INFO:root:FL Epoch: 38 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :961
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676227
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612019
INFO:root:FL Epoch: 38 Norm Difference for worker 961 is 1.136304
INFO:root:FL Epoch: 38 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1634
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616428
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469846
INFO:root:FL Epoch: 38 Norm Difference for worker 1634 is 1.133207
INFO:root:FL Epoch: 38 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :278
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.653536
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 278 is 1.124619
INFO:root:FL Epoch: 38 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1725
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715434
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.791636
INFO:root:FL Epoch: 38 Norm Difference for worker 1725 is 1.205787
INFO:root:FL Epoch: 38 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1426
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476664
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398017
INFO:root:FL Epoch: 38 Norm Difference for worker 1426 is 1.159812
INFO:root:FL Epoch: 38 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :171
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.825803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 171 is 1.148769
INFO:root:FL Epoch: 38 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1341
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.633365157772513 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:0.9202888906002045                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :793
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578314
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641379
INFO:root:FL Epoch: 39 Norm Difference for worker 793 is 1.005196
INFO:root:FL Epoch: 39 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1430
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627068
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565230
INFO:root:FL Epoch: 39 Norm Difference for worker 1430 is 0.970113
INFO:root:FL Epoch: 39 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1259
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606225
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650844
INFO:root:FL Epoch: 39 Norm Difference for worker 1259 is 0.951668
INFO:root:FL Epoch: 39 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :83
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 83 is 0.968045
INFO:root:FL Epoch: 39 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :963
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542038
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688763
INFO:root:FL Epoch: 39 Norm Difference for worker 963 is 1.083712
INFO:root:FL Epoch: 39 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :727
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667478
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662980
INFO:root:FL Epoch: 39 Norm Difference for worker 727 is 1.005076
INFO:root:FL Epoch: 39 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1798
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702457
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594115
INFO:root:FL Epoch: 39 Norm Difference for worker 1798 is 0.960546
INFO:root:FL Epoch: 39 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1045
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707056
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591838
INFO:root:FL Epoch: 39 Norm Difference for worker 1045 is 0.988474
INFO:root:FL Epoch: 39 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :795
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605060
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570277
INFO:root:FL Epoch: 39 Norm Difference for worker 795 is 1.026004
INFO:root:FL Epoch: 39 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495896
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592717
INFO:root:FL Epoch: 39 Norm Difference for worker 1544 is 1.026557
INFO:root:FL Epoch: 39 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 39 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 39 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6313027634340174 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:0.9385249515374502                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :1876
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659770
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554296
INFO:root:FL Epoch: 40 Norm Difference for worker 1876 is 0.914986
INFO:root:FL Epoch: 40 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1511
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751949
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586842
INFO:root:FL Epoch: 40 Norm Difference for worker 1511 is 0.839348
INFO:root:FL Epoch: 40 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1817
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670823
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407081
INFO:root:FL Epoch: 40 Norm Difference for worker 1817 is 1.019566
INFO:root:FL Epoch: 40 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :696
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706463
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611943
INFO:root:FL Epoch: 40 Norm Difference for worker 696 is 0.895187
INFO:root:FL Epoch: 40 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :514
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574537
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562617
INFO:root:FL Epoch: 40 Norm Difference for worker 514 is 0.959866
INFO:root:FL Epoch: 40 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :724
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671265
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619016
INFO:root:FL Epoch: 40 Norm Difference for worker 724 is 0.863022
INFO:root:FL Epoch: 40 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :71
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 71 is 0.858683
INFO:root:FL Epoch: 40 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1627
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743977
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544913
INFO:root:FL Epoch: 40 Norm Difference for worker 1627 is 0.900483
INFO:root:FL Epoch: 40 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1036
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668635
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657374
INFO:root:FL Epoch: 40 Norm Difference for worker 1036 is 0.886798
INFO:root:FL Epoch: 40 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1139
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743727
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490017
INFO:root:FL Epoch: 40 Norm Difference for worker 1139 is 0.887136
INFO:root:FL Epoch: 40 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.6297743127626532 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:0.8222993910312653                             and Backdoor Test Accuracy:40.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [431, 1920, 659, 855, 1679, 48, 359, 1794, 466, 1659]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :431
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533204
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553291
INFO:root:FL Epoch: 41 Norm Difference for worker 431 is 0.982068
INFO:root:FL Epoch: 41 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1920
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776813
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496817
INFO:root:FL Epoch: 41 Norm Difference for worker 1920 is 0.96055
INFO:root:FL Epoch: 41 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642588
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730596
INFO:root:FL Epoch: 41 Norm Difference for worker 659 is 0.996916
INFO:root:FL Epoch: 41 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :855
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736769
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548719
INFO:root:FL Epoch: 41 Norm Difference for worker 855 is 1.025232
INFO:root:FL Epoch: 41 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1679
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591569
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526683
INFO:root:FL Epoch: 41 Norm Difference for worker 1679 is 1.032897
INFO:root:FL Epoch: 41 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :48
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 48 is 0.978227
INFO:root:FL Epoch: 41 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :359
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637714
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673063
INFO:root:FL Epoch: 41 Norm Difference for worker 359 is 1.010342
INFO:root:FL Epoch: 41 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1794
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759929
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573543
INFO:root:FL Epoch: 41 Norm Difference for worker 1794 is 1.073005
INFO:root:FL Epoch: 41 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :466
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749712
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769274
INFO:root:FL Epoch: 41 Norm Difference for worker 466 is 0.96893
INFO:root:FL Epoch: 41 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609107
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520898
INFO:root:FL Epoch: 41 Norm Difference for worker 1659 is 1.042136
INFO:root:FL Epoch: 41 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 431
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 41 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 41 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.6236278204356923 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:0.9777872264385223                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1016
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689175
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508346
INFO:root:FL Epoch: 42 Norm Difference for worker 1016 is 1.098946
INFO:root:FL Epoch: 42 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :758
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544005
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639515
INFO:root:FL Epoch: 42 Norm Difference for worker 758 is 1.03567
INFO:root:FL Epoch: 42 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1919
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566086
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569130
INFO:root:FL Epoch: 42 Norm Difference for worker 1919 is 1.099881
INFO:root:FL Epoch: 42 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1693
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711742
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503503
INFO:root:FL Epoch: 42 Norm Difference for worker 1693 is 1.049396
INFO:root:FL Epoch: 42 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1465
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535331
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.752379
INFO:root:FL Epoch: 42 Norm Difference for worker 1465 is 1.072689
INFO:root:FL Epoch: 42 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :882
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574806
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385388
INFO:root:FL Epoch: 42 Norm Difference for worker 882 is 1.059817
INFO:root:FL Epoch: 42 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :176
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 176 is 1.073642
INFO:root:FL Epoch: 42 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1854
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612225
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553450
INFO:root:FL Epoch: 42 Norm Difference for worker 1854 is 1.116993
INFO:root:FL Epoch: 42 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :107
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 107 is 1.023558
INFO:root:FL Epoch: 42 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :77
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 77 is 1.054987
INFO:root:FL Epoch: 42 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 758
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6285897826447207 and Test Accuracy:65.0 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:1.0492537220319111                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 43 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :301
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.873872
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 301 is 1.097061
INFO:root:FL Epoch: 43 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :961
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522665
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641580
INFO:root:FL Epoch: 43 Norm Difference for worker 961 is 1.123994
INFO:root:FL Epoch: 43 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1081
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746575
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585227
INFO:root:FL Epoch: 43 Norm Difference for worker 1081 is 1.144671
INFO:root:FL Epoch: 43 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :165
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 165 is 1.060839
INFO:root:FL Epoch: 43 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1765
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611750
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.847567
INFO:root:FL Epoch: 43 Norm Difference for worker 1765 is 1.082572
INFO:root:FL Epoch: 43 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 1.091813
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :21
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 21 is 1.080998
INFO:root:FL Epoch: 43 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :425
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804675
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587517
INFO:root:FL Epoch: 43 Norm Difference for worker 425 is 1.14083
INFO:root:FL Epoch: 43 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1827
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812229
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589133
INFO:root:FL Epoch: 43 Norm Difference for worker 1827 is 1.109895
INFO:root:FL Epoch: 43 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1721
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647727
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.801012
INFO:root:FL Epoch: 43 Norm Difference for worker 1721 is 1.117727
INFO:root:FL Epoch: 43 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 301
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6245982752126806 and Test Accuracy:65.0 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.7719658513863882                             and Backdoor Test Accuracy:44.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :617
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516489
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561543
INFO:root:FL Epoch: 44 Norm Difference for worker 617 is 1.034135
INFO:root:FL Epoch: 44 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :842
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595392
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628203
INFO:root:FL Epoch: 44 Norm Difference for worker 842 is 0.900551
INFO:root:FL Epoch: 44 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :851
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725533
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622107
INFO:root:FL Epoch: 44 Norm Difference for worker 851 is 0.850151
INFO:root:FL Epoch: 44 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :604
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604500
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469879
INFO:root:FL Epoch: 44 Norm Difference for worker 604 is 1.0222
INFO:root:FL Epoch: 44 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1478
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494632
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553049
INFO:root:FL Epoch: 44 Norm Difference for worker 1478 is 0.997882
INFO:root:FL Epoch: 44 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1239
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665632
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636507
INFO:root:FL Epoch: 44 Norm Difference for worker 1239 is 0.950851
INFO:root:FL Epoch: 44 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1744
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650730
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477903
INFO:root:FL Epoch: 44 Norm Difference for worker 1744 is 0.953427
INFO:root:FL Epoch: 44 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1946
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609633
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581388
INFO:root:FL Epoch: 44 Norm Difference for worker 1946 is 0.978153
INFO:root:FL Epoch: 44 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1499
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647346
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532950
INFO:root:FL Epoch: 44 Norm Difference for worker 1499 is 0.99607
INFO:root:FL Epoch: 44 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1072
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627448
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481571
INFO:root:FL Epoch: 44 Norm Difference for worker 1072 is 0.924081
INFO:root:FL Epoch: 44 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 851
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.610612995484296 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:0.8585043450196584                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :284
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814531
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 284 is 1.049909
INFO:root:FL Epoch: 45 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :629
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676240
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566449
INFO:root:FL Epoch: 45 Norm Difference for worker 629 is 1.008646
INFO:root:FL Epoch: 45 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1483
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606275
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589504
INFO:root:FL Epoch: 45 Norm Difference for worker 1483 is 1.026726
INFO:root:FL Epoch: 45 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :496
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672421
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671239
INFO:root:FL Epoch: 45 Norm Difference for worker 496 is 0.988763
INFO:root:FL Epoch: 45 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1902
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695820
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639340
INFO:root:FL Epoch: 45 Norm Difference for worker 1902 is 0.997608
INFO:root:FL Epoch: 45 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :261
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 261 is 1.019149
INFO:root:FL Epoch: 45 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1691
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598420
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521479
INFO:root:FL Epoch: 45 Norm Difference for worker 1691 is 1.029211
INFO:root:FL Epoch: 45 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :309
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.664914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 309 is 1.031179
INFO:root:FL Epoch: 45 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :195
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647992
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 195 is 1.081722
INFO:root:FL Epoch: 45 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :346
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625009
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603709
INFO:root:FL Epoch: 45 Norm Difference for worker 346 is 1.046144
INFO:root:FL Epoch: 45 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1902
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6133072288597331 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:0.9219057063261668                             and Backdoor Test Accuracy:30.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1012
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579044
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576081
INFO:root:FL Epoch: 46 Norm Difference for worker 1012 is 0.970667
INFO:root:FL Epoch: 46 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1287
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559309
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555922
INFO:root:FL Epoch: 46 Norm Difference for worker 1287 is 1.039376
INFO:root:FL Epoch: 46 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1772
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648441
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575902
INFO:root:FL Epoch: 46 Norm Difference for worker 1772 is 1.019406
INFO:root:FL Epoch: 46 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :973
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614679
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590043
INFO:root:FL Epoch: 46 Norm Difference for worker 973 is 1.078854
INFO:root:FL Epoch: 46 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :355
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729147
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659141
INFO:root:FL Epoch: 46 Norm Difference for worker 355 is 1.026372
INFO:root:FL Epoch: 46 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :15
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 15 is 0.990849
INFO:root:FL Epoch: 46 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1335
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772788
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474145
INFO:root:FL Epoch: 46 Norm Difference for worker 1335 is 0.93525
INFO:root:FL Epoch: 46 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :859
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474164
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747370
INFO:root:FL Epoch: 46 Norm Difference for worker 859 is 0.964323
INFO:root:FL Epoch: 46 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1060
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607904
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478989
INFO:root:FL Epoch: 46 Norm Difference for worker 1060 is 1.103636
INFO:root:FL Epoch: 46 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1175
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592473
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565835
INFO:root:FL Epoch: 46 Norm Difference for worker 1175 is 1.042073
INFO:root:FL Epoch: 46 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6104219240300796 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:0.8395439883073171                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1026
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633071
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591626
INFO:root:FL Epoch: 47 Norm Difference for worker 1026 is 0.978013
INFO:root:FL Epoch: 47 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1386
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697422
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645439
INFO:root:FL Epoch: 47 Norm Difference for worker 1386 is 0.978283
INFO:root:FL Epoch: 47 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :370
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532963
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651447
INFO:root:FL Epoch: 47 Norm Difference for worker 370 is 0.983013
INFO:root:FL Epoch: 47 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1316
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573972
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640239
INFO:root:FL Epoch: 47 Norm Difference for worker 1316 is 0.895754
INFO:root:FL Epoch: 47 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1423
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584028
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436515
INFO:root:FL Epoch: 47 Norm Difference for worker 1423 is 0.986884
INFO:root:FL Epoch: 47 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1323
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670523
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544746
INFO:root:FL Epoch: 47 Norm Difference for worker 1323 is 0.980473
INFO:root:FL Epoch: 47 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1440
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531019
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614802
INFO:root:FL Epoch: 47 Norm Difference for worker 1440 is 0.963323
INFO:root:FL Epoch: 47 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :374
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542920
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579999
INFO:root:FL Epoch: 47 Norm Difference for worker 374 is 0.943646
INFO:root:FL Epoch: 47 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :641
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702216
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532036
INFO:root:FL Epoch: 47 Norm Difference for worker 641 is 0.957843
INFO:root:FL Epoch: 47 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :685
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591784
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506590
INFO:root:FL Epoch: 47 Norm Difference for worker 685 is 0.9442
INFO:root:FL Epoch: 47 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 47 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 47 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.6137103999362272 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:0.8531433939933777                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :742
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539745
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609898
INFO:root:FL Epoch: 48 Norm Difference for worker 742 is 0.912692
INFO:root:FL Epoch: 48 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :885
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669149
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687710
INFO:root:FL Epoch: 48 Norm Difference for worker 885 is 0.902736
INFO:root:FL Epoch: 48 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :169
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593279
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 169 is 0.8519
INFO:root:FL Epoch: 48 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551679
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563385
INFO:root:FL Epoch: 48 Norm Difference for worker 1527 is 0.928746
INFO:root:FL Epoch: 48 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :884
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601285
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681900
INFO:root:FL Epoch: 48 Norm Difference for worker 884 is 0.872762
INFO:root:FL Epoch: 48 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1072
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628110
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514641
INFO:root:FL Epoch: 48 Norm Difference for worker 1072 is 0.869094
INFO:root:FL Epoch: 48 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :458
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672769
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507746
INFO:root:FL Epoch: 48 Norm Difference for worker 458 is 0.882817
INFO:root:FL Epoch: 48 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1623
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620679
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613622
INFO:root:FL Epoch: 48 Norm Difference for worker 1623 is 0.884262
INFO:root:FL Epoch: 48 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1318
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678135
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617267
INFO:root:FL Epoch: 48 Norm Difference for worker 1318 is 0.892754
INFO:root:FL Epoch: 48 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1808
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555974
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482295
INFO:root:FL Epoch: 48 Norm Difference for worker 1808 is 1.002146
INFO:root:FL Epoch: 48 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 169
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.6235567524152643 and Test Accuracy:61.76470588235294 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.043555309375127                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :1089
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699128
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699124
INFO:root:FL Epoch: 49 Norm Difference for worker 1089 is 0.91826
INFO:root:FL Epoch: 49 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1220
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575351
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508539
INFO:root:FL Epoch: 49 Norm Difference for worker 1220 is 0.957483
INFO:root:FL Epoch: 49 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :832
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535596
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492711
INFO:root:FL Epoch: 49 Norm Difference for worker 832 is 0.942937
INFO:root:FL Epoch: 49 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :348
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717969
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578632
INFO:root:FL Epoch: 49 Norm Difference for worker 348 is 1.030745
INFO:root:FL Epoch: 49 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1483
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701501
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419365
INFO:root:FL Epoch: 49 Norm Difference for worker 1483 is 0.925976
INFO:root:FL Epoch: 49 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1709
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733263
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624514
INFO:root:FL Epoch: 49 Norm Difference for worker 1709 is 0.921429
INFO:root:FL Epoch: 49 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :170
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 170 is 0.966394
INFO:root:FL Epoch: 49 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557251
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744589
INFO:root:FL Epoch: 49 Norm Difference for worker 862 is 1.005129
INFO:root:FL Epoch: 49 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1619
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656057
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534644
INFO:root:FL Epoch: 49 Norm Difference for worker 1619 is 0.919778
INFO:root:FL Epoch: 49 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :52
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 52 is 1.02881
INFO:root:FL Epoch: 49 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.6088963449001312 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:0.9576325217882792                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :1159
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668866
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612412
INFO:root:FL Epoch: 50 Norm Difference for worker 1159 is 0.890566
INFO:root:FL Epoch: 50 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :973
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571795
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574601
INFO:root:FL Epoch: 50 Norm Difference for worker 973 is 0.958977
INFO:root:FL Epoch: 50 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :918
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669154
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581817
INFO:root:FL Epoch: 50 Norm Difference for worker 918 is 0.91401
INFO:root:FL Epoch: 50 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :978
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484075
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502880
INFO:root:FL Epoch: 50 Norm Difference for worker 978 is 0.989158
INFO:root:FL Epoch: 50 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1454
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781936
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575595
INFO:root:FL Epoch: 50 Norm Difference for worker 1454 is 0.946597
INFO:root:FL Epoch: 50 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1102
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595927
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570541
INFO:root:FL Epoch: 50 Norm Difference for worker 1102 is 0.967865
INFO:root:FL Epoch: 50 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :762
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611075
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601719
INFO:root:FL Epoch: 50 Norm Difference for worker 762 is 0.90538
INFO:root:FL Epoch: 50 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :302
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591622
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 302 is 0.913005
INFO:root:FL Epoch: 50 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1871
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574049
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604009
INFO:root:FL Epoch: 50 Norm Difference for worker 1871 is 0.970695
INFO:root:FL Epoch: 50 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :580
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538853
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548258
INFO:root:FL Epoch: 50 Norm Difference for worker 580 is 0.928531
INFO:root:FL Epoch: 50 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1159
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6055587179520551 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.032453139623006                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [1942, 848, 888, 1807, 655, 164, 302, 119, 1277, 1553]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :1942
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788686
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483146
INFO:root:FL Epoch: 51 Norm Difference for worker 1942 is 1.002208
INFO:root:FL Epoch: 51 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :848
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735235
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585477
INFO:root:FL Epoch: 51 Norm Difference for worker 848 is 0.99053
INFO:root:FL Epoch: 51 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :888
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583745
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514061
INFO:root:FL Epoch: 51 Norm Difference for worker 888 is 1.031507
INFO:root:FL Epoch: 51 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1807
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601490
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490541
INFO:root:FL Epoch: 51 Norm Difference for worker 1807 is 0.999277
INFO:root:FL Epoch: 51 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :655
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672205
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644377
INFO:root:FL Epoch: 51 Norm Difference for worker 655 is 0.948233
INFO:root:FL Epoch: 51 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :164
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 164 is 1.024716
INFO:root:FL Epoch: 51 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :302
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691248
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 302 is 0.945622
INFO:root:FL Epoch: 51 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :119
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 119 is 1.06659
INFO:root:FL Epoch: 51 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1277
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731969
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641042
INFO:root:FL Epoch: 51 Norm Difference for worker 1277 is 0.985106
INFO:root:FL Epoch: 51 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1553
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723147
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537511
INFO:root:FL Epoch: 51 Norm Difference for worker 1553 is 0.983295
INFO:root:FL Epoch: 51 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 655
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.5934087826925165 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:0.8191490471363068                             and Backdoor Test Accuracy:45.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :410
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570361
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605975
INFO:root:FL Epoch: 52 Norm Difference for worker 410 is 1.076701
INFO:root:FL Epoch: 52 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :710
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534339
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507407
INFO:root:FL Epoch: 52 Norm Difference for worker 710 is 1.0654
INFO:root:FL Epoch: 52 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1013
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622554
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644448
INFO:root:FL Epoch: 52 Norm Difference for worker 1013 is 1.036208
INFO:root:FL Epoch: 52 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :60
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 60 is 1.084693
INFO:root:FL Epoch: 52 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :109
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 109 is 1.077962
INFO:root:FL Epoch: 52 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1576
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588854
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579805
INFO:root:FL Epoch: 52 Norm Difference for worker 1576 is 1.084683
INFO:root:FL Epoch: 52 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :931
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520824
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478120
INFO:root:FL Epoch: 52 Norm Difference for worker 931 is 1.14761
INFO:root:FL Epoch: 52 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :407
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523769
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628926
INFO:root:FL Epoch: 52 Norm Difference for worker 407 is 1.01707
INFO:root:FL Epoch: 52 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :697
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709413
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571620
INFO:root:FL Epoch: 52 Norm Difference for worker 697 is 1.094922
INFO:root:FL Epoch: 52 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1217
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757436
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413749
INFO:root:FL Epoch: 52 Norm Difference for worker 1217 is 1.079532
INFO:root:FL Epoch: 52 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.6084787898203906 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:1.0735350251197815                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1299
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558859
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504111
INFO:root:FL Epoch: 53 Norm Difference for worker 1299 is 0.940764
INFO:root:FL Epoch: 53 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :593
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637846
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564557
INFO:root:FL Epoch: 53 Norm Difference for worker 593 is 1.013462
INFO:root:FL Epoch: 53 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1438
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682450
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597202
INFO:root:FL Epoch: 53 Norm Difference for worker 1438 is 1.021344
INFO:root:FL Epoch: 53 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1891
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530819
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600850
INFO:root:FL Epoch: 53 Norm Difference for worker 1891 is 0.991245
INFO:root:FL Epoch: 53 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1705
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474710
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372819
INFO:root:FL Epoch: 53 Norm Difference for worker 1705 is 1.008651
INFO:root:FL Epoch: 53 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1052
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765219
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505292
INFO:root:FL Epoch: 53 Norm Difference for worker 1052 is 1.020622
INFO:root:FL Epoch: 53 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1474
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683211
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643562
INFO:root:FL Epoch: 53 Norm Difference for worker 1474 is 1.050933
INFO:root:FL Epoch: 53 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :550
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606774
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732892
INFO:root:FL Epoch: 53 Norm Difference for worker 550 is 1.020484
INFO:root:FL Epoch: 53 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :475
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620374
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619297
INFO:root:FL Epoch: 53 Norm Difference for worker 475 is 1.021944
INFO:root:FL Epoch: 53 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1925
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626783
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726755
INFO:root:FL Epoch: 53 Norm Difference for worker 1925 is 1.100713
INFO:root:FL Epoch: 53 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1299
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.5956206549616421 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.1463481783866882                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 54 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :1628
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667794
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587575
INFO:root:FL Epoch: 54 Norm Difference for worker 1628 is 1.022803
INFO:root:FL Epoch: 54 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :165
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 165 is 1.023833
INFO:root:FL Epoch: 54 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :671
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625504
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590643
INFO:root:FL Epoch: 54 Norm Difference for worker 671 is 1.023596
INFO:root:FL Epoch: 54 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :216
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.766679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 216 is 1.153495
INFO:root:FL Epoch: 54 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :620
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530370
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528180
INFO:root:FL Epoch: 54 Norm Difference for worker 620 is 0.997195
INFO:root:FL Epoch: 54 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :465
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801308
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515328
INFO:root:FL Epoch: 54 Norm Difference for worker 465 is 1.047896
INFO:root:FL Epoch: 54 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :72
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592322
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 72 is 1.077613
INFO:root:FL Epoch: 54 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :559
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873978
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592644
INFO:root:FL Epoch: 54 Norm Difference for worker 559 is 0.990859
INFO:root:FL Epoch: 54 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :886
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773403
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444407
INFO:root:FL Epoch: 54 Norm Difference for worker 886 is 1.01383
INFO:root:FL Epoch: 54 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1530
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507150
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537037
INFO:root:FL Epoch: 54 Norm Difference for worker 1530 is 1.050432
INFO:root:FL Epoch: 54 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.962890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.5930433238253874 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:0.9609369039535522                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1536
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573856
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509711
INFO:root:FL Epoch: 55 Norm Difference for worker 1536 is 1.044244
INFO:root:FL Epoch: 55 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1204
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700406
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643993
INFO:root:FL Epoch: 55 Norm Difference for worker 1204 is 1.135408
INFO:root:FL Epoch: 55 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1550
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599681
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677184
INFO:root:FL Epoch: 55 Norm Difference for worker 1550 is 1.126831
INFO:root:FL Epoch: 55 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1139
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456689
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484943
INFO:root:FL Epoch: 55 Norm Difference for worker 1139 is 1.095704
INFO:root:FL Epoch: 55 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :735
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481278
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574795
INFO:root:FL Epoch: 55 Norm Difference for worker 735 is 1.073634
INFO:root:FL Epoch: 55 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1804
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598194
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656625
INFO:root:FL Epoch: 55 Norm Difference for worker 1804 is 1.063522
INFO:root:FL Epoch: 55 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1303
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570181
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412681
INFO:root:FL Epoch: 55 Norm Difference for worker 1303 is 1.109586
INFO:root:FL Epoch: 55 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :856
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545867
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549593
INFO:root:FL Epoch: 55 Norm Difference for worker 856 is 1.121306
INFO:root:FL Epoch: 55 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1587
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623542
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624516
INFO:root:FL Epoch: 55 Norm Difference for worker 1587 is 1.045315
INFO:root:FL Epoch: 55 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :124
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592056
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 124 is 1.04089
INFO:root:FL Epoch: 55 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1587
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6006695154835197 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:0.9632889032363892                             and Backdoor Test Accuracy:30.0 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 56 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :103
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631489
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 103 is 0.994688
INFO:root:FL Epoch: 56 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :47
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 47 is 1.064553
INFO:root:FL Epoch: 56 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1805
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712304
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557799
INFO:root:FL Epoch: 56 Norm Difference for worker 1805 is 1.023456
INFO:root:FL Epoch: 56 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1280
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692569
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585273
INFO:root:FL Epoch: 56 Norm Difference for worker 1280 is 0.969472
INFO:root:FL Epoch: 56 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1599
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653865
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533542
INFO:root:FL Epoch: 56 Norm Difference for worker 1599 is 0.991975
INFO:root:FL Epoch: 56 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1088
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565016
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638165
INFO:root:FL Epoch: 56 Norm Difference for worker 1088 is 0.953926
INFO:root:FL Epoch: 56 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1092
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583129
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573764
INFO:root:FL Epoch: 56 Norm Difference for worker 1092 is 1.051415
INFO:root:FL Epoch: 56 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1468
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 1.010801
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591190
INFO:root:FL Epoch: 56 Norm Difference for worker 1468 is 1.034431
INFO:root:FL Epoch: 56 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :962
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479863
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514413
INFO:root:FL Epoch: 56 Norm Difference for worker 962 is 1.032039
INFO:root:FL Epoch: 56 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1742
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564570
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477493
INFO:root:FL Epoch: 56 Norm Difference for worker 1742 is 0.978662
INFO:root:FL Epoch: 56 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.5969431821037742 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.0575917065143585                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :1087
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740103
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644541
INFO:root:FL Epoch: 57 Norm Difference for worker 1087 is 1.111286
INFO:root:FL Epoch: 57 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :51
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.783527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 51 is 1.091329
INFO:root:FL Epoch: 57 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :352
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446373
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553574
INFO:root:FL Epoch: 57 Norm Difference for worker 352 is 1.100597
INFO:root:FL Epoch: 57 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1760
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862332
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496491
INFO:root:FL Epoch: 57 Norm Difference for worker 1760 is 1.165719
INFO:root:FL Epoch: 57 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1518
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904883
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520471
INFO:root:FL Epoch: 57 Norm Difference for worker 1518 is 1.105283
INFO:root:FL Epoch: 57 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1886
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628932
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701894
INFO:root:FL Epoch: 57 Norm Difference for worker 1886 is 1.134628
INFO:root:FL Epoch: 57 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1418
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744759
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394656
INFO:root:FL Epoch: 57 Norm Difference for worker 1418 is 1.147919
INFO:root:FL Epoch: 57 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :593
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704240
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566539
INFO:root:FL Epoch: 57 Norm Difference for worker 593 is 1.120281
INFO:root:FL Epoch: 57 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :803
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.919484
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515967
INFO:root:FL Epoch: 57 Norm Difference for worker 803 is 1.158827
INFO:root:FL Epoch: 57 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1360
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602563
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465535
INFO:root:FL Epoch: 57 Norm Difference for worker 1360 is 1.103472
INFO:root:FL Epoch: 57 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1418
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6033859428237466 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:1.1731557448705037                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1472
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562111
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723950
INFO:root:FL Epoch: 58 Norm Difference for worker 1472 is 1.04872
INFO:root:FL Epoch: 58 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :142
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 142 is 1.060437
INFO:root:FL Epoch: 58 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :686
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881603
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514784
INFO:root:FL Epoch: 58 Norm Difference for worker 686 is 1.087943
INFO:root:FL Epoch: 58 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1238
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609060
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531844
INFO:root:FL Epoch: 58 Norm Difference for worker 1238 is 1.069994
INFO:root:FL Epoch: 58 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :610
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517211
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571835
INFO:root:FL Epoch: 58 Norm Difference for worker 610 is 1.08797
INFO:root:FL Epoch: 58 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :438
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611505
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640006
INFO:root:FL Epoch: 58 Norm Difference for worker 438 is 1.062498
INFO:root:FL Epoch: 58 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1853
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633102
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772018
INFO:root:FL Epoch: 58 Norm Difference for worker 1853 is 1.078103
INFO:root:FL Epoch: 58 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1371
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633759
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610967
INFO:root:FL Epoch: 58 Norm Difference for worker 1371 is 1.039518
INFO:root:FL Epoch: 58 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :839
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566551
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474810
INFO:root:FL Epoch: 58 Norm Difference for worker 839 is 1.03544
INFO:root:FL Epoch: 58 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1439
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600871
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664001
INFO:root:FL Epoch: 58 Norm Difference for worker 1439 is 1.034132
INFO:root:FL Epoch: 58 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1472
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.583664678475436 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:0.832257479429245                             and Backdoor Test Accuracy:35.0 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1354
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709283
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563287
INFO:root:FL Epoch: 59 Norm Difference for worker 1354 is 0.888657
INFO:root:FL Epoch: 59 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :228
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 228 is 1.009041
INFO:root:FL Epoch: 59 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :462
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672750
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528310
INFO:root:FL Epoch: 59 Norm Difference for worker 462 is 0.950267
INFO:root:FL Epoch: 59 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1636
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563403
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474446
INFO:root:FL Epoch: 59 Norm Difference for worker 1636 is 1.013358
INFO:root:FL Epoch: 59 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1046
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706475
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608523
INFO:root:FL Epoch: 59 Norm Difference for worker 1046 is 0.923208
INFO:root:FL Epoch: 59 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1188
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491477
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580140
INFO:root:FL Epoch: 59 Norm Difference for worker 1188 is 0.958309
INFO:root:FL Epoch: 59 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1882
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682864
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595872
INFO:root:FL Epoch: 59 Norm Difference for worker 1882 is 0.945919
INFO:root:FL Epoch: 59 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1003
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753655
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661133
INFO:root:FL Epoch: 59 Norm Difference for worker 1003 is 0.884868
INFO:root:FL Epoch: 59 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1658
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488197
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615435
INFO:root:FL Epoch: 59 Norm Difference for worker 1658 is 0.952007
INFO:root:FL Epoch: 59 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1075
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557460
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597086
INFO:root:FL Epoch: 59 Norm Difference for worker 1075 is 0.958972
INFO:root:FL Epoch: 59 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1354
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 59 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 59 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.5875541269779205 and Test Accuracy:70.0 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.026885191599528                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :160
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 160 is 0.920811
INFO:root:FL Epoch: 60 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1460
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561277
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513368
INFO:root:FL Epoch: 60 Norm Difference for worker 1460 is 0.931181
INFO:root:FL Epoch: 60 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1369
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639861
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713179
INFO:root:FL Epoch: 60 Norm Difference for worker 1369 is 0.931869
INFO:root:FL Epoch: 60 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1465
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683164
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632352
INFO:root:FL Epoch: 60 Norm Difference for worker 1465 is 0.923487
INFO:root:FL Epoch: 60 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :920
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610288
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527176
INFO:root:FL Epoch: 60 Norm Difference for worker 920 is 0.971819
INFO:root:FL Epoch: 60 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :167
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 167 is 0.938544
INFO:root:FL Epoch: 60 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :434
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628679
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492502
INFO:root:FL Epoch: 60 Norm Difference for worker 434 is 1.032583
INFO:root:FL Epoch: 60 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :908
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574962
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406965
INFO:root:FL Epoch: 60 Norm Difference for worker 908 is 0.978607
INFO:root:FL Epoch: 60 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1014
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586396
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557797
INFO:root:FL Epoch: 60 Norm Difference for worker 1014 is 0.931189
INFO:root:FL Epoch: 60 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1614
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684921
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639992
INFO:root:FL Epoch: 60 Norm Difference for worker 1614 is 0.962921
INFO:root:FL Epoch: 60 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 160
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 60 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 60 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.5867784917354584 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:0.9193277955055237                             and Backdoor Test Accuracy:30.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [1377, 126, 1194, 362, 1279, 1826, 1404, 1802, 128, 1290]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 61 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :1377
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492248
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554118
INFO:root:FL Epoch: 61 Norm Difference for worker 1377 is 0.931866
INFO:root:FL Epoch: 61 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :126
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 126 is 0.891724
INFO:root:FL Epoch: 61 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1194
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604809
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690192
INFO:root:FL Epoch: 61 Norm Difference for worker 1194 is 0.928547
INFO:root:FL Epoch: 61 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :362
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473373
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675682
INFO:root:FL Epoch: 61 Norm Difference for worker 362 is 1.001985
INFO:root:FL Epoch: 61 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1279
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554999
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560567
INFO:root:FL Epoch: 61 Norm Difference for worker 1279 is 0.916991
INFO:root:FL Epoch: 61 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1826
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599559
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405175
INFO:root:FL Epoch: 61 Norm Difference for worker 1826 is 0.975906
INFO:root:FL Epoch: 61 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1404
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538814
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593994
INFO:root:FL Epoch: 61 Norm Difference for worker 1404 is 0.916193
INFO:root:FL Epoch: 61 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1802
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607206
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479649
INFO:root:FL Epoch: 61 Norm Difference for worker 1802 is 0.90565
INFO:root:FL Epoch: 61 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :128
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 128 is 0.88086
INFO:root:FL Epoch: 61 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1290
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494058
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640982
INFO:root:FL Epoch: 61 Norm Difference for worker 1290 is 0.965799
INFO:root:FL Epoch: 61 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1404
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.6094780739615945 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.2800077597300212                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :228
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579229
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 228 is 1.133389
INFO:root:FL Epoch: 62 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :380
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667660
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626776
INFO:root:FL Epoch: 62 Norm Difference for worker 380 is 1.190389
INFO:root:FL Epoch: 62 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1593
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608170
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533071
INFO:root:FL Epoch: 62 Norm Difference for worker 1593 is 1.053286
INFO:root:FL Epoch: 62 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1340
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769359
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574020
INFO:root:FL Epoch: 62 Norm Difference for worker 1340 is 1.116725
INFO:root:FL Epoch: 62 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :838
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558396
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578010
INFO:root:FL Epoch: 62 Norm Difference for worker 838 is 1.198805
INFO:root:FL Epoch: 62 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :117
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 117 is 1.158961
INFO:root:FL Epoch: 62 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :48
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 48 is 1.092213
INFO:root:FL Epoch: 62 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :793
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617592
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526722
INFO:root:FL Epoch: 62 Norm Difference for worker 793 is 1.131354
INFO:root:FL Epoch: 62 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1118
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630410
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683067
INFO:root:FL Epoch: 62 Norm Difference for worker 1118 is 1.107821
INFO:root:FL Epoch: 62 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1657
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653245
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474146
INFO:root:FL Epoch: 62 Norm Difference for worker 1657 is 1.141853
INFO:root:FL Epoch: 62 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.6138535510091221 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.1981941262880962                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1234
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856781
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568306
INFO:root:FL Epoch: 63 Norm Difference for worker 1234 is 1.357608
INFO:root:FL Epoch: 63 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :729
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616736
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508308
INFO:root:FL Epoch: 63 Norm Difference for worker 729 is 1.177408
INFO:root:FL Epoch: 63 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :469
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429618
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371253
INFO:root:FL Epoch: 63 Norm Difference for worker 469 is 1.149117
INFO:root:FL Epoch: 63 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :846
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337284
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472825
INFO:root:FL Epoch: 63 Norm Difference for worker 846 is 1.24738
INFO:root:FL Epoch: 63 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1600
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600139
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525731
INFO:root:FL Epoch: 63 Norm Difference for worker 1600 is 1.333116
INFO:root:FL Epoch: 63 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :157
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.765036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 157 is 1.220422
INFO:root:FL Epoch: 63 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1182
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 1.001293
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574818
INFO:root:FL Epoch: 63 Norm Difference for worker 1182 is 1.158999
INFO:root:FL Epoch: 63 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1061
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548141
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423840
INFO:root:FL Epoch: 63 Norm Difference for worker 1061 is 1.265428
INFO:root:FL Epoch: 63 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1408
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517055
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519611
INFO:root:FL Epoch: 63 Norm Difference for worker 1408 is 1.206765
INFO:root:FL Epoch: 63 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :650
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449056
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555085
INFO:root:FL Epoch: 63 Norm Difference for worker 650 is 1.200983
INFO:root:FL Epoch: 63 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1182
INFO:root:Norm of Aggregated Model: 5154.96337890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.6252531847533058 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.1381744742393494                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :207
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663005
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 207 is 1.051894
INFO:root:FL Epoch: 64 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :542
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511569
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490954
INFO:root:FL Epoch: 64 Norm Difference for worker 542 is 1.04711
INFO:root:FL Epoch: 64 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1793
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686099
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428868
INFO:root:FL Epoch: 64 Norm Difference for worker 1793 is 1.04853
INFO:root:FL Epoch: 64 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1161
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441482
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493151
INFO:root:FL Epoch: 64 Norm Difference for worker 1161 is 1.092089
INFO:root:FL Epoch: 64 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1832
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705168
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692574
INFO:root:FL Epoch: 64 Norm Difference for worker 1832 is 1.093585
INFO:root:FL Epoch: 64 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1180
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583988
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522712
INFO:root:FL Epoch: 64 Norm Difference for worker 1180 is 1.045269
INFO:root:FL Epoch: 64 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1370
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831725
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488891
INFO:root:FL Epoch: 64 Norm Difference for worker 1370 is 1.034292
INFO:root:FL Epoch: 64 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :679
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589812
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589491
INFO:root:FL Epoch: 64 Norm Difference for worker 679 is 1.022888
INFO:root:FL Epoch: 64 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1235
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640430
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486005
INFO:root:FL Epoch: 64 Norm Difference for worker 1235 is 1.076706
INFO:root:FL Epoch: 64 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :562
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561091
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518217
INFO:root:FL Epoch: 64 Norm Difference for worker 562 is 1.071455
INFO:root:FL Epoch: 64 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.6175558935193455 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:1.099574327468872                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 65 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :7
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513449
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529841
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 7 is 0.987164
INFO:root:FL Epoch: 65 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :806
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818065
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581895
INFO:root:FL Epoch: 65 Norm Difference for worker 806 is 0.939115
INFO:root:FL Epoch: 65 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :172
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 172 is 0.910373
INFO:root:FL Epoch: 65 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :751
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491055
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522734
INFO:root:FL Epoch: 65 Norm Difference for worker 751 is 1.005619
INFO:root:FL Epoch: 65 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :922
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608068
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601722
INFO:root:FL Epoch: 65 Norm Difference for worker 922 is 0.99661
INFO:root:FL Epoch: 65 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1606
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725781
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512427
INFO:root:FL Epoch: 65 Norm Difference for worker 1606 is 1.009081
INFO:root:FL Epoch: 65 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :904
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518462
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501764
INFO:root:FL Epoch: 65 Norm Difference for worker 904 is 0.938138
INFO:root:FL Epoch: 65 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1023
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589237
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437798
INFO:root:FL Epoch: 65 Norm Difference for worker 1023 is 0.991502
INFO:root:FL Epoch: 65 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :451
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603616
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542737
INFO:root:FL Epoch: 65 Norm Difference for worker 451 is 0.996195
INFO:root:FL Epoch: 65 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :871
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687421
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411231
INFO:root:FL Epoch: 65 Norm Difference for worker 871 is 1.020041
INFO:root:FL Epoch: 65 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 172
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.6046477643882527 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.1035040219624836                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1824
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755283
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412476
INFO:root:FL Epoch: 66 Norm Difference for worker 1824 is 1.016136
INFO:root:FL Epoch: 66 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :776
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515996
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643553
INFO:root:FL Epoch: 66 Norm Difference for worker 776 is 1.038191
INFO:root:FL Epoch: 66 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :679
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505992
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503624
INFO:root:FL Epoch: 66 Norm Difference for worker 679 is 1.012718
INFO:root:FL Epoch: 66 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1263
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614132
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711257
INFO:root:FL Epoch: 66 Norm Difference for worker 1263 is 1.058645
INFO:root:FL Epoch: 66 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1658
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424446
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567222
INFO:root:FL Epoch: 66 Norm Difference for worker 1658 is 1.005416
INFO:root:FL Epoch: 66 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :161
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721125
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 161 is 0.938885
INFO:root:FL Epoch: 66 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :623
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541313
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644737
INFO:root:FL Epoch: 66 Norm Difference for worker 623 is 1.091178
INFO:root:FL Epoch: 66 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1308
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645022
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569994
INFO:root:FL Epoch: 66 Norm Difference for worker 1308 is 1.03214
INFO:root:FL Epoch: 66 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :248
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574759
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 248 is 0.996067
INFO:root:FL Epoch: 66 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :692
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641239
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655979
INFO:root:FL Epoch: 66 Norm Difference for worker 692 is 0.973917
INFO:root:FL Epoch: 66 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.6124547825140112 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:1.1516667008399963                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :1855
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681541
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439355
INFO:root:FL Epoch: 67 Norm Difference for worker 1855 is 1.038131
INFO:root:FL Epoch: 67 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :447
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564843
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409040
INFO:root:FL Epoch: 67 Norm Difference for worker 447 is 1.044224
INFO:root:FL Epoch: 67 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :860
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761680
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636128
INFO:root:FL Epoch: 67 Norm Difference for worker 860 is 1.116349
INFO:root:FL Epoch: 67 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685317
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514196
INFO:root:FL Epoch: 67 Norm Difference for worker 1575 is 1.043372
INFO:root:FL Epoch: 67 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :818
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498026
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551086
INFO:root:FL Epoch: 67 Norm Difference for worker 818 is 1.066759
INFO:root:FL Epoch: 67 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1745
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528545
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405081
INFO:root:FL Epoch: 67 Norm Difference for worker 1745 is 1.05549
INFO:root:FL Epoch: 67 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :201
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 201 is 1.070383
INFO:root:FL Epoch: 67 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :82
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600288
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 82 is 1.026226
INFO:root:FL Epoch: 67 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :907
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580193
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561116
INFO:root:FL Epoch: 67 Norm Difference for worker 907 is 1.096048
INFO:root:FL Epoch: 67 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1068
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685615
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517271
INFO:root:FL Epoch: 67 Norm Difference for worker 1068 is 1.050011
INFO:root:FL Epoch: 67 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.6205737801159129 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.3289885520935059                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1385
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640954
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521442
INFO:root:FL Epoch: 68 Norm Difference for worker 1385 is 0.968463
INFO:root:FL Epoch: 68 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1108
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771925
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551844
INFO:root:FL Epoch: 68 Norm Difference for worker 1108 is 0.984881
INFO:root:FL Epoch: 68 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1575
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501214
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548785
INFO:root:FL Epoch: 68 Norm Difference for worker 1575 is 1.031219
INFO:root:FL Epoch: 68 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :567
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547092
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413037
INFO:root:FL Epoch: 68 Norm Difference for worker 567 is 1.006202
INFO:root:FL Epoch: 68 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1334
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656254
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456634
INFO:root:FL Epoch: 68 Norm Difference for worker 1334 is 1.032119
INFO:root:FL Epoch: 68 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :186
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 186 is 1.032527
INFO:root:FL Epoch: 68 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :589
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564803
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676060
INFO:root:FL Epoch: 68 Norm Difference for worker 589 is 0.935674
INFO:root:FL Epoch: 68 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :861
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643238
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559610
INFO:root:FL Epoch: 68 Norm Difference for worker 861 is 1.025182
INFO:root:FL Epoch: 68 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :249
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 249 is 1.053181
INFO:root:FL Epoch: 68 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :363
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514350
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604120
INFO:root:FL Epoch: 68 Norm Difference for worker 363 is 1.039988
INFO:root:FL Epoch: 68 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 567
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5849494390627917 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.3579597075780232                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :1792
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550612
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553681
INFO:root:FL Epoch: 69 Norm Difference for worker 1792 is 1.098267
INFO:root:FL Epoch: 69 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1931
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726166
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426198
INFO:root:FL Epoch: 69 Norm Difference for worker 1931 is 1.155713
INFO:root:FL Epoch: 69 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1446
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655088
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385568
INFO:root:FL Epoch: 69 Norm Difference for worker 1446 is 1.169982
INFO:root:FL Epoch: 69 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1658
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422531
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553509
INFO:root:FL Epoch: 69 Norm Difference for worker 1658 is 1.149785
INFO:root:FL Epoch: 69 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1501
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543178
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474171
INFO:root:FL Epoch: 69 Norm Difference for worker 1501 is 1.218563
INFO:root:FL Epoch: 69 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :633
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677597
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499678
INFO:root:FL Epoch: 69 Norm Difference for worker 633 is 1.146738
INFO:root:FL Epoch: 69 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :191
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444724
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686678
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 191 is 1.259272
INFO:root:FL Epoch: 69 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :365
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474887
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343459
INFO:root:FL Epoch: 69 Norm Difference for worker 365 is 1.214225
INFO:root:FL Epoch: 69 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :539
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878692
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538248
INFO:root:FL Epoch: 69 Norm Difference for worker 539 is 1.243187
INFO:root:FL Epoch: 69 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1151
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532079
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529796
INFO:root:FL Epoch: 69 Norm Difference for worker 1151 is 1.150424
INFO:root:FL Epoch: 69 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1931
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5821303322034723 and Test Accuracy:70.0 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.251898507277171                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1947
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527252
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509987
INFO:root:FL Epoch: 70 Norm Difference for worker 1947 is 1.072974
INFO:root:FL Epoch: 70 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :708
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501932
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564067
INFO:root:FL Epoch: 70 Norm Difference for worker 708 is 1.101692
INFO:root:FL Epoch: 70 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1032
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514741
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542007
INFO:root:FL Epoch: 70 Norm Difference for worker 1032 is 1.140709
INFO:root:FL Epoch: 70 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1835
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360291
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457483
INFO:root:FL Epoch: 70 Norm Difference for worker 1835 is 1.153079
INFO:root:FL Epoch: 70 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1097
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744105
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470466
INFO:root:FL Epoch: 70 Norm Difference for worker 1097 is 1.092703
INFO:root:FL Epoch: 70 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1636
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682812
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550126
INFO:root:FL Epoch: 70 Norm Difference for worker 1636 is 1.174935
INFO:root:FL Epoch: 70 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :104
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.996182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.662090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 104 is 1.104363
INFO:root:FL Epoch: 70 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1018
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583236
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575167
INFO:root:FL Epoch: 70 Norm Difference for worker 1018 is 1.159339
INFO:root:FL Epoch: 70 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :783
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541046
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677097
INFO:root:FL Epoch: 70 Norm Difference for worker 783 is 1.189951
INFO:root:FL Epoch: 70 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1165
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393231
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660277
INFO:root:FL Epoch: 70 Norm Difference for worker 1165 is 1.218172
INFO:root:FL Epoch: 70 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 104
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.6015237376970404 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.165725330511729                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [62, 1637, 492, 467, 439, 1788, 1531, 1101, 1372, 1289]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :62
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653067
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 62 is 0.997943
INFO:root:FL Epoch: 71 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1637
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621561
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755871
INFO:root:FL Epoch: 71 Norm Difference for worker 1637 is 0.903561
INFO:root:FL Epoch: 71 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :492
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624840
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551883
INFO:root:FL Epoch: 71 Norm Difference for worker 492 is 0.975237
INFO:root:FL Epoch: 71 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :467
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583761
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646860
INFO:root:FL Epoch: 71 Norm Difference for worker 467 is 0.957696
INFO:root:FL Epoch: 71 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :439
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520035
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467948
INFO:root:FL Epoch: 71 Norm Difference for worker 439 is 0.983288
INFO:root:FL Epoch: 71 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1788
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640734
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512998
INFO:root:FL Epoch: 71 Norm Difference for worker 1788 is 0.997444
INFO:root:FL Epoch: 71 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1531
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590826
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645580
INFO:root:FL Epoch: 71 Norm Difference for worker 1531 is 0.999727
INFO:root:FL Epoch: 71 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1101
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706807
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508412
INFO:root:FL Epoch: 71 Norm Difference for worker 1101 is 0.900466
INFO:root:FL Epoch: 71 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1372
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564517
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481218
INFO:root:FL Epoch: 71 Norm Difference for worker 1372 is 0.983987
INFO:root:FL Epoch: 71 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1289
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584072
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477444
INFO:root:FL Epoch: 71 Norm Difference for worker 1289 is 0.921369
INFO:root:FL Epoch: 71 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.6017202103839201 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.0152596135934193                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1808
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605087
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583964
INFO:root:FL Epoch: 72 Norm Difference for worker 1808 is 1.032331
INFO:root:FL Epoch: 72 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :988
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599128
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471321
INFO:root:FL Epoch: 72 Norm Difference for worker 988 is 0.987215
INFO:root:FL Epoch: 72 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1871
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567583
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724967
INFO:root:FL Epoch: 72 Norm Difference for worker 1871 is 0.982342
INFO:root:FL Epoch: 72 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :246
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673130
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 246 is 0.970774
INFO:root:FL Epoch: 72 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :578
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598960
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482635
INFO:root:FL Epoch: 72 Norm Difference for worker 578 is 0.923656
INFO:root:FL Epoch: 72 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1167
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567327
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449724
INFO:root:FL Epoch: 72 Norm Difference for worker 1167 is 1.001157
INFO:root:FL Epoch: 72 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1905
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640051
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549001
INFO:root:FL Epoch: 72 Norm Difference for worker 1905 is 0.9409
INFO:root:FL Epoch: 72 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :161
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 161 is 1.027752
INFO:root:FL Epoch: 72 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :115
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 115 is 0.976282
INFO:root:FL Epoch: 72 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :918
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570113
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636414
INFO:root:FL Epoch: 72 Norm Difference for worker 918 is 1.016379
INFO:root:FL Epoch: 72 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5900472788249745 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:1.056948979695638                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 73 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1190
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665599
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701369
INFO:root:FL Epoch: 73 Norm Difference for worker 1190 is 1.002245
INFO:root:FL Epoch: 73 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :534
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706430
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582294
INFO:root:FL Epoch: 73 Norm Difference for worker 534 is 1.066013
INFO:root:FL Epoch: 73 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1482
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637743
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637816
INFO:root:FL Epoch: 73 Norm Difference for worker 1482 is 0.958222
INFO:root:FL Epoch: 73 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :854
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644065
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473808
INFO:root:FL Epoch: 73 Norm Difference for worker 854 is 1.088809
INFO:root:FL Epoch: 73 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1711
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510818
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749990
INFO:root:FL Epoch: 73 Norm Difference for worker 1711 is 1.079781
INFO:root:FL Epoch: 73 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :834
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669918
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554112
INFO:root:FL Epoch: 73 Norm Difference for worker 834 is 1.009758
INFO:root:FL Epoch: 73 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :816
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579873
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638364
INFO:root:FL Epoch: 73 Norm Difference for worker 816 is 1.073593
INFO:root:FL Epoch: 73 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1421
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479911
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504571
INFO:root:FL Epoch: 73 Norm Difference for worker 1421 is 1.065582
INFO:root:FL Epoch: 73 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1353
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489556
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419747
INFO:root:FL Epoch: 73 Norm Difference for worker 1353 is 1.040267
INFO:root:FL Epoch: 73 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :991
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566337
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629601
INFO:root:FL Epoch: 73 Norm Difference for worker 991 is 1.017544
INFO:root:FL Epoch: 73 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.5950342574540306 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:1.250770390033722                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :906
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526589
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607169
INFO:root:FL Epoch: 74 Norm Difference for worker 906 is 1.029994
INFO:root:FL Epoch: 74 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :572
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752198
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692128
INFO:root:FL Epoch: 74 Norm Difference for worker 572 is 1.00878
INFO:root:FL Epoch: 74 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1804
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782023
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542967
INFO:root:FL Epoch: 74 Norm Difference for worker 1804 is 0.93607
INFO:root:FL Epoch: 74 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :98
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.664997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 98 is 0.973033
INFO:root:FL Epoch: 74 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1645
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643039
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557196
INFO:root:FL Epoch: 74 Norm Difference for worker 1645 is 0.990821
INFO:root:FL Epoch: 74 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :583
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491536
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534584
INFO:root:FL Epoch: 74 Norm Difference for worker 583 is 0.987483
INFO:root:FL Epoch: 74 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :100
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 100 is 0.953991
INFO:root:FL Epoch: 74 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1709
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729430
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577183
INFO:root:FL Epoch: 74 Norm Difference for worker 1709 is 0.988738
INFO:root:FL Epoch: 74 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :278
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 278 is 0.962754
INFO:root:FL Epoch: 74 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :942
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762891
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655744
INFO:root:FL Epoch: 74 Norm Difference for worker 942 is 0.943417
INFO:root:FL Epoch: 74 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1804
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.5928618855336133 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.1932765642801921                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :978
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532417
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620980
INFO:root:FL Epoch: 75 Norm Difference for worker 978 is 0.970063
INFO:root:FL Epoch: 75 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :410
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560578
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495511
INFO:root:FL Epoch: 75 Norm Difference for worker 410 is 0.983673
INFO:root:FL Epoch: 75 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :848
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581012
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626813
INFO:root:FL Epoch: 75 Norm Difference for worker 848 is 0.942297
INFO:root:FL Epoch: 75 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1023
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675059
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515121
INFO:root:FL Epoch: 75 Norm Difference for worker 1023 is 0.916306
INFO:root:FL Epoch: 75 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :197
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 197 is 0.897362
INFO:root:FL Epoch: 75 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1535
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626606
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450966
INFO:root:FL Epoch: 75 Norm Difference for worker 1535 is 0.982558
INFO:root:FL Epoch: 75 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :786
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648951
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602578
INFO:root:FL Epoch: 75 Norm Difference for worker 786 is 0.890926
INFO:root:FL Epoch: 75 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1486
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577016
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571878
INFO:root:FL Epoch: 75 Norm Difference for worker 1486 is 0.96912
INFO:root:FL Epoch: 75 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1128
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640099
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529189
INFO:root:FL Epoch: 75 Norm Difference for worker 1128 is 0.955304
INFO:root:FL Epoch: 75 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1761
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578883
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588129
INFO:root:FL Epoch: 75 Norm Difference for worker 1761 is 0.964203
INFO:root:FL Epoch: 75 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.575077531968846 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:1.1798851291338603                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 76 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1548
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661058
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605673
INFO:root:FL Epoch: 76 Norm Difference for worker 1548 is 1.046491
INFO:root:FL Epoch: 76 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1417
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658409
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592912
INFO:root:FL Epoch: 76 Norm Difference for worker 1417 is 0.997107
INFO:root:FL Epoch: 76 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :840
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673638
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525555
INFO:root:FL Epoch: 76 Norm Difference for worker 840 is 1.031549
INFO:root:FL Epoch: 76 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :570
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628468
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632853
INFO:root:FL Epoch: 76 Norm Difference for worker 570 is 0.949568
INFO:root:FL Epoch: 76 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1300
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574912
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566774
INFO:root:FL Epoch: 76 Norm Difference for worker 1300 is 1.031596
INFO:root:FL Epoch: 76 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1440
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532785
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628344
INFO:root:FL Epoch: 76 Norm Difference for worker 1440 is 1.046487
INFO:root:FL Epoch: 76 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :716
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471140
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431775
INFO:root:FL Epoch: 76 Norm Difference for worker 716 is 1.017832
INFO:root:FL Epoch: 76 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1434
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744609
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485069
INFO:root:FL Epoch: 76 Norm Difference for worker 1434 is 1.082885
INFO:root:FL Epoch: 76 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1090
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516190
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740149
INFO:root:FL Epoch: 76 Norm Difference for worker 1090 is 1.037079
INFO:root:FL Epoch: 76 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :170
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 170 is 1.019423
INFO:root:FL Epoch: 76 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 76 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 76 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.560050755739212 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.304881493250529                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :975
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566556
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506381
INFO:root:FL Epoch: 77 Norm Difference for worker 975 is 1.223999
INFO:root:FL Epoch: 77 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :926
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547236
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631688
INFO:root:FL Epoch: 77 Norm Difference for worker 926 is 1.118224
INFO:root:FL Epoch: 77 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480899
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501473
INFO:root:FL Epoch: 77 Norm Difference for worker 1128 is 1.104914
INFO:root:FL Epoch: 77 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 303 is 1.103217
INFO:root:FL Epoch: 77 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1274
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708612
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591859
INFO:root:FL Epoch: 77 Norm Difference for worker 1274 is 1.158564
INFO:root:FL Epoch: 77 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :483
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678582
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675970
INFO:root:FL Epoch: 77 Norm Difference for worker 483 is 1.129494
INFO:root:FL Epoch: 77 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :944
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557091
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609722
INFO:root:FL Epoch: 77 Norm Difference for worker 944 is 1.10598
INFO:root:FL Epoch: 77 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :904
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773278
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435558
INFO:root:FL Epoch: 77 Norm Difference for worker 904 is 1.026077
INFO:root:FL Epoch: 77 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :394
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748694
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559200
INFO:root:FL Epoch: 77 Norm Difference for worker 394 is 1.168267
INFO:root:FL Epoch: 77 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1282
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445345
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570703
INFO:root:FL Epoch: 77 Norm Difference for worker 1282 is 1.18048
INFO:root:FL Epoch: 77 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 904
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 77 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 77 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5732906530885136 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.2584894895553589                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :1205
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703331
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567674
INFO:root:FL Epoch: 78 Norm Difference for worker 1205 is 1.124609
INFO:root:FL Epoch: 78 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :886
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519625
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613182
INFO:root:FL Epoch: 78 Norm Difference for worker 886 is 1.130002
INFO:root:FL Epoch: 78 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :835
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518700
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402066
INFO:root:FL Epoch: 78 Norm Difference for worker 835 is 1.113898
INFO:root:FL Epoch: 78 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1830
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589023
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520226
INFO:root:FL Epoch: 78 Norm Difference for worker 1830 is 1.134901
INFO:root:FL Epoch: 78 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :482
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424701
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.754845
INFO:root:FL Epoch: 78 Norm Difference for worker 482 is 1.130183
INFO:root:FL Epoch: 78 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1179
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620420
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520240
INFO:root:FL Epoch: 78 Norm Difference for worker 1179 is 1.10063
INFO:root:FL Epoch: 78 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1312
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589817
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589377
INFO:root:FL Epoch: 78 Norm Difference for worker 1312 is 1.123735
INFO:root:FL Epoch: 78 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1592
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714425
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632455
INFO:root:FL Epoch: 78 Norm Difference for worker 1592 is 1.155296
INFO:root:FL Epoch: 78 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :45
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.916012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597916
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 45 is 1.149063
INFO:root:FL Epoch: 78 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1934
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878428
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487860
INFO:root:FL Epoch: 78 Norm Difference for worker 1934 is 1.165044
INFO:root:FL Epoch: 78 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1179
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.5732240852187661 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.2962849140167236                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1712
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598143
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698265
INFO:root:FL Epoch: 79 Norm Difference for worker 1712 is 1.083652
INFO:root:FL Epoch: 79 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :194
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.841008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 194 is 1.087658
INFO:root:FL Epoch: 79 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :814
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641866
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532003
INFO:root:FL Epoch: 79 Norm Difference for worker 814 is 1.155042
INFO:root:FL Epoch: 79 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :277
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.828224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 277 is 1.108719
INFO:root:FL Epoch: 79 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1810
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597776
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527994
INFO:root:FL Epoch: 79 Norm Difference for worker 1810 is 1.121156
INFO:root:FL Epoch: 79 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :235
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 235 is 1.203101
INFO:root:FL Epoch: 79 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :487
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644994
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528263
INFO:root:FL Epoch: 79 Norm Difference for worker 487 is 1.099405
INFO:root:FL Epoch: 79 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1274
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871857
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515654
INFO:root:FL Epoch: 79 Norm Difference for worker 1274 is 1.111286
INFO:root:FL Epoch: 79 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :998
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680914
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604253
INFO:root:FL Epoch: 79 Norm Difference for worker 998 is 1.090481
INFO:root:FL Epoch: 79 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1460
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728374
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543410
INFO:root:FL Epoch: 79 Norm Difference for worker 1460 is 1.149536
INFO:root:FL Epoch: 79 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 277
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.5678763722672182 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.2432420055071514                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 80 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :951
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614711
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560882
INFO:root:FL Epoch: 80 Norm Difference for worker 951 is 1.043967
INFO:root:FL Epoch: 80 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :196
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 196 is 1.072028
INFO:root:FL Epoch: 80 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :695
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656371
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416234
INFO:root:FL Epoch: 80 Norm Difference for worker 695 is 1.041524
INFO:root:FL Epoch: 80 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1847
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602013
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557394
INFO:root:FL Epoch: 80 Norm Difference for worker 1847 is 1.005344
INFO:root:FL Epoch: 80 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1670
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599157
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609445
INFO:root:FL Epoch: 80 Norm Difference for worker 1670 is 1.092621
INFO:root:FL Epoch: 80 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1872
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693947
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454468
INFO:root:FL Epoch: 80 Norm Difference for worker 1872 is 1.119936
INFO:root:FL Epoch: 80 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628346
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529237
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.037679
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :564
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717908
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493221
INFO:root:FL Epoch: 80 Norm Difference for worker 564 is 1.060269
INFO:root:FL Epoch: 80 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :683
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546538
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457152
INFO:root:FL Epoch: 80 Norm Difference for worker 683 is 1.083851
INFO:root:FL Epoch: 80 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :33
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 33 is 1.023204
INFO:root:FL Epoch: 80 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 33
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5788466299281401 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:1.5404506921768188                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1552, 722, 895, 1912, 1905, 370, 1295, 616, 579, 1867]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1552
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603658
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503508
INFO:root:FL Epoch: 81 Norm Difference for worker 1552 is 1.091337
INFO:root:FL Epoch: 81 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :722
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673229
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548367
INFO:root:FL Epoch: 81 Norm Difference for worker 722 is 1.123204
INFO:root:FL Epoch: 81 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :895
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589175
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597386
INFO:root:FL Epoch: 81 Norm Difference for worker 895 is 1.09988
INFO:root:FL Epoch: 81 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1912
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684250
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596127
INFO:root:FL Epoch: 81 Norm Difference for worker 1912 is 1.069074
INFO:root:FL Epoch: 81 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1905
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640203
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309347
INFO:root:FL Epoch: 81 Norm Difference for worker 1905 is 1.057128
INFO:root:FL Epoch: 81 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :370
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736670
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518351
INFO:root:FL Epoch: 81 Norm Difference for worker 370 is 1.007195
INFO:root:FL Epoch: 81 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1295
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609281
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457640
INFO:root:FL Epoch: 81 Norm Difference for worker 1295 is 1.095917
INFO:root:FL Epoch: 81 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :616
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545128
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693945
INFO:root:FL Epoch: 81 Norm Difference for worker 616 is 1.081043
INFO:root:FL Epoch: 81 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :579
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650055
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566508
INFO:root:FL Epoch: 81 Norm Difference for worker 579 is 1.124842
INFO:root:FL Epoch: 81 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1867
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520672
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554912
INFO:root:FL Epoch: 81 Norm Difference for worker 1867 is 1.103592
INFO:root:FL Epoch: 81 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 370
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5838547927491805 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.4641833106676738                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1016
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661627
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501261
INFO:root:FL Epoch: 82 Norm Difference for worker 1016 is 1.09234
INFO:root:FL Epoch: 82 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1907
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672201
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514747
INFO:root:FL Epoch: 82 Norm Difference for worker 1907 is 1.094697
INFO:root:FL Epoch: 82 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :171
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584411
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595828
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 171 is 1.099874
INFO:root:FL Epoch: 82 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :180
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 180 is 1.156484
INFO:root:FL Epoch: 82 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1447
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563987
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482466
INFO:root:FL Epoch: 82 Norm Difference for worker 1447 is 1.040634
INFO:root:FL Epoch: 82 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :316
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528209
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 316 is 1.080034
INFO:root:FL Epoch: 82 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1107
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632258
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492369
INFO:root:FL Epoch: 82 Norm Difference for worker 1107 is 1.113136
INFO:root:FL Epoch: 82 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :451
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604887
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413092
INFO:root:FL Epoch: 82 Norm Difference for worker 451 is 1.097149
INFO:root:FL Epoch: 82 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1246
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635552
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739203
INFO:root:FL Epoch: 82 Norm Difference for worker 1246 is 1.14015
INFO:root:FL Epoch: 82 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :792
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611234
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499470
INFO:root:FL Epoch: 82 Norm Difference for worker 792 is 1.045164
INFO:root:FL Epoch: 82 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 792
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.6030357409926022 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.5307402610778809                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1537
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602229
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560674
INFO:root:FL Epoch: 83 Norm Difference for worker 1537 is 1.257674
INFO:root:FL Epoch: 83 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :890
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466317
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535782
INFO:root:FL Epoch: 83 Norm Difference for worker 890 is 1.208766
INFO:root:FL Epoch: 83 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1098
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670068
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618155
INFO:root:FL Epoch: 83 Norm Difference for worker 1098 is 1.180538
INFO:root:FL Epoch: 83 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :872
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715707
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584470
INFO:root:FL Epoch: 83 Norm Difference for worker 872 is 1.24973
INFO:root:FL Epoch: 83 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1229
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656495
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699698
INFO:root:FL Epoch: 83 Norm Difference for worker 1229 is 1.167857
INFO:root:FL Epoch: 83 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :169
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596722
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 169 is 1.157156
INFO:root:FL Epoch: 83 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1490
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617330
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473521
INFO:root:FL Epoch: 83 Norm Difference for worker 1490 is 1.116841
INFO:root:FL Epoch: 83 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :659
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600878
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595504
INFO:root:FL Epoch: 83 Norm Difference for worker 659 is 1.193017
INFO:root:FL Epoch: 83 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :81
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.850556
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.793400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 81 is 1.240217
INFO:root:FL Epoch: 83 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :873
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728738
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553408
INFO:root:FL Epoch: 83 Norm Difference for worker 873 is 1.132266
INFO:root:FL Epoch: 83 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1490
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.6148771293023053 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.5257265170415242                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1878
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559464
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538969
INFO:root:FL Epoch: 84 Norm Difference for worker 1878 is 1.277271
INFO:root:FL Epoch: 84 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1224
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741681
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493660
INFO:root:FL Epoch: 84 Norm Difference for worker 1224 is 1.148805
INFO:root:FL Epoch: 84 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :132
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 132 is 1.209438
INFO:root:FL Epoch: 84 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :198
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 198 is 1.139593
INFO:root:FL Epoch: 84 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :140
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 140 is 1.220137
INFO:root:FL Epoch: 84 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :649
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673790
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385688
INFO:root:FL Epoch: 84 Norm Difference for worker 649 is 1.300143
INFO:root:FL Epoch: 84 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :436
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806293
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632897
INFO:root:FL Epoch: 84 Norm Difference for worker 436 is 1.265142
INFO:root:FL Epoch: 84 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :86
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 86 is 1.218995
INFO:root:FL Epoch: 84 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1238
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638257
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445077
INFO:root:FL Epoch: 84 Norm Difference for worker 1238 is 1.185689
INFO:root:FL Epoch: 84 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1616
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690913
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415450
INFO:root:FL Epoch: 84 Norm Difference for worker 1616 is 1.186035
INFO:root:FL Epoch: 84 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1224
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5979036338189069 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:1.2879438400268555                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :376
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760156
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512099
INFO:root:FL Epoch: 85 Norm Difference for worker 376 is 0.910162
INFO:root:FL Epoch: 85 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :587
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646461
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619468
INFO:root:FL Epoch: 85 Norm Difference for worker 587 is 0.902643
INFO:root:FL Epoch: 85 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1674
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574384
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536793
INFO:root:FL Epoch: 85 Norm Difference for worker 1674 is 0.959597
INFO:root:FL Epoch: 85 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1650
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827361
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725804
INFO:root:FL Epoch: 85 Norm Difference for worker 1650 is 0.92192
INFO:root:FL Epoch: 85 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1395
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642274
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563749
INFO:root:FL Epoch: 85 Norm Difference for worker 1395 is 0.899874
INFO:root:FL Epoch: 85 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :747
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618972
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594435
INFO:root:FL Epoch: 85 Norm Difference for worker 747 is 0.914989
INFO:root:FL Epoch: 85 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :841
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614038
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646281
INFO:root:FL Epoch: 85 Norm Difference for worker 841 is 0.94177
INFO:root:FL Epoch: 85 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1713
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480819
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488927
INFO:root:FL Epoch: 85 Norm Difference for worker 1713 is 0.958968
INFO:root:FL Epoch: 85 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :586
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543664
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551083
INFO:root:FL Epoch: 85 Norm Difference for worker 586 is 0.909575
INFO:root:FL Epoch: 85 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :76
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516620
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 76 is 0.936481
INFO:root:FL Epoch: 85 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 376
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5685731014784645 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:1.2733176747957866                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1588
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440345
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423363
INFO:root:FL Epoch: 86 Norm Difference for worker 1588 is 1.072777
INFO:root:FL Epoch: 86 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :653
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581696
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583723
INFO:root:FL Epoch: 86 Norm Difference for worker 653 is 1.06338
INFO:root:FL Epoch: 86 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1926
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731987
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486612
INFO:root:FL Epoch: 86 Norm Difference for worker 1926 is 1.067242
INFO:root:FL Epoch: 86 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1027
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631943
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485899
INFO:root:FL Epoch: 86 Norm Difference for worker 1027 is 1.125155
INFO:root:FL Epoch: 86 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :529
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601338
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473148
INFO:root:FL Epoch: 86 Norm Difference for worker 529 is 1.102514
INFO:root:FL Epoch: 86 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1929
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502573
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627014
INFO:root:FL Epoch: 86 Norm Difference for worker 1929 is 1.146099
INFO:root:FL Epoch: 86 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :184
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 184 is 1.079695
INFO:root:FL Epoch: 86 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1709
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691503
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597380
INFO:root:FL Epoch: 86 Norm Difference for worker 1709 is 1.091796
INFO:root:FL Epoch: 86 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :74
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470600
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 74 is 1.08039
INFO:root:FL Epoch: 86 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1001
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363844
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533573
INFO:root:FL Epoch: 86 Norm Difference for worker 1001 is 0.994312
INFO:root:FL Epoch: 86 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1001
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5722400177927578 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:1.155303955078125                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1919
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650562
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533459
INFO:root:FL Epoch: 87 Norm Difference for worker 1919 is 1.104141
INFO:root:FL Epoch: 87 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :211
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458222
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.634030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 211 is 1.064707
INFO:root:FL Epoch: 87 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :692
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470604
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.751645
INFO:root:FL Epoch: 87 Norm Difference for worker 692 is 1.060503
INFO:root:FL Epoch: 87 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :756
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521020
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582803
INFO:root:FL Epoch: 87 Norm Difference for worker 756 is 1.093551
INFO:root:FL Epoch: 87 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :452
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498846
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542137
INFO:root:FL Epoch: 87 Norm Difference for worker 452 is 1.087634
INFO:root:FL Epoch: 87 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1940
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569032
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578234
INFO:root:FL Epoch: 87 Norm Difference for worker 1940 is 1.024694
INFO:root:FL Epoch: 87 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1274
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535753
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693043
INFO:root:FL Epoch: 87 Norm Difference for worker 1274 is 1.099058
INFO:root:FL Epoch: 87 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :505
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718147
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636218
INFO:root:FL Epoch: 87 Norm Difference for worker 505 is 1.107058
INFO:root:FL Epoch: 87 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1090
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663129
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428037
INFO:root:FL Epoch: 87 Norm Difference for worker 1090 is 1.11975
INFO:root:FL Epoch: 87 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :674
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764524
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602497
INFO:root:FL Epoch: 87 Norm Difference for worker 674 is 1.075954
INFO:root:FL Epoch: 87 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1940
INFO:root:Norm of Aggregated Model: 5154.9638671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5803546362063464 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.2150123516718547                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :754
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715049
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622597
INFO:root:FL Epoch: 88 Norm Difference for worker 754 is 1.102227
INFO:root:FL Epoch: 88 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1867
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495389
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405778
INFO:root:FL Epoch: 88 Norm Difference for worker 1867 is 1.07733
INFO:root:FL Epoch: 88 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1196
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515465
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555124
INFO:root:FL Epoch: 88 Norm Difference for worker 1196 is 1.170211
INFO:root:FL Epoch: 88 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1355
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535099
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592456
INFO:root:FL Epoch: 88 Norm Difference for worker 1355 is 1.120167
INFO:root:FL Epoch: 88 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1912
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509221
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467381
INFO:root:FL Epoch: 88 Norm Difference for worker 1912 is 1.11536
INFO:root:FL Epoch: 88 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1919
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.866667
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575097
INFO:root:FL Epoch: 88 Norm Difference for worker 1919 is 1.104751
INFO:root:FL Epoch: 88 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1518
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539462
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518958
INFO:root:FL Epoch: 88 Norm Difference for worker 1518 is 1.129967
INFO:root:FL Epoch: 88 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :818
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606091
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583693
INFO:root:FL Epoch: 88 Norm Difference for worker 818 is 1.085871
INFO:root:FL Epoch: 88 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1600
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456055
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763024
INFO:root:FL Epoch: 88 Norm Difference for worker 1600 is 1.201101
INFO:root:FL Epoch: 88 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1594
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559512
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599941
INFO:root:FL Epoch: 88 Norm Difference for worker 1594 is 1.074869
INFO:root:FL Epoch: 88 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 818
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5799403593820684 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.3037700653076172                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 89 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1856
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557007
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461911
INFO:root:FL Epoch: 89 Norm Difference for worker 1856 is 1.122322
INFO:root:FL Epoch: 89 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :476
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474361
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519511
INFO:root:FL Epoch: 89 Norm Difference for worker 476 is 0.997737
INFO:root:FL Epoch: 89 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :191
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 191 is 1.053483
INFO:root:FL Epoch: 89 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :401
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596142
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557660
INFO:root:FL Epoch: 89 Norm Difference for worker 401 is 1.05137
INFO:root:FL Epoch: 89 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :350
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708173
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458645
INFO:root:FL Epoch: 89 Norm Difference for worker 350 is 1.02815
INFO:root:FL Epoch: 89 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :34
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 34 is 1.009315
INFO:root:FL Epoch: 89 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :742
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564764
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391015
INFO:root:FL Epoch: 89 Norm Difference for worker 742 is 1.091071
INFO:root:FL Epoch: 89 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1521
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572313
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648121
INFO:root:FL Epoch: 89 Norm Difference for worker 1521 is 1.045163
INFO:root:FL Epoch: 89 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1275
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637834
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535650
INFO:root:FL Epoch: 89 Norm Difference for worker 1275 is 0.998901
INFO:root:FL Epoch: 89 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :107
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.809272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.676003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 107 is 1.000662
INFO:root:FL Epoch: 89 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 476
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.5865425520083484 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.3761275211970012                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1193
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728604
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415878
INFO:root:FL Epoch: 90 Norm Difference for worker 1193 is 1.249757
INFO:root:FL Epoch: 90 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :930
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542673
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473161
INFO:root:FL Epoch: 90 Norm Difference for worker 930 is 1.085345
INFO:root:FL Epoch: 90 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1680
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532895
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562890
INFO:root:FL Epoch: 90 Norm Difference for worker 1680 is 1.116974
INFO:root:FL Epoch: 90 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1543
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550144
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422103
INFO:root:FL Epoch: 90 Norm Difference for worker 1543 is 1.161292
INFO:root:FL Epoch: 90 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :25
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 25 is 1.091823
INFO:root:FL Epoch: 90 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1115
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497703
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428763
INFO:root:FL Epoch: 90 Norm Difference for worker 1115 is 1.109784
INFO:root:FL Epoch: 90 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1856
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812230
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496123
INFO:root:FL Epoch: 90 Norm Difference for worker 1856 is 1.144479
INFO:root:FL Epoch: 90 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :687
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747862
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543746
INFO:root:FL Epoch: 90 Norm Difference for worker 687 is 1.180135
INFO:root:FL Epoch: 90 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :24
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641412
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 24 is 1.264291
INFO:root:FL Epoch: 90 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :850
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674763
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525805
INFO:root:FL Epoch: 90 Norm Difference for worker 850 is 1.159182
INFO:root:FL Epoch: 90 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1115
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5851410837734446 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.269984285036723                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [623, 1591, 1404, 853, 1441, 944, 1326, 1243, 1153, 1122]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 91 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :623
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762252
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565056
INFO:root:FL Epoch: 91 Norm Difference for worker 623 is 1.119272
INFO:root:FL Epoch: 91 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1591
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565460
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439517
INFO:root:FL Epoch: 91 Norm Difference for worker 1591 is 1.101178
INFO:root:FL Epoch: 91 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1404
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502345
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623509
INFO:root:FL Epoch: 91 Norm Difference for worker 1404 is 1.102463
INFO:root:FL Epoch: 91 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :853
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510018
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506156
INFO:root:FL Epoch: 91 Norm Difference for worker 853 is 1.086643
INFO:root:FL Epoch: 91 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1441
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524646
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409663
INFO:root:FL Epoch: 91 Norm Difference for worker 1441 is 1.127892
INFO:root:FL Epoch: 91 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :944
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595827
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599334
INFO:root:FL Epoch: 91 Norm Difference for worker 944 is 1.087013
INFO:root:FL Epoch: 91 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1326
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760021
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480611
INFO:root:FL Epoch: 91 Norm Difference for worker 1326 is 1.088655
INFO:root:FL Epoch: 91 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1243
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649358
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494336
INFO:root:FL Epoch: 91 Norm Difference for worker 1243 is 1.180666
INFO:root:FL Epoch: 91 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1153
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485063
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523888
INFO:root:FL Epoch: 91 Norm Difference for worker 1153 is 1.107031
INFO:root:FL Epoch: 91 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1122
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549717
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458274
INFO:root:FL Epoch: 91 Norm Difference for worker 1122 is 1.053083
INFO:root:FL Epoch: 91 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 944
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.5944822360487545 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:1.3478845556577046                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :845
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467750
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547906
INFO:root:FL Epoch: 92 Norm Difference for worker 845 is 1.130614
INFO:root:FL Epoch: 92 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1139
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581837
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667020
INFO:root:FL Epoch: 92 Norm Difference for worker 1139 is 1.087286
INFO:root:FL Epoch: 92 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :844
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594027
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641125
INFO:root:FL Epoch: 92 Norm Difference for worker 844 is 1.062274
INFO:root:FL Epoch: 92 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :540
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544318
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599001
INFO:root:FL Epoch: 92 Norm Difference for worker 540 is 1.096331
INFO:root:FL Epoch: 92 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :872
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675994
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606933
INFO:root:FL Epoch: 92 Norm Difference for worker 872 is 1.105804
INFO:root:FL Epoch: 92 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1177
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527781
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518488
INFO:root:FL Epoch: 92 Norm Difference for worker 1177 is 1.131606
INFO:root:FL Epoch: 92 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1685
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731731
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453518
INFO:root:FL Epoch: 92 Norm Difference for worker 1685 is 1.061993
INFO:root:FL Epoch: 92 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445095
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 175 is 1.101474
INFO:root:FL Epoch: 92 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :376
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644711
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496791
INFO:root:FL Epoch: 92 Norm Difference for worker 376 is 1.045401
INFO:root:FL Epoch: 92 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1367
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693072
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463587
INFO:root:FL Epoch: 92 Norm Difference for worker 1367 is 1.186123
INFO:root:FL Epoch: 92 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 376
INFO:root:Norm of Aggregated Model: 5154.96435546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.5742651154013241 and Test Accuracy:70.0 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:1.3073729077974956                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 93 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :48
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 48 is 1.327521
INFO:root:FL Epoch: 93 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :872
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614144
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434452
INFO:root:FL Epoch: 93 Norm Difference for worker 872 is 1.272666
INFO:root:FL Epoch: 93 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1196
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585283
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502444
INFO:root:FL Epoch: 93 Norm Difference for worker 1196 is 1.283723
INFO:root:FL Epoch: 93 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1390
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550985
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399741
INFO:root:FL Epoch: 93 Norm Difference for worker 1390 is 1.363942
INFO:root:FL Epoch: 93 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1195
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615110
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667931
INFO:root:FL Epoch: 93 Norm Difference for worker 1195 is 1.38028
INFO:root:FL Epoch: 93 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :341
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681155
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666797
INFO:root:FL Epoch: 93 Norm Difference for worker 341 is 1.27064
INFO:root:FL Epoch: 93 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :279
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472711
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658334
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 279 is 1.251786
INFO:root:FL Epoch: 93 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :241
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.728508
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 241 is 1.348653
INFO:root:FL Epoch: 93 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1160
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715940
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575343
INFO:root:FL Epoch: 93 Norm Difference for worker 1160 is 1.249674
INFO:root:FL Epoch: 93 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1421
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425364
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555222
INFO:root:FL Epoch: 93 Norm Difference for worker 1421 is 1.238852
INFO:root:FL Epoch: 93 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1160
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.5700976778479183 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:1.2988612055778503                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1770
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649316
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398554
INFO:root:FL Epoch: 94 Norm Difference for worker 1770 is 1.154646
INFO:root:FL Epoch: 94 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :149
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 149 is 1.128811
INFO:root:FL Epoch: 94 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1939
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606190
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533421
INFO:root:FL Epoch: 94 Norm Difference for worker 1939 is 1.166815
INFO:root:FL Epoch: 94 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1250
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600521
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435162
INFO:root:FL Epoch: 94 Norm Difference for worker 1250 is 1.117844
INFO:root:FL Epoch: 94 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :809
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639795
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518055
INFO:root:FL Epoch: 94 Norm Difference for worker 809 is 1.101781
INFO:root:FL Epoch: 94 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :301
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 301 is 1.23287
INFO:root:FL Epoch: 94 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :636
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587799
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571517
INFO:root:FL Epoch: 94 Norm Difference for worker 636 is 1.215783
INFO:root:FL Epoch: 94 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1925
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459523
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532395
INFO:root:FL Epoch: 94 Norm Difference for worker 1925 is 1.155051
INFO:root:FL Epoch: 94 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :125
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429440
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 125 is 1.121113
INFO:root:FL Epoch: 94 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1537
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853761
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659209
INFO:root:FL Epoch: 94 Norm Difference for worker 1537 is 1.233777
INFO:root:FL Epoch: 94 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 125
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.5802696715382969 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.2796105742454529                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :1495
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518897
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.800735
INFO:root:FL Epoch: 95 Norm Difference for worker 1495 is 1.249951
INFO:root:FL Epoch: 95 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1264
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497119
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481396
INFO:root:FL Epoch: 95 Norm Difference for worker 1264 is 1.245693
INFO:root:FL Epoch: 95 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :469
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470758
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450419
INFO:root:FL Epoch: 95 Norm Difference for worker 469 is 1.184813
INFO:root:FL Epoch: 95 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1275
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481850
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330339
INFO:root:FL Epoch: 95 Norm Difference for worker 1275 is 1.170264
INFO:root:FL Epoch: 95 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :734
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494127
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486487
INFO:root:FL Epoch: 95 Norm Difference for worker 734 is 1.17398
INFO:root:FL Epoch: 95 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1533
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582098
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575036
INFO:root:FL Epoch: 95 Norm Difference for worker 1533 is 1.224965
INFO:root:FL Epoch: 95 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1555
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686220
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544314
INFO:root:FL Epoch: 95 Norm Difference for worker 1555 is 1.245952
INFO:root:FL Epoch: 95 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :94
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650621
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 94 is 1.24468
INFO:root:FL Epoch: 95 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :311
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 311 is 1.194526
INFO:root:FL Epoch: 95 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :243
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 243 is 1.141842
INFO:root:FL Epoch: 95 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 243
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.5980495407300837 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.4373758633931477                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788452
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483493
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 1.155896
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1172
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582520
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588010
INFO:root:FL Epoch: 96 Norm Difference for worker 1172 is 1.182269
INFO:root:FL Epoch: 96 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :440
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431552
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348671
INFO:root:FL Epoch: 96 Norm Difference for worker 440 is 1.065962
INFO:root:FL Epoch: 96 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :207
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.846799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 207 is 1.133672
INFO:root:FL Epoch: 96 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :205
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.822796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 205 is 1.179639
INFO:root:FL Epoch: 96 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :542
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570876
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503590
INFO:root:FL Epoch: 96 Norm Difference for worker 542 is 1.142751
INFO:root:FL Epoch: 96 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1428
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523759
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546001
INFO:root:FL Epoch: 96 Norm Difference for worker 1428 is 1.147675
INFO:root:FL Epoch: 96 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1348
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615193
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638261
INFO:root:FL Epoch: 96 Norm Difference for worker 1348 is 1.081096
INFO:root:FL Epoch: 96 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1135
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777495
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508323
INFO:root:FL Epoch: 96 Norm Difference for worker 1135 is 1.13587
INFO:root:FL Epoch: 96 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :308
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 308 is 1.121077
INFO:root:FL Epoch: 96 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1348
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.580613523721695 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.4966034889221191                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 97 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :848
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578224
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609846
INFO:root:FL Epoch: 97 Norm Difference for worker 848 is 1.209682
INFO:root:FL Epoch: 97 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :769
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665035
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648630
INFO:root:FL Epoch: 97 Norm Difference for worker 769 is 1.164116
INFO:root:FL Epoch: 97 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :627
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351306
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432576
INFO:root:FL Epoch: 97 Norm Difference for worker 627 is 1.18768
INFO:root:FL Epoch: 97 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :413
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454966
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568641
INFO:root:FL Epoch: 97 Norm Difference for worker 413 is 1.229529
INFO:root:FL Epoch: 97 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1061
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859602
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486021
INFO:root:FL Epoch: 97 Norm Difference for worker 1061 is 1.148179
INFO:root:FL Epoch: 97 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1302
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593561
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450099
INFO:root:FL Epoch: 97 Norm Difference for worker 1302 is 1.188624
INFO:root:FL Epoch: 97 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1445
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657025
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558890
INFO:root:FL Epoch: 97 Norm Difference for worker 1445 is 1.184547
INFO:root:FL Epoch: 97 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :973
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559107
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353482
INFO:root:FL Epoch: 97 Norm Difference for worker 973 is 1.232627
INFO:root:FL Epoch: 97 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :110
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 110 is 1.137163
INFO:root:FL Epoch: 97 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :15
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497324
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 15 is 1.161638
INFO:root:FL Epoch: 97 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5701193581609165 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:1.6375048557917278                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 98 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :633
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621626
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600406
INFO:root:FL Epoch: 98 Norm Difference for worker 633 is 1.095397
INFO:root:FL Epoch: 98 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :77
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601160
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 77 is 1.093775
INFO:root:FL Epoch: 98 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1548
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 1.077602
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571605
INFO:root:FL Epoch: 98 Norm Difference for worker 1548 is 1.093713
INFO:root:FL Epoch: 98 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :734
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839884
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537024
INFO:root:FL Epoch: 98 Norm Difference for worker 734 is 1.057687
INFO:root:FL Epoch: 98 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1609
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396979
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506901
INFO:root:FL Epoch: 98 Norm Difference for worker 1609 is 1.165657
INFO:root:FL Epoch: 98 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1375
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872220
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468173
INFO:root:FL Epoch: 98 Norm Difference for worker 1375 is 1.120613
INFO:root:FL Epoch: 98 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1209
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535070
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574125
INFO:root:FL Epoch: 98 Norm Difference for worker 1209 is 1.066755
INFO:root:FL Epoch: 98 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1751
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676757
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524953
INFO:root:FL Epoch: 98 Norm Difference for worker 1751 is 1.142408
INFO:root:FL Epoch: 98 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1773
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568018
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615149
INFO:root:FL Epoch: 98 Norm Difference for worker 1773 is 1.151866
INFO:root:FL Epoch: 98 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1238
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521930
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497824
INFO:root:FL Epoch: 98 Norm Difference for worker 1238 is 1.132569
INFO:root:FL Epoch: 98 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 734
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.585981993114247 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.2828283111254375                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 99 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1854
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659276
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405104
INFO:root:FL Epoch: 99 Norm Difference for worker 1854 is 1.104616
INFO:root:FL Epoch: 99 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1767
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401063
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694220
INFO:root:FL Epoch: 99 Norm Difference for worker 1767 is 1.081501
INFO:root:FL Epoch: 99 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1325
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803840
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606709
INFO:root:FL Epoch: 99 Norm Difference for worker 1325 is 1.12034
INFO:root:FL Epoch: 99 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :857
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706446
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617529
INFO:root:FL Epoch: 99 Norm Difference for worker 857 is 1.097354
INFO:root:FL Epoch: 99 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :918
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802594
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371469
INFO:root:FL Epoch: 99 Norm Difference for worker 918 is 1.065844
INFO:root:FL Epoch: 99 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :86
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 86 is 1.103427
INFO:root:FL Epoch: 99 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :420
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695521
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563578
INFO:root:FL Epoch: 99 Norm Difference for worker 420 is 1.07392
INFO:root:FL Epoch: 99 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :564
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647385
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454330
INFO:root:FL Epoch: 99 Norm Difference for worker 564 is 1.111922
INFO:root:FL Epoch: 99 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :958
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491660
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620534
INFO:root:FL Epoch: 99 Norm Difference for worker 958 is 1.088072
INFO:root:FL Epoch: 99 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :800
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565685
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744041
INFO:root:FL Epoch: 99 Norm Difference for worker 800 is 1.127862
INFO:root:FL Epoch: 99 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1767
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.5862184920731712 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.4109071890513103                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1823
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436967
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664869
INFO:root:FL Epoch: 100 Norm Difference for worker 1823 is 1.166087
INFO:root:FL Epoch: 100 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1049
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425946
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500592
INFO:root:FL Epoch: 100 Norm Difference for worker 1049 is 0.98565
INFO:root:FL Epoch: 100 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1864
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678136
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436408
INFO:root:FL Epoch: 100 Norm Difference for worker 1864 is 1.065876
INFO:root:FL Epoch: 100 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1066
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714194
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561583
INFO:root:FL Epoch: 100 Norm Difference for worker 1066 is 1.134497
INFO:root:FL Epoch: 100 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1740
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516976
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630083
INFO:root:FL Epoch: 100 Norm Difference for worker 1740 is 1.050845
INFO:root:FL Epoch: 100 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1716
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520995
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513842
INFO:root:FL Epoch: 100 Norm Difference for worker 1716 is 1.099624
INFO:root:FL Epoch: 100 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :840
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553589
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431123
INFO:root:FL Epoch: 100 Norm Difference for worker 840 is 1.057702
INFO:root:FL Epoch: 100 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :11
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 11 is 1.06397
INFO:root:FL Epoch: 100 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1887
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423468
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643585
INFO:root:FL Epoch: 100 Norm Difference for worker 1887 is 1.054385
INFO:root:FL Epoch: 100 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :845
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678467
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480086
INFO:root:FL Epoch: 100 Norm Difference for worker 845 is 1.116418
INFO:root:FL Epoch: 100 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 100 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saved Checkpoint at this epoch.
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.587871674229117 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:1.4413862824440002                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.050291
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675420
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.5689328958590826 Backdoor Test Accuracy: 71.66666666666667
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.5965117067098618 Backdoor Train Accuracy: 69.5
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.568981
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833345
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643742
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.5736647347609202 Backdoor Test Accuracy: 71.66666666666667
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.6017496049404144 Backdoor Train Accuracy: 68.0
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 0.556283
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.939994
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633217
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.5270208915074667 Backdoor Test Accuracy: 74.16666666666667
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.6024307042360306 Backdoor Train Accuracy: 68.5
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 0.576183
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544143
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406624
INFO:root:FL Epoch: 101 Norm Difference for worker 1526 is 1.140759
INFO:root:FL Epoch: 101 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1322
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616427
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565545
INFO:root:FL Epoch: 101 Norm Difference for worker 1322 is 1.238929
INFO:root:FL Epoch: 101 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :862
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649949
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465464
INFO:root:FL Epoch: 101 Norm Difference for worker 862 is 1.293167
INFO:root:FL Epoch: 101 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :701
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626609
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581229
INFO:root:FL Epoch: 101 Norm Difference for worker 701 is 1.178272
INFO:root:FL Epoch: 101 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1726
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523744
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610399
INFO:root:FL Epoch: 101 Norm Difference for worker 1726 is 1.187568
INFO:root:FL Epoch: 101 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704223
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544925
INFO:root:FL Epoch: 101 Norm Difference for worker 526 is 1.182017
INFO:root:FL Epoch: 101 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1267
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625258
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508516
INFO:root:FL Epoch: 101 Norm Difference for worker 1267 is 1.125602
INFO:root:FL Epoch: 101 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.6378520394072813 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.5736647347609202                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1911
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716872
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510790
INFO:root:FL Epoch: 102 Norm Difference for worker 1911 is 1.127493
INFO:root:FL Epoch: 102 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :427
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874986
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599911
INFO:root:FL Epoch: 102 Norm Difference for worker 427 is 1.027864
INFO:root:FL Epoch: 102 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1354
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618029
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371814
INFO:root:FL Epoch: 102 Norm Difference for worker 1354 is 1.010558
INFO:root:FL Epoch: 102 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :10
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 10 is 1.091181
INFO:root:FL Epoch: 102 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1326
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664819
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461799
INFO:root:FL Epoch: 102 Norm Difference for worker 1326 is 1.075143
INFO:root:FL Epoch: 102 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1947
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695803
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372065
INFO:root:FL Epoch: 102 Norm Difference for worker 1947 is 1.005752
INFO:root:FL Epoch: 102 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1506
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719416
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431041
INFO:root:FL Epoch: 102 Norm Difference for worker 1506 is 1.12335
INFO:root:FL Epoch: 102 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1248
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502501
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632671
INFO:root:FL Epoch: 102 Norm Difference for worker 1248 is 1.067285
INFO:root:FL Epoch: 102 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :887
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567996
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674686
INFO:root:FL Epoch: 102 Norm Difference for worker 887 is 1.160113
INFO:root:FL Epoch: 102 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1077
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620572
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547539
INFO:root:FL Epoch: 102 Norm Difference for worker 1077 is 1.029822
INFO:root:FL Epoch: 102 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 427
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5875511800541597 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.9645825823148092                             and Backdoor Test Accuracy:26.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1424
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584940
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480827
INFO:root:FL Epoch: 103 Norm Difference for worker 1424 is 1.054991
INFO:root:FL Epoch: 103 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :869
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445356
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560122
INFO:root:FL Epoch: 103 Norm Difference for worker 869 is 1.015828
INFO:root:FL Epoch: 103 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1947
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559207
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485897
INFO:root:FL Epoch: 103 Norm Difference for worker 1947 is 0.981953
INFO:root:FL Epoch: 103 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1218
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616890
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545411
INFO:root:FL Epoch: 103 Norm Difference for worker 1218 is 0.996679
INFO:root:FL Epoch: 103 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :731
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774332
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612418
INFO:root:FL Epoch: 103 Norm Difference for worker 731 is 0.945897
INFO:root:FL Epoch: 103 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :391
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621054
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593726
INFO:root:FL Epoch: 103 Norm Difference for worker 391 is 0.920838
INFO:root:FL Epoch: 103 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1873
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470979
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419348
INFO:root:FL Epoch: 103 Norm Difference for worker 1873 is 1.061335
INFO:root:FL Epoch: 103 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :163
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489025
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 163 is 0.916992
INFO:root:FL Epoch: 103 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1175
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580715
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689169
INFO:root:FL Epoch: 103 Norm Difference for worker 1175 is 0.972895
INFO:root:FL Epoch: 103 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1457
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374543
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650841
INFO:root:FL Epoch: 103 Norm Difference for worker 1457 is 1.027998
INFO:root:FL Epoch: 103 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 163
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.5777981877326965 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:1.0386942128340404                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :612
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592920
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739397
INFO:root:FL Epoch: 104 Norm Difference for worker 612 is 0.997913
INFO:root:FL Epoch: 104 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1157
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799426
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710724
INFO:root:FL Epoch: 104 Norm Difference for worker 1157 is 0.991776
INFO:root:FL Epoch: 104 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1471
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477040
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667507
INFO:root:FL Epoch: 104 Norm Difference for worker 1471 is 0.993337
INFO:root:FL Epoch: 104 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :128
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658076
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 128 is 0.990773
INFO:root:FL Epoch: 104 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :66
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753757
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 66 is 0.9783
INFO:root:FL Epoch: 104 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :879
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506436
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593432
INFO:root:FL Epoch: 104 Norm Difference for worker 879 is 0.951075
INFO:root:FL Epoch: 104 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1042
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532131
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461686
INFO:root:FL Epoch: 104 Norm Difference for worker 1042 is 1.012811
INFO:root:FL Epoch: 104 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1632
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552768
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528831
INFO:root:FL Epoch: 104 Norm Difference for worker 1632 is 1.010609
INFO:root:FL Epoch: 104 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :150
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595587
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.660784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 150 is 1.019548
INFO:root:FL Epoch: 104 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1712
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669592
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677671
INFO:root:FL Epoch: 104 Norm Difference for worker 1712 is 0.979557
INFO:root:FL Epoch: 104 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 879
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5844302492983201 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:0.9785897036393484                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1124
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791177
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484861
INFO:root:FL Epoch: 105 Norm Difference for worker 1124 is 0.935478
INFO:root:FL Epoch: 105 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :766
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626430
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601849
INFO:root:FL Epoch: 105 Norm Difference for worker 766 is 1.001723
INFO:root:FL Epoch: 105 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :284
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 284 is 0.99695
INFO:root:FL Epoch: 105 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1589
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605721
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607693
INFO:root:FL Epoch: 105 Norm Difference for worker 1589 is 1.013789
INFO:root:FL Epoch: 105 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1409
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471102
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710340
INFO:root:FL Epoch: 105 Norm Difference for worker 1409 is 0.933982
INFO:root:FL Epoch: 105 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1883
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660793
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687283
INFO:root:FL Epoch: 105 Norm Difference for worker 1883 is 0.876296
INFO:root:FL Epoch: 105 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :833
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627175
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575500
INFO:root:FL Epoch: 105 Norm Difference for worker 833 is 0.908519
INFO:root:FL Epoch: 105 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1441
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389051
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603692
INFO:root:FL Epoch: 105 Norm Difference for worker 1441 is 0.962656
INFO:root:FL Epoch: 105 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :847
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617323
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530297
INFO:root:FL Epoch: 105 Norm Difference for worker 847 is 0.930105
INFO:root:FL Epoch: 105 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1423
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432725
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554874
INFO:root:FL Epoch: 105 Norm Difference for worker 1423 is 0.980568
INFO:root:FL Epoch: 105 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1883
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5951482513371635 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:0.9523942073186239                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :534
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765509
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633611
INFO:root:FL Epoch: 106 Norm Difference for worker 534 is 0.974324
INFO:root:FL Epoch: 106 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :186
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 186 is 0.991877
INFO:root:FL Epoch: 106 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :452
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670293
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389917
INFO:root:FL Epoch: 106 Norm Difference for worker 452 is 0.967006
INFO:root:FL Epoch: 106 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :985
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500648
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439289
INFO:root:FL Epoch: 106 Norm Difference for worker 985 is 1.045325
INFO:root:FL Epoch: 106 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1302
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606938
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497694
INFO:root:FL Epoch: 106 Norm Difference for worker 1302 is 0.993802
INFO:root:FL Epoch: 106 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1826
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607684
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558226
INFO:root:FL Epoch: 106 Norm Difference for worker 1826 is 1.026319
INFO:root:FL Epoch: 106 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :274
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669510
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 274 is 0.973409
INFO:root:FL Epoch: 106 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1833
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493536
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473181
INFO:root:FL Epoch: 106 Norm Difference for worker 1833 is 0.959573
INFO:root:FL Epoch: 106 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :626
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538976
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525830
INFO:root:FL Epoch: 106 Norm Difference for worker 626 is 0.96985
INFO:root:FL Epoch: 106 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412723
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437289
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.061564
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 452
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5775884249631096 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.1048232118288677                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1731
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822218
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555236
INFO:root:FL Epoch: 107 Norm Difference for worker 1731 is 1.006323
INFO:root:FL Epoch: 107 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1909
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536943
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534043
INFO:root:FL Epoch: 107 Norm Difference for worker 1909 is 1.109874
INFO:root:FL Epoch: 107 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1927
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663422
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517018
INFO:root:FL Epoch: 107 Norm Difference for worker 1927 is 1.093949
INFO:root:FL Epoch: 107 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1664
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702478
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478598
INFO:root:FL Epoch: 107 Norm Difference for worker 1664 is 1.074273
INFO:root:FL Epoch: 107 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :392
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495789
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544941
INFO:root:FL Epoch: 107 Norm Difference for worker 392 is 1.066727
INFO:root:FL Epoch: 107 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :575
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631512
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627553
INFO:root:FL Epoch: 107 Norm Difference for worker 575 is 1.090956
INFO:root:FL Epoch: 107 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1365
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472193
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442417
INFO:root:FL Epoch: 107 Norm Difference for worker 1365 is 1.114144
INFO:root:FL Epoch: 107 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :308
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449565
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 308 is 1.069416
INFO:root:FL Epoch: 107 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1329
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636718
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519095
INFO:root:FL Epoch: 107 Norm Difference for worker 1329 is 1.026901
INFO:root:FL Epoch: 107 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :142
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 142 is 1.046726
INFO:root:FL Epoch: 107 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.96484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.580553659621407 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.179822603861491                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 108 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :65
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 65 is 1.064501
INFO:root:FL Epoch: 108 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :163
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 163 is 1.017141
INFO:root:FL Epoch: 108 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :504
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665361
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473751
INFO:root:FL Epoch: 108 Norm Difference for worker 504 is 1.035235
INFO:root:FL Epoch: 108 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :120
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395353
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 120 is 1.133559
INFO:root:FL Epoch: 108 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1859
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802449
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656727
INFO:root:FL Epoch: 108 Norm Difference for worker 1859 is 1.077422
INFO:root:FL Epoch: 108 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1651
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488315
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471170
INFO:root:FL Epoch: 108 Norm Difference for worker 1651 is 1.130765
INFO:root:FL Epoch: 108 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1272
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656374
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473130
INFO:root:FL Epoch: 108 Norm Difference for worker 1272 is 1.068997
INFO:root:FL Epoch: 108 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :595
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629506
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522425
INFO:root:FL Epoch: 108 Norm Difference for worker 595 is 1.100394
INFO:root:FL Epoch: 108 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :487
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645011
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523120
INFO:root:FL Epoch: 108 Norm Difference for worker 487 is 1.068049
INFO:root:FL Epoch: 108 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1181
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556908
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454654
INFO:root:FL Epoch: 108 Norm Difference for worker 1181 is 1.092317
INFO:root:FL Epoch: 108 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 504
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.5753061771392822 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:0.8723286092281342                             and Backdoor Test Accuracy:40.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :659
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593637
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491384
INFO:root:FL Epoch: 109 Norm Difference for worker 659 is 1.078345
INFO:root:FL Epoch: 109 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1630
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665550
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532883
INFO:root:FL Epoch: 109 Norm Difference for worker 1630 is 1.091409
INFO:root:FL Epoch: 109 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :147
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522750
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 147 is 1.020864
INFO:root:FL Epoch: 109 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1704
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607179
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631873
INFO:root:FL Epoch: 109 Norm Difference for worker 1704 is 1.120745
INFO:root:FL Epoch: 109 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1338
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712821
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684237
INFO:root:FL Epoch: 109 Norm Difference for worker 1338 is 1.006743
INFO:root:FL Epoch: 109 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :376
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388813
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552323
INFO:root:FL Epoch: 109 Norm Difference for worker 376 is 1.012814
INFO:root:FL Epoch: 109 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :790
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620269
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677813
INFO:root:FL Epoch: 109 Norm Difference for worker 790 is 1.037957
INFO:root:FL Epoch: 109 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1004
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673968
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483809
INFO:root:FL Epoch: 109 Norm Difference for worker 1004 is 1.066905
INFO:root:FL Epoch: 109 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1131
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825484
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.820947
INFO:root:FL Epoch: 109 Norm Difference for worker 1131 is 1.073421
INFO:root:FL Epoch: 109 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :172
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 172 is 1.029468
INFO:root:FL Epoch: 109 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.5597250426516813 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.0737847884496052                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :191
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 191 is 0.991924
INFO:root:FL Epoch: 110 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :844
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674520
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622393
INFO:root:FL Epoch: 110 Norm Difference for worker 844 is 0.88862
INFO:root:FL Epoch: 110 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1062
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682850
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576319
INFO:root:FL Epoch: 110 Norm Difference for worker 1062 is 0.908561
INFO:root:FL Epoch: 110 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1182
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498719
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427979
INFO:root:FL Epoch: 110 Norm Difference for worker 1182 is 0.96626
INFO:root:FL Epoch: 110 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1038
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716953
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675202
INFO:root:FL Epoch: 110 Norm Difference for worker 1038 is 0.942948
INFO:root:FL Epoch: 110 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :791
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484593
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608450
INFO:root:FL Epoch: 110 Norm Difference for worker 791 is 0.95154
INFO:root:FL Epoch: 110 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1015
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502357
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455520
INFO:root:FL Epoch: 110 Norm Difference for worker 1015 is 0.920496
INFO:root:FL Epoch: 110 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :160
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.710672
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 160 is 0.96841
INFO:root:FL Epoch: 110 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :803
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566383
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384818
INFO:root:FL Epoch: 110 Norm Difference for worker 803 is 0.986552
INFO:root:FL Epoch: 110 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :902
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747047
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413094
INFO:root:FL Epoch: 110 Norm Difference for worker 902 is 0.967034
INFO:root:FL Epoch: 110 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.5630112342974719 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.1643269658088684                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731730
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492899
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.5253695547580719 Backdoor Test Accuracy: 78.33333333333333
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.5429856151342392 Backdoor Train Accuracy: 71.5
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.451784
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716649
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619086
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.5113514711459478 Backdoor Test Accuracy: 78.33333333333333
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.544000118970871 Backdoor Train Accuracy: 71.5
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 0.456597
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660436
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581722
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.5179914931456248 Backdoor Test Accuracy: 78.33333333333333
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.5423520296812058 Backdoor Train Accuracy: 71.0
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 0.45467
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :212
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.793513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 212 is 1.059249
INFO:root:FL Epoch: 111 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :603
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452643
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424188
INFO:root:FL Epoch: 111 Norm Difference for worker 603 is 1.066463
INFO:root:FL Epoch: 111 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1485
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669319
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476098
INFO:root:FL Epoch: 111 Norm Difference for worker 1485 is 1.015074
INFO:root:FL Epoch: 111 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1334
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698355
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521482
INFO:root:FL Epoch: 111 Norm Difference for worker 1334 is 1.05281
INFO:root:FL Epoch: 111 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :260
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.708297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 260 is 0.995745
INFO:root:FL Epoch: 111 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1352
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562364
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466418
INFO:root:FL Epoch: 111 Norm Difference for worker 1352 is 1.049927
INFO:root:FL Epoch: 111 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1619
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509514
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449733
INFO:root:FL Epoch: 111 Norm Difference for worker 1619 is 0.998502
INFO:root:FL Epoch: 111 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.6057544245439417 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.5253695547580719                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 112 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :254
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 254 is 0.927062
INFO:root:FL Epoch: 112 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :253
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 253 is 0.922895
INFO:root:FL Epoch: 112 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :267
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 267 is 1.022754
INFO:root:FL Epoch: 112 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1281
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576553
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456020
INFO:root:FL Epoch: 112 Norm Difference for worker 1281 is 1.042583
INFO:root:FL Epoch: 112 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :552
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627661
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658154
INFO:root:FL Epoch: 112 Norm Difference for worker 552 is 0.937201
INFO:root:FL Epoch: 112 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1889
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659310
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580121
INFO:root:FL Epoch: 112 Norm Difference for worker 1889 is 1.038802
INFO:root:FL Epoch: 112 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1555
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602749
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611449
INFO:root:FL Epoch: 112 Norm Difference for worker 1555 is 1.008535
INFO:root:FL Epoch: 112 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1475
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657731
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618259
INFO:root:FL Epoch: 112 Norm Difference for worker 1475 is 1.003817
INFO:root:FL Epoch: 112 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :334
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 334 is 0.987206
INFO:root:FL Epoch: 112 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :202
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 202 is 1.023484
INFO:root:FL Epoch: 112 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 253
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.5706451938432806 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.8536919057369232                             and Backdoor Test Accuracy:39.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 113 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :173
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 173 is 1.125543
INFO:root:FL Epoch: 113 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1677
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439688
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447888
INFO:root:FL Epoch: 113 Norm Difference for worker 1677 is 1.034692
INFO:root:FL Epoch: 113 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1063
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651979
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414352
INFO:root:FL Epoch: 113 Norm Difference for worker 1063 is 1.086428
INFO:root:FL Epoch: 113 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :828
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534353
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656874
INFO:root:FL Epoch: 113 Norm Difference for worker 828 is 1.173171
INFO:root:FL Epoch: 113 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1243
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633973
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546524
INFO:root:FL Epoch: 113 Norm Difference for worker 1243 is 1.036885
INFO:root:FL Epoch: 113 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1645
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709812
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494171
INFO:root:FL Epoch: 113 Norm Difference for worker 1645 is 1.031048
INFO:root:FL Epoch: 113 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :701
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481730
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623883
INFO:root:FL Epoch: 113 Norm Difference for worker 701 is 1.072444
INFO:root:FL Epoch: 113 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :511
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660645
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540162
INFO:root:FL Epoch: 113 Norm Difference for worker 511 is 1.059732
INFO:root:FL Epoch: 113 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1769
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551455
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439583
INFO:root:FL Epoch: 113 Norm Difference for worker 1769 is 0.995683
INFO:root:FL Epoch: 113 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :539
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719457
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599434
INFO:root:FL Epoch: 113 Norm Difference for worker 539 is 1.10884
INFO:root:FL Epoch: 113 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.5845723029445199 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.8848462601502737                             and Backdoor Test Accuracy:36.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1682
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572094
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744936
INFO:root:FL Epoch: 114 Norm Difference for worker 1682 is 1.006611
INFO:root:FL Epoch: 114 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :817
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659322
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579196
INFO:root:FL Epoch: 114 Norm Difference for worker 817 is 0.987911
INFO:root:FL Epoch: 114 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :747
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566193
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656586
INFO:root:FL Epoch: 114 Norm Difference for worker 747 is 0.994134
INFO:root:FL Epoch: 114 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1065
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449731
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474637
INFO:root:FL Epoch: 114 Norm Difference for worker 1065 is 0.968369
INFO:root:FL Epoch: 114 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :615
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444690
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480233
INFO:root:FL Epoch: 114 Norm Difference for worker 615 is 1.005879
INFO:root:FL Epoch: 114 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :439
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436504
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502241
INFO:root:FL Epoch: 114 Norm Difference for worker 439 is 0.957206
INFO:root:FL Epoch: 114 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :501
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599393
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492708
INFO:root:FL Epoch: 114 Norm Difference for worker 501 is 1.03296
INFO:root:FL Epoch: 114 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1941
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686124
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677160
INFO:root:FL Epoch: 114 Norm Difference for worker 1941 is 1.006102
INFO:root:FL Epoch: 114 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :729
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617133
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432429
INFO:root:FL Epoch: 114 Norm Difference for worker 729 is 1.008457
INFO:root:FL Epoch: 114 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1621
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473106
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434940
INFO:root:FL Epoch: 114 Norm Difference for worker 1621 is 0.983285
INFO:root:FL Epoch: 114 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 439
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.5653379331616795 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.9398268759250641                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1247
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451844
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666376
INFO:root:FL Epoch: 115 Norm Difference for worker 1247 is 1.075415
INFO:root:FL Epoch: 115 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1891
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534207
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476091
INFO:root:FL Epoch: 115 Norm Difference for worker 1891 is 1.115215
INFO:root:FL Epoch: 115 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1092
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624542
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664801
INFO:root:FL Epoch: 115 Norm Difference for worker 1092 is 1.103515
INFO:root:FL Epoch: 115 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1160
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592503
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585660
INFO:root:FL Epoch: 115 Norm Difference for worker 1160 is 1.110869
INFO:root:FL Epoch: 115 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1542
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564186
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437940
INFO:root:FL Epoch: 115 Norm Difference for worker 1542 is 1.088009
INFO:root:FL Epoch: 115 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687175
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638908
INFO:root:FL Epoch: 115 Norm Difference for worker 1248 is 1.093607
INFO:root:FL Epoch: 115 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1758
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755141
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574386
INFO:root:FL Epoch: 115 Norm Difference for worker 1758 is 1.043145
INFO:root:FL Epoch: 115 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :206
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.409854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 206 is 1.060276
INFO:root:FL Epoch: 115 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :881
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437196
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565936
INFO:root:FL Epoch: 115 Norm Difference for worker 881 is 1.06922
INFO:root:FL Epoch: 115 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1311
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494509
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594978
INFO:root:FL Epoch: 115 Norm Difference for worker 1311 is 1.103653
INFO:root:FL Epoch: 115 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1758
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.5982249396688798 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:1.1713846921920776                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :670
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650399
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537025
INFO:root:FL Epoch: 116 Norm Difference for worker 670 is 1.040098
INFO:root:FL Epoch: 116 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :77
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 77 is 1.038693
INFO:root:FL Epoch: 116 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :14
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.757501
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 14 is 0.984642
INFO:root:FL Epoch: 116 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :831
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595411
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559366
INFO:root:FL Epoch: 116 Norm Difference for worker 831 is 1.020179
INFO:root:FL Epoch: 116 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :557
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621402
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524351
INFO:root:FL Epoch: 116 Norm Difference for worker 557 is 0.982813
INFO:root:FL Epoch: 116 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1196
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760397
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592099
INFO:root:FL Epoch: 116 Norm Difference for worker 1196 is 1.013814
INFO:root:FL Epoch: 116 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1519
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598529
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530520
INFO:root:FL Epoch: 116 Norm Difference for worker 1519 is 0.967074
INFO:root:FL Epoch: 116 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :237
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534719
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 237 is 1.041684
INFO:root:FL Epoch: 116 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1512
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596716
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582184
INFO:root:FL Epoch: 116 Norm Difference for worker 1512 is 1.08667
INFO:root:FL Epoch: 116 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :592
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494919
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464503
INFO:root:FL Epoch: 116 Norm Difference for worker 592 is 1.112007
INFO:root:FL Epoch: 116 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1519
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.5789671031867757 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.8834863901138306                             and Backdoor Test Accuracy:35.0 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 117 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :300
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 300 is 0.934602
INFO:root:FL Epoch: 117 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :251
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637459
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 251 is 0.901551
INFO:root:FL Epoch: 117 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :562
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589974
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519250
INFO:root:FL Epoch: 117 Norm Difference for worker 562 is 0.954198
INFO:root:FL Epoch: 117 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1356
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508244
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586992
INFO:root:FL Epoch: 117 Norm Difference for worker 1356 is 0.948091
INFO:root:FL Epoch: 117 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :204
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 204 is 0.954963
INFO:root:FL Epoch: 117 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :809
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619483
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492659
INFO:root:FL Epoch: 117 Norm Difference for worker 809 is 0.87385
INFO:root:FL Epoch: 117 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :968
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453457
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642316
INFO:root:FL Epoch: 117 Norm Difference for worker 968 is 0.981293
INFO:root:FL Epoch: 117 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1645
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619333
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665557
INFO:root:FL Epoch: 117 Norm Difference for worker 1645 is 0.91189
INFO:root:FL Epoch: 117 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1482
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566331
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558254
INFO:root:FL Epoch: 117 Norm Difference for worker 1482 is 0.958528
INFO:root:FL Epoch: 117 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :844
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533116
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471921
INFO:root:FL Epoch: 117 Norm Difference for worker 844 is 0.915182
INFO:root:FL Epoch: 117 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 809
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.5781225439380197 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.9373584389686584                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 118 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :191
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 191 is 0.95072
INFO:root:FL Epoch: 118 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1890
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566539
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575583
INFO:root:FL Epoch: 118 Norm Difference for worker 1890 is 0.911404
INFO:root:FL Epoch: 118 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :999
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675975
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642140
INFO:root:FL Epoch: 118 Norm Difference for worker 999 is 0.908714
INFO:root:FL Epoch: 118 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1404
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478256
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329630
INFO:root:FL Epoch: 118 Norm Difference for worker 1404 is 1.004041
INFO:root:FL Epoch: 118 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :725
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508542
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501169
INFO:root:FL Epoch: 118 Norm Difference for worker 725 is 0.912309
INFO:root:FL Epoch: 118 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1853
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515539
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573516
INFO:root:FL Epoch: 118 Norm Difference for worker 1853 is 0.928024
INFO:root:FL Epoch: 118 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1315
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544289
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659818
INFO:root:FL Epoch: 118 Norm Difference for worker 1315 is 0.974898
INFO:root:FL Epoch: 118 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1082
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545873
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652122
INFO:root:FL Epoch: 118 Norm Difference for worker 1082 is 0.903301
INFO:root:FL Epoch: 118 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :862
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665037
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698462
INFO:root:FL Epoch: 118 Norm Difference for worker 862 is 0.948964
INFO:root:FL Epoch: 118 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :84
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 84 is 0.9503
INFO:root:FL Epoch: 118 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.5748153802226571 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:1.039436678091685                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :917
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705521
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540023
INFO:root:FL Epoch: 119 Norm Difference for worker 917 is 0.902816
INFO:root:FL Epoch: 119 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :474
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603455
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561520
INFO:root:FL Epoch: 119 Norm Difference for worker 474 is 0.886197
INFO:root:FL Epoch: 119 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602201
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483472
INFO:root:FL Epoch: 119 Norm Difference for worker 748 is 0.918911
INFO:root:FL Epoch: 119 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1071
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687099
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560754
INFO:root:FL Epoch: 119 Norm Difference for worker 1071 is 0.90583
INFO:root:FL Epoch: 119 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :436
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613495
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571138
INFO:root:FL Epoch: 119 Norm Difference for worker 436 is 0.881927
INFO:root:FL Epoch: 119 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1413
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665013
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576987
INFO:root:FL Epoch: 119 Norm Difference for worker 1413 is 0.959315
INFO:root:FL Epoch: 119 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :141
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 141 is 0.929952
INFO:root:FL Epoch: 119 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :439
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498943
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477410
INFO:root:FL Epoch: 119 Norm Difference for worker 439 is 1.045287
INFO:root:FL Epoch: 119 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :281
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 281 is 0.919364
INFO:root:FL Epoch: 119 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1415
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694906
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617342
INFO:root:FL Epoch: 119 Norm Difference for worker 1415 is 0.943516
INFO:root:FL Epoch: 119 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 474
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.5706711779622471 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:1.0710592865943909                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :672
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604697
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521802
INFO:root:FL Epoch: 120 Norm Difference for worker 672 is 0.97341
INFO:root:FL Epoch: 120 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1130
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741854
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682385
INFO:root:FL Epoch: 120 Norm Difference for worker 1130 is 1.04625
INFO:root:FL Epoch: 120 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :89
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 89 is 0.989513
INFO:root:FL Epoch: 120 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :766
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385623
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468001
INFO:root:FL Epoch: 120 Norm Difference for worker 766 is 0.983805
INFO:root:FL Epoch: 120 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :604
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495277
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349490
INFO:root:FL Epoch: 120 Norm Difference for worker 604 is 1.033061
INFO:root:FL Epoch: 120 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1934
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458507
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609556
INFO:root:FL Epoch: 120 Norm Difference for worker 1934 is 0.997243
INFO:root:FL Epoch: 120 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1085
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738652
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592921
INFO:root:FL Epoch: 120 Norm Difference for worker 1085 is 0.926002
INFO:root:FL Epoch: 120 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1785
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660466
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496361
INFO:root:FL Epoch: 120 Norm Difference for worker 1785 is 0.926172
INFO:root:FL Epoch: 120 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :799
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604327
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541591
INFO:root:FL Epoch: 120 Norm Difference for worker 799 is 1.011827
INFO:root:FL Epoch: 120 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :394
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531758
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557718
INFO:root:FL Epoch: 120 Norm Difference for worker 394 is 1.032654
INFO:root:FL Epoch: 120 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1085
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.576968813643736 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:1.1400250593821208                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876183
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505370
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.4711376428604126 Backdoor Test Accuracy: 81.66666666666667
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.5079105645418167 Backdoor Train Accuracy: 76.5
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.446447
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795564
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634941
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.4402719835440318 Backdoor Test Accuracy: 83.33333333333333
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.5089158862829208 Backdoor Train Accuracy: 76.5
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 0.468565
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657231
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521874
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.43504128853480023 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.5133860737085343 Backdoor Train Accuracy: 76.0
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 0.469377
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1516
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804119
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496454
INFO:root:FL Epoch: 121 Norm Difference for worker 1516 is 1.001806
INFO:root:FL Epoch: 121 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1691
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544182
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496319
INFO:root:FL Epoch: 121 Norm Difference for worker 1691 is 1.038406
INFO:root:FL Epoch: 121 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1534
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634419
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606394
INFO:root:FL Epoch: 121 Norm Difference for worker 1534 is 1.057912
INFO:root:FL Epoch: 121 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1245
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563899
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520414
INFO:root:FL Epoch: 121 Norm Difference for worker 1245 is 1.073577
INFO:root:FL Epoch: 121 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1693
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518666
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522392
INFO:root:FL Epoch: 121 Norm Difference for worker 1693 is 1.042484
INFO:root:FL Epoch: 121 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :520
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456663
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405890
INFO:root:FL Epoch: 121 Norm Difference for worker 520 is 1.037118
INFO:root:FL Epoch: 121 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586027
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450824
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 1.051469
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.6042803262963015 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.4711376428604126                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 122 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :847
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676365
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504595
INFO:root:FL Epoch: 122 Norm Difference for worker 847 is 1.004042
INFO:root:FL Epoch: 122 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :302
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679007
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 302 is 0.989016
INFO:root:FL Epoch: 122 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1156
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723118
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716960
INFO:root:FL Epoch: 122 Norm Difference for worker 1156 is 1.022973
INFO:root:FL Epoch: 122 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1187
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384892
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629803
INFO:root:FL Epoch: 122 Norm Difference for worker 1187 is 1.018187
INFO:root:FL Epoch: 122 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :252
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554995
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 252 is 1.040887
INFO:root:FL Epoch: 122 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :460
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759600
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460018
INFO:root:FL Epoch: 122 Norm Difference for worker 460 is 1.065695
INFO:root:FL Epoch: 122 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1246
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640311
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522884
INFO:root:FL Epoch: 122 Norm Difference for worker 1246 is 0.991274
INFO:root:FL Epoch: 122 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :151
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 151 is 0.973716
INFO:root:FL Epoch: 122 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :556
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667057
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439000
INFO:root:FL Epoch: 122 Norm Difference for worker 556 is 1.071117
INFO:root:FL Epoch: 122 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1367
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674762
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527826
INFO:root:FL Epoch: 122 Norm Difference for worker 1367 is 1.101557
INFO:root:FL Epoch: 122 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 151
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.577270483269411 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.7402991553147634                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :900
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596912
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678546
INFO:root:FL Epoch: 123 Norm Difference for worker 900 is 1.018982
INFO:root:FL Epoch: 123 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :614
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548112
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495969
INFO:root:FL Epoch: 123 Norm Difference for worker 614 is 0.964218
INFO:root:FL Epoch: 123 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1916
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581209
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548587
INFO:root:FL Epoch: 123 Norm Difference for worker 1916 is 1.007857
INFO:root:FL Epoch: 123 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1149
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566531
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611740
INFO:root:FL Epoch: 123 Norm Difference for worker 1149 is 0.980576
INFO:root:FL Epoch: 123 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1225
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539896
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588876
INFO:root:FL Epoch: 123 Norm Difference for worker 1225 is 0.954405
INFO:root:FL Epoch: 123 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :315
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 315 is 0.949692
INFO:root:FL Epoch: 123 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :66
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 66 is 0.990922
INFO:root:FL Epoch: 123 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :959
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532835
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546816
INFO:root:FL Epoch: 123 Norm Difference for worker 959 is 1.004743
INFO:root:FL Epoch: 123 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :938
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633334
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827086
INFO:root:FL Epoch: 123 Norm Difference for worker 938 is 0.916722
INFO:root:FL Epoch: 123 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1349
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575623
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477429
INFO:root:FL Epoch: 123 Norm Difference for worker 1349 is 0.938233
INFO:root:FL Epoch: 123 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1349
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5944229592295254 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.732466479142507                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :1329
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424977
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378967
INFO:root:FL Epoch: 124 Norm Difference for worker 1329 is 0.991519
INFO:root:FL Epoch: 124 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1737
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500800
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478322
INFO:root:FL Epoch: 124 Norm Difference for worker 1737 is 0.984692
INFO:root:FL Epoch: 124 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :570
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436752
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468260
INFO:root:FL Epoch: 124 Norm Difference for worker 570 is 0.955179
INFO:root:FL Epoch: 124 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1802
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697855
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489947
INFO:root:FL Epoch: 124 Norm Difference for worker 1802 is 1.030964
INFO:root:FL Epoch: 124 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1438
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770030
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630943
INFO:root:FL Epoch: 124 Norm Difference for worker 1438 is 0.959614
INFO:root:FL Epoch: 124 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :725
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479452
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413323
INFO:root:FL Epoch: 124 Norm Difference for worker 725 is 0.975392
INFO:root:FL Epoch: 124 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :394
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439644
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645285
INFO:root:FL Epoch: 124 Norm Difference for worker 394 is 1.030409
INFO:root:FL Epoch: 124 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :456
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679777
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553578
INFO:root:FL Epoch: 124 Norm Difference for worker 456 is 1.013282
INFO:root:FL Epoch: 124 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1801
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488184
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472409
INFO:root:FL Epoch: 124 Norm Difference for worker 1801 is 0.973509
INFO:root:FL Epoch: 124 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1221
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655473
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658597
INFO:root:FL Epoch: 124 Norm Difference for worker 1221 is 0.984379
INFO:root:FL Epoch: 124 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.5660301832591786 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.6726965109507242                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :371
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684858
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575805
INFO:root:FL Epoch: 125 Norm Difference for worker 371 is 1.059064
INFO:root:FL Epoch: 125 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :455
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679012
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545968
INFO:root:FL Epoch: 125 Norm Difference for worker 455 is 1.159245
INFO:root:FL Epoch: 125 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :747
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734971
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595001
INFO:root:FL Epoch: 125 Norm Difference for worker 747 is 1.133545
INFO:root:FL Epoch: 125 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :106
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.757659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 106 is 1.088938
INFO:root:FL Epoch: 125 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1722
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547570
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737135
INFO:root:FL Epoch: 125 Norm Difference for worker 1722 is 1.158353
INFO:root:FL Epoch: 125 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :631
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769337
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534241
INFO:root:FL Epoch: 125 Norm Difference for worker 631 is 1.153661
INFO:root:FL Epoch: 125 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :374
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651570
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647892
INFO:root:FL Epoch: 125 Norm Difference for worker 374 is 1.120902
INFO:root:FL Epoch: 125 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1617
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738053
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455382
INFO:root:FL Epoch: 125 Norm Difference for worker 1617 is 1.058501
INFO:root:FL Epoch: 125 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :513
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758445
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585894
INFO:root:FL Epoch: 125 Norm Difference for worker 513 is 1.134213
INFO:root:FL Epoch: 125 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1270
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670958
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493358
INFO:root:FL Epoch: 125 Norm Difference for worker 1270 is 1.059588
INFO:root:FL Epoch: 125 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1617
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.579072084497003 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.8037445942560831                             and Backdoor Test Accuracy:50.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 126 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1262
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471240
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510580
INFO:root:FL Epoch: 126 Norm Difference for worker 1262 is 1.059334
INFO:root:FL Epoch: 126 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :808
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460337
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554517
INFO:root:FL Epoch: 126 Norm Difference for worker 808 is 1.066796
INFO:root:FL Epoch: 126 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :93
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 93 is 1.058541
INFO:root:FL Epoch: 126 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1323
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558612
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536674
INFO:root:FL Epoch: 126 Norm Difference for worker 1323 is 1.060022
INFO:root:FL Epoch: 126 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1090
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471303
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520638
INFO:root:FL Epoch: 126 Norm Difference for worker 1090 is 1.111267
INFO:root:FL Epoch: 126 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :844
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420715
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384140
INFO:root:FL Epoch: 126 Norm Difference for worker 844 is 0.984772
INFO:root:FL Epoch: 126 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :915
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796210
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518062
INFO:root:FL Epoch: 126 Norm Difference for worker 915 is 1.025551
INFO:root:FL Epoch: 126 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :433
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573780
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526196
INFO:root:FL Epoch: 126 Norm Difference for worker 433 is 1.051368
INFO:root:FL Epoch: 126 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :605
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532282
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494518
INFO:root:FL Epoch: 126 Norm Difference for worker 605 is 1.079393
INFO:root:FL Epoch: 126 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :416
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813760
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733947
INFO:root:FL Epoch: 126 Norm Difference for worker 416 is 1.074562
INFO:root:FL Epoch: 126 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.5900878520572886 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.9604403177897135                             and Backdoor Test Accuracy:37.5 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :857
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577519
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472912
INFO:root:FL Epoch: 127 Norm Difference for worker 857 is 1.209232
INFO:root:FL Epoch: 127 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1514
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575514
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496772
INFO:root:FL Epoch: 127 Norm Difference for worker 1514 is 1.225564
INFO:root:FL Epoch: 127 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :267
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 267 is 1.226062
INFO:root:FL Epoch: 127 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1586
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513031
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588753
INFO:root:FL Epoch: 127 Norm Difference for worker 1586 is 1.189813
INFO:root:FL Epoch: 127 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :889
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452898
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552184
INFO:root:FL Epoch: 127 Norm Difference for worker 889 is 1.183368
INFO:root:FL Epoch: 127 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1059
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530696
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587576
INFO:root:FL Epoch: 127 Norm Difference for worker 1059 is 1.185352
INFO:root:FL Epoch: 127 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1388
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762571
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703246
INFO:root:FL Epoch: 127 Norm Difference for worker 1388 is 1.20295
INFO:root:FL Epoch: 127 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1617
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469768
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317920
INFO:root:FL Epoch: 127 Norm Difference for worker 1617 is 0.992927
INFO:root:FL Epoch: 127 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1454
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357944
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568734
INFO:root:FL Epoch: 127 Norm Difference for worker 1454 is 1.117898
INFO:root:FL Epoch: 127 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1616
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440502
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546711
INFO:root:FL Epoch: 127 Norm Difference for worker 1616 is 1.158565
INFO:root:FL Epoch: 127 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1617
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.6198923237183515 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:1.2281830509503682                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 128 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :310
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465338
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 310 is 1.316102
INFO:root:FL Epoch: 128 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :104
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 104 is 1.293211
INFO:root:FL Epoch: 128 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :160
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468707
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 160 is 1.396318
INFO:root:FL Epoch: 128 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :498
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639793
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602040
INFO:root:FL Epoch: 128 Norm Difference for worker 498 is 1.391686
INFO:root:FL Epoch: 128 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :577
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660140
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501147
INFO:root:FL Epoch: 128 Norm Difference for worker 577 is 1.270901
INFO:root:FL Epoch: 128 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1023
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355468
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389094
INFO:root:FL Epoch: 128 Norm Difference for worker 1023 is 1.359212
INFO:root:FL Epoch: 128 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :911
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525301
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396258
INFO:root:FL Epoch: 128 Norm Difference for worker 911 is 1.342003
INFO:root:FL Epoch: 128 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :823
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698152
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330982
INFO:root:FL Epoch: 128 Norm Difference for worker 823 is 1.325439
INFO:root:FL Epoch: 128 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1667
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539247
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499977
INFO:root:FL Epoch: 128 Norm Difference for worker 1667 is 1.343474
INFO:root:FL Epoch: 128 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :754
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731484
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463783
INFO:root:FL Epoch: 128 Norm Difference for worker 754 is 1.251395
INFO:root:FL Epoch: 128 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 754
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.5835877551751978 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.9628194073836008                             and Backdoor Test Accuracy:39.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1492
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590857
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707955
INFO:root:FL Epoch: 129 Norm Difference for worker 1492 is 1.168434
INFO:root:FL Epoch: 129 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :354
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670885
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487530
INFO:root:FL Epoch: 129 Norm Difference for worker 354 is 1.136076
INFO:root:FL Epoch: 129 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :33
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614308
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 33 is 1.115421
INFO:root:FL Epoch: 129 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1440
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628822
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619788
INFO:root:FL Epoch: 129 Norm Difference for worker 1440 is 1.078142
INFO:root:FL Epoch: 129 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :773
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600570
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517061
INFO:root:FL Epoch: 129 Norm Difference for worker 773 is 1.159675
INFO:root:FL Epoch: 129 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1028
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825857
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618625
INFO:root:FL Epoch: 129 Norm Difference for worker 1028 is 1.055242
INFO:root:FL Epoch: 129 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :863
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412095
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619710
INFO:root:FL Epoch: 129 Norm Difference for worker 863 is 1.095012
INFO:root:FL Epoch: 129 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :755
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645411
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500143
INFO:root:FL Epoch: 129 Norm Difference for worker 755 is 1.175953
INFO:root:FL Epoch: 129 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1307
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498189
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455903
INFO:root:FL Epoch: 129 Norm Difference for worker 1307 is 1.156192
INFO:root:FL Epoch: 129 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1724
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529851
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527608
INFO:root:FL Epoch: 129 Norm Difference for worker 1724 is 1.150683
INFO:root:FL Epoch: 129 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1028
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.5856274787117454 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.9359316726525625                             and Backdoor Test Accuracy:44.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 130 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :324
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532519
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.664204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 324 is 1.103552
INFO:root:FL Epoch: 130 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :145
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 145 is 1.093037
INFO:root:FL Epoch: 130 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :544
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655893
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496929
INFO:root:FL Epoch: 130 Norm Difference for worker 544 is 1.117525
INFO:root:FL Epoch: 130 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :970
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664151
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457887
INFO:root:FL Epoch: 130 Norm Difference for worker 970 is 1.207598
INFO:root:FL Epoch: 130 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1423
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490669
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595106
INFO:root:FL Epoch: 130 Norm Difference for worker 1423 is 1.177748
INFO:root:FL Epoch: 130 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1402
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552904
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640912
INFO:root:FL Epoch: 130 Norm Difference for worker 1402 is 1.059199
INFO:root:FL Epoch: 130 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :689
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784209
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553167
INFO:root:FL Epoch: 130 Norm Difference for worker 689 is 1.102838
INFO:root:FL Epoch: 130 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1486
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555446
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577550
INFO:root:FL Epoch: 130 Norm Difference for worker 1486 is 1.125477
INFO:root:FL Epoch: 130 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :765
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546077
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580365
INFO:root:FL Epoch: 130 Norm Difference for worker 765 is 1.13923
INFO:root:FL Epoch: 130 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :11
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 11 is 1.084998
INFO:root:FL Epoch: 130 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1402
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.6124298274517059 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.9865395029385885                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699360
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599685
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.4735589921474457 Backdoor Test Accuracy: 80.83333333333333
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.46914813220500945 Backdoor Train Accuracy: 81.0
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.41089
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541929
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547746
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.4698771784702937 Backdoor Test Accuracy: 80.83333333333333
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.47176467478275297 Backdoor Train Accuracy: 80.5
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 0.411772
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534389
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596419
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.456155185898145 Backdoor Test Accuracy: 82.5
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.47192221879959106 Backdoor Train Accuracy: 79.5
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 0.419703
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1513
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649157
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592462
INFO:root:FL Epoch: 131 Norm Difference for worker 1513 is 1.097662
INFO:root:FL Epoch: 131 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1131
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729338
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575926
INFO:root:FL Epoch: 131 Norm Difference for worker 1131 is 1.076654
INFO:root:FL Epoch: 131 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :516
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585415
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.818575
INFO:root:FL Epoch: 131 Norm Difference for worker 516 is 1.056675
INFO:root:FL Epoch: 131 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :950
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521121
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509798
INFO:root:FL Epoch: 131 Norm Difference for worker 950 is 1.083432
INFO:root:FL Epoch: 131 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :910
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627907
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371511
INFO:root:FL Epoch: 131 Norm Difference for worker 910 is 1.080747
INFO:root:FL Epoch: 131 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :386
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612038
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422448
INFO:root:FL Epoch: 131 Norm Difference for worker 386 is 1.036971
INFO:root:FL Epoch: 131 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :240
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 240 is 1.04135
INFO:root:FL Epoch: 131 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.6230268285554998 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.4735589921474457                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 132 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :1511
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740995
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545085
INFO:root:FL Epoch: 132 Norm Difference for worker 1511 is 1.155343
INFO:root:FL Epoch: 132 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1912
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679707
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519437
INFO:root:FL Epoch: 132 Norm Difference for worker 1912 is 1.092838
INFO:root:FL Epoch: 132 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :355
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522851
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575437
INFO:root:FL Epoch: 132 Norm Difference for worker 355 is 1.072978
INFO:root:FL Epoch: 132 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :961
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506476
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513223
INFO:root:FL Epoch: 132 Norm Difference for worker 961 is 1.099757
INFO:root:FL Epoch: 132 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :352
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583664
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458175
INFO:root:FL Epoch: 132 Norm Difference for worker 352 is 1.063868
INFO:root:FL Epoch: 132 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :366
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706492
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615130
INFO:root:FL Epoch: 132 Norm Difference for worker 366 is 1.124436
INFO:root:FL Epoch: 132 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :136
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 136 is 1.114074
INFO:root:FL Epoch: 132 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :335
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 335 is 1.112476
INFO:root:FL Epoch: 132 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1156
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698359
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567571
INFO:root:FL Epoch: 132 Norm Difference for worker 1156 is 1.108782
INFO:root:FL Epoch: 132 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1522
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781641
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538320
INFO:root:FL Epoch: 132 Norm Difference for worker 1522 is 1.039044
INFO:root:FL Epoch: 132 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1522
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.5980517408427071 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.5322426855564117                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1447
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612168
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524505
INFO:root:FL Epoch: 133 Norm Difference for worker 1447 is 1.021002
INFO:root:FL Epoch: 133 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1313
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651330
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387660
INFO:root:FL Epoch: 133 Norm Difference for worker 1313 is 1.08133
INFO:root:FL Epoch: 133 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1892
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740081
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468739
INFO:root:FL Epoch: 133 Norm Difference for worker 1892 is 1.009571
INFO:root:FL Epoch: 133 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539503
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415511
INFO:root:FL Epoch: 133 Norm Difference for worker 700 is 1.065295
INFO:root:FL Epoch: 133 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1180
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562067
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419345
INFO:root:FL Epoch: 133 Norm Difference for worker 1180 is 0.997421
INFO:root:FL Epoch: 133 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :208
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 208 is 1.023065
INFO:root:FL Epoch: 133 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1366
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773341
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733178
INFO:root:FL Epoch: 133 Norm Difference for worker 1366 is 0.983723
INFO:root:FL Epoch: 133 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1174
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804771
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606905
INFO:root:FL Epoch: 133 Norm Difference for worker 1174 is 1.049312
INFO:root:FL Epoch: 133 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :968
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450726
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390565
INFO:root:FL Epoch: 133 Norm Difference for worker 968 is 1.040326
INFO:root:FL Epoch: 133 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519710
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479750
INFO:root:FL Epoch: 133 Norm Difference for worker 869 is 0.993378
INFO:root:FL Epoch: 133 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.6061354910626131 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.6032239298025767                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1137
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.922645
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673097
INFO:root:FL Epoch: 134 Norm Difference for worker 1137 is 1.20699
INFO:root:FL Epoch: 134 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1389
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640325
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646959
INFO:root:FL Epoch: 134 Norm Difference for worker 1389 is 1.166978
INFO:root:FL Epoch: 134 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :158
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.774705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 158 is 1.102525
INFO:root:FL Epoch: 134 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :892
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315695
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366516
INFO:root:FL Epoch: 134 Norm Difference for worker 892 is 1.096193
INFO:root:FL Epoch: 134 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :314
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 314 is 1.172695
INFO:root:FL Epoch: 134 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :737
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701406
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452471
INFO:root:FL Epoch: 134 Norm Difference for worker 737 is 1.08562
INFO:root:FL Epoch: 134 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1206
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463055
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575773
INFO:root:FL Epoch: 134 Norm Difference for worker 1206 is 1.126044
INFO:root:FL Epoch: 134 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :362
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791332
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370046
INFO:root:FL Epoch: 134 Norm Difference for worker 362 is 1.179224
INFO:root:FL Epoch: 134 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1354
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690841
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399221
INFO:root:FL Epoch: 134 Norm Difference for worker 1354 is 1.08897
INFO:root:FL Epoch: 134 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :650
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604757
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469812
INFO:root:FL Epoch: 134 Norm Difference for worker 650 is 1.149984
INFO:root:FL Epoch: 134 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 737
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.5946948160143459 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.6585291028022766                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1702
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719587
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562874
INFO:root:FL Epoch: 135 Norm Difference for worker 1702 is 1.02095
INFO:root:FL Epoch: 135 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :19
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.884348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 19 is 1.008702
INFO:root:FL Epoch: 135 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :779
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511472
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552529
INFO:root:FL Epoch: 135 Norm Difference for worker 779 is 1.150956
INFO:root:FL Epoch: 135 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1874
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686096
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659495
INFO:root:FL Epoch: 135 Norm Difference for worker 1874 is 1.056404
INFO:root:FL Epoch: 135 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :153
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 153 is 0.965238
INFO:root:FL Epoch: 135 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :751
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615364
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298413
INFO:root:FL Epoch: 135 Norm Difference for worker 751 is 1.051644
INFO:root:FL Epoch: 135 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1409
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513282
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452067
INFO:root:FL Epoch: 135 Norm Difference for worker 1409 is 0.999766
INFO:root:FL Epoch: 135 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1891
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652789
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489428
INFO:root:FL Epoch: 135 Norm Difference for worker 1891 is 1.032928
INFO:root:FL Epoch: 135 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1327
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619062
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399458
INFO:root:FL Epoch: 135 Norm Difference for worker 1327 is 1.023372
INFO:root:FL Epoch: 135 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :312
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 312 is 1.065915
INFO:root:FL Epoch: 135 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 153
INFO:root:Norm of Aggregated Model: 5154.96533203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.592272492016063 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.7135493755340576                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :950
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576029
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593363
INFO:root:FL Epoch: 136 Norm Difference for worker 950 is 0.996316
INFO:root:FL Epoch: 136 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1614
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465262
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622674
INFO:root:FL Epoch: 136 Norm Difference for worker 1614 is 1.028907
INFO:root:FL Epoch: 136 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1069
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656779
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759428
INFO:root:FL Epoch: 136 Norm Difference for worker 1069 is 1.049057
INFO:root:FL Epoch: 136 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1082
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590758
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575662
INFO:root:FL Epoch: 136 Norm Difference for worker 1082 is 0.92357
INFO:root:FL Epoch: 136 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :755
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522665
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436048
INFO:root:FL Epoch: 136 Norm Difference for worker 755 is 1.054462
INFO:root:FL Epoch: 136 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :211
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633209
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 211 is 1.013917
INFO:root:FL Epoch: 136 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :626
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556035
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528278
INFO:root:FL Epoch: 136 Norm Difference for worker 626 is 0.993646
INFO:root:FL Epoch: 136 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1801
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546106
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530498
INFO:root:FL Epoch: 136 Norm Difference for worker 1801 is 0.996412
INFO:root:FL Epoch: 136 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :592
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515341
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419711
INFO:root:FL Epoch: 136 Norm Difference for worker 592 is 1.06583
INFO:root:FL Epoch: 136 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :113
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 113 is 0.986385
INFO:root:FL Epoch: 136 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.6086017594617956 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.9678925971190134                             and Backdoor Test Accuracy:38.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :935
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478567
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621649
INFO:root:FL Epoch: 137 Norm Difference for worker 935 is 1.097619
INFO:root:FL Epoch: 137 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1785
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524674
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362293
INFO:root:FL Epoch: 137 Norm Difference for worker 1785 is 1.139666
INFO:root:FL Epoch: 137 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :769
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625003
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541955
INFO:root:FL Epoch: 137 Norm Difference for worker 769 is 1.116867
INFO:root:FL Epoch: 137 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :514
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512020
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474046
INFO:root:FL Epoch: 137 Norm Difference for worker 514 is 1.129911
INFO:root:FL Epoch: 137 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :59
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 59 is 1.162573
INFO:root:FL Epoch: 137 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1601
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582185
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487476
INFO:root:FL Epoch: 137 Norm Difference for worker 1601 is 1.169424
INFO:root:FL Epoch: 137 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1554
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743306
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298716
INFO:root:FL Epoch: 137 Norm Difference for worker 1554 is 1.096779
INFO:root:FL Epoch: 137 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1492
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588437
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615667
INFO:root:FL Epoch: 137 Norm Difference for worker 1492 is 1.190962
INFO:root:FL Epoch: 137 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :393
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571226
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523425
INFO:root:FL Epoch: 137 Norm Difference for worker 393 is 1.158129
INFO:root:FL Epoch: 137 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1921
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814851
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572541
INFO:root:FL Epoch: 137 Norm Difference for worker 1921 is 1.176492
INFO:root:FL Epoch: 137 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 769
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.5780514180660248 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.6518072783946991                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :589
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515414
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506975
INFO:root:FL Epoch: 138 Norm Difference for worker 589 is 0.923129
INFO:root:FL Epoch: 138 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1143
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643675
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414050
INFO:root:FL Epoch: 138 Norm Difference for worker 1143 is 0.98584
INFO:root:FL Epoch: 138 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1020
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772331
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735178
INFO:root:FL Epoch: 138 Norm Difference for worker 1020 is 0.92568
INFO:root:FL Epoch: 138 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1022
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538638
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578705
INFO:root:FL Epoch: 138 Norm Difference for worker 1022 is 0.910319
INFO:root:FL Epoch: 138 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :730
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575206
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514449
INFO:root:FL Epoch: 138 Norm Difference for worker 730 is 1.039792
INFO:root:FL Epoch: 138 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :346
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554394
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395143
INFO:root:FL Epoch: 138 Norm Difference for worker 346 is 1.041673
INFO:root:FL Epoch: 138 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 0.988236
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :139
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 139 is 0.97026
INFO:root:FL Epoch: 138 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1469
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536332
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469915
INFO:root:FL Epoch: 138 Norm Difference for worker 1469 is 0.986826
INFO:root:FL Epoch: 138 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1364
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487053
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654703
INFO:root:FL Epoch: 138 Norm Difference for worker 1364 is 1.017296
INFO:root:FL Epoch: 138 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.595838890356176 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.9330002764860789                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 139 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :545
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600603
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619821
INFO:root:FL Epoch: 139 Norm Difference for worker 545 is 1.20351
INFO:root:FL Epoch: 139 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :55
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 55 is 1.125025
INFO:root:FL Epoch: 139 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :702
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604747
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491679
INFO:root:FL Epoch: 139 Norm Difference for worker 702 is 1.054967
INFO:root:FL Epoch: 139 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1861
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583687
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543032
INFO:root:FL Epoch: 139 Norm Difference for worker 1861 is 1.129565
INFO:root:FL Epoch: 139 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1745
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623582
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400592
INFO:root:FL Epoch: 139 Norm Difference for worker 1745 is 1.136411
INFO:root:FL Epoch: 139 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :524
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616449
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502071
INFO:root:FL Epoch: 139 Norm Difference for worker 524 is 1.071085
INFO:root:FL Epoch: 139 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :900
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573677
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592164
INFO:root:FL Epoch: 139 Norm Difference for worker 900 is 1.19505
INFO:root:FL Epoch: 139 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :492
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478273
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426896
INFO:root:FL Epoch: 139 Norm Difference for worker 492 is 1.119859
INFO:root:FL Epoch: 139 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1013
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.901323
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569677
INFO:root:FL Epoch: 139 Norm Difference for worker 1013 is 1.172905
INFO:root:FL Epoch: 139 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1556
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597723
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447295
INFO:root:FL Epoch: 139 Norm Difference for worker 1556 is 1.097954
INFO:root:FL Epoch: 139 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 702
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 139 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 139 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.5697752675589394 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.6344901522000631                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :1834
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573550
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449976
INFO:root:FL Epoch: 140 Norm Difference for worker 1834 is 1.188842
INFO:root:FL Epoch: 140 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :946
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566288
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467490
INFO:root:FL Epoch: 140 Norm Difference for worker 946 is 1.18819
INFO:root:FL Epoch: 140 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :646
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348922
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523208
INFO:root:FL Epoch: 140 Norm Difference for worker 646 is 1.118401
INFO:root:FL Epoch: 140 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1428
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812686
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488890
INFO:root:FL Epoch: 140 Norm Difference for worker 1428 is 1.169506
INFO:root:FL Epoch: 140 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :50
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 50 is 1.160587
INFO:root:FL Epoch: 140 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1198
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698845
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508081
INFO:root:FL Epoch: 140 Norm Difference for worker 1198 is 1.154776
INFO:root:FL Epoch: 140 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1355
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610792
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389067
INFO:root:FL Epoch: 140 Norm Difference for worker 1355 is 1.192605
INFO:root:FL Epoch: 140 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :222
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 222 is 1.073217
INFO:root:FL Epoch: 140 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1642
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608723
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645828
INFO:root:FL Epoch: 140 Norm Difference for worker 1642 is 1.155208
INFO:root:FL Epoch: 140 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1223
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623544
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650068
INFO:root:FL Epoch: 140 Norm Difference for worker 1223 is 1.127338
INFO:root:FL Epoch: 140 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.5792840929592357 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.8202310601870219                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508523
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657193
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.3086267908414205 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.43310465961694716 Backdoor Train Accuracy: 79.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.426509
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 1.049929
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436184
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.33560065428415936 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.43031796514987947 Backdoor Train Accuracy: 81.5
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 0.408989
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453518
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461961
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.33544589082400006 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.4234188735485077 Backdoor Train Accuracy: 81.5
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 0.416954
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1878
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715203
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553687
INFO:root:FL Epoch: 141 Norm Difference for worker 1878 is 1.369723
INFO:root:FL Epoch: 141 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :962
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436215
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421641
INFO:root:FL Epoch: 141 Norm Difference for worker 962 is 1.216912
INFO:root:FL Epoch: 141 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394639
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327982
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.189185
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :976
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888253
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411849
INFO:root:FL Epoch: 141 Norm Difference for worker 976 is 1.303333
INFO:root:FL Epoch: 141 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :769
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611664
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422657
INFO:root:FL Epoch: 141 Norm Difference for worker 769 is 1.15305
INFO:root:FL Epoch: 141 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :465
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685433
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540519
INFO:root:FL Epoch: 141 Norm Difference for worker 465 is 1.244502
INFO:root:FL Epoch: 141 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1750
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657251
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458588
INFO:root:FL Epoch: 141 Norm Difference for worker 1750 is 1.17429
INFO:root:FL Epoch: 141 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.6077455352334415 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.33560065428415936                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1841
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740175
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468745
INFO:root:FL Epoch: 142 Norm Difference for worker 1841 is 1.226859
INFO:root:FL Epoch: 142 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1522
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585264
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509012
INFO:root:FL Epoch: 142 Norm Difference for worker 1522 is 1.076404
INFO:root:FL Epoch: 142 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :23
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594959
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483037
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 23 is 1.200408
INFO:root:FL Epoch: 142 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1157
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808971
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580102
INFO:root:FL Epoch: 142 Norm Difference for worker 1157 is 1.213736
INFO:root:FL Epoch: 142 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :56
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 56 is 1.123537
INFO:root:FL Epoch: 142 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1269
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438797
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.921135
INFO:root:FL Epoch: 142 Norm Difference for worker 1269 is 1.260646
INFO:root:FL Epoch: 142 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :442
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554463
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359264
INFO:root:FL Epoch: 142 Norm Difference for worker 442 is 1.140412
INFO:root:FL Epoch: 142 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :577
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790817
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455571
INFO:root:FL Epoch: 142 Norm Difference for worker 577 is 1.106613
INFO:root:FL Epoch: 142 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :219
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 219 is 1.190639
INFO:root:FL Epoch: 142 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1614
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786455
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655125
INFO:root:FL Epoch: 142 Norm Difference for worker 1614 is 1.326234
INFO:root:FL Epoch: 142 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 577
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.5686423042241264 and Test Accuracy:70.0 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.5257736891508102                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1520
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473463
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592935
INFO:root:FL Epoch: 143 Norm Difference for worker 1520 is 1.112681
INFO:root:FL Epoch: 143 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1151
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549195
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582975
INFO:root:FL Epoch: 143 Norm Difference for worker 1151 is 1.03712
INFO:root:FL Epoch: 143 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :182
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.812419
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 182 is 1.159581
INFO:root:FL Epoch: 143 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :755
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557340
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360932
INFO:root:FL Epoch: 143 Norm Difference for worker 755 is 1.154189
INFO:root:FL Epoch: 143 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :86
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 86 is 1.079701
INFO:root:FL Epoch: 143 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1828
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536063
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502263
INFO:root:FL Epoch: 143 Norm Difference for worker 1828 is 1.080513
INFO:root:FL Epoch: 143 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1417
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465093
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476341
INFO:root:FL Epoch: 143 Norm Difference for worker 1417 is 1.016576
INFO:root:FL Epoch: 143 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :504
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535852
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537847
INFO:root:FL Epoch: 143 Norm Difference for worker 504 is 1.035778
INFO:root:FL Epoch: 143 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :250
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 250 is 1.060784
INFO:root:FL Epoch: 143 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :634
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573622
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411204
INFO:root:FL Epoch: 143 Norm Difference for worker 634 is 1.03637
INFO:root:FL Epoch: 143 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 504
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.5660826791735256 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.5188659181197485                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1753
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577278
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460477
INFO:root:FL Epoch: 144 Norm Difference for worker 1753 is 1.108544
INFO:root:FL Epoch: 144 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1838
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549334
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350316
INFO:root:FL Epoch: 144 Norm Difference for worker 1838 is 1.152443
INFO:root:FL Epoch: 144 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :71
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537720
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522600
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 71 is 1.186537
INFO:root:FL Epoch: 144 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :711
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696410
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721157
INFO:root:FL Epoch: 144 Norm Difference for worker 711 is 1.199029
INFO:root:FL Epoch: 144 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :960
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728750
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612296
INFO:root:FL Epoch: 144 Norm Difference for worker 960 is 1.170038
INFO:root:FL Epoch: 144 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :665
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559702
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552526
INFO:root:FL Epoch: 144 Norm Difference for worker 665 is 1.215891
INFO:root:FL Epoch: 144 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1500
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497592
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355766
INFO:root:FL Epoch: 144 Norm Difference for worker 1500 is 1.166305
INFO:root:FL Epoch: 144 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1467
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674031
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493328
INFO:root:FL Epoch: 144 Norm Difference for worker 1467 is 1.199765
INFO:root:FL Epoch: 144 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :800
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520198
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610857
INFO:root:FL Epoch: 144 Norm Difference for worker 800 is 1.21735
INFO:root:FL Epoch: 144 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :787
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660730
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634710
INFO:root:FL Epoch: 144 Norm Difference for worker 787 is 1.168393
INFO:root:FL Epoch: 144 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.5752518404932583 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.631366084019343                             and Backdoor Test Accuracy:65.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :380
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713038
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586631
INFO:root:FL Epoch: 145 Norm Difference for worker 380 is 1.193666
INFO:root:FL Epoch: 145 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :95
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 95 is 1.19177
INFO:root:FL Epoch: 145 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :818
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472137
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338566
INFO:root:FL Epoch: 145 Norm Difference for worker 818 is 1.141705
INFO:root:FL Epoch: 145 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1766
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571609
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510584
INFO:root:FL Epoch: 145 Norm Difference for worker 1766 is 1.160265
INFO:root:FL Epoch: 145 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1585
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835095
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545667
INFO:root:FL Epoch: 145 Norm Difference for worker 1585 is 1.23868
INFO:root:FL Epoch: 145 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1927
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592224
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531807
INFO:root:FL Epoch: 145 Norm Difference for worker 1927 is 1.127266
INFO:root:FL Epoch: 145 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1721
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519489
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.809990
INFO:root:FL Epoch: 145 Norm Difference for worker 1721 is 1.157795
INFO:root:FL Epoch: 145 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637575
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388644
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 1.213379
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1393
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503544
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454355
INFO:root:FL Epoch: 145 Norm Difference for worker 1393 is 1.135959
INFO:root:FL Epoch: 145 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1170
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710606
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582207
INFO:root:FL Epoch: 145 Norm Difference for worker 1170 is 1.187934
INFO:root:FL Epoch: 145 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1393
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.5824131422183093 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.6348841488361359                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :968
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588049
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523982
INFO:root:FL Epoch: 146 Norm Difference for worker 968 is 1.058364
INFO:root:FL Epoch: 146 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :715
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595245
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503917
INFO:root:FL Epoch: 146 Norm Difference for worker 715 is 1.124713
INFO:root:FL Epoch: 146 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :798
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438046
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605003
INFO:root:FL Epoch: 146 Norm Difference for worker 798 is 1.076453
INFO:root:FL Epoch: 146 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1158
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362461
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538216
INFO:root:FL Epoch: 146 Norm Difference for worker 1158 is 1.063832
INFO:root:FL Epoch: 146 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1312
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637722
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546040
INFO:root:FL Epoch: 146 Norm Difference for worker 1312 is 1.097076
INFO:root:FL Epoch: 146 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :656
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686323
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711247
INFO:root:FL Epoch: 146 Norm Difference for worker 656 is 1.130879
INFO:root:FL Epoch: 146 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :911
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567195
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513792
INFO:root:FL Epoch: 146 Norm Difference for worker 911 is 1.139527
INFO:root:FL Epoch: 146 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :391
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798512
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632816
INFO:root:FL Epoch: 146 Norm Difference for worker 391 is 1.092428
INFO:root:FL Epoch: 146 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587548
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 1.044202
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :800
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744285
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574021
INFO:root:FL Epoch: 146 Norm Difference for worker 800 is 1.129143
INFO:root:FL Epoch: 146 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 798
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.5770213095580831 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.5400463541348776                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1230
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617552
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446203
INFO:root:FL Epoch: 147 Norm Difference for worker 1230 is 1.006932
INFO:root:FL Epoch: 147 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1810
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622926
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573649
INFO:root:FL Epoch: 147 Norm Difference for worker 1810 is 0.997878
INFO:root:FL Epoch: 147 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :202
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 202 is 1.038676
INFO:root:FL Epoch: 147 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :692
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524048
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497533
INFO:root:FL Epoch: 147 Norm Difference for worker 692 is 1.012763
INFO:root:FL Epoch: 147 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1869
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607056
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598834
INFO:root:FL Epoch: 147 Norm Difference for worker 1869 is 1.021123
INFO:root:FL Epoch: 147 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1931
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484156
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484609
INFO:root:FL Epoch: 147 Norm Difference for worker 1931 is 1.000509
INFO:root:FL Epoch: 147 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1058
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621140
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.785497
INFO:root:FL Epoch: 147 Norm Difference for worker 1058 is 1.051223
INFO:root:FL Epoch: 147 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :783
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683283
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429807
INFO:root:FL Epoch: 147 Norm Difference for worker 783 is 1.04418
INFO:root:FL Epoch: 147 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :536
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580064
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539995
INFO:root:FL Epoch: 147 Norm Difference for worker 536 is 1.012615
INFO:root:FL Epoch: 147 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :950
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359838
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433987
INFO:root:FL Epoch: 147 Norm Difference for worker 950 is 1.00915
INFO:root:FL Epoch: 147 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.5750686280867633 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.7759556273619334                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :376
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615912
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520126
INFO:root:FL Epoch: 148 Norm Difference for worker 376 is 1.037434
INFO:root:FL Epoch: 148 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :932
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572140
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496495
INFO:root:FL Epoch: 148 Norm Difference for worker 932 is 1.091993
INFO:root:FL Epoch: 148 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :206
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506490
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 206 is 1.117193
INFO:root:FL Epoch: 148 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :532
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471454
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537673
INFO:root:FL Epoch: 148 Norm Difference for worker 532 is 1.053003
INFO:root:FL Epoch: 148 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1088
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592798
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487748
INFO:root:FL Epoch: 148 Norm Difference for worker 1088 is 1.046427
INFO:root:FL Epoch: 148 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :339
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 339 is 1.013501
INFO:root:FL Epoch: 148 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1682
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424640
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478929
INFO:root:FL Epoch: 148 Norm Difference for worker 1682 is 1.061203
INFO:root:FL Epoch: 148 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :436
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655540
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560334
INFO:root:FL Epoch: 148 Norm Difference for worker 436 is 1.082868
INFO:root:FL Epoch: 148 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1295
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724519
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464523
INFO:root:FL Epoch: 148 Norm Difference for worker 1295 is 1.037074
INFO:root:FL Epoch: 148 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1789
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383787
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387126
INFO:root:FL Epoch: 148 Norm Difference for worker 1789 is 1.016677
INFO:root:FL Epoch: 148 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1789
INFO:root:Norm of Aggregated Model: 5154.9658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.5744552279219908 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.6041314254204432                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :648
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432951
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671036
INFO:root:FL Epoch: 149 Norm Difference for worker 648 is 1.198386
INFO:root:FL Epoch: 149 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1268
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378652
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432963
INFO:root:FL Epoch: 149 Norm Difference for worker 1268 is 1.136811
INFO:root:FL Epoch: 149 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :337
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574811
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 337 is 1.124683
INFO:root:FL Epoch: 149 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1086
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592038
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581040
INFO:root:FL Epoch: 149 Norm Difference for worker 1086 is 1.082456
INFO:root:FL Epoch: 149 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1112
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547362
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383947
INFO:root:FL Epoch: 149 Norm Difference for worker 1112 is 1.130244
INFO:root:FL Epoch: 149 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :725
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616714
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350859
INFO:root:FL Epoch: 149 Norm Difference for worker 725 is 1.18915
INFO:root:FL Epoch: 149 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :610
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492688
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456403
INFO:root:FL Epoch: 149 Norm Difference for worker 610 is 1.134983
INFO:root:FL Epoch: 149 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1600
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608714
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519544
INFO:root:FL Epoch: 149 Norm Difference for worker 1600 is 1.258457
INFO:root:FL Epoch: 149 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :335
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 335 is 1.236421
INFO:root:FL Epoch: 149 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :996
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718908
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271721
INFO:root:FL Epoch: 149 Norm Difference for worker 996 is 1.200515
INFO:root:FL Epoch: 149 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.5784319516490487 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.7024329702059428                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :969
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648972
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432257
INFO:root:FL Epoch: 150 Norm Difference for worker 969 is 1.032626
INFO:root:FL Epoch: 150 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :73
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 73 is 1.090719
INFO:root:FL Epoch: 150 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1089
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520357
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326030
INFO:root:FL Epoch: 150 Norm Difference for worker 1089 is 1.02748
INFO:root:FL Epoch: 150 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1428
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816594
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520267
INFO:root:FL Epoch: 150 Norm Difference for worker 1428 is 1.055905
INFO:root:FL Epoch: 150 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :306
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367392
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 306 is 1.081109
INFO:root:FL Epoch: 150 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :424
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513088
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711385
INFO:root:FL Epoch: 150 Norm Difference for worker 424 is 0.980779
INFO:root:FL Epoch: 150 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1357
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467682
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530771
INFO:root:FL Epoch: 150 Norm Difference for worker 1357 is 1.010567
INFO:root:FL Epoch: 150 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :441
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620910
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474724
INFO:root:FL Epoch: 150 Norm Difference for worker 441 is 1.045186
INFO:root:FL Epoch: 150 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :62
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 62 is 1.065265
INFO:root:FL Epoch: 150 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :459
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647701
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466335
INFO:root:FL Epoch: 150 Norm Difference for worker 459 is 1.133264
INFO:root:FL Epoch: 150 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.5769489074454588 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.6452390551567078                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605028
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390907
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.34390967587629956 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.408618700504303 Backdoor Train Accuracy: 83.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.330566
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477147
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515340
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.3514002412557602 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.4040866792201996 Backdoor Train Accuracy: 84.0
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 0.332639
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479099
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490749
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.38345053791999817 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.39795133769512175 Backdoor Train Accuracy: 86.0
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 0.320447
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :954
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488570
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559924
INFO:root:FL Epoch: 151 Norm Difference for worker 954 is 1.095443
INFO:root:FL Epoch: 151 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1013
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561571
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538208
INFO:root:FL Epoch: 151 Norm Difference for worker 1013 is 1.128834
INFO:root:FL Epoch: 151 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :183
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503918
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 183 is 1.104803
INFO:root:FL Epoch: 151 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :593
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489224
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574006
INFO:root:FL Epoch: 151 Norm Difference for worker 593 is 1.101575
INFO:root:FL Epoch: 151 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1646
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255908
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444794
INFO:root:FL Epoch: 151 Norm Difference for worker 1646 is 1.080883
INFO:root:FL Epoch: 151 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :153
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 153 is 0.969773
INFO:root:FL Epoch: 151 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :653
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567983
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577425
INFO:root:FL Epoch: 151 Norm Difference for worker 653 is 1.044704
INFO:root:FL Epoch: 151 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.5970074288985309 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.38345053791999817                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1082
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672424
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334564
INFO:root:FL Epoch: 152 Norm Difference for worker 1082 is 1.042825
INFO:root:FL Epoch: 152 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :949
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877550
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401212
INFO:root:FL Epoch: 152 Norm Difference for worker 949 is 1.110588
INFO:root:FL Epoch: 152 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1688
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640893
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602826
INFO:root:FL Epoch: 152 Norm Difference for worker 1688 is 1.092941
INFO:root:FL Epoch: 152 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :734
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570807
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568873
INFO:root:FL Epoch: 152 Norm Difference for worker 734 is 1.077342
INFO:root:FL Epoch: 152 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :277
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 277 is 1.119175
INFO:root:FL Epoch: 152 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :966
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411855
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639558
INFO:root:FL Epoch: 152 Norm Difference for worker 966 is 1.187059
INFO:root:FL Epoch: 152 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :748
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487093
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.817166
INFO:root:FL Epoch: 152 Norm Difference for worker 748 is 1.16964
INFO:root:FL Epoch: 152 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :886
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521762
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279243
INFO:root:FL Epoch: 152 Norm Difference for worker 886 is 1.072448
INFO:root:FL Epoch: 152 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :918
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743317
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489731
INFO:root:FL Epoch: 152 Norm Difference for worker 918 is 1.136119
INFO:root:FL Epoch: 152 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :418
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419818
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439348
INFO:root:FL Epoch: 152 Norm Difference for worker 418 is 1.093492
INFO:root:FL Epoch: 152 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 734
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.6068221979281482 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.3934093117713928                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :115
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 115 is 1.030316
INFO:root:FL Epoch: 153 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :899
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610998
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544539
INFO:root:FL Epoch: 153 Norm Difference for worker 899 is 1.09376
INFO:root:FL Epoch: 153 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1476
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587870
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522732
INFO:root:FL Epoch: 153 Norm Difference for worker 1476 is 1.041983
INFO:root:FL Epoch: 153 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :185
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 185 is 1.040484
INFO:root:FL Epoch: 153 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :482
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706647
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407300
INFO:root:FL Epoch: 153 Norm Difference for worker 482 is 1.058257
INFO:root:FL Epoch: 153 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1640
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715206
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489923
INFO:root:FL Epoch: 153 Norm Difference for worker 1640 is 0.999389
INFO:root:FL Epoch: 153 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1042
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574668
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643214
INFO:root:FL Epoch: 153 Norm Difference for worker 1042 is 1.087162
INFO:root:FL Epoch: 153 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :354
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710745
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656606
INFO:root:FL Epoch: 153 Norm Difference for worker 354 is 1.073125
INFO:root:FL Epoch: 153 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :626
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679707
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449229
INFO:root:FL Epoch: 153 Norm Difference for worker 626 is 1.06726
INFO:root:FL Epoch: 153 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :922
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521251
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447111
INFO:root:FL Epoch: 153 Norm Difference for worker 922 is 1.038208
INFO:root:FL Epoch: 153 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1640
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.5883570629007676 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.6144493023554484                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :1534
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419357
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512416
INFO:root:FL Epoch: 154 Norm Difference for worker 1534 is 1.005847
INFO:root:FL Epoch: 154 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1285
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511118
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557057
INFO:root:FL Epoch: 154 Norm Difference for worker 1285 is 0.963527
INFO:root:FL Epoch: 154 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :791
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920021
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395516
INFO:root:FL Epoch: 154 Norm Difference for worker 791 is 0.944523
INFO:root:FL Epoch: 154 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :829
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786214
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576274
INFO:root:FL Epoch: 154 Norm Difference for worker 829 is 1.002386
INFO:root:FL Epoch: 154 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1852
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736251
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496847
INFO:root:FL Epoch: 154 Norm Difference for worker 1852 is 0.946437
INFO:root:FL Epoch: 154 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1002
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506933
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404672
INFO:root:FL Epoch: 154 Norm Difference for worker 1002 is 1.033944
INFO:root:FL Epoch: 154 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :160
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522763
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 160 is 1.007052
INFO:root:FL Epoch: 154 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1586
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619428
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474909
INFO:root:FL Epoch: 154 Norm Difference for worker 1586 is 1.037498
INFO:root:FL Epoch: 154 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1575
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560595
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545644
INFO:root:FL Epoch: 154 Norm Difference for worker 1575 is 1.015917
INFO:root:FL Epoch: 154 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :545
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594818
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596065
INFO:root:FL Epoch: 154 Norm Difference for worker 545 is 0.985586
INFO:root:FL Epoch: 154 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 791
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.5811547584393445 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.4815025528271993                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 155 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1219
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592783
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415725
INFO:root:FL Epoch: 155 Norm Difference for worker 1219 is 1.057065
INFO:root:FL Epoch: 155 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :334
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612895
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 334 is 1.052668
INFO:root:FL Epoch: 155 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :82
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.634817
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 82 is 1.022032
INFO:root:FL Epoch: 155 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :426
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458566
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392968
INFO:root:FL Epoch: 155 Norm Difference for worker 426 is 0.995871
INFO:root:FL Epoch: 155 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :457
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510361
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612256
INFO:root:FL Epoch: 155 Norm Difference for worker 457 is 1.058255
INFO:root:FL Epoch: 155 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :687
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693408
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447636
INFO:root:FL Epoch: 155 Norm Difference for worker 687 is 1.084924
INFO:root:FL Epoch: 155 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :836
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598255
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377482
INFO:root:FL Epoch: 155 Norm Difference for worker 836 is 1.071425
INFO:root:FL Epoch: 155 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1157
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741054
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408729
INFO:root:FL Epoch: 155 Norm Difference for worker 1157 is 1.092895
INFO:root:FL Epoch: 155 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :845
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671231
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439012
INFO:root:FL Epoch: 155 Norm Difference for worker 845 is 1.124779
INFO:root:FL Epoch: 155 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :422
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618221
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438584
INFO:root:FL Epoch: 155 Norm Difference for worker 422 is 1.069512
INFO:root:FL Epoch: 155 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 426
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.5809768859077903 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.48458637297153473                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :1330
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644451
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595787
INFO:root:FL Epoch: 156 Norm Difference for worker 1330 is 1.271245
INFO:root:FL Epoch: 156 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1035
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622280
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333265
INFO:root:FL Epoch: 156 Norm Difference for worker 1035 is 1.257436
INFO:root:FL Epoch: 156 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :774
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466412
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427036
INFO:root:FL Epoch: 156 Norm Difference for worker 774 is 1.123731
INFO:root:FL Epoch: 156 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1736
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686229
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520620
INFO:root:FL Epoch: 156 Norm Difference for worker 1736 is 1.194425
INFO:root:FL Epoch: 156 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1439
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580104
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490781
INFO:root:FL Epoch: 156 Norm Difference for worker 1439 is 1.221033
INFO:root:FL Epoch: 156 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :824
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687087
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581589
INFO:root:FL Epoch: 156 Norm Difference for worker 824 is 1.141067
INFO:root:FL Epoch: 156 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :957
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708998
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476122
INFO:root:FL Epoch: 156 Norm Difference for worker 957 is 1.190357
INFO:root:FL Epoch: 156 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :80
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785222
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 80 is 1.154374
INFO:root:FL Epoch: 156 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :952
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578455
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463998
INFO:root:FL Epoch: 156 Norm Difference for worker 952 is 1.254288
INFO:root:FL Epoch: 156 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :703
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530359
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321794
INFO:root:FL Epoch: 156 Norm Difference for worker 703 is 1.162394
INFO:root:FL Epoch: 156 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.5817571475225336 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.48726417124271393                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :1090
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632952
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454161
INFO:root:FL Epoch: 157 Norm Difference for worker 1090 is 1.053079
INFO:root:FL Epoch: 157 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1884
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535007
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328778
INFO:root:FL Epoch: 157 Norm Difference for worker 1884 is 1.056913
INFO:root:FL Epoch: 157 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1139
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445975
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452737
INFO:root:FL Epoch: 157 Norm Difference for worker 1139 is 1.070754
INFO:root:FL Epoch: 157 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :349
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498244
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470445
INFO:root:FL Epoch: 157 Norm Difference for worker 349 is 1.034192
INFO:root:FL Epoch: 157 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :877
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420035
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475892
INFO:root:FL Epoch: 157 Norm Difference for worker 877 is 1.112123
INFO:root:FL Epoch: 157 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :538
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461834
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565417
INFO:root:FL Epoch: 157 Norm Difference for worker 538 is 1.096697
INFO:root:FL Epoch: 157 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :147
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534738
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 147 is 1.08695
INFO:root:FL Epoch: 157 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1085
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496753
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382862
INFO:root:FL Epoch: 157 Norm Difference for worker 1085 is 1.040587
INFO:root:FL Epoch: 157 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1142
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551120
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659938
INFO:root:FL Epoch: 157 Norm Difference for worker 1142 is 1.151193
INFO:root:FL Epoch: 157 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :98
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 98 is 1.132641
INFO:root:FL Epoch: 157 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 349
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.5884142973843742 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.4607655157645543                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 158 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :527
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818194
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477252
INFO:root:FL Epoch: 158 Norm Difference for worker 527 is 1.09684
INFO:root:FL Epoch: 158 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :126
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 126 is 1.098313
INFO:root:FL Epoch: 158 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1253
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688214
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555501
INFO:root:FL Epoch: 158 Norm Difference for worker 1253 is 1.141332
INFO:root:FL Epoch: 158 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :917
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554868
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415499
INFO:root:FL Epoch: 158 Norm Difference for worker 917 is 1.074634
INFO:root:FL Epoch: 158 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1316
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369687
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351778
INFO:root:FL Epoch: 158 Norm Difference for worker 1316 is 1.086159
INFO:root:FL Epoch: 158 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396652
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623159
INFO:root:FL Epoch: 158 Norm Difference for worker 1311 is 1.092854
INFO:root:FL Epoch: 158 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541795
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 311 is 1.07525
INFO:root:FL Epoch: 158 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :779
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848329
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504234
INFO:root:FL Epoch: 158 Norm Difference for worker 779 is 1.11053
INFO:root:FL Epoch: 158 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1872
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588326
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517684
INFO:root:FL Epoch: 158 Norm Difference for worker 1872 is 1.139155
INFO:root:FL Epoch: 158 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :900
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710127
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535631
INFO:root:FL Epoch: 158 Norm Difference for worker 900 is 1.138784
INFO:root:FL Epoch: 158 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 527
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.5723886717768276 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.4866672605276108                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :757
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528839
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766101
INFO:root:FL Epoch: 159 Norm Difference for worker 757 is 0.950851
INFO:root:FL Epoch: 159 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1832
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514598
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554761
INFO:root:FL Epoch: 159 Norm Difference for worker 1832 is 0.998042
INFO:root:FL Epoch: 159 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :439
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494046
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559045
INFO:root:FL Epoch: 159 Norm Difference for worker 439 is 0.982298
INFO:root:FL Epoch: 159 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :689
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568986
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607136
INFO:root:FL Epoch: 159 Norm Difference for worker 689 is 0.969097
INFO:root:FL Epoch: 159 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :232
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585735
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 232 is 0.965479
INFO:root:FL Epoch: 159 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1446
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571622
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384868
INFO:root:FL Epoch: 159 Norm Difference for worker 1446 is 1.009389
INFO:root:FL Epoch: 159 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1516
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482809
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518573
INFO:root:FL Epoch: 159 Norm Difference for worker 1516 is 0.953033
INFO:root:FL Epoch: 159 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :603
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685465
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548146
INFO:root:FL Epoch: 159 Norm Difference for worker 603 is 0.982807
INFO:root:FL Epoch: 159 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1899
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446408
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569436
INFO:root:FL Epoch: 159 Norm Difference for worker 1899 is 0.962249
INFO:root:FL Epoch: 159 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1913
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606551
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726874
INFO:root:FL Epoch: 159 Norm Difference for worker 1913 is 0.985927
INFO:root:FL Epoch: 159 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1913
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.5735647099859574 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.6503104269504547                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 160 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :492
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404556
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525073
INFO:root:FL Epoch: 160 Norm Difference for worker 492 is 0.936831
INFO:root:FL Epoch: 160 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :665
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582133
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514788
INFO:root:FL Epoch: 160 Norm Difference for worker 665 is 0.903648
INFO:root:FL Epoch: 160 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1803
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615636
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582848
INFO:root:FL Epoch: 160 Norm Difference for worker 1803 is 0.92096
INFO:root:FL Epoch: 160 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1792
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484970
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425582
INFO:root:FL Epoch: 160 Norm Difference for worker 1792 is 0.903529
INFO:root:FL Epoch: 160 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1299
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697698
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465008
INFO:root:FL Epoch: 160 Norm Difference for worker 1299 is 0.874044
INFO:root:FL Epoch: 160 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :384
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750777
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634225
INFO:root:FL Epoch: 160 Norm Difference for worker 384 is 0.894419
INFO:root:FL Epoch: 160 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1039
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612074
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462832
INFO:root:FL Epoch: 160 Norm Difference for worker 1039 is 0.926846
INFO:root:FL Epoch: 160 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :603
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708965
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630590
INFO:root:FL Epoch: 160 Norm Difference for worker 603 is 0.927847
INFO:root:FL Epoch: 160 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :159
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 159 is 0.947909
INFO:root:FL Epoch: 160 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :209
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576442
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476289
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 209 is 0.929698
INFO:root:FL Epoch: 160 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1299
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.5575000994345721 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.6672930618127187                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492001
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539717
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.3388105630874634 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.38539753407239913 Backdoor Train Accuracy: 84.5
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.319754
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490472
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553730
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.3361601134141286 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.38907025158405306 Backdoor Train Accuracy: 85.0
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 0.315813
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526012
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447560
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.3721463978290558 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.3797844171524048 Backdoor Train Accuracy: 85.5
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 0.309983
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :906
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456486
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621100
INFO:root:FL Epoch: 161 Norm Difference for worker 906 is 1.006041
INFO:root:FL Epoch: 161 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1144
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657699
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526964
INFO:root:FL Epoch: 161 Norm Difference for worker 1144 is 0.954414
INFO:root:FL Epoch: 161 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1064
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558804
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575563
INFO:root:FL Epoch: 161 Norm Difference for worker 1064 is 1.031756
INFO:root:FL Epoch: 161 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :596
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616526
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505155
INFO:root:FL Epoch: 161 Norm Difference for worker 596 is 1.046205
INFO:root:FL Epoch: 161 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1021
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709312
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.771769
INFO:root:FL Epoch: 161 Norm Difference for worker 1021 is 0.95563
INFO:root:FL Epoch: 161 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :234
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677535
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 234 is 1.013414
INFO:root:FL Epoch: 161 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1844
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566633
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310775
INFO:root:FL Epoch: 161 Norm Difference for worker 1844 is 1.002893
INFO:root:FL Epoch: 161 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.568570836501963 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.3721463978290558                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.880963
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634220
INFO:root:FL Epoch: 162 Norm Difference for worker 941 is 1.013608
INFO:root:FL Epoch: 162 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1390
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375837
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713191
INFO:root:FL Epoch: 162 Norm Difference for worker 1390 is 1.085933
INFO:root:FL Epoch: 162 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561988
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561425
INFO:root:FL Epoch: 162 Norm Difference for worker 1941 is 0.976582
INFO:root:FL Epoch: 162 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :884
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528799
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567021
INFO:root:FL Epoch: 162 Norm Difference for worker 884 is 1.080534
INFO:root:FL Epoch: 162 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :44
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 44 is 1.04531
INFO:root:FL Epoch: 162 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1585
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744175
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439909
INFO:root:FL Epoch: 162 Norm Difference for worker 1585 is 1.052714
INFO:root:FL Epoch: 162 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1081
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547516
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.776364
INFO:root:FL Epoch: 162 Norm Difference for worker 1081 is 1.11747
INFO:root:FL Epoch: 162 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1024
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704957
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490290
INFO:root:FL Epoch: 162 Norm Difference for worker 1024 is 1.010629
INFO:root:FL Epoch: 162 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1886
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541802
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405942
INFO:root:FL Epoch: 162 Norm Difference for worker 1886 is 1.06701
INFO:root:FL Epoch: 162 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1439
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683107
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627437
INFO:root:FL Epoch: 162 Norm Difference for worker 1439 is 1.081164
INFO:root:FL Epoch: 162 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1941
INFO:root:Norm of Aggregated Model: 5154.96630859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.5497327692368451 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.4979469031095505                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1559
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654958
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555448
INFO:root:FL Epoch: 163 Norm Difference for worker 1559 is 0.940973
INFO:root:FL Epoch: 163 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1487
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495898
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432932
INFO:root:FL Epoch: 163 Norm Difference for worker 1487 is 1.01654
INFO:root:FL Epoch: 163 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :359
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526160
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577048
INFO:root:FL Epoch: 163 Norm Difference for worker 359 is 0.890732
INFO:root:FL Epoch: 163 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1586
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619641
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588156
INFO:root:FL Epoch: 163 Norm Difference for worker 1586 is 0.911565
INFO:root:FL Epoch: 163 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1338
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423465
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561319
INFO:root:FL Epoch: 163 Norm Difference for worker 1338 is 0.871636
INFO:root:FL Epoch: 163 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1840
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614934
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433406
INFO:root:FL Epoch: 163 Norm Difference for worker 1840 is 0.944467
INFO:root:FL Epoch: 163 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :901
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489938
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364298
INFO:root:FL Epoch: 163 Norm Difference for worker 901 is 0.950015
INFO:root:FL Epoch: 163 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :711
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676257
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694394
INFO:root:FL Epoch: 163 Norm Difference for worker 711 is 0.964971
INFO:root:FL Epoch: 163 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1413
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591241
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550467
INFO:root:FL Epoch: 163 Norm Difference for worker 1413 is 0.970515
INFO:root:FL Epoch: 163 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :431
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557803
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540484
INFO:root:FL Epoch: 163 Norm Difference for worker 431 is 0.949131
INFO:root:FL Epoch: 163 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 163 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 163 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.5371062036822823 and Test Accuracy:75.0 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.5388484944899877                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 164 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1316
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534748
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747400
INFO:root:FL Epoch: 164 Norm Difference for worker 1316 is 0.932554
INFO:root:FL Epoch: 164 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :898
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375125
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606744
INFO:root:FL Epoch: 164 Norm Difference for worker 898 is 0.978423
INFO:root:FL Epoch: 164 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :465
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583453
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474237
INFO:root:FL Epoch: 164 Norm Difference for worker 465 is 1.03835
INFO:root:FL Epoch: 164 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :599
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586776
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423871
INFO:root:FL Epoch: 164 Norm Difference for worker 599 is 0.968874
INFO:root:FL Epoch: 164 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1822
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459769
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616498
INFO:root:FL Epoch: 164 Norm Difference for worker 1822 is 0.953537
INFO:root:FL Epoch: 164 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1634
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650113
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570608
INFO:root:FL Epoch: 164 Norm Difference for worker 1634 is 0.996397
INFO:root:FL Epoch: 164 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1455
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572406
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653108
INFO:root:FL Epoch: 164 Norm Difference for worker 1455 is 1.016708
INFO:root:FL Epoch: 164 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :250
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 250 is 1.000296
INFO:root:FL Epoch: 164 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :791
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623071
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378797
INFO:root:FL Epoch: 164 Norm Difference for worker 791 is 0.942834
INFO:root:FL Epoch: 164 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1388
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553297
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348838
INFO:root:FL Epoch: 164 Norm Difference for worker 1388 is 0.994018
INFO:root:FL Epoch: 164 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1822
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.5464930884978351 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.5543419470389684                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 165 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :1295
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657396
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404194
INFO:root:FL Epoch: 165 Norm Difference for worker 1295 is 0.961677
INFO:root:FL Epoch: 165 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1294
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453329
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539970
INFO:root:FL Epoch: 165 Norm Difference for worker 1294 is 0.991479
INFO:root:FL Epoch: 165 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1754
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425640
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564205
INFO:root:FL Epoch: 165 Norm Difference for worker 1754 is 0.931981
INFO:root:FL Epoch: 165 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :782
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495240
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711851
INFO:root:FL Epoch: 165 Norm Difference for worker 782 is 1.051975
INFO:root:FL Epoch: 165 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :108
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 108 is 0.952271
INFO:root:FL Epoch: 165 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1018
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558273
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481007
INFO:root:FL Epoch: 165 Norm Difference for worker 1018 is 0.946716
INFO:root:FL Epoch: 165 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :832
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636911
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515251
INFO:root:FL Epoch: 165 Norm Difference for worker 832 is 1.032576
INFO:root:FL Epoch: 165 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :133
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560070
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 133 is 0.95153
INFO:root:FL Epoch: 165 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :12
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552640
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 12 is 0.977059
INFO:root:FL Epoch: 165 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :34
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495566
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 34 is 0.960883
INFO:root:FL Epoch: 165 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 165 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 165 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.5424770239521476 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.5543354898691177                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 166 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :319
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620625
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 319 is 1.034769
INFO:root:FL Epoch: 166 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :958
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383309
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584672
INFO:root:FL Epoch: 166 Norm Difference for worker 958 is 1.057129
INFO:root:FL Epoch: 166 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1164
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508733
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406631
INFO:root:FL Epoch: 166 Norm Difference for worker 1164 is 1.136959
INFO:root:FL Epoch: 166 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :515
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501219
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464744
INFO:root:FL Epoch: 166 Norm Difference for worker 515 is 1.020692
INFO:root:FL Epoch: 166 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :688
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569897
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647914
INFO:root:FL Epoch: 166 Norm Difference for worker 688 is 1.0044
INFO:root:FL Epoch: 166 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1693
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655524
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341830
INFO:root:FL Epoch: 166 Norm Difference for worker 1693 is 1.011115
INFO:root:FL Epoch: 166 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1070
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710949
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517652
INFO:root:FL Epoch: 166 Norm Difference for worker 1070 is 1.062523
INFO:root:FL Epoch: 166 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1237
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537149
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396083
INFO:root:FL Epoch: 166 Norm Difference for worker 1237 is 1.004078
INFO:root:FL Epoch: 166 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1365
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749284
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439791
INFO:root:FL Epoch: 166 Norm Difference for worker 1365 is 1.024787
INFO:root:FL Epoch: 166 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :936
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676859
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431072
INFO:root:FL Epoch: 166 Norm Difference for worker 936 is 1.018329
INFO:root:FL Epoch: 166 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 688
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.5638959477929508 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.6848371227582296                             and Backdoor Test Accuracy:59.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :106
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645795
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491049
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 106 is 0.990441
INFO:root:FL Epoch: 167 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627553
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643204
INFO:root:FL Epoch: 167 Norm Difference for worker 755 is 0.991537
INFO:root:FL Epoch: 167 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :81
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 81 is 0.938653
INFO:root:FL Epoch: 167 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1241
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587297
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583206
INFO:root:FL Epoch: 167 Norm Difference for worker 1241 is 0.94117
INFO:root:FL Epoch: 167 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :665
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553537
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525556
INFO:root:FL Epoch: 167 Norm Difference for worker 665 is 0.986776
INFO:root:FL Epoch: 167 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1244
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501486
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578608
INFO:root:FL Epoch: 167 Norm Difference for worker 1244 is 1.007562
INFO:root:FL Epoch: 167 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617988
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729184
INFO:root:FL Epoch: 167 Norm Difference for worker 1755 is 0.978703
INFO:root:FL Epoch: 167 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1189
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593225
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579243
INFO:root:FL Epoch: 167 Norm Difference for worker 1189 is 0.933274
INFO:root:FL Epoch: 167 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :785
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465160
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346865
INFO:root:FL Epoch: 167 Norm Difference for worker 785 is 1.015514
INFO:root:FL Epoch: 167 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1463
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734803
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501314
INFO:root:FL Epoch: 167 Norm Difference for worker 1463 is 1.004093
INFO:root:FL Epoch: 167 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1241
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.5523105666917913 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.693142165740331                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1872
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484302
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565969
INFO:root:FL Epoch: 168 Norm Difference for worker 1872 is 1.027294
INFO:root:FL Epoch: 168 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1711
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705507
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636025
INFO:root:FL Epoch: 168 Norm Difference for worker 1711 is 1.00474
INFO:root:FL Epoch: 168 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :18
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.720219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 18 is 0.940007
INFO:root:FL Epoch: 168 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :202
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 202 is 0.999545
INFO:root:FL Epoch: 168 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591395
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 0.959701
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1782
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379647
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525367
INFO:root:FL Epoch: 168 Norm Difference for worker 1782 is 0.981509
INFO:root:FL Epoch: 168 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1869
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432872
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566941
INFO:root:FL Epoch: 168 Norm Difference for worker 1869 is 0.975746
INFO:root:FL Epoch: 168 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1830
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522850
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401170
INFO:root:FL Epoch: 168 Norm Difference for worker 1830 is 0.966552
INFO:root:FL Epoch: 168 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1197
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755147
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575422
INFO:root:FL Epoch: 168 Norm Difference for worker 1197 is 1.024174
INFO:root:FL Epoch: 168 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1476
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759071
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453784
INFO:root:FL Epoch: 168 Norm Difference for worker 1476 is 0.968804
INFO:root:FL Epoch: 168 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.5479076031376334 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.6254362861315409                             and Backdoor Test Accuracy:65.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 169 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :945
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730685
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312364
INFO:root:FL Epoch: 169 Norm Difference for worker 945 is 0.919681
INFO:root:FL Epoch: 169 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :273
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355279
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 273 is 0.967354
INFO:root:FL Epoch: 169 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1442
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632776
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661676
INFO:root:FL Epoch: 169 Norm Difference for worker 1442 is 0.916661
INFO:root:FL Epoch: 169 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :952
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779089
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674224
INFO:root:FL Epoch: 169 Norm Difference for worker 952 is 0.932045
INFO:root:FL Epoch: 169 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1360
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528404
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549056
INFO:root:FL Epoch: 169 Norm Difference for worker 1360 is 0.936805
INFO:root:FL Epoch: 169 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :854
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569651
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418953
INFO:root:FL Epoch: 169 Norm Difference for worker 854 is 1.032024
INFO:root:FL Epoch: 169 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :821
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579720
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538088
INFO:root:FL Epoch: 169 Norm Difference for worker 821 is 0.922812
INFO:root:FL Epoch: 169 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1782
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484378
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376799
INFO:root:FL Epoch: 169 Norm Difference for worker 1782 is 1.026918
INFO:root:FL Epoch: 169 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :807
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508168
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670267
INFO:root:FL Epoch: 169 Norm Difference for worker 807 is 1.075005
INFO:root:FL Epoch: 169 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :24
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 24 is 1.000974
INFO:root:FL Epoch: 169 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.5459621355814093 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.6796897153059641                             and Backdoor Test Accuracy:60.0 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :603
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686102
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528239
INFO:root:FL Epoch: 170 Norm Difference for worker 603 is 1.10854
INFO:root:FL Epoch: 170 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :40
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 40 is 1.117977
INFO:root:FL Epoch: 170 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1838
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432290
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592317
INFO:root:FL Epoch: 170 Norm Difference for worker 1838 is 1.145541
INFO:root:FL Epoch: 170 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :467
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669232
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465203
INFO:root:FL Epoch: 170 Norm Difference for worker 467 is 1.070233
INFO:root:FL Epoch: 170 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :350
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530527
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803651
INFO:root:FL Epoch: 170 Norm Difference for worker 350 is 1.227767
INFO:root:FL Epoch: 170 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :263
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 263 is 1.114553
INFO:root:FL Epoch: 170 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1301
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476664
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312272
INFO:root:FL Epoch: 170 Norm Difference for worker 1301 is 1.141718
INFO:root:FL Epoch: 170 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :833
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806721
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453623
INFO:root:FL Epoch: 170 Norm Difference for worker 833 is 1.115783
INFO:root:FL Epoch: 170 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :465
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471993
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589806
INFO:root:FL Epoch: 170 Norm Difference for worker 465 is 1.125257
INFO:root:FL Epoch: 170 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :863
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456350
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655245
INFO:root:FL Epoch: 170 Norm Difference for worker 863 is 1.1318
INFO:root:FL Epoch: 170 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 263
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.5389276655281291 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.8326115906238556                             and Backdoor Test Accuracy:43.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499814
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525987
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.4288209428389867 Backdoor Test Accuracy: 81.66666666666667
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.4032642275094986 Backdoor Train Accuracy: 83.0
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.353149
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551123
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377000
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.4308090607325236 Backdoor Test Accuracy: 81.66666666666667
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.40333864390850066 Backdoor Train Accuracy: 83.0
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 0.353584
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543321
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510150
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.42632531623045605 Backdoor Test Accuracy: 82.5
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.40351189076900484 Backdoor Train Accuracy: 83.5
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 0.357276
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :694
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533099
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450285
INFO:root:FL Epoch: 171 Norm Difference for worker 694 is 0.901492
INFO:root:FL Epoch: 171 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1305
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611984
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588004
INFO:root:FL Epoch: 171 Norm Difference for worker 1305 is 0.971003
INFO:root:FL Epoch: 171 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1063
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802565
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543495
INFO:root:FL Epoch: 171 Norm Difference for worker 1063 is 0.969014
INFO:root:FL Epoch: 171 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1767
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525731
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518710
INFO:root:FL Epoch: 171 Norm Difference for worker 1767 is 0.925804
INFO:root:FL Epoch: 171 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :318
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.739498
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 318 is 0.924878
INFO:root:FL Epoch: 171 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :760
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582835
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511299
INFO:root:FL Epoch: 171 Norm Difference for worker 760 is 0.903486
INFO:root:FL Epoch: 171 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1876
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534189
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705902
INFO:root:FL Epoch: 171 Norm Difference for worker 1876 is 0.930075
INFO:root:FL Epoch: 171 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 171 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 171 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.5405095938374015 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.4288209428389867                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1003
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529668
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576923
INFO:root:FL Epoch: 172 Norm Difference for worker 1003 is 1.002567
INFO:root:FL Epoch: 172 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :375
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624815
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505016
INFO:root:FL Epoch: 172 Norm Difference for worker 375 is 1.081188
INFO:root:FL Epoch: 172 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :966
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747370
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546010
INFO:root:FL Epoch: 172 Norm Difference for worker 966 is 1.069824
INFO:root:FL Epoch: 172 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :334
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.784798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419248
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 334 is 0.973561
INFO:root:FL Epoch: 172 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :312
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 312 is 0.967471
INFO:root:FL Epoch: 172 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1747
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591356
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483636
INFO:root:FL Epoch: 172 Norm Difference for worker 1747 is 1.012908
INFO:root:FL Epoch: 172 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1294
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493854
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418226
INFO:root:FL Epoch: 172 Norm Difference for worker 1294 is 1.061581
INFO:root:FL Epoch: 172 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :737
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600974
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492783
INFO:root:FL Epoch: 172 Norm Difference for worker 737 is 0.991594
INFO:root:FL Epoch: 172 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1064
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588772
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763092
INFO:root:FL Epoch: 172 Norm Difference for worker 1064 is 1.049083
INFO:root:FL Epoch: 172 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1392
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540362
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489848
INFO:root:FL Epoch: 172 Norm Difference for worker 1392 is 0.997347
INFO:root:FL Epoch: 172 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 334
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.5313391825732063 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.6164065500100454                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1721
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627505
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339430
INFO:root:FL Epoch: 173 Norm Difference for worker 1721 is 1.027953
INFO:root:FL Epoch: 173 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1093
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664010
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647081
INFO:root:FL Epoch: 173 Norm Difference for worker 1093 is 1.070754
INFO:root:FL Epoch: 173 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1173
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717081
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418356
INFO:root:FL Epoch: 173 Norm Difference for worker 1173 is 1.00967
INFO:root:FL Epoch: 173 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :968
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459294
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541414
INFO:root:FL Epoch: 173 Norm Difference for worker 968 is 1.093113
INFO:root:FL Epoch: 173 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :270
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 270 is 1.06381
INFO:root:FL Epoch: 173 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :894
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409909
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575764
INFO:root:FL Epoch: 173 Norm Difference for worker 894 is 1.098075
INFO:root:FL Epoch: 173 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :594
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776443
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589196
INFO:root:FL Epoch: 173 Norm Difference for worker 594 is 1.159378
INFO:root:FL Epoch: 173 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1009
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558550
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531586
INFO:root:FL Epoch: 173 Norm Difference for worker 1009 is 1.089571
INFO:root:FL Epoch: 173 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1378
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609874
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636763
INFO:root:FL Epoch: 173 Norm Difference for worker 1378 is 1.078007
INFO:root:FL Epoch: 173 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :906
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752805
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.784721
INFO:root:FL Epoch: 173 Norm Difference for worker 906 is 1.076072
INFO:root:FL Epoch: 173 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1173
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.5361688522731557 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.6386140386263529                             and Backdoor Test Accuracy:65.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 174 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :1667
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467230
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626001
INFO:root:FL Epoch: 174 Norm Difference for worker 1667 is 1.251885
INFO:root:FL Epoch: 174 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :907
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641279
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740473
INFO:root:FL Epoch: 174 Norm Difference for worker 907 is 1.171031
INFO:root:FL Epoch: 174 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1313
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448341
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461885
INFO:root:FL Epoch: 174 Norm Difference for worker 1313 is 1.173846
INFO:root:FL Epoch: 174 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :522
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486826
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529890
INFO:root:FL Epoch: 174 Norm Difference for worker 522 is 1.212789
INFO:root:FL Epoch: 174 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :913
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417829
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683518
INFO:root:FL Epoch: 174 Norm Difference for worker 913 is 1.301594
INFO:root:FL Epoch: 174 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1260
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619308
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.774639
INFO:root:FL Epoch: 174 Norm Difference for worker 1260 is 1.17231
INFO:root:FL Epoch: 174 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1683
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793506
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578148
INFO:root:FL Epoch: 174 Norm Difference for worker 1683 is 1.205276
INFO:root:FL Epoch: 174 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :925
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421035
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451529
INFO:root:FL Epoch: 174 Norm Difference for worker 925 is 1.091659
INFO:root:FL Epoch: 174 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1459
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581784
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.795888
INFO:root:FL Epoch: 174 Norm Difference for worker 1459 is 1.276106
INFO:root:FL Epoch: 174 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1264
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798546
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502033
INFO:root:FL Epoch: 174 Norm Difference for worker 1264 is 1.181951
INFO:root:FL Epoch: 174 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.5317023291307337 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.6617352863152822                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464123
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555473
INFO:root:FL Epoch: 175 Norm Difference for worker 850 is 1.197087
INFO:root:FL Epoch: 175 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856433
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578095
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 1.208616
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1212
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422184
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435344
INFO:root:FL Epoch: 175 Norm Difference for worker 1212 is 1.068889
INFO:root:FL Epoch: 175 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1570
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409929
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463289
INFO:root:FL Epoch: 175 Norm Difference for worker 1570 is 1.204966
INFO:root:FL Epoch: 175 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :305
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 305 is 1.125747
INFO:root:FL Epoch: 175 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1197
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685568
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689026
INFO:root:FL Epoch: 175 Norm Difference for worker 1197 is 1.311113
INFO:root:FL Epoch: 175 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1169
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358375
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417618
INFO:root:FL Epoch: 175 Norm Difference for worker 1169 is 1.254807
INFO:root:FL Epoch: 175 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1057
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572275
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466217
INFO:root:FL Epoch: 175 Norm Difference for worker 1057 is 1.176387
INFO:root:FL Epoch: 175 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1584
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690452
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502632
INFO:root:FL Epoch: 175 Norm Difference for worker 1584 is 1.143088
INFO:root:FL Epoch: 175 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1528
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317951
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578917
INFO:root:FL Epoch: 175 Norm Difference for worker 1528 is 1.05179
INFO:root:FL Epoch: 175 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1212
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.517754316329956 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.6472204377253851                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :637
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654068
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404036
INFO:root:FL Epoch: 176 Norm Difference for worker 637 is 1.268506
INFO:root:FL Epoch: 176 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1889
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427620
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411005
INFO:root:FL Epoch: 176 Norm Difference for worker 1889 is 1.149044
INFO:root:FL Epoch: 176 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :528
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 1.088656
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398489
INFO:root:FL Epoch: 176 Norm Difference for worker 528 is 1.249754
INFO:root:FL Epoch: 176 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1101
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640281
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426642
INFO:root:FL Epoch: 176 Norm Difference for worker 1101 is 1.182243
INFO:root:FL Epoch: 176 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1673
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445495
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417642
INFO:root:FL Epoch: 176 Norm Difference for worker 1673 is 1.147498
INFO:root:FL Epoch: 176 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :974
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624355
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536745
INFO:root:FL Epoch: 176 Norm Difference for worker 974 is 1.220403
INFO:root:FL Epoch: 176 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1233
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646394
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487454
INFO:root:FL Epoch: 176 Norm Difference for worker 1233 is 1.270765
INFO:root:FL Epoch: 176 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :787
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760594
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553976
INFO:root:FL Epoch: 176 Norm Difference for worker 787 is 1.18008
INFO:root:FL Epoch: 176 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :977
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560859
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739295
INFO:root:FL Epoch: 176 Norm Difference for worker 977 is 1.240079
INFO:root:FL Epoch: 176 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :516
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738677
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460984
INFO:root:FL Epoch: 176 Norm Difference for worker 516 is 1.204876
INFO:root:FL Epoch: 176 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1101
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.5297880593468162 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.6458521137634913                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :313
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401296
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 313 is 1.038578
INFO:root:FL Epoch: 177 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :908
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759510
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467562
INFO:root:FL Epoch: 177 Norm Difference for worker 908 is 1.044052
INFO:root:FL Epoch: 177 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :557
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604406
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524904
INFO:root:FL Epoch: 177 Norm Difference for worker 557 is 1.00816
INFO:root:FL Epoch: 177 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :881
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507742
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478180
INFO:root:FL Epoch: 177 Norm Difference for worker 881 is 1.040327
INFO:root:FL Epoch: 177 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1256
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826322
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571959
INFO:root:FL Epoch: 177 Norm Difference for worker 1256 is 1.052543
INFO:root:FL Epoch: 177 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :539
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877514
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499263
INFO:root:FL Epoch: 177 Norm Difference for worker 539 is 1.123285
INFO:root:FL Epoch: 177 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 1.058681
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :220
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 220 is 0.990534
INFO:root:FL Epoch: 177 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :342
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591821
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595942
INFO:root:FL Epoch: 177 Norm Difference for worker 342 is 1.027901
INFO:root:FL Epoch: 177 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1936
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354498
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528038
INFO:root:FL Epoch: 177 Norm Difference for worker 1936 is 1.094245
INFO:root:FL Epoch: 177 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.966796875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 177 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 177 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.53123679932426 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.5653917193412781                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :1855
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539400
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624874
INFO:root:FL Epoch: 178 Norm Difference for worker 1855 is 1.056584
INFO:root:FL Epoch: 178 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :418
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422316
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376417
INFO:root:FL Epoch: 178 Norm Difference for worker 418 is 1.053556
INFO:root:FL Epoch: 178 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1550
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529780
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691393
INFO:root:FL Epoch: 178 Norm Difference for worker 1550 is 1.140361
INFO:root:FL Epoch: 178 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1800
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679596
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707522
INFO:root:FL Epoch: 178 Norm Difference for worker 1800 is 1.055958
INFO:root:FL Epoch: 178 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1189
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516580
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533547
INFO:root:FL Epoch: 178 Norm Difference for worker 1189 is 1.057175
INFO:root:FL Epoch: 178 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :611
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661793
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624812
INFO:root:FL Epoch: 178 Norm Difference for worker 611 is 1.101706
INFO:root:FL Epoch: 178 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :325
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 325 is 1.108036
INFO:root:FL Epoch: 178 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :983
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790005
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444458
INFO:root:FL Epoch: 178 Norm Difference for worker 983 is 1.158689
INFO:root:FL Epoch: 178 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573682
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605626
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.073403
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609666
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 0.994622
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.5369154968682457 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.672342985868454                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1226
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964997
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486832
INFO:root:FL Epoch: 179 Norm Difference for worker 1226 is 1.025689
INFO:root:FL Epoch: 179 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1285
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535902
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315215
INFO:root:FL Epoch: 179 Norm Difference for worker 1285 is 1.02756
INFO:root:FL Epoch: 179 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :972
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495121
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484283
INFO:root:FL Epoch: 179 Norm Difference for worker 972 is 1.073184
INFO:root:FL Epoch: 179 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :393
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710546
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565810
INFO:root:FL Epoch: 179 Norm Difference for worker 393 is 0.995713
INFO:root:FL Epoch: 179 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :977
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553534
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481736
INFO:root:FL Epoch: 179 Norm Difference for worker 977 is 1.008533
INFO:root:FL Epoch: 179 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :59
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410461
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 59 is 1.00843
INFO:root:FL Epoch: 179 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :575
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691837
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564682
INFO:root:FL Epoch: 179 Norm Difference for worker 575 is 1.025129
INFO:root:FL Epoch: 179 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :472
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538725
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460544
INFO:root:FL Epoch: 179 Norm Difference for worker 472 is 1.012973
INFO:root:FL Epoch: 179 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1689
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498285
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595216
INFO:root:FL Epoch: 179 Norm Difference for worker 1689 is 1.067225
INFO:root:FL Epoch: 179 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :565
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571492
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331168
INFO:root:FL Epoch: 179 Norm Difference for worker 565 is 1.042785
INFO:root:FL Epoch: 179 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 472
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.5507958268418032 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.583485354979833                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1850
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477713
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475439
INFO:root:FL Epoch: 180 Norm Difference for worker 1850 is 1.039539
INFO:root:FL Epoch: 180 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :989
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723888
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469239
INFO:root:FL Epoch: 180 Norm Difference for worker 989 is 1.050188
INFO:root:FL Epoch: 180 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :611
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491611
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480650
INFO:root:FL Epoch: 180 Norm Difference for worker 611 is 1.041904
INFO:root:FL Epoch: 180 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :637
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717895
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490947
INFO:root:FL Epoch: 180 Norm Difference for worker 637 is 1.081067
INFO:root:FL Epoch: 180 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1690
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537993
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537023
INFO:root:FL Epoch: 180 Norm Difference for worker 1690 is 1.059783
INFO:root:FL Epoch: 180 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1250
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674672
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389641
INFO:root:FL Epoch: 180 Norm Difference for worker 1250 is 0.998006
INFO:root:FL Epoch: 180 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :844
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337716
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329145
INFO:root:FL Epoch: 180 Norm Difference for worker 844 is 1.007915
INFO:root:FL Epoch: 180 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1444
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658476
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454686
INFO:root:FL Epoch: 180 Norm Difference for worker 1444 is 1.01287
INFO:root:FL Epoch: 180 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :120
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613394
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 120 is 1.000725
INFO:root:FL Epoch: 180 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :134
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 134 is 0.958002
INFO:root:FL Epoch: 180 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 134
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.5654427531887504 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.6583823213974634                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589578
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382764
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.35213147352139157 Backdoor Test Accuracy: 85.83333333333333
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.35362489223480226 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.308968
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.216092
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309590
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.3592737689614296 Backdoor Test Accuracy: 85.83333333333333
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.352139613032341 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.30365
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587540
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373403
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.3527532418568929 Backdoor Test Accuracy: 85.83333333333333
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.3503833904862404 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.312689
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :869
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542841
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391372
INFO:root:FL Epoch: 181 Norm Difference for worker 869 is 1.147139
INFO:root:FL Epoch: 181 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :716
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399951
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482090
INFO:root:FL Epoch: 181 Norm Difference for worker 716 is 1.169674
INFO:root:FL Epoch: 181 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1560
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497793
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485788
INFO:root:FL Epoch: 181 Norm Difference for worker 1560 is 1.116697
INFO:root:FL Epoch: 181 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :623
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656498
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531698
INFO:root:FL Epoch: 181 Norm Difference for worker 623 is 1.234994
INFO:root:FL Epoch: 181 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1018
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505992
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532651
INFO:root:FL Epoch: 181 Norm Difference for worker 1018 is 1.198798
INFO:root:FL Epoch: 181 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :195
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 195 is 1.314429
INFO:root:FL Epoch: 181 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1034
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636155
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416396
INFO:root:FL Epoch: 181 Norm Difference for worker 1034 is 1.132617
INFO:root:FL Epoch: 181 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.550937179256888 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.3592737689614296                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1201
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535497
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403416
INFO:root:FL Epoch: 182 Norm Difference for worker 1201 is 1.17173
INFO:root:FL Epoch: 182 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1052
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404592
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.760606
INFO:root:FL Epoch: 182 Norm Difference for worker 1052 is 1.208253
INFO:root:FL Epoch: 182 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :959
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489566
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379879
INFO:root:FL Epoch: 182 Norm Difference for worker 959 is 1.203112
INFO:root:FL Epoch: 182 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1624
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417796
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583904
INFO:root:FL Epoch: 182 Norm Difference for worker 1624 is 1.242266
INFO:root:FL Epoch: 182 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :825
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577764
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456511
INFO:root:FL Epoch: 182 Norm Difference for worker 825 is 1.126225
INFO:root:FL Epoch: 182 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1782
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366198
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394319
INFO:root:FL Epoch: 182 Norm Difference for worker 1782 is 1.249239
INFO:root:FL Epoch: 182 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :488
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392641
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492045
INFO:root:FL Epoch: 182 Norm Difference for worker 488 is 1.145517
INFO:root:FL Epoch: 182 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :507
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722920
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384625
INFO:root:FL Epoch: 182 Norm Difference for worker 507 is 1.225627
INFO:root:FL Epoch: 182 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1078
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462082
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763375
INFO:root:FL Epoch: 182 Norm Difference for worker 1078 is 1.199727
INFO:root:FL Epoch: 182 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1849
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419731
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405612
INFO:root:FL Epoch: 182 Norm Difference for worker 1849 is 1.177154
INFO:root:FL Epoch: 182 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.5656418221838334 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.35967275003592175                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1215
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540131
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402768
INFO:root:FL Epoch: 183 Norm Difference for worker 1215 is 1.154153
INFO:root:FL Epoch: 183 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1520
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341635
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353081
INFO:root:FL Epoch: 183 Norm Difference for worker 1520 is 1.155094
INFO:root:FL Epoch: 183 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :630
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481787
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502217
INFO:root:FL Epoch: 183 Norm Difference for worker 630 is 1.204969
INFO:root:FL Epoch: 183 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :563
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595766
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532947
INFO:root:FL Epoch: 183 Norm Difference for worker 563 is 1.169497
INFO:root:FL Epoch: 183 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404405
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 1.125781
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1104
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528748
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803750
INFO:root:FL Epoch: 183 Norm Difference for worker 1104 is 1.254296
INFO:root:FL Epoch: 183 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1522
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420927
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366274
INFO:root:FL Epoch: 183 Norm Difference for worker 1522 is 1.168592
INFO:root:FL Epoch: 183 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1754
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799690
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445753
INFO:root:FL Epoch: 183 Norm Difference for worker 1754 is 1.132896
INFO:root:FL Epoch: 183 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :48
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 48 is 1.117599
INFO:root:FL Epoch: 183 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1604
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723337
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479870
INFO:root:FL Epoch: 183 Norm Difference for worker 1604 is 1.176497
INFO:root:FL Epoch: 183 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.5356659766505746 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.3886751780907313                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1775
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761118
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530074
INFO:root:FL Epoch: 184 Norm Difference for worker 1775 is 0.983444
INFO:root:FL Epoch: 184 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1560
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705777
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488773
INFO:root:FL Epoch: 184 Norm Difference for worker 1560 is 1.010086
INFO:root:FL Epoch: 184 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1234
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593936
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514816
INFO:root:FL Epoch: 184 Norm Difference for worker 1234 is 1.060933
INFO:root:FL Epoch: 184 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1381
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.939739
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574201
INFO:root:FL Epoch: 184 Norm Difference for worker 1381 is 1.01337
INFO:root:FL Epoch: 184 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1244
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480825
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413092
INFO:root:FL Epoch: 184 Norm Difference for worker 1244 is 1.009423
INFO:root:FL Epoch: 184 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1478
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359630
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265024
INFO:root:FL Epoch: 184 Norm Difference for worker 1478 is 0.99273
INFO:root:FL Epoch: 184 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1887
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462584
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443264
INFO:root:FL Epoch: 184 Norm Difference for worker 1887 is 0.952944
INFO:root:FL Epoch: 184 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :825
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430116
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359748
INFO:root:FL Epoch: 184 Norm Difference for worker 825 is 0.988835
INFO:root:FL Epoch: 184 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :202
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 202 is 1.121079
INFO:root:FL Epoch: 184 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :471
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373115
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389166
INFO:root:FL Epoch: 184 Norm Difference for worker 471 is 1.07462
INFO:root:FL Epoch: 184 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.542694372289321 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.49128683904806775                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1656
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332931
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465688
INFO:root:FL Epoch: 185 Norm Difference for worker 1656 is 1.09581
INFO:root:FL Epoch: 185 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1518
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570771
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477547
INFO:root:FL Epoch: 185 Norm Difference for worker 1518 is 1.117192
INFO:root:FL Epoch: 185 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1088
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586495
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599701
INFO:root:FL Epoch: 185 Norm Difference for worker 1088 is 1.080935
INFO:root:FL Epoch: 185 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :559
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614336
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703984
INFO:root:FL Epoch: 185 Norm Difference for worker 559 is 1.09887
INFO:root:FL Epoch: 185 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :487
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611597
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476473
INFO:root:FL Epoch: 185 Norm Difference for worker 487 is 1.090548
INFO:root:FL Epoch: 185 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :317
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771443
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 317 is 1.130104
INFO:root:FL Epoch: 185 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1080
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828587
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561849
INFO:root:FL Epoch: 185 Norm Difference for worker 1080 is 1.147982
INFO:root:FL Epoch: 185 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.749861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 1.107063
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1146
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501128
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733967
INFO:root:FL Epoch: 185 Norm Difference for worker 1146 is 1.168569
INFO:root:FL Epoch: 185 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.569304
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 1.133939
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.536670553333619 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.47448114057381946                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738031
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443485
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.097299
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :785
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719400
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582804
INFO:root:FL Epoch: 186 Norm Difference for worker 785 is 1.112033
INFO:root:FL Epoch: 186 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :663
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465207
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440605
INFO:root:FL Epoch: 186 Norm Difference for worker 663 is 1.035285
INFO:root:FL Epoch: 186 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1530
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569065
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396365
INFO:root:FL Epoch: 186 Norm Difference for worker 1530 is 1.079608
INFO:root:FL Epoch: 186 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :738
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550080
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479739
INFO:root:FL Epoch: 186 Norm Difference for worker 738 is 1.098754
INFO:root:FL Epoch: 186 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :128
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.344447
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 128 is 1.098775
INFO:root:FL Epoch: 186 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1070
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498588
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342204
INFO:root:FL Epoch: 186 Norm Difference for worker 1070 is 1.083765
INFO:root:FL Epoch: 186 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :823
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381861
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258318
INFO:root:FL Epoch: 186 Norm Difference for worker 823 is 1.109198
INFO:root:FL Epoch: 186 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :385
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437740
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.774858
INFO:root:FL Epoch: 186 Norm Difference for worker 385 is 1.084094
INFO:root:FL Epoch: 186 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :503
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473068
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398108
INFO:root:FL Epoch: 186 Norm Difference for worker 503 is 1.057842
INFO:root:FL Epoch: 186 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 663
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.5398055262425366 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.5317108829816183                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 187 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :301
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 301 is 0.906652
INFO:root:FL Epoch: 187 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :277
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488623
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 277 is 0.908406
INFO:root:FL Epoch: 187 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :269
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 269 is 1.000751
INFO:root:FL Epoch: 187 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1198
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545385
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508207
INFO:root:FL Epoch: 187 Norm Difference for worker 1198 is 0.87525
INFO:root:FL Epoch: 187 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :545
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393326
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318151
INFO:root:FL Epoch: 187 Norm Difference for worker 545 is 0.89471
INFO:root:FL Epoch: 187 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1043
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735236
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583507
INFO:root:FL Epoch: 187 Norm Difference for worker 1043 is 0.991497
INFO:root:FL Epoch: 187 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :766
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507975
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414280
INFO:root:FL Epoch: 187 Norm Difference for worker 766 is 0.929069
INFO:root:FL Epoch: 187 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :736
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568360
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520258
INFO:root:FL Epoch: 187 Norm Difference for worker 736 is 0.990083
INFO:root:FL Epoch: 187 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :458
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474619
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557602
INFO:root:FL Epoch: 187 Norm Difference for worker 458 is 1.06366
INFO:root:FL Epoch: 187 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1218
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600475
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452562
INFO:root:FL Epoch: 187 Norm Difference for worker 1218 is 1.005776
INFO:root:FL Epoch: 187 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1198
INFO:root:Norm of Aggregated Model: 5154.96728515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.5457609015352586 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.5431183179219564                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 188 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :1848
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611443
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473511
INFO:root:FL Epoch: 188 Norm Difference for worker 1848 is 1.010577
INFO:root:FL Epoch: 188 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :77
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 77 is 1.007233
INFO:root:FL Epoch: 188 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1719
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557335
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382980
INFO:root:FL Epoch: 188 Norm Difference for worker 1719 is 0.982983
INFO:root:FL Epoch: 188 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :49
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 49 is 1.012092
INFO:root:FL Epoch: 188 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :382
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804207
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540787
INFO:root:FL Epoch: 188 Norm Difference for worker 382 is 0.998297
INFO:root:FL Epoch: 188 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :721
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543355
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424736
INFO:root:FL Epoch: 188 Norm Difference for worker 721 is 0.97807
INFO:root:FL Epoch: 188 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1690
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598626
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572653
INFO:root:FL Epoch: 188 Norm Difference for worker 1690 is 1.019239
INFO:root:FL Epoch: 188 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1774
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517098
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376431
INFO:root:FL Epoch: 188 Norm Difference for worker 1774 is 0.91651
INFO:root:FL Epoch: 188 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1927
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580319
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485872
INFO:root:FL Epoch: 188 Norm Difference for worker 1927 is 0.981699
INFO:root:FL Epoch: 188 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :433
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541942
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452701
INFO:root:FL Epoch: 188 Norm Difference for worker 433 is 1.019978
INFO:root:FL Epoch: 188 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1774
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.5310692681985743 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.47241751352945965                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :486
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442634
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448714
INFO:root:FL Epoch: 189 Norm Difference for worker 486 is 0.947392
INFO:root:FL Epoch: 189 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1170
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527054
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603313
INFO:root:FL Epoch: 189 Norm Difference for worker 1170 is 1.006258
INFO:root:FL Epoch: 189 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1606
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672542
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353627
INFO:root:FL Epoch: 189 Norm Difference for worker 1606 is 1.018249
INFO:root:FL Epoch: 189 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1307
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669659
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527542
INFO:root:FL Epoch: 189 Norm Difference for worker 1307 is 0.990516
INFO:root:FL Epoch: 189 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :901
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549153
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510761
INFO:root:FL Epoch: 189 Norm Difference for worker 901 is 0.986417
INFO:root:FL Epoch: 189 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :556
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628609
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667815
INFO:root:FL Epoch: 189 Norm Difference for worker 556 is 1.017535
INFO:root:FL Epoch: 189 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :740
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307673
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440221
INFO:root:FL Epoch: 189 Norm Difference for worker 740 is 0.99028
INFO:root:FL Epoch: 189 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :927
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416005
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394364
INFO:root:FL Epoch: 189 Norm Difference for worker 927 is 0.96535
INFO:root:FL Epoch: 189 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :270
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 270 is 1.034174
INFO:root:FL Epoch: 189 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :488
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473152
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601261
INFO:root:FL Epoch: 189 Norm Difference for worker 488 is 1.027615
INFO:root:FL Epoch: 189 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 927
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.5328326014911428 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.515377456943194                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :256
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496718
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 256 is 1.274518
INFO:root:FL Epoch: 190 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :751
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703556
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477981
INFO:root:FL Epoch: 190 Norm Difference for worker 751 is 1.142065
INFO:root:FL Epoch: 190 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1156
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802616
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583618
INFO:root:FL Epoch: 190 Norm Difference for worker 1156 is 1.194122
INFO:root:FL Epoch: 190 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1330
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568816
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486429
INFO:root:FL Epoch: 190 Norm Difference for worker 1330 is 1.25132
INFO:root:FL Epoch: 190 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :859
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566270
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487229
INFO:root:FL Epoch: 190 Norm Difference for worker 859 is 1.22128
INFO:root:FL Epoch: 190 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :257
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 257 is 1.258277
INFO:root:FL Epoch: 190 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1432
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564196
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357840
INFO:root:FL Epoch: 190 Norm Difference for worker 1432 is 1.233657
INFO:root:FL Epoch: 190 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741115
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375273
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 1.238276
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1730
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488454
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624036
INFO:root:FL Epoch: 190 Norm Difference for worker 1730 is 1.231195
INFO:root:FL Epoch: 190 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :608
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483328
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559537
INFO:root:FL Epoch: 190 Norm Difference for worker 608 is 1.152337
INFO:root:FL Epoch: 190 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 751
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.5048536658287048 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.5283081630865732                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284335
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437229
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.32737698405981064 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.36455888450145724 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.26324
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486315
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509354
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.32822298010190326 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.36479137241840365 Backdoor Train Accuracy: 85.5
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.263238
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472071
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452173
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.326801598072052 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.3642471134662628 Backdoor Train Accuracy: 86.0
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.266329
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1898
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488579
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546183
INFO:root:FL Epoch: 191 Norm Difference for worker 1898 is 1.13537
INFO:root:FL Epoch: 191 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414855
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393174
INFO:root:FL Epoch: 191 Norm Difference for worker 555 is 1.05237
INFO:root:FL Epoch: 191 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :925
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318198
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296617
INFO:root:FL Epoch: 191 Norm Difference for worker 925 is 0.962586
INFO:root:FL Epoch: 191 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :113
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 113 is 1.103297
INFO:root:FL Epoch: 191 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1363
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748967
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562726
INFO:root:FL Epoch: 191 Norm Difference for worker 1363 is 1.116302
INFO:root:FL Epoch: 191 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1837
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666186
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487411
INFO:root:FL Epoch: 191 Norm Difference for worker 1837 is 1.113052
INFO:root:FL Epoch: 191 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :781
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542241
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411559
INFO:root:FL Epoch: 191 Norm Difference for worker 781 is 1.086988
INFO:root:FL Epoch: 191 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 191 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 191 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.5055110892828774 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.32737698405981064                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :562
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583171
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503166
INFO:root:FL Epoch: 192 Norm Difference for worker 562 is 1.098841
INFO:root:FL Epoch: 192 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1742
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445551
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749695
INFO:root:FL Epoch: 192 Norm Difference for worker 1742 is 1.202929
INFO:root:FL Epoch: 192 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :947
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516107
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455805
INFO:root:FL Epoch: 192 Norm Difference for worker 947 is 1.08196
INFO:root:FL Epoch: 192 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :406
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458150
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271095
INFO:root:FL Epoch: 192 Norm Difference for worker 406 is 1.180145
INFO:root:FL Epoch: 192 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1259
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521274
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404980
INFO:root:FL Epoch: 192 Norm Difference for worker 1259 is 1.109209
INFO:root:FL Epoch: 192 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :390
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672327
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407921
INFO:root:FL Epoch: 192 Norm Difference for worker 390 is 1.230267
INFO:root:FL Epoch: 192 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1140
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394231
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584812
INFO:root:FL Epoch: 192 Norm Difference for worker 1140 is 1.187401
INFO:root:FL Epoch: 192 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1411
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556991
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441695
INFO:root:FL Epoch: 192 Norm Difference for worker 1411 is 1.092594
INFO:root:FL Epoch: 192 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :66
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 66 is 1.174111
INFO:root:FL Epoch: 192 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :468
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656810
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404328
INFO:root:FL Epoch: 192 Norm Difference for worker 468 is 1.104352
INFO:root:FL Epoch: 192 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1411
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.5177271821919609 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.45387916763623554                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1614
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.971300
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579569
INFO:root:FL Epoch: 193 Norm Difference for worker 1614 is 1.030807
INFO:root:FL Epoch: 193 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :504
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448965
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382450
INFO:root:FL Epoch: 193 Norm Difference for worker 504 is 0.984221
INFO:root:FL Epoch: 193 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1022
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287558
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363150
INFO:root:FL Epoch: 193 Norm Difference for worker 1022 is 0.886628
INFO:root:FL Epoch: 193 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :580
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619596
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570709
INFO:root:FL Epoch: 193 Norm Difference for worker 580 is 0.993261
INFO:root:FL Epoch: 193 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1730
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808034
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460740
INFO:root:FL Epoch: 193 Norm Difference for worker 1730 is 0.997461
INFO:root:FL Epoch: 193 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :828
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475856
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588235
INFO:root:FL Epoch: 193 Norm Difference for worker 828 is 1.059792
INFO:root:FL Epoch: 193 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1619
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546650
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579039
INFO:root:FL Epoch: 193 Norm Difference for worker 1619 is 0.947291
INFO:root:FL Epoch: 193 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1205
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557798
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449452
INFO:root:FL Epoch: 193 Norm Difference for worker 1205 is 0.970357
INFO:root:FL Epoch: 193 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :511
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723699
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547596
INFO:root:FL Epoch: 193 Norm Difference for worker 511 is 0.993314
INFO:root:FL Epoch: 193 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1270
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773809
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418585
INFO:root:FL Epoch: 193 Norm Difference for worker 1270 is 0.885864
INFO:root:FL Epoch: 193 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.5116447543396669 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.47796806196371716                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 135 is 1.169575
INFO:root:FL Epoch: 194 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1532
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627746
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320809
INFO:root:FL Epoch: 194 Norm Difference for worker 1532 is 1.045603
INFO:root:FL Epoch: 194 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1525
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.199644
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510704
INFO:root:FL Epoch: 194 Norm Difference for worker 1525 is 1.087157
INFO:root:FL Epoch: 194 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :103
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587039
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 103 is 1.144504
INFO:root:FL Epoch: 194 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1790
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492063
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375787
INFO:root:FL Epoch: 194 Norm Difference for worker 1790 is 1.066409
INFO:root:FL Epoch: 194 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :752
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531569
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509506
INFO:root:FL Epoch: 194 Norm Difference for worker 752 is 1.108944
INFO:root:FL Epoch: 194 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :784
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505578
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417528
INFO:root:FL Epoch: 194 Norm Difference for worker 784 is 1.122938
INFO:root:FL Epoch: 194 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :630
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553067
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437367
INFO:root:FL Epoch: 194 Norm Difference for worker 630 is 1.152101
INFO:root:FL Epoch: 194 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1283
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569125
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477523
INFO:root:FL Epoch: 194 Norm Difference for worker 1283 is 1.092539
INFO:root:FL Epoch: 194 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1290
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462655
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650361
INFO:root:FL Epoch: 194 Norm Difference for worker 1290 is 1.099542
INFO:root:FL Epoch: 194 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1532
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.5238614397890428 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.5017017225424448                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :926
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446363
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290932
INFO:root:FL Epoch: 195 Norm Difference for worker 926 is 1.09853
INFO:root:FL Epoch: 195 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :191
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 191 is 1.16113
INFO:root:FL Epoch: 195 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1426
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312528
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401154
INFO:root:FL Epoch: 195 Norm Difference for worker 1426 is 1.134132
INFO:root:FL Epoch: 195 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :261
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 261 is 1.118644
INFO:root:FL Epoch: 195 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :874
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595689
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456554
INFO:root:FL Epoch: 195 Norm Difference for worker 874 is 1.201044
INFO:root:FL Epoch: 195 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :700
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441059
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278134
INFO:root:FL Epoch: 195 Norm Difference for worker 700 is 1.119474
INFO:root:FL Epoch: 195 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :7
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.783907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 7 is 1.169582
INFO:root:FL Epoch: 195 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :301
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 301 is 1.157891
INFO:root:FL Epoch: 195 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :502
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550584
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480616
INFO:root:FL Epoch: 195 Norm Difference for worker 502 is 1.119316
INFO:root:FL Epoch: 195 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1471
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539076
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652046
INFO:root:FL Epoch: 195 Norm Difference for worker 1471 is 1.141729
INFO:root:FL Epoch: 195 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.5541506707668304 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.7184235354264578                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :437
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548757
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481656
INFO:root:FL Epoch: 196 Norm Difference for worker 437 is 1.089009
INFO:root:FL Epoch: 196 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.339140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 1.141947
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1524
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619391
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664550
INFO:root:FL Epoch: 196 Norm Difference for worker 1524 is 1.131914
INFO:root:FL Epoch: 196 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :130
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562127
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 130 is 1.128047
INFO:root:FL Epoch: 196 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :478
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537629
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670249
INFO:root:FL Epoch: 196 Norm Difference for worker 478 is 1.257263
INFO:root:FL Epoch: 196 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :911
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468713
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638551
INFO:root:FL Epoch: 196 Norm Difference for worker 911 is 1.151471
INFO:root:FL Epoch: 196 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1227
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452779
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360700
INFO:root:FL Epoch: 196 Norm Difference for worker 1227 is 1.096781
INFO:root:FL Epoch: 196 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1529
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611608
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450922
INFO:root:FL Epoch: 196 Norm Difference for worker 1529 is 1.122316
INFO:root:FL Epoch: 196 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1567
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534723
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671338
INFO:root:FL Epoch: 196 Norm Difference for worker 1567 is 1.245074
INFO:root:FL Epoch: 196 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :633
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537856
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444138
INFO:root:FL Epoch: 196 Norm Difference for worker 633 is 1.103207
INFO:root:FL Epoch: 196 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 130
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.5318547925528359 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.5038688778877258                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1836
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490601
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658711
INFO:root:FL Epoch: 197 Norm Difference for worker 1836 is 0.974392
INFO:root:FL Epoch: 197 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1738
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538939
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689240
INFO:root:FL Epoch: 197 Norm Difference for worker 1738 is 0.988373
INFO:root:FL Epoch: 197 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :552
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495628
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412769
INFO:root:FL Epoch: 197 Norm Difference for worker 552 is 0.985063
INFO:root:FL Epoch: 197 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356657
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 0.952143
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1244
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689460
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369136
INFO:root:FL Epoch: 197 Norm Difference for worker 1244 is 1.007473
INFO:root:FL Epoch: 197 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :932
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665559
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408261
INFO:root:FL Epoch: 197 Norm Difference for worker 932 is 0.975589
INFO:root:FL Epoch: 197 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1049
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736368
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555995
INFO:root:FL Epoch: 197 Norm Difference for worker 1049 is 0.940982
INFO:root:FL Epoch: 197 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1589
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.949057
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511087
INFO:root:FL Epoch: 197 Norm Difference for worker 1589 is 1.017913
INFO:root:FL Epoch: 197 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :208
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577472
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 208 is 1.014631
INFO:root:FL Epoch: 197 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :677
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390754
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494877
INFO:root:FL Epoch: 197 Norm Difference for worker 677 is 0.973436
INFO:root:FL Epoch: 197 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.5358115417115829 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.662979930639267                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :1491
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645372
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299539
INFO:root:FL Epoch: 198 Norm Difference for worker 1491 is 0.917903
INFO:root:FL Epoch: 198 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1790
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443433
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621206
INFO:root:FL Epoch: 198 Norm Difference for worker 1790 is 0.903832
INFO:root:FL Epoch: 198 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1639
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451285
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386209
INFO:root:FL Epoch: 198 Norm Difference for worker 1639 is 0.944147
INFO:root:FL Epoch: 198 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1719
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501001
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614884
INFO:root:FL Epoch: 198 Norm Difference for worker 1719 is 0.978299
INFO:root:FL Epoch: 198 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :448
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532856
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509380
INFO:root:FL Epoch: 198 Norm Difference for worker 448 is 0.930371
INFO:root:FL Epoch: 198 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1768
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423473
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482651
INFO:root:FL Epoch: 198 Norm Difference for worker 1768 is 0.933553
INFO:root:FL Epoch: 198 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1077
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485891
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426237
INFO:root:FL Epoch: 198 Norm Difference for worker 1077 is 0.959642
INFO:root:FL Epoch: 198 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1215
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649442
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540582
INFO:root:FL Epoch: 198 Norm Difference for worker 1215 is 0.93546
INFO:root:FL Epoch: 198 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1640
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371846
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742249
INFO:root:FL Epoch: 198 Norm Difference for worker 1640 is 0.929693
INFO:root:FL Epoch: 198 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1128
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650998
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445298
INFO:root:FL Epoch: 198 Norm Difference for worker 1128 is 0.927304
INFO:root:FL Epoch: 198 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1128
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.5296164873768302 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.5135609904925028                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :180
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541829
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 180 is 1.01765
INFO:root:FL Epoch: 199 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1879
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614797
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673096
INFO:root:FL Epoch: 199 Norm Difference for worker 1879 is 1.02484
INFO:root:FL Epoch: 199 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1185
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746619
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582609
INFO:root:FL Epoch: 199 Norm Difference for worker 1185 is 1.028286
INFO:root:FL Epoch: 199 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :280
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 280 is 0.910419
INFO:root:FL Epoch: 199 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1055
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651156
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397846
INFO:root:FL Epoch: 199 Norm Difference for worker 1055 is 0.987032
INFO:root:FL Epoch: 199 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1690
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561192
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518641
INFO:root:FL Epoch: 199 Norm Difference for worker 1690 is 1.020369
INFO:root:FL Epoch: 199 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :722
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373113
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490952
INFO:root:FL Epoch: 199 Norm Difference for worker 722 is 1.009977
INFO:root:FL Epoch: 199 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :933
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543244
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484229
INFO:root:FL Epoch: 199 Norm Difference for worker 933 is 0.972619
INFO:root:FL Epoch: 199 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1874
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321495
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503869
INFO:root:FL Epoch: 199 Norm Difference for worker 1874 is 0.964986
INFO:root:FL Epoch: 199 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1457
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460970
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582984
INFO:root:FL Epoch: 199 Norm Difference for worker 1457 is 1.011182
INFO:root:FL Epoch: 199 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 280
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.5150646865367889 and Test Accuracy:75.0 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.5398301581541697                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :487
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430179
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514317
INFO:root:FL Epoch: 200 Norm Difference for worker 487 is 0.881895
INFO:root:FL Epoch: 200 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :707
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655585
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594500
INFO:root:FL Epoch: 200 Norm Difference for worker 707 is 1.00413
INFO:root:FL Epoch: 200 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :38
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 38 is 0.999084
INFO:root:FL Epoch: 200 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :996
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440006
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426752
INFO:root:FL Epoch: 200 Norm Difference for worker 996 is 1.008695
INFO:root:FL Epoch: 200 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1140
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603575
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378120
INFO:root:FL Epoch: 200 Norm Difference for worker 1140 is 0.994517
INFO:root:FL Epoch: 200 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1706
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508435
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524069
INFO:root:FL Epoch: 200 Norm Difference for worker 1706 is 0.965926
INFO:root:FL Epoch: 200 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :765
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505372
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414418
INFO:root:FL Epoch: 200 Norm Difference for worker 765 is 1.054497
INFO:root:FL Epoch: 200 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1194
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640812
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494815
INFO:root:FL Epoch: 200 Norm Difference for worker 1194 is 1.048213
INFO:root:FL Epoch: 200 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1234
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622371
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497004
INFO:root:FL Epoch: 200 Norm Difference for worker 1234 is 1.063636
INFO:root:FL Epoch: 200 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1892
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576241
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618098
INFO:root:FL Epoch: 200 Norm Difference for worker 1892 is 0.990599
INFO:root:FL Epoch: 200 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.5274768419125501 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.6288334627946218                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503429
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272272
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.25690911958614987 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.3294942244887352 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.327577
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346433
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314804
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.2908860668540001 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.3237006515264511 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.309258
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482984
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474175
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.25201282898585003 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.3302067548036575 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.333581
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1449
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629822
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452175
INFO:root:FL Epoch: 201 Norm Difference for worker 1449 is 1.263635
INFO:root:FL Epoch: 201 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1835
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637824
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670527
INFO:root:FL Epoch: 201 Norm Difference for worker 1835 is 1.312754
INFO:root:FL Epoch: 201 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1755
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546816
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515577
INFO:root:FL Epoch: 201 Norm Difference for worker 1755 is 1.130777
INFO:root:FL Epoch: 201 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :22
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 22 is 1.153519
INFO:root:FL Epoch: 201 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1640
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472310
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451753
INFO:root:FL Epoch: 201 Norm Difference for worker 1640 is 1.10167
INFO:root:FL Epoch: 201 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :544
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793863
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372978
INFO:root:FL Epoch: 201 Norm Difference for worker 544 is 1.302503
INFO:root:FL Epoch: 201 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :122
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554404
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 122 is 1.149682
INFO:root:FL Epoch: 201 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.511659282095292 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.2908860668540001                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1483
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636041
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343757
INFO:root:FL Epoch: 202 Norm Difference for worker 1483 is 1.319507
INFO:root:FL Epoch: 202 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :377
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640373
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469418
INFO:root:FL Epoch: 202 Norm Difference for worker 377 is 1.223444
INFO:root:FL Epoch: 202 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :300
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 300 is 1.268808
INFO:root:FL Epoch: 202 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :982
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388252
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528463
INFO:root:FL Epoch: 202 Norm Difference for worker 982 is 1.201707
INFO:root:FL Epoch: 202 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :93
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 93 is 1.298743
INFO:root:FL Epoch: 202 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1665
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684424
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618853
INFO:root:FL Epoch: 202 Norm Difference for worker 1665 is 1.241376
INFO:root:FL Epoch: 202 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1168
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576030
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493977
INFO:root:FL Epoch: 202 Norm Difference for worker 1168 is 1.22284
INFO:root:FL Epoch: 202 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :351
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526845
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343000
INFO:root:FL Epoch: 202 Norm Difference for worker 351 is 1.189145
INFO:root:FL Epoch: 202 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :124
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 124 is 1.298866
INFO:root:FL Epoch: 202 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1314
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483746
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240366
INFO:root:FL Epoch: 202 Norm Difference for worker 1314 is 1.194363
INFO:root:FL Epoch: 202 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 982
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.5456145265523125 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.37768640617529553                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1790
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524513
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464159
INFO:root:FL Epoch: 203 Norm Difference for worker 1790 is 0.966068
INFO:root:FL Epoch: 203 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1275
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568259
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457226
INFO:root:FL Epoch: 203 Norm Difference for worker 1275 is 1.038488
INFO:root:FL Epoch: 203 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1712
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531833
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655049
INFO:root:FL Epoch: 203 Norm Difference for worker 1712 is 1.085765
INFO:root:FL Epoch: 203 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :594
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860232
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545411
INFO:root:FL Epoch: 203 Norm Difference for worker 594 is 1.0624
INFO:root:FL Epoch: 203 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :256
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.348670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 256 is 1.05724
INFO:root:FL Epoch: 203 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1075
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691942
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425262
INFO:root:FL Epoch: 203 Norm Difference for worker 1075 is 1.059811
INFO:root:FL Epoch: 203 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1770
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494772
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413671
INFO:root:FL Epoch: 203 Norm Difference for worker 1770 is 1.063926
INFO:root:FL Epoch: 203 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1543
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680053
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630498
INFO:root:FL Epoch: 203 Norm Difference for worker 1543 is 1.051866
INFO:root:FL Epoch: 203 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :483
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818386
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551449
INFO:root:FL Epoch: 203 Norm Difference for worker 483 is 1.063255
INFO:root:FL Epoch: 203 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :433
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461176
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524591
INFO:root:FL Epoch: 203 Norm Difference for worker 433 is 1.071538
INFO:root:FL Epoch: 203 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1790
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.5511248935671413 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.5140548447767893                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :643
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716379
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516820
INFO:root:FL Epoch: 204 Norm Difference for worker 643 is 1.063697
INFO:root:FL Epoch: 204 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :796
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537012
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408615
INFO:root:FL Epoch: 204 Norm Difference for worker 796 is 1.048179
INFO:root:FL Epoch: 204 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1743
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557192
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550384
INFO:root:FL Epoch: 204 Norm Difference for worker 1743 is 1.035801
INFO:root:FL Epoch: 204 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1572
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539385
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393465
INFO:root:FL Epoch: 204 Norm Difference for worker 1572 is 0.965185
INFO:root:FL Epoch: 204 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :644
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375014
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630559
INFO:root:FL Epoch: 204 Norm Difference for worker 644 is 1.108847
INFO:root:FL Epoch: 204 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :893
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502989
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581273
INFO:root:FL Epoch: 204 Norm Difference for worker 893 is 1.012287
INFO:root:FL Epoch: 204 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :307
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 307 is 1.067071
INFO:root:FL Epoch: 204 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1460
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504804
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383088
INFO:root:FL Epoch: 204 Norm Difference for worker 1460 is 1.011916
INFO:root:FL Epoch: 204 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1890
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620744
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375580
INFO:root:FL Epoch: 204 Norm Difference for worker 1890 is 1.028273
INFO:root:FL Epoch: 204 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :179
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 179 is 1.09403
INFO:root:FL Epoch: 204 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1572
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.5477066741270178 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.4911020447810491                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1646
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615477
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492123
INFO:root:FL Epoch: 205 Norm Difference for worker 1646 is 1.029603
INFO:root:FL Epoch: 205 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488887
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 1.014526
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :498
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577244
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503206
INFO:root:FL Epoch: 205 Norm Difference for worker 498 is 1.045894
INFO:root:FL Epoch: 205 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :132
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 132 is 1.027853
INFO:root:FL Epoch: 205 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400901
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403635
INFO:root:FL Epoch: 205 Norm Difference for worker 1171 is 1.005066
INFO:root:FL Epoch: 205 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :587
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402335
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518636
INFO:root:FL Epoch: 205 Norm Difference for worker 587 is 0.998628
INFO:root:FL Epoch: 205 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1921
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612544
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440937
INFO:root:FL Epoch: 205 Norm Difference for worker 1921 is 1.056878
INFO:root:FL Epoch: 205 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1482
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402384
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330547
INFO:root:FL Epoch: 205 Norm Difference for worker 1482 is 0.933171
INFO:root:FL Epoch: 205 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :230
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 230 is 0.994608
INFO:root:FL Epoch: 205 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1399
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674508
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445551
INFO:root:FL Epoch: 205 Norm Difference for worker 1399 is 1.0447
INFO:root:FL Epoch: 205 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.558741478358998 and Test Accuracy:70.0 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.599607119957606                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 206 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :118
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290720
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 118 is 1.106517
INFO:root:FL Epoch: 206 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1272
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659833
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.890293
INFO:root:FL Epoch: 206 Norm Difference for worker 1272 is 1.082013
INFO:root:FL Epoch: 206 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1114
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514910
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521435
INFO:root:FL Epoch: 206 Norm Difference for worker 1114 is 1.133875
INFO:root:FL Epoch: 206 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :236
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 236 is 1.171935
INFO:root:FL Epoch: 206 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500699
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639323
INFO:root:FL Epoch: 206 Norm Difference for worker 1838 is 1.129962
INFO:root:FL Epoch: 206 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1835
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585843
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439642
INFO:root:FL Epoch: 206 Norm Difference for worker 1835 is 1.105935
INFO:root:FL Epoch: 206 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :460
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433716
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479255
INFO:root:FL Epoch: 206 Norm Difference for worker 460 is 1.096214
INFO:root:FL Epoch: 206 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1482
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440435
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381168
INFO:root:FL Epoch: 206 Norm Difference for worker 1482 is 0.85559
INFO:root:FL Epoch: 206 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :289
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429145
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460837
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 289 is 1.058429
INFO:root:FL Epoch: 206 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :329
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 329 is 1.082991
INFO:root:FL Epoch: 206 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5655744601698482 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.5394305636485418                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1442
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969054
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447143
INFO:root:FL Epoch: 207 Norm Difference for worker 1442 is 1.498547
INFO:root:FL Epoch: 207 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1664
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339923
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481009
INFO:root:FL Epoch: 207 Norm Difference for worker 1664 is 1.334918
INFO:root:FL Epoch: 207 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :483
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799783
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597669
INFO:root:FL Epoch: 207 Norm Difference for worker 483 is 1.347071
INFO:root:FL Epoch: 207 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :754
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707102
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338921
INFO:root:FL Epoch: 207 Norm Difference for worker 754 is 1.284754
INFO:root:FL Epoch: 207 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :166
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.946506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 166 is 1.426981
INFO:root:FL Epoch: 207 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1570
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556641
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505830
INFO:root:FL Epoch: 207 Norm Difference for worker 1570 is 1.453023
INFO:root:FL Epoch: 207 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :541
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524985
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421790
INFO:root:FL Epoch: 207 Norm Difference for worker 541 is 1.436584
INFO:root:FL Epoch: 207 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1604
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467190
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284882
INFO:root:FL Epoch: 207 Norm Difference for worker 1604 is 1.445099
INFO:root:FL Epoch: 207 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :800
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830266
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455528
INFO:root:FL Epoch: 207 Norm Difference for worker 800 is 1.455488
INFO:root:FL Epoch: 207 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :277
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 277 is 1.372662
INFO:root:FL Epoch: 207 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 754
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.5484354881679311 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.5631351619958878                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1406
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768847
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420738
INFO:root:FL Epoch: 208 Norm Difference for worker 1406 is 1.378766
INFO:root:FL Epoch: 208 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :774
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605280
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445404
INFO:root:FL Epoch: 208 Norm Difference for worker 774 is 1.241588
INFO:root:FL Epoch: 208 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :854
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575668
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483598
INFO:root:FL Epoch: 208 Norm Difference for worker 854 is 1.329535
INFO:root:FL Epoch: 208 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1449
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563079
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481981
INFO:root:FL Epoch: 208 Norm Difference for worker 1449 is 1.29271
INFO:root:FL Epoch: 208 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :741
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739074
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377655
INFO:root:FL Epoch: 208 Norm Difference for worker 741 is 1.319486
INFO:root:FL Epoch: 208 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :740
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386664
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513348
INFO:root:FL Epoch: 208 Norm Difference for worker 740 is 1.26258
INFO:root:FL Epoch: 208 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1869
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737436
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316487
INFO:root:FL Epoch: 208 Norm Difference for worker 1869 is 1.190164
INFO:root:FL Epoch: 208 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1080
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563155
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607508
INFO:root:FL Epoch: 208 Norm Difference for worker 1080 is 1.446257
INFO:root:FL Epoch: 208 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1637
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672635
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380434
INFO:root:FL Epoch: 208 Norm Difference for worker 1637 is 1.20352
INFO:root:FL Epoch: 208 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1546
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593408
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526300
INFO:root:FL Epoch: 208 Norm Difference for worker 1546 is 1.293887
INFO:root:FL Epoch: 208 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.5417111901675954 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.5501544624567032                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1904
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595452
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518626
INFO:root:FL Epoch: 209 Norm Difference for worker 1904 is 1.080293
INFO:root:FL Epoch: 209 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1753
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464221
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470472
INFO:root:FL Epoch: 209 Norm Difference for worker 1753 is 0.955008
INFO:root:FL Epoch: 209 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1821
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629898
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496287
INFO:root:FL Epoch: 209 Norm Difference for worker 1821 is 1.027376
INFO:root:FL Epoch: 209 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1207
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588593
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478406
INFO:root:FL Epoch: 209 Norm Difference for worker 1207 is 1.018507
INFO:root:FL Epoch: 209 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :9
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 9 is 1.060344
INFO:root:FL Epoch: 209 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1378
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436543
INFO:root:FL Epoch: 209 Norm Difference for worker 1378 is 1.110695
INFO:root:FL Epoch: 209 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :211
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.788338
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 211 is 1.061864
INFO:root:FL Epoch: 209 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :883
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604084
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611206
INFO:root:FL Epoch: 209 Norm Difference for worker 883 is 1.096672
INFO:root:FL Epoch: 209 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :876
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474898
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399762
INFO:root:FL Epoch: 209 Norm Difference for worker 876 is 1.013306
INFO:root:FL Epoch: 209 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :812
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550572
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591499
INFO:root:FL Epoch: 209 Norm Difference for worker 812 is 1.056173
INFO:root:FL Epoch: 209 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5571415722370148 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.49147019783655804                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :321
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 321 is 1.224098
INFO:root:FL Epoch: 210 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :758
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580030
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394494
INFO:root:FL Epoch: 210 Norm Difference for worker 758 is 1.149282
INFO:root:FL Epoch: 210 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :550
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609705
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405455
INFO:root:FL Epoch: 210 Norm Difference for worker 550 is 1.140041
INFO:root:FL Epoch: 210 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1387
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431801
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336544
INFO:root:FL Epoch: 210 Norm Difference for worker 1387 is 1.131691
INFO:root:FL Epoch: 210 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1806
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807583
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658543
INFO:root:FL Epoch: 210 Norm Difference for worker 1806 is 1.158749
INFO:root:FL Epoch: 210 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655047
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318185
INFO:root:FL Epoch: 210 Norm Difference for worker 760 is 1.115045
INFO:root:FL Epoch: 210 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :316
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.241162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 316 is 1.138826
INFO:root:FL Epoch: 210 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1694
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467078
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495359
INFO:root:FL Epoch: 210 Norm Difference for worker 1694 is 1.221781
INFO:root:FL Epoch: 210 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :937
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567697
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455007
INFO:root:FL Epoch: 210 Norm Difference for worker 937 is 1.12448
INFO:root:FL Epoch: 210 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1178
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738814
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501039
INFO:root:FL Epoch: 210 Norm Difference for worker 1178 is 1.207895
INFO:root:FL Epoch: 210 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 760
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.5540884996161741 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.39918843905131024                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349379
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225780
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.2913670837879181 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.31784017831087114 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.242593
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367753
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478473
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.30342510094245273 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.31697031706571577 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.245297
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632217
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333055
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.30200032889842987 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.3173054024577141 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.244602
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1428
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475458
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448305
INFO:root:FL Epoch: 211 Norm Difference for worker 1428 is 1.155895
INFO:root:FL Epoch: 211 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :391
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655096
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487341
INFO:root:FL Epoch: 211 Norm Difference for worker 391 is 1.081442
INFO:root:FL Epoch: 211 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1560
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664246
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624870
INFO:root:FL Epoch: 211 Norm Difference for worker 1560 is 1.104337
INFO:root:FL Epoch: 211 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1489
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593224
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474344
INFO:root:FL Epoch: 211 Norm Difference for worker 1489 is 1.218328
INFO:root:FL Epoch: 211 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :106
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.840888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 106 is 1.10069
INFO:root:FL Epoch: 211 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :729
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715879
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466354
INFO:root:FL Epoch: 211 Norm Difference for worker 729 is 1.143379
INFO:root:FL Epoch: 211 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1080
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673609
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544994
INFO:root:FL Epoch: 211 Norm Difference for worker 1080 is 1.168048
INFO:root:FL Epoch: 211 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5557722712264341 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.30200032889842987                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :850
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520639
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566547
INFO:root:FL Epoch: 212 Norm Difference for worker 850 is 1.164755
INFO:root:FL Epoch: 212 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1190
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751053
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452756
INFO:root:FL Epoch: 212 Norm Difference for worker 1190 is 0.991817
INFO:root:FL Epoch: 212 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :991
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 1.125699
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553469
INFO:root:FL Epoch: 212 Norm Difference for worker 991 is 1.18346
INFO:root:FL Epoch: 212 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :137
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 137 is 1.105638
INFO:root:FL Epoch: 212 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1175
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554131
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542632
INFO:root:FL Epoch: 212 Norm Difference for worker 1175 is 1.194114
INFO:root:FL Epoch: 212 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1765
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576347
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441456
INFO:root:FL Epoch: 212 Norm Difference for worker 1765 is 1.141938
INFO:root:FL Epoch: 212 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1107
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485067
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504191
INFO:root:FL Epoch: 212 Norm Difference for worker 1107 is 1.140491
INFO:root:FL Epoch: 212 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :415
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421437
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503115
INFO:root:FL Epoch: 212 Norm Difference for worker 415 is 1.133655
INFO:root:FL Epoch: 212 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1168
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521641
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532529
INFO:root:FL Epoch: 212 Norm Difference for worker 1168 is 1.082308
INFO:root:FL Epoch: 212 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :123
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.893602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 123 is 1.14158
INFO:root:FL Epoch: 212 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.550848019473693 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.33350716531276703                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1125
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583111
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552936
INFO:root:FL Epoch: 213 Norm Difference for worker 1125 is 1.128275
INFO:root:FL Epoch: 213 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :873
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614032
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649755
INFO:root:FL Epoch: 213 Norm Difference for worker 873 is 1.161185
INFO:root:FL Epoch: 213 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1501
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635179
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666748
INFO:root:FL Epoch: 213 Norm Difference for worker 1501 is 1.130822
INFO:root:FL Epoch: 213 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1370
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782539
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454082
INFO:root:FL Epoch: 213 Norm Difference for worker 1370 is 1.153011
INFO:root:FL Epoch: 213 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1513
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376824
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492253
INFO:root:FL Epoch: 213 Norm Difference for worker 1513 is 1.090235
INFO:root:FL Epoch: 213 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :744
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406953
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393715
INFO:root:FL Epoch: 213 Norm Difference for worker 744 is 1.161393
INFO:root:FL Epoch: 213 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :533
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462315
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542245
INFO:root:FL Epoch: 213 Norm Difference for worker 533 is 1.224348
INFO:root:FL Epoch: 213 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1237
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644476
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489002
INFO:root:FL Epoch: 213 Norm Difference for worker 1237 is 1.156491
INFO:root:FL Epoch: 213 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1929
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.236844
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382827
INFO:root:FL Epoch: 213 Norm Difference for worker 1929 is 1.023975
INFO:root:FL Epoch: 213 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1117
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526979
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621213
INFO:root:FL Epoch: 213 Norm Difference for worker 1117 is 1.11512
INFO:root:FL Epoch: 213 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5432049649603227 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.33049261818329495                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1192
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624784
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448396
INFO:root:FL Epoch: 214 Norm Difference for worker 1192 is 1.110965
INFO:root:FL Epoch: 214 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1056
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674330
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557520
INFO:root:FL Epoch: 214 Norm Difference for worker 1056 is 1.112677
INFO:root:FL Epoch: 214 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :257
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595102
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 257 is 1.148656
INFO:root:FL Epoch: 214 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :852
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539064
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600824
INFO:root:FL Epoch: 214 Norm Difference for worker 852 is 1.162658
INFO:root:FL Epoch: 214 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1024
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554501
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410169
INFO:root:FL Epoch: 214 Norm Difference for worker 1024 is 1.093504
INFO:root:FL Epoch: 214 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1453
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636327
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409437
INFO:root:FL Epoch: 214 Norm Difference for worker 1453 is 1.111661
INFO:root:FL Epoch: 214 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1392
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554136
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446233
INFO:root:FL Epoch: 214 Norm Difference for worker 1392 is 1.041299
INFO:root:FL Epoch: 214 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1700
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489311
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475622
INFO:root:FL Epoch: 214 Norm Difference for worker 1700 is 1.087749
INFO:root:FL Epoch: 214 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :203
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 203 is 1.169989
INFO:root:FL Epoch: 214 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :661
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620327
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285072
INFO:root:FL Epoch: 214 Norm Difference for worker 661 is 1.112708
INFO:root:FL Epoch: 214 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1392
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5345225772436928 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.4134673724571864                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :408
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511348
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507130
INFO:root:FL Epoch: 215 Norm Difference for worker 408 is 1.102783
INFO:root:FL Epoch: 215 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1362
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457942
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277457
INFO:root:FL Epoch: 215 Norm Difference for worker 1362 is 1.052455
INFO:root:FL Epoch: 215 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :158
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.776133
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 158 is 1.150567
INFO:root:FL Epoch: 215 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :368
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637441
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508562
INFO:root:FL Epoch: 215 Norm Difference for worker 368 is 1.191438
INFO:root:FL Epoch: 215 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :468
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512341
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675493
INFO:root:FL Epoch: 215 Norm Difference for worker 468 is 1.073718
INFO:root:FL Epoch: 215 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1463
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584803
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722579
INFO:root:FL Epoch: 215 Norm Difference for worker 1463 is 1.249264
INFO:root:FL Epoch: 215 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :341
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435188
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473948
INFO:root:FL Epoch: 215 Norm Difference for worker 341 is 1.214448
INFO:root:FL Epoch: 215 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1793
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730054
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665355
INFO:root:FL Epoch: 215 Norm Difference for worker 1793 is 1.182485
INFO:root:FL Epoch: 215 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :609
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688501
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589776
INFO:root:FL Epoch: 215 Norm Difference for worker 609 is 1.219512
INFO:root:FL Epoch: 215 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :594
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641806
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780018
INFO:root:FL Epoch: 215 Norm Difference for worker 594 is 1.219102
INFO:root:FL Epoch: 215 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1362
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5460983725155101 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.38200855751832324                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1256
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825992
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502664
INFO:root:FL Epoch: 216 Norm Difference for worker 1256 is 1.109188
INFO:root:FL Epoch: 216 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1698
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750163
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545340
INFO:root:FL Epoch: 216 Norm Difference for worker 1698 is 1.107576
INFO:root:FL Epoch: 216 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :318
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 318 is 1.095529
INFO:root:FL Epoch: 216 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1075
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424425
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472501
INFO:root:FL Epoch: 216 Norm Difference for worker 1075 is 1.103337
INFO:root:FL Epoch: 216 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :427
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642569
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308804
INFO:root:FL Epoch: 216 Norm Difference for worker 427 is 1.063811
INFO:root:FL Epoch: 216 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :895
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607324
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590884
INFO:root:FL Epoch: 216 Norm Difference for worker 895 is 1.162684
INFO:root:FL Epoch: 216 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1686
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419975
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413712
INFO:root:FL Epoch: 216 Norm Difference for worker 1686 is 1.113598
INFO:root:FL Epoch: 216 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :939
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556629
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359725
INFO:root:FL Epoch: 216 Norm Difference for worker 939 is 1.065974
INFO:root:FL Epoch: 216 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1008
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600695
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593329
INFO:root:FL Epoch: 216 Norm Difference for worker 1008 is 1.198418
INFO:root:FL Epoch: 216 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1785
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489652
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519260
INFO:root:FL Epoch: 216 Norm Difference for worker 1785 is 1.173948
INFO:root:FL Epoch: 216 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.5602372954873478 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.5607411712408066                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :795
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701134
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409032
INFO:root:FL Epoch: 217 Norm Difference for worker 795 is 0.920216
INFO:root:FL Epoch: 217 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1488
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464599
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407965
INFO:root:FL Epoch: 217 Norm Difference for worker 1488 is 0.946952
INFO:root:FL Epoch: 217 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :830
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348710
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415985
INFO:root:FL Epoch: 217 Norm Difference for worker 830 is 0.986075
INFO:root:FL Epoch: 217 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1412
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484677
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381436
INFO:root:FL Epoch: 217 Norm Difference for worker 1412 is 0.99586
INFO:root:FL Epoch: 217 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1025
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445870
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459871
INFO:root:FL Epoch: 217 Norm Difference for worker 1025 is 0.989903
INFO:root:FL Epoch: 217 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543474
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355762
INFO:root:FL Epoch: 217 Norm Difference for worker 1652 is 0.999993
INFO:root:FL Epoch: 217 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :631
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473821
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453831
INFO:root:FL Epoch: 217 Norm Difference for worker 631 is 1.042182
INFO:root:FL Epoch: 217 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1898
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635886
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403981
INFO:root:FL Epoch: 217 Norm Difference for worker 1898 is 1.014282
INFO:root:FL Epoch: 217 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :872
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592332
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565176
INFO:root:FL Epoch: 217 Norm Difference for worker 872 is 0.982891
INFO:root:FL Epoch: 217 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :698
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470462
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636470
INFO:root:FL Epoch: 217 Norm Difference for worker 698 is 1.003843
INFO:root:FL Epoch: 217 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.9677734375
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.5883460185107063 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.6523764530817667                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1823
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681572
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537344
INFO:root:FL Epoch: 218 Norm Difference for worker 1823 is 1.100378
INFO:root:FL Epoch: 218 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :16
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 16 is 1.096575
INFO:root:FL Epoch: 218 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1683
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404594
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510288
INFO:root:FL Epoch: 218 Norm Difference for worker 1683 is 1.056005
INFO:root:FL Epoch: 218 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1802
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632394
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388774
INFO:root:FL Epoch: 218 Norm Difference for worker 1802 is 1.080946
INFO:root:FL Epoch: 218 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :663
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668920
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566384
INFO:root:FL Epoch: 218 Norm Difference for worker 663 is 1.032464
INFO:root:FL Epoch: 218 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1406
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675013
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596053
INFO:root:FL Epoch: 218 Norm Difference for worker 1406 is 1.111373
INFO:root:FL Epoch: 218 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1358
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328729
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497258
INFO:root:FL Epoch: 218 Norm Difference for worker 1358 is 1.005665
INFO:root:FL Epoch: 218 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :240
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 240 is 1.076932
INFO:root:FL Epoch: 218 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :101
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 101 is 1.072189
INFO:root:FL Epoch: 218 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1363
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570987
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343948
INFO:root:FL Epoch: 218 Norm Difference for worker 1363 is 1.081026
INFO:root:FL Epoch: 218 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1358
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.5396587059778326 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.4266209105650584                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 219 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :185
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477137
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 185 is 1.034307
INFO:root:FL Epoch: 219 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1693
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541831
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451400
INFO:root:FL Epoch: 219 Norm Difference for worker 1693 is 1.014133
INFO:root:FL Epoch: 219 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :737
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536364
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531887
INFO:root:FL Epoch: 219 Norm Difference for worker 737 is 0.969509
INFO:root:FL Epoch: 219 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1553
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391508
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645880
INFO:root:FL Epoch: 219 Norm Difference for worker 1553 is 1.015593
INFO:root:FL Epoch: 219 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :560
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691225
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522566
INFO:root:FL Epoch: 219 Norm Difference for worker 560 is 1.026011
INFO:root:FL Epoch: 219 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1190
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341959
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285844
INFO:root:FL Epoch: 219 Norm Difference for worker 1190 is 0.898048
INFO:root:FL Epoch: 219 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :926
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408080
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287884
INFO:root:FL Epoch: 219 Norm Difference for worker 926 is 0.932359
INFO:root:FL Epoch: 219 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :912
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598020
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648304
INFO:root:FL Epoch: 219 Norm Difference for worker 912 is 1.029469
INFO:root:FL Epoch: 219 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469090
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581268
INFO:root:FL Epoch: 219 Norm Difference for worker 1477 is 1.000245
INFO:root:FL Epoch: 219 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :173
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455112
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 173 is 1.102315
INFO:root:FL Epoch: 219 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.5538626085309422 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.4105394234259923                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1326
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363394
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803186
INFO:root:FL Epoch: 220 Norm Difference for worker 1326 is 1.395883
INFO:root:FL Epoch: 220 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :919
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429112
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672256
INFO:root:FL Epoch: 220 Norm Difference for worker 919 is 1.342326
INFO:root:FL Epoch: 220 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1829
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592275
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386454
INFO:root:FL Epoch: 220 Norm Difference for worker 1829 is 1.247975
INFO:root:FL Epoch: 220 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1536
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661439
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451616
INFO:root:FL Epoch: 220 Norm Difference for worker 1536 is 1.365654
INFO:root:FL Epoch: 220 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1533
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737660
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557146
INFO:root:FL Epoch: 220 Norm Difference for worker 1533 is 1.401366
INFO:root:FL Epoch: 220 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1562
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582080
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446741
INFO:root:FL Epoch: 220 Norm Difference for worker 1562 is 1.356055
INFO:root:FL Epoch: 220 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :524
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530030
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315027
INFO:root:FL Epoch: 220 Norm Difference for worker 524 is 1.229757
INFO:root:FL Epoch: 220 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :652
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376073
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574820
INFO:root:FL Epoch: 220 Norm Difference for worker 652 is 1.295954
INFO:root:FL Epoch: 220 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1778
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805935
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397860
INFO:root:FL Epoch: 220 Norm Difference for worker 1778 is 1.308602
INFO:root:FL Epoch: 220 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :59
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.806575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680676
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 59 is 1.322191
INFO:root:FL Epoch: 220 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 524
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.561127971200382 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.388933186729749                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408451
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414923
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.22932297984759012 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.2705458402633667 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.262903
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367816
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430350
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.24289279927810034 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.2660941883921623 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.26433
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295290
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418426
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.24776572734117508 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.26991923451423644 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.250065
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :316
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 316 is 1.26659
INFO:root:FL Epoch: 221 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1143
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 1.061357
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624451
INFO:root:FL Epoch: 221 Norm Difference for worker 1143 is 1.203386
INFO:root:FL Epoch: 221 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :39
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.837456
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 39 is 1.404063
INFO:root:FL Epoch: 221 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :451
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448121
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420160
INFO:root:FL Epoch: 221 Norm Difference for worker 451 is 1.180842
INFO:root:FL Epoch: 221 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1522
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480597
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447251
INFO:root:FL Epoch: 221 Norm Difference for worker 1522 is 1.267845
INFO:root:FL Epoch: 221 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1199
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703789
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459765
INFO:root:FL Epoch: 221 Norm Difference for worker 1199 is 1.268273
INFO:root:FL Epoch: 221 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1403
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511087
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629035
INFO:root:FL Epoch: 221 Norm Difference for worker 1403 is 1.314628
INFO:root:FL Epoch: 221 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.5679523655596901 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.22932297984759012                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1432
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745938
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377451
INFO:root:FL Epoch: 222 Norm Difference for worker 1432 is 1.298148
INFO:root:FL Epoch: 222 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1879
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765292
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327103
INFO:root:FL Epoch: 222 Norm Difference for worker 1879 is 1.313185
INFO:root:FL Epoch: 222 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1374
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583021
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460718
INFO:root:FL Epoch: 222 Norm Difference for worker 1374 is 1.32264
INFO:root:FL Epoch: 222 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :138
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491060
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 138 is 1.409738
INFO:root:FL Epoch: 222 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1818
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794540
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727923
INFO:root:FL Epoch: 222 Norm Difference for worker 1818 is 1.37763
INFO:root:FL Epoch: 222 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1897
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624020
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467551
INFO:root:FL Epoch: 222 Norm Difference for worker 1897 is 1.323606
INFO:root:FL Epoch: 222 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1713
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.919627
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724343
INFO:root:FL Epoch: 222 Norm Difference for worker 1713 is 1.365055
INFO:root:FL Epoch: 222 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1190
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239918
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127690
INFO:root:FL Epoch: 222 Norm Difference for worker 1190 is 0.82231
INFO:root:FL Epoch: 222 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.993113
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636293
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 1.474349
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1704
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810515
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411318
INFO:root:FL Epoch: 222 Norm Difference for worker 1704 is 1.309545
INFO:root:FL Epoch: 222 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.6210475248448989 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.14759905201693377                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 270 is 1.5267
INFO:root:FL Epoch: 223 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :754
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421045
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557396
INFO:root:FL Epoch: 223 Norm Difference for worker 754 is 1.283589
INFO:root:FL Epoch: 223 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :153
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736674
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 153 is 1.492731
INFO:root:FL Epoch: 223 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :729
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753072
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547475
INFO:root:FL Epoch: 223 Norm Difference for worker 729 is 1.612717
INFO:root:FL Epoch: 223 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377375
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422494
INFO:root:FL Epoch: 223 Norm Difference for worker 1270 is 1.443532
INFO:root:FL Epoch: 223 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :198
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.892404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 198 is 1.72378
INFO:root:FL Epoch: 223 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :422
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692420
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594667
INFO:root:FL Epoch: 223 Norm Difference for worker 422 is 1.736337
INFO:root:FL Epoch: 223 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :357
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590204
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465751
INFO:root:FL Epoch: 223 Norm Difference for worker 357 is 1.559181
INFO:root:FL Epoch: 223 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1197
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760014
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490165
INFO:root:FL Epoch: 223 Norm Difference for worker 1197 is 1.823157
INFO:root:FL Epoch: 223 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1215
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688326
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540955
INFO:root:FL Epoch: 223 Norm Difference for worker 1215 is 1.62492
INFO:root:FL Epoch: 223 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.5586724666988149 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.3088533356785774                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :1695
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681000
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489770
INFO:root:FL Epoch: 224 Norm Difference for worker 1695 is 1.13131
INFO:root:FL Epoch: 224 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550473
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631091
INFO:root:FL Epoch: 224 Norm Difference for worker 1865 is 1.118521
INFO:root:FL Epoch: 224 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1713
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857735
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503685
INFO:root:FL Epoch: 224 Norm Difference for worker 1713 is 1.083922
INFO:root:FL Epoch: 224 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :297
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 297 is 1.101815
INFO:root:FL Epoch: 224 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1928
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559618
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275894
INFO:root:FL Epoch: 224 Norm Difference for worker 1928 is 1.120385
INFO:root:FL Epoch: 224 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1649
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486208
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601541
INFO:root:FL Epoch: 224 Norm Difference for worker 1649 is 1.157404
INFO:root:FL Epoch: 224 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :866
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430849
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527415
INFO:root:FL Epoch: 224 Norm Difference for worker 866 is 1.164395
INFO:root:FL Epoch: 224 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1522
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437740
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508227
INFO:root:FL Epoch: 224 Norm Difference for worker 1522 is 1.093226
INFO:root:FL Epoch: 224 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :950
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595776
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348789
INFO:root:FL Epoch: 224 Norm Difference for worker 950 is 1.138487
INFO:root:FL Epoch: 224 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1672
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581433
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617553
INFO:root:FL Epoch: 224 Norm Difference for worker 1672 is 1.047088
INFO:root:FL Epoch: 224 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1713
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.5603110299390905 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.3292798201243083                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :772
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658243
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545703
INFO:root:FL Epoch: 225 Norm Difference for worker 772 is 1.026649
INFO:root:FL Epoch: 225 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :146
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 146 is 1.096592
INFO:root:FL Epoch: 225 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :483
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643982
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521760
INFO:root:FL Epoch: 225 Norm Difference for worker 483 is 1.028983
INFO:root:FL Epoch: 225 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :630
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428816
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607475
INFO:root:FL Epoch: 225 Norm Difference for worker 630 is 1.040523
INFO:root:FL Epoch: 225 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1459
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463455
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567553
INFO:root:FL Epoch: 225 Norm Difference for worker 1459 is 1.103157
INFO:root:FL Epoch: 225 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1607
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745282
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411645
INFO:root:FL Epoch: 225 Norm Difference for worker 1607 is 1.051927
INFO:root:FL Epoch: 225 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1636
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624325
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521183
INFO:root:FL Epoch: 225 Norm Difference for worker 1636 is 1.082526
INFO:root:FL Epoch: 225 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1906
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741111
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558519
INFO:root:FL Epoch: 225 Norm Difference for worker 1906 is 1.072223
INFO:root:FL Epoch: 225 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1540
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630452
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428638
INFO:root:FL Epoch: 225 Norm Difference for worker 1540 is 1.014844
INFO:root:FL Epoch: 225 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :320
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 320 is 1.057965
INFO:root:FL Epoch: 225 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 483
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.5452545390409582 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.40626204510529834                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :607
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489661
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340602
INFO:root:FL Epoch: 226 Norm Difference for worker 607 is 0.894334
INFO:root:FL Epoch: 226 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1256
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432517
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336484
INFO:root:FL Epoch: 226 Norm Difference for worker 1256 is 0.923257
INFO:root:FL Epoch: 226 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :305
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457841
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398919
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 305 is 0.900253
INFO:root:FL Epoch: 226 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1249
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592983
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482769
INFO:root:FL Epoch: 226 Norm Difference for worker 1249 is 0.993952
INFO:root:FL Epoch: 226 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1338
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629149
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408444
INFO:root:FL Epoch: 226 Norm Difference for worker 1338 is 0.811212
INFO:root:FL Epoch: 226 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :942
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419945
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646653
INFO:root:FL Epoch: 226 Norm Difference for worker 942 is 0.914619
INFO:root:FL Epoch: 226 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1340
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459895
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655684
INFO:root:FL Epoch: 226 Norm Difference for worker 1340 is 0.915468
INFO:root:FL Epoch: 226 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :822
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449218
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378189
INFO:root:FL Epoch: 226 Norm Difference for worker 822 is 0.940062
INFO:root:FL Epoch: 226 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :41
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.242129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 41 is 0.919941
INFO:root:FL Epoch: 226 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1770
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405241
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485644
INFO:root:FL Epoch: 226 Norm Difference for worker 1770 is 0.943185
INFO:root:FL Epoch: 226 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.5494216943488401 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.29516005516052246                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 227 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :77
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717412
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 77 is 1.017908
INFO:root:FL Epoch: 227 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :907
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472639
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550733
INFO:root:FL Epoch: 227 Norm Difference for worker 907 is 1.023439
INFO:root:FL Epoch: 227 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :431
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459348
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418085
INFO:root:FL Epoch: 227 Norm Difference for worker 431 is 0.991858
INFO:root:FL Epoch: 227 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1546
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430504
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415175
INFO:root:FL Epoch: 227 Norm Difference for worker 1546 is 1.041033
INFO:root:FL Epoch: 227 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1892
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624818
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379957
INFO:root:FL Epoch: 227 Norm Difference for worker 1892 is 1.02266
INFO:root:FL Epoch: 227 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :70
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 70 is 0.976722
INFO:root:FL Epoch: 227 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1513
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455134
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422444
INFO:root:FL Epoch: 227 Norm Difference for worker 1513 is 0.988854
INFO:root:FL Epoch: 227 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :959
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603334
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418507
INFO:root:FL Epoch: 227 Norm Difference for worker 959 is 1.033991
INFO:root:FL Epoch: 227 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :274
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.875482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 274 is 1.020747
INFO:root:FL Epoch: 227 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :157
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 157 is 1.043075
INFO:root:FL Epoch: 227 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.5875826881212347 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.5560390303532282                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :683
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660542
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482151
INFO:root:FL Epoch: 228 Norm Difference for worker 683 is 1.129983
INFO:root:FL Epoch: 228 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1670
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381574
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607540
INFO:root:FL Epoch: 228 Norm Difference for worker 1670 is 1.056164
INFO:root:FL Epoch: 228 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1846
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639590
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466643
INFO:root:FL Epoch: 228 Norm Difference for worker 1846 is 1.049949
INFO:root:FL Epoch: 228 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :949
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747272
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563217
INFO:root:FL Epoch: 228 Norm Difference for worker 949 is 1.118547
INFO:root:FL Epoch: 228 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1749
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383992
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356225
INFO:root:FL Epoch: 228 Norm Difference for worker 1749 is 1.021826
INFO:root:FL Epoch: 228 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1722
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513961
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471485
INFO:root:FL Epoch: 228 Norm Difference for worker 1722 is 1.107813
INFO:root:FL Epoch: 228 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :993
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650840
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556157
INFO:root:FL Epoch: 228 Norm Difference for worker 993 is 1.109342
INFO:root:FL Epoch: 228 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1085
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521479
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474684
INFO:root:FL Epoch: 228 Norm Difference for worker 1085 is 1.047719
INFO:root:FL Epoch: 228 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :948
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515300
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562259
INFO:root:FL Epoch: 228 Norm Difference for worker 948 is 1.127291
INFO:root:FL Epoch: 228 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1414
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721636
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521478
INFO:root:FL Epoch: 228 Norm Difference for worker 1414 is 1.105989
INFO:root:FL Epoch: 228 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1749
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.5503201852826511 and Test Accuracy:70.0 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.32058215886354446                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :958
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736888
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252474
INFO:root:FL Epoch: 229 Norm Difference for worker 958 is 1.0439
INFO:root:FL Epoch: 229 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :924
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473923
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399390
INFO:root:FL Epoch: 229 Norm Difference for worker 924 is 1.078206
INFO:root:FL Epoch: 229 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :923
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330567
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612536
INFO:root:FL Epoch: 229 Norm Difference for worker 923 is 1.08773
INFO:root:FL Epoch: 229 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :170
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.225752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 170 is 1.077995
INFO:root:FL Epoch: 229 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1886
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628493
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273186
INFO:root:FL Epoch: 229 Norm Difference for worker 1886 is 1.07546
INFO:root:FL Epoch: 229 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :71
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 71 is 1.108234
INFO:root:FL Epoch: 229 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :912
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828933
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.856104
INFO:root:FL Epoch: 229 Norm Difference for worker 912 is 1.075505
INFO:root:FL Epoch: 229 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1134
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442180
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490120
INFO:root:FL Epoch: 229 Norm Difference for worker 1134 is 1.099893
INFO:root:FL Epoch: 229 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1808
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464488
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444525
INFO:root:FL Epoch: 229 Norm Difference for worker 1808 is 1.04186
INFO:root:FL Epoch: 229 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1870
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594995
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454829
INFO:root:FL Epoch: 229 Norm Difference for worker 1870 is 1.094368
INFO:root:FL Epoch: 229 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1886
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.5498997200937832 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.272154301404953                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :1469
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527241
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504154
INFO:root:FL Epoch: 230 Norm Difference for worker 1469 is 1.132592
INFO:root:FL Epoch: 230 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :582
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652987
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505546
INFO:root:FL Epoch: 230 Norm Difference for worker 582 is 1.193688
INFO:root:FL Epoch: 230 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :963
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349499
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445085
INFO:root:FL Epoch: 230 Norm Difference for worker 963 is 1.19074
INFO:root:FL Epoch: 230 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :936
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622107
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347207
INFO:root:FL Epoch: 230 Norm Difference for worker 936 is 1.116047
INFO:root:FL Epoch: 230 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1610
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405203
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524726
INFO:root:FL Epoch: 230 Norm Difference for worker 1610 is 1.135347
INFO:root:FL Epoch: 230 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1285
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385899
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.819957
INFO:root:FL Epoch: 230 Norm Difference for worker 1285 is 1.167298
INFO:root:FL Epoch: 230 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :954
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599077
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418627
INFO:root:FL Epoch: 230 Norm Difference for worker 954 is 1.143919
INFO:root:FL Epoch: 230 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :660
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569283
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388204
INFO:root:FL Epoch: 230 Norm Difference for worker 660 is 1.080125
INFO:root:FL Epoch: 230 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :200
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637130
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 200 is 1.182121
INFO:root:FL Epoch: 230 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :238
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.875291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 238 is 1.095734
INFO:root:FL Epoch: 230 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 238
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.5439003443016726 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.385287086168925                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267131
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256469
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.27213206390539807 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.29718942642211915 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.223228
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376713
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241219
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.2730996285875638 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.30059383511543275 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.210795
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425240
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458436
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.2691018432378769 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.29931803941726687 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.219247
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :182
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 182 is 1.035868
INFO:root:FL Epoch: 231 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :207
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.733244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 207 is 0.996062
INFO:root:FL Epoch: 231 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1332
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586186
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485308
INFO:root:FL Epoch: 231 Norm Difference for worker 1332 is 0.954181
INFO:root:FL Epoch: 231 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :956
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507771
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532389
INFO:root:FL Epoch: 231 Norm Difference for worker 956 is 1.008913
INFO:root:FL Epoch: 231 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591247
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468649
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 0.933574
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1364
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536669
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497299
INFO:root:FL Epoch: 231 Norm Difference for worker 1364 is 1.013913
INFO:root:FL Epoch: 231 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :648
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900193
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458053
INFO:root:FL Epoch: 231 Norm Difference for worker 648 is 0.97171
INFO:root:FL Epoch: 231 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.5440002224024605 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.2730996285875638                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1755
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492477
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334398
INFO:root:FL Epoch: 232 Norm Difference for worker 1755 is 0.982812
INFO:root:FL Epoch: 232 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1533
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794690
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473107
INFO:root:FL Epoch: 232 Norm Difference for worker 1533 is 1.090862
INFO:root:FL Epoch: 232 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1003
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595053
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340656
INFO:root:FL Epoch: 232 Norm Difference for worker 1003 is 1.015655
INFO:root:FL Epoch: 232 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1514
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391628
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619216
INFO:root:FL Epoch: 232 Norm Difference for worker 1514 is 1.085609
INFO:root:FL Epoch: 232 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :482
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661988
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432467
INFO:root:FL Epoch: 232 Norm Difference for worker 482 is 1.081771
INFO:root:FL Epoch: 232 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :38
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 38 is 0.983238
INFO:root:FL Epoch: 232 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1305
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671960
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577413
INFO:root:FL Epoch: 232 Norm Difference for worker 1305 is 1.150388
INFO:root:FL Epoch: 232 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :806
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804132
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631194
INFO:root:FL Epoch: 232 Norm Difference for worker 806 is 1.077443
INFO:root:FL Epoch: 232 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624669
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426800
INFO:root:FL Epoch: 232 Norm Difference for worker 1291 is 1.022061
INFO:root:FL Epoch: 232 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1342
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479268
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441911
INFO:root:FL Epoch: 232 Norm Difference for worker 1342 is 1.015428
INFO:root:FL Epoch: 232 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1755
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.5536253610078026 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.2205993210275968                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1736
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447141
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329922
INFO:root:FL Epoch: 233 Norm Difference for worker 1736 is 1.153699
INFO:root:FL Epoch: 233 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1347
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495620
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442790
INFO:root:FL Epoch: 233 Norm Difference for worker 1347 is 1.227331
INFO:root:FL Epoch: 233 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :965
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527309
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462606
INFO:root:FL Epoch: 233 Norm Difference for worker 965 is 1.191619
INFO:root:FL Epoch: 233 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1370
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613806
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607539
INFO:root:FL Epoch: 233 Norm Difference for worker 1370 is 1.255125
INFO:root:FL Epoch: 233 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :121
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 121 is 1.225405
INFO:root:FL Epoch: 233 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1393
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757913
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406340
INFO:root:FL Epoch: 233 Norm Difference for worker 1393 is 1.154151
INFO:root:FL Epoch: 233 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :456
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527594
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438192
INFO:root:FL Epoch: 233 Norm Difference for worker 456 is 1.201921
INFO:root:FL Epoch: 233 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1814
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862669
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501259
INFO:root:FL Epoch: 233 Norm Difference for worker 1814 is 1.239291
INFO:root:FL Epoch: 233 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1922
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348162
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412766
INFO:root:FL Epoch: 233 Norm Difference for worker 1922 is 1.125351
INFO:root:FL Epoch: 233 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :825
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807863
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457999
INFO:root:FL Epoch: 233 Norm Difference for worker 825 is 1.114302
INFO:root:FL Epoch: 233 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1922
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.5654741700957803 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.33866674701372784                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1426
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411875
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478629
INFO:root:FL Epoch: 234 Norm Difference for worker 1426 is 1.201851
INFO:root:FL Epoch: 234 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1515
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574129
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409941
INFO:root:FL Epoch: 234 Norm Difference for worker 1515 is 1.054844
INFO:root:FL Epoch: 234 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1029
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817824
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433060
INFO:root:FL Epoch: 234 Norm Difference for worker 1029 is 1.134486
INFO:root:FL Epoch: 234 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1283
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331892
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341594
INFO:root:FL Epoch: 234 Norm Difference for worker 1283 is 1.148324
INFO:root:FL Epoch: 234 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :292
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.843828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 292 is 1.144843
INFO:root:FL Epoch: 234 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :988
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660645
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523595
INFO:root:FL Epoch: 234 Norm Difference for worker 988 is 1.098812
INFO:root:FL Epoch: 234 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :434
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286043
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338523
INFO:root:FL Epoch: 234 Norm Difference for worker 434 is 1.155772
INFO:root:FL Epoch: 234 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1197
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771932
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600723
INFO:root:FL Epoch: 234 Norm Difference for worker 1197 is 1.169601
INFO:root:FL Epoch: 234 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1772
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704611
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612020
INFO:root:FL Epoch: 234 Norm Difference for worker 1772 is 1.157502
INFO:root:FL Epoch: 234 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1338
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336927
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352037
INFO:root:FL Epoch: 234 Norm Difference for worker 1338 is 0.902646
INFO:root:FL Epoch: 234 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.5610053556806901 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.22178140158454576                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :522
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558243
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649247
INFO:root:FL Epoch: 235 Norm Difference for worker 522 is 1.221097
INFO:root:FL Epoch: 235 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1084
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699006
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694488
INFO:root:FL Epoch: 235 Norm Difference for worker 1084 is 1.37816
INFO:root:FL Epoch: 235 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508895
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357583
INFO:root:FL Epoch: 235 Norm Difference for worker 794 is 1.219341
INFO:root:FL Epoch: 235 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1467
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.911707
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651781
INFO:root:FL Epoch: 235 Norm Difference for worker 1467 is 1.353069
INFO:root:FL Epoch: 235 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494627
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459026
INFO:root:FL Epoch: 235 Norm Difference for worker 1794 is 1.267068
INFO:root:FL Epoch: 235 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1935
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781253
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492666
INFO:root:FL Epoch: 235 Norm Difference for worker 1935 is 1.276607
INFO:root:FL Epoch: 235 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486014
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330638
INFO:root:FL Epoch: 235 Norm Difference for worker 1180 is 1.122177
INFO:root:FL Epoch: 235 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1316
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472081
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522202
INFO:root:FL Epoch: 235 Norm Difference for worker 1316 is 1.22851
INFO:root:FL Epoch: 235 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1029
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655944
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280920
INFO:root:FL Epoch: 235 Norm Difference for worker 1029 is 1.249746
INFO:root:FL Epoch: 235 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1087
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808751
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353409
INFO:root:FL Epoch: 235 Norm Difference for worker 1087 is 1.199809
INFO:root:FL Epoch: 235 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.5539964262176963 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.2726697238783042                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1500
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850825
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702129
INFO:root:FL Epoch: 236 Norm Difference for worker 1500 is 1.193951
INFO:root:FL Epoch: 236 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1518
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621509
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581341
INFO:root:FL Epoch: 236 Norm Difference for worker 1518 is 1.255006
INFO:root:FL Epoch: 236 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603680
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501582
INFO:root:FL Epoch: 236 Norm Difference for worker 1356 is 1.294811
INFO:root:FL Epoch: 236 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1009
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651529
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382937
INFO:root:FL Epoch: 236 Norm Difference for worker 1009 is 1.243297
INFO:root:FL Epoch: 236 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :923
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676717
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615128
INFO:root:FL Epoch: 236 Norm Difference for worker 923 is 1.21165
INFO:root:FL Epoch: 236 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1137
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445286
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395685
INFO:root:FL Epoch: 236 Norm Difference for worker 1137 is 1.238051
INFO:root:FL Epoch: 236 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1947
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413697
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619614
INFO:root:FL Epoch: 236 Norm Difference for worker 1947 is 1.194088
INFO:root:FL Epoch: 236 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718896
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532594
INFO:root:FL Epoch: 236 Norm Difference for worker 1178 is 1.307696
INFO:root:FL Epoch: 236 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :44
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.797820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 44 is 1.242841
INFO:root:FL Epoch: 236 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :161
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 161 is 1.20505
INFO:root:FL Epoch: 236 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1500
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.5334100337589488 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.36229730645815533                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :312
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 312 is 0.982132
INFO:root:FL Epoch: 237 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1612
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535199
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467241
INFO:root:FL Epoch: 237 Norm Difference for worker 1612 is 0.975205
INFO:root:FL Epoch: 237 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1685
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615847
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607779
INFO:root:FL Epoch: 237 Norm Difference for worker 1685 is 0.986366
INFO:root:FL Epoch: 237 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :582
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461691
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455631
INFO:root:FL Epoch: 237 Norm Difference for worker 582 is 1.010042
INFO:root:FL Epoch: 237 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :797
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552717
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429944
INFO:root:FL Epoch: 237 Norm Difference for worker 797 is 1.013148
INFO:root:FL Epoch: 237 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :600
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529936
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458335
INFO:root:FL Epoch: 237 Norm Difference for worker 600 is 0.879686
INFO:root:FL Epoch: 237 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :237
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 237 is 0.999504
INFO:root:FL Epoch: 237 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1308
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756562
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444280
INFO:root:FL Epoch: 237 Norm Difference for worker 1308 is 0.998744
INFO:root:FL Epoch: 237 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :534
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487534
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516868
INFO:root:FL Epoch: 237 Norm Difference for worker 534 is 0.989259
INFO:root:FL Epoch: 237 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :844
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377861
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501011
INFO:root:FL Epoch: 237 Norm Difference for worker 844 is 0.96301
INFO:root:FL Epoch: 237 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.96826171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.5447148049578947 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.3403424248099327                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :58
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 58 is 1.024829
INFO:root:FL Epoch: 238 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :859
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729714
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460819
INFO:root:FL Epoch: 238 Norm Difference for worker 859 is 1.026223
INFO:root:FL Epoch: 238 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :433
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777675
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439959
INFO:root:FL Epoch: 238 Norm Difference for worker 433 is 1.021915
INFO:root:FL Epoch: 238 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1026
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462078
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537387
INFO:root:FL Epoch: 238 Norm Difference for worker 1026 is 0.995903
INFO:root:FL Epoch: 238 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :994
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596288
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590101
INFO:root:FL Epoch: 238 Norm Difference for worker 994 is 0.977026
INFO:root:FL Epoch: 238 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1506
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577730
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305124
INFO:root:FL Epoch: 238 Norm Difference for worker 1506 is 0.924797
INFO:root:FL Epoch: 238 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :858
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440172
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508603
INFO:root:FL Epoch: 238 Norm Difference for worker 858 is 0.981777
INFO:root:FL Epoch: 238 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :763
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413682
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551942
INFO:root:FL Epoch: 238 Norm Difference for worker 763 is 1.043028
INFO:root:FL Epoch: 238 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1007
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525267
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407964
INFO:root:FL Epoch: 238 Norm Difference for worker 1007 is 1.042677
INFO:root:FL Epoch: 238 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :921
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390362
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365691
INFO:root:FL Epoch: 238 Norm Difference for worker 921 is 0.959104
INFO:root:FL Epoch: 238 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.5333613928626565 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.3737536296248436                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1052
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834516
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341961
INFO:root:FL Epoch: 239 Norm Difference for worker 1052 is 0.959789
INFO:root:FL Epoch: 239 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :845
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621224
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495343
INFO:root:FL Epoch: 239 Norm Difference for worker 845 is 1.011533
INFO:root:FL Epoch: 239 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :221
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.744187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 221 is 0.997057
INFO:root:FL Epoch: 239 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :456
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547286
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319739
INFO:root:FL Epoch: 239 Norm Difference for worker 456 is 0.98625
INFO:root:FL Epoch: 239 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :255
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605859
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646511
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 255 is 0.945179
INFO:root:FL Epoch: 239 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :587
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419654
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519695
INFO:root:FL Epoch: 239 Norm Difference for worker 587 is 0.977771
INFO:root:FL Epoch: 239 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :86
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465449
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 86 is 0.973787
INFO:root:FL Epoch: 239 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1398
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506755
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350333
INFO:root:FL Epoch: 239 Norm Difference for worker 1398 is 1.013204
INFO:root:FL Epoch: 239 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :451
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714854
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507163
INFO:root:FL Epoch: 239 Norm Difference for worker 451 is 0.989916
INFO:root:FL Epoch: 239 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1030
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718962
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449285
INFO:root:FL Epoch: 239 Norm Difference for worker 1030 is 1.008026
INFO:root:FL Epoch: 239 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.5646838563330033 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.5035653313000997                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1503
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553291
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437496
INFO:root:FL Epoch: 240 Norm Difference for worker 1503 is 1.032122
INFO:root:FL Epoch: 240 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644921
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335240
INFO:root:FL Epoch: 240 Norm Difference for worker 627 is 0.995528
INFO:root:FL Epoch: 240 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1705
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540813
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482916
INFO:root:FL Epoch: 240 Norm Difference for worker 1705 is 1.061511
INFO:root:FL Epoch: 240 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1702
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813971
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463264
INFO:root:FL Epoch: 240 Norm Difference for worker 1702 is 1.045324
INFO:root:FL Epoch: 240 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1356
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347459
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604551
INFO:root:FL Epoch: 240 Norm Difference for worker 1356 is 1.070411
INFO:root:FL Epoch: 240 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :22
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657014
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603284
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 22 is 1.082044
INFO:root:FL Epoch: 240 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1709
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721697
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712156
INFO:root:FL Epoch: 240 Norm Difference for worker 1709 is 1.022067
INFO:root:FL Epoch: 240 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :31
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593370
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514556
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 31 is 1.006326
INFO:root:FL Epoch: 240 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :42
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 42 is 0.975119
INFO:root:FL Epoch: 240 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :358
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295613
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428526
INFO:root:FL Epoch: 240 Norm Difference for worker 358 is 0.988279
INFO:root:FL Epoch: 240 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.5441959360066582 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.509966308871905                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461751
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419436
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.36265063285827637 Backdoor Test Accuracy: 83.33333333333333
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.31630952954292296 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.230385
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405028
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492191
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.3444787487387657 Backdoor Test Accuracy: 83.33333333333333
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.31469818502664565 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.242313
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445063
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465740
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.3266559764742851 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.31721863001585004 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.245582
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1593
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587350
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564374
INFO:root:FL Epoch: 241 Norm Difference for worker 1593 is 0.939619
INFO:root:FL Epoch: 241 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1631
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554240
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258028
INFO:root:FL Epoch: 241 Norm Difference for worker 1631 is 0.935599
INFO:root:FL Epoch: 241 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1647
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703342
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496253
INFO:root:FL Epoch: 241 Norm Difference for worker 1647 is 1.023212
INFO:root:FL Epoch: 241 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1726
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703341
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629984
INFO:root:FL Epoch: 241 Norm Difference for worker 1726 is 0.919193
INFO:root:FL Epoch: 241 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1002
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500162
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393220
INFO:root:FL Epoch: 241 Norm Difference for worker 1002 is 1.016143
INFO:root:FL Epoch: 241 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1907
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583000
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499372
INFO:root:FL Epoch: 241 Norm Difference for worker 1907 is 0.935823
INFO:root:FL Epoch: 241 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :518
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555331
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526677
INFO:root:FL Epoch: 241 Norm Difference for worker 518 is 1.0011
INFO:root:FL Epoch: 241 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5418426902855144 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.36265063285827637                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1813
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731918
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377525
INFO:root:FL Epoch: 242 Norm Difference for worker 1813 is 1.060146
INFO:root:FL Epoch: 242 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1657
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552131
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487980
INFO:root:FL Epoch: 242 Norm Difference for worker 1657 is 1.026287
INFO:root:FL Epoch: 242 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1921
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422710
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383209
INFO:root:FL Epoch: 242 Norm Difference for worker 1921 is 1.037195
INFO:root:FL Epoch: 242 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :123
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 123 is 0.980356
INFO:root:FL Epoch: 242 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :56
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.797534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 56 is 1.015543
INFO:root:FL Epoch: 242 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :975
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471804
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543096
INFO:root:FL Epoch: 242 Norm Difference for worker 975 is 1.037959
INFO:root:FL Epoch: 242 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1165
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572069
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417455
INFO:root:FL Epoch: 242 Norm Difference for worker 1165 is 1.001855
INFO:root:FL Epoch: 242 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :380
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666005
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493075
INFO:root:FL Epoch: 242 Norm Difference for worker 380 is 0.996101
INFO:root:FL Epoch: 242 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :313
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 313 is 1.02567
INFO:root:FL Epoch: 242 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1324
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483866
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450146
INFO:root:FL Epoch: 242 Norm Difference for worker 1324 is 1.044793
INFO:root:FL Epoch: 242 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 56
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.5537171539138345 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.4201187342405319                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1593
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465308
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391007
INFO:root:FL Epoch: 243 Norm Difference for worker 1593 is 0.921885
INFO:root:FL Epoch: 243 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1300
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583646
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581857
INFO:root:FL Epoch: 243 Norm Difference for worker 1300 is 0.966245
INFO:root:FL Epoch: 243 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :642
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584493
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491006
INFO:root:FL Epoch: 243 Norm Difference for worker 642 is 1.031413
INFO:root:FL Epoch: 243 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1371
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572889
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697825
INFO:root:FL Epoch: 243 Norm Difference for worker 1371 is 1.009871
INFO:root:FL Epoch: 243 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :278
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688660
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 278 is 0.987506
INFO:root:FL Epoch: 243 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :562
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737295
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435077
INFO:root:FL Epoch: 243 Norm Difference for worker 562 is 0.984647
INFO:root:FL Epoch: 243 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1220
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414557
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452667
INFO:root:FL Epoch: 243 Norm Difference for worker 1220 is 0.924231
INFO:root:FL Epoch: 243 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :620
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556299
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311125
INFO:root:FL Epoch: 243 Norm Difference for worker 620 is 0.932284
INFO:root:FL Epoch: 243 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :885
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779482
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462962
INFO:root:FL Epoch: 243 Norm Difference for worker 885 is 0.991711
INFO:root:FL Epoch: 243 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1473
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580330
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408611
INFO:root:FL Epoch: 243 Norm Difference for worker 1473 is 1.024788
INFO:root:FL Epoch: 243 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.5658558729816886 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.4282744179169337                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :828
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519302
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739333
INFO:root:FL Epoch: 244 Norm Difference for worker 828 is 1.244293
INFO:root:FL Epoch: 244 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1531
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594167
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803985
INFO:root:FL Epoch: 244 Norm Difference for worker 1531 is 1.181697
INFO:root:FL Epoch: 244 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :942
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518917
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405780
INFO:root:FL Epoch: 244 Norm Difference for worker 942 is 1.118811
INFO:root:FL Epoch: 244 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1585
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456596
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335792
INFO:root:FL Epoch: 244 Norm Difference for worker 1585 is 1.089692
INFO:root:FL Epoch: 244 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :214
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.930253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 214 is 1.123506
INFO:root:FL Epoch: 244 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1712
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698527
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512311
INFO:root:FL Epoch: 244 Norm Difference for worker 1712 is 1.137627
INFO:root:FL Epoch: 244 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :760
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495221
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342207
INFO:root:FL Epoch: 244 Norm Difference for worker 760 is 0.998629
INFO:root:FL Epoch: 244 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1577
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869009
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441033
INFO:root:FL Epoch: 244 Norm Difference for worker 1577 is 1.118048
INFO:root:FL Epoch: 244 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :161
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 161 is 1.085162
INFO:root:FL Epoch: 244 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :872
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375113
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487468
INFO:root:FL Epoch: 244 Norm Difference for worker 872 is 1.097599
INFO:root:FL Epoch: 244 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 760
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.5719969833598417 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.40985307097435                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 245 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :42
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.281043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 42 is 0.879142
INFO:root:FL Epoch: 245 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539722
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 320 is 1.112178
INFO:root:FL Epoch: 245 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1861
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707853
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524453
INFO:root:FL Epoch: 245 Norm Difference for worker 1861 is 1.085484
INFO:root:FL Epoch: 245 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :965
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523845
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340995
INFO:root:FL Epoch: 245 Norm Difference for worker 965 is 1.094085
INFO:root:FL Epoch: 245 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :484
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695459
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558932
INFO:root:FL Epoch: 245 Norm Difference for worker 484 is 1.098817
INFO:root:FL Epoch: 245 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :884
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453771
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625376
INFO:root:FL Epoch: 245 Norm Difference for worker 884 is 1.159967
INFO:root:FL Epoch: 245 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1238
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470979
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423565
INFO:root:FL Epoch: 245 Norm Difference for worker 1238 is 1.119389
INFO:root:FL Epoch: 245 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :214
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 214 is 1.079933
INFO:root:FL Epoch: 245 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1012
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644324
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376797
INFO:root:FL Epoch: 245 Norm Difference for worker 1012 is 1.078186
INFO:root:FL Epoch: 245 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :674
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565775
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474152
INFO:root:FL Epoch: 245 Norm Difference for worker 674 is 1.092062
INFO:root:FL Epoch: 245 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.587170388768701 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.44832198818524677                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :501
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646217
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468485
INFO:root:FL Epoch: 246 Norm Difference for worker 501 is 1.186731
INFO:root:FL Epoch: 246 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1726
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445170
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540135
INFO:root:FL Epoch: 246 Norm Difference for worker 1726 is 1.246102
INFO:root:FL Epoch: 246 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1606
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791743
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498126
INFO:root:FL Epoch: 246 Norm Difference for worker 1606 is 1.215642
INFO:root:FL Epoch: 246 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1903
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904042
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312520
INFO:root:FL Epoch: 246 Norm Difference for worker 1903 is 1.303311
INFO:root:FL Epoch: 246 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :59
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694589
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 59 is 1.206103
INFO:root:FL Epoch: 246 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1152
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425969
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445576
INFO:root:FL Epoch: 246 Norm Difference for worker 1152 is 1.276222
INFO:root:FL Epoch: 246 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :944
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374287
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572723
INFO:root:FL Epoch: 246 Norm Difference for worker 944 is 1.24709
INFO:root:FL Epoch: 246 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1138
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537657
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476357
INFO:root:FL Epoch: 246 Norm Difference for worker 1138 is 1.338747
INFO:root:FL Epoch: 246 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :484
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742363
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457087
INFO:root:FL Epoch: 246 Norm Difference for worker 484 is 1.219938
INFO:root:FL Epoch: 246 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1176
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655536
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374213
INFO:root:FL Epoch: 246 Norm Difference for worker 1176 is 1.22286
INFO:root:FL Epoch: 246 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 501
INFO:root:Norm of Aggregated Model: 5154.96875
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.5634656092699837 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.46866997083028156                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1188
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522826
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532552
INFO:root:FL Epoch: 247 Norm Difference for worker 1188 is 1.119803
INFO:root:FL Epoch: 247 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1113
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843723
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407404
INFO:root:FL Epoch: 247 Norm Difference for worker 1113 is 1.149183
INFO:root:FL Epoch: 247 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1084
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581123
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423079
INFO:root:FL Epoch: 247 Norm Difference for worker 1084 is 1.08363
INFO:root:FL Epoch: 247 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1606
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706515
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338468
INFO:root:FL Epoch: 247 Norm Difference for worker 1606 is 1.09554
INFO:root:FL Epoch: 247 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :769
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622833
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441096
INFO:root:FL Epoch: 247 Norm Difference for worker 769 is 1.052122
INFO:root:FL Epoch: 247 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :829
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639594
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579255
INFO:root:FL Epoch: 247 Norm Difference for worker 829 is 1.155603
INFO:root:FL Epoch: 247 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :116
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 116 is 1.145943
INFO:root:FL Epoch: 247 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :544
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478875
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502795
INFO:root:FL Epoch: 247 Norm Difference for worker 544 is 1.060645
INFO:root:FL Epoch: 247 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1566
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826337
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498243
INFO:root:FL Epoch: 247 Norm Difference for worker 1566 is 1.087978
INFO:root:FL Epoch: 247 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1301
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888886
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617764
INFO:root:FL Epoch: 247 Norm Difference for worker 1301 is 1.222158
INFO:root:FL Epoch: 247 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 769
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.5467423638876747 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.4683362990617752                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :36
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 36 is 0.975844
INFO:root:FL Epoch: 248 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1147
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541816
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614609
INFO:root:FL Epoch: 248 Norm Difference for worker 1147 is 0.99976
INFO:root:FL Epoch: 248 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :785
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623151
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560646
INFO:root:FL Epoch: 248 Norm Difference for worker 785 is 1.025772
INFO:root:FL Epoch: 248 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :826
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751608
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603420
INFO:root:FL Epoch: 248 Norm Difference for worker 826 is 0.978423
INFO:root:FL Epoch: 248 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :778
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811252
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683181
INFO:root:FL Epoch: 248 Norm Difference for worker 778 is 1.056128
INFO:root:FL Epoch: 248 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :373
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460480
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400197
INFO:root:FL Epoch: 248 Norm Difference for worker 373 is 1.033667
INFO:root:FL Epoch: 248 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1904
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654301
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461796
INFO:root:FL Epoch: 248 Norm Difference for worker 1904 is 0.991773
INFO:root:FL Epoch: 248 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :495
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725351
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552952
INFO:root:FL Epoch: 248 Norm Difference for worker 495 is 1.00388
INFO:root:FL Epoch: 248 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :501
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325915
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342519
INFO:root:FL Epoch: 248 Norm Difference for worker 501 is 0.839096
INFO:root:FL Epoch: 248 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :869
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512112
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350091
INFO:root:FL Epoch: 248 Norm Difference for worker 869 is 0.976084
INFO:root:FL Epoch: 248 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 501
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.5696195662021637 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.4360220630963643                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :606
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763350
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461736
INFO:root:FL Epoch: 249 Norm Difference for worker 606 is 1.257063
INFO:root:FL Epoch: 249 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1727
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663923
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772355
INFO:root:FL Epoch: 249 Norm Difference for worker 1727 is 1.307971
INFO:root:FL Epoch: 249 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :935
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719724
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403413
INFO:root:FL Epoch: 249 Norm Difference for worker 935 is 1.285283
INFO:root:FL Epoch: 249 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :362
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738872
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497812
INFO:root:FL Epoch: 249 Norm Difference for worker 362 is 1.229832
INFO:root:FL Epoch: 249 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :666
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635397
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405160
INFO:root:FL Epoch: 249 Norm Difference for worker 666 is 1.345833
INFO:root:FL Epoch: 249 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :491
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555792
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356805
INFO:root:FL Epoch: 249 Norm Difference for worker 491 is 1.211303
INFO:root:FL Epoch: 249 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :80
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.314366
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 80 is 1.187037
INFO:root:FL Epoch: 249 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1533
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602299
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390745
INFO:root:FL Epoch: 249 Norm Difference for worker 1533 is 1.392653
INFO:root:FL Epoch: 249 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :496
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823256
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326702
INFO:root:FL Epoch: 249 Norm Difference for worker 496 is 1.278852
INFO:root:FL Epoch: 249 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :290
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.923852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 290 is 1.386768
INFO:root:FL Epoch: 249 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.5619558551732231 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.37300697217384976                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 250 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :78
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 78 is 1.285618
INFO:root:FL Epoch: 250 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :296
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 296 is 1.280054
INFO:root:FL Epoch: 250 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1388
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588755
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611470
INFO:root:FL Epoch: 250 Norm Difference for worker 1388 is 1.307562
INFO:root:FL Epoch: 250 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :169
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514198
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 169 is 1.30212
INFO:root:FL Epoch: 250 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :351
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672629
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390625
INFO:root:FL Epoch: 250 Norm Difference for worker 351 is 1.270866
INFO:root:FL Epoch: 250 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1200
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610307
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630671
INFO:root:FL Epoch: 250 Norm Difference for worker 1200 is 1.309446
INFO:root:FL Epoch: 250 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1052
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323722
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465732
INFO:root:FL Epoch: 250 Norm Difference for worker 1052 is 1.329693
INFO:root:FL Epoch: 250 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :729
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.954501
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380512
INFO:root:FL Epoch: 250 Norm Difference for worker 729 is 1.362386
INFO:root:FL Epoch: 250 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :151
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 151 is 1.328566
INFO:root:FL Epoch: 250 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1317
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486406
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654784
INFO:root:FL Epoch: 250 Norm Difference for worker 1317 is 1.345705
INFO:root:FL Epoch: 250 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.5641931014902452 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.466795081893603                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352182
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437796
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.3050296554962794 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.30519852936267855 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.26257
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338894
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211030
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.3049776802460353 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.30626188963651657 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.258718
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457812
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489664
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.3120558485388756 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.30696889013051987 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.25488
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :764
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593100
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561545
INFO:root:FL Epoch: 251 Norm Difference for worker 764 is 1.031129
INFO:root:FL Epoch: 251 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1000
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779638
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411998
INFO:root:FL Epoch: 251 Norm Difference for worker 1000 is 1.149004
INFO:root:FL Epoch: 251 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :718
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686586
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451428
INFO:root:FL Epoch: 251 Norm Difference for worker 718 is 0.971145
INFO:root:FL Epoch: 251 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :697
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501426
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590306
INFO:root:FL Epoch: 251 Norm Difference for worker 697 is 1.085625
INFO:root:FL Epoch: 251 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :204
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 204 is 1.07252
INFO:root:FL Epoch: 251 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1862
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479878
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382302
INFO:root:FL Epoch: 251 Norm Difference for worker 1862 is 1.002701
INFO:root:FL Epoch: 251 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :913
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607990
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556887
INFO:root:FL Epoch: 251 Norm Difference for worker 913 is 1.159946
INFO:root:FL Epoch: 251 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.5560717863195083 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.3120558485388756                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1465
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398658
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531426
INFO:root:FL Epoch: 252 Norm Difference for worker 1465 is 1.057744
INFO:root:FL Epoch: 252 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740657
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627319
INFO:root:FL Epoch: 252 Norm Difference for worker 1481 is 1.17514
INFO:root:FL Epoch: 252 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1390
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326693
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402293
INFO:root:FL Epoch: 252 Norm Difference for worker 1390 is 1.09619
INFO:root:FL Epoch: 252 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1870
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.961589
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449617
INFO:root:FL Epoch: 252 Norm Difference for worker 1870 is 1.071847
INFO:root:FL Epoch: 252 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :755
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496863
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309853
INFO:root:FL Epoch: 252 Norm Difference for worker 755 is 1.078736
INFO:root:FL Epoch: 252 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1728
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457047
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407374
INFO:root:FL Epoch: 252 Norm Difference for worker 1728 is 1.078362
INFO:root:FL Epoch: 252 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1074
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469120
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523117
INFO:root:FL Epoch: 252 Norm Difference for worker 1074 is 1.18615
INFO:root:FL Epoch: 252 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563297
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435944
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 1.015121
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1734
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583326
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473342
INFO:root:FL Epoch: 252 Norm Difference for worker 1734 is 1.128024
INFO:root:FL Epoch: 252 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1268
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634967
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340921
INFO:root:FL Epoch: 252 Norm Difference for worker 1268 is 1.040814
INFO:root:FL Epoch: 252 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1268
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.5625643502263462 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.3376304656267166                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1274
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450988
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561551
INFO:root:FL Epoch: 253 Norm Difference for worker 1274 is 1.244538
INFO:root:FL Epoch: 253 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1234
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602680
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427697
INFO:root:FL Epoch: 253 Norm Difference for worker 1234 is 1.276522
INFO:root:FL Epoch: 253 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :852
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794036
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562418
INFO:root:FL Epoch: 253 Norm Difference for worker 852 is 1.24179
INFO:root:FL Epoch: 253 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1737
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764722
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462104
INFO:root:FL Epoch: 253 Norm Difference for worker 1737 is 1.205223
INFO:root:FL Epoch: 253 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1163
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540345
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305661
INFO:root:FL Epoch: 253 Norm Difference for worker 1163 is 1.22764
INFO:root:FL Epoch: 253 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :213
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526498
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.735246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 213 is 1.260676
INFO:root:FL Epoch: 253 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1350
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494592
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682757
INFO:root:FL Epoch: 253 Norm Difference for worker 1350 is 1.263632
INFO:root:FL Epoch: 253 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :291
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 291 is 1.17793
INFO:root:FL Epoch: 253 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :800
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492603
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452844
INFO:root:FL Epoch: 253 Norm Difference for worker 800 is 1.243692
INFO:root:FL Epoch: 253 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1016
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808202
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473572
INFO:root:FL Epoch: 253 Norm Difference for worker 1016 is 1.320822
INFO:root:FL Epoch: 253 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 291
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.5344619365299449 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.41770651439825696                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 254 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1754
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525236
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486852
INFO:root:FL Epoch: 254 Norm Difference for worker 1754 is 1.022021
INFO:root:FL Epoch: 254 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1163
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685946
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404517
INFO:root:FL Epoch: 254 Norm Difference for worker 1163 is 1.02761
INFO:root:FL Epoch: 254 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :896
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487208
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373898
INFO:root:FL Epoch: 254 Norm Difference for worker 896 is 1.063347
INFO:root:FL Epoch: 254 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :38
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 38 is 1.020797
INFO:root:FL Epoch: 254 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1431
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476457
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421850
INFO:root:FL Epoch: 254 Norm Difference for worker 1431 is 0.986893
INFO:root:FL Epoch: 254 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :945
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431539
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406522
INFO:root:FL Epoch: 254 Norm Difference for worker 945 is 0.924684
INFO:root:FL Epoch: 254 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1882
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585594
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556066
INFO:root:FL Epoch: 254 Norm Difference for worker 1882 is 1.048918
INFO:root:FL Epoch: 254 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1311
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753857
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588139
INFO:root:FL Epoch: 254 Norm Difference for worker 1311 is 1.086406
INFO:root:FL Epoch: 254 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :721
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730682
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587763
INFO:root:FL Epoch: 254 Norm Difference for worker 721 is 1.043984
INFO:root:FL Epoch: 254 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :844
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462675
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276938
INFO:root:FL Epoch: 254 Norm Difference for worker 844 is 0.947386
INFO:root:FL Epoch: 254 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.5475648816894082 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.4321483125289281                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1458
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598787
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562816
INFO:root:FL Epoch: 255 Norm Difference for worker 1458 is 1.187293
INFO:root:FL Epoch: 255 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :415
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508600
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388713
INFO:root:FL Epoch: 255 Norm Difference for worker 415 is 1.129689
INFO:root:FL Epoch: 255 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1593
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294994
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402549
INFO:root:FL Epoch: 255 Norm Difference for worker 1593 is 0.951377
INFO:root:FL Epoch: 255 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1941
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418293
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301405
INFO:root:FL Epoch: 255 Norm Difference for worker 1941 is 1.138228
INFO:root:FL Epoch: 255 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :575
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723932
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597143
INFO:root:FL Epoch: 255 Norm Difference for worker 575 is 1.294571
INFO:root:FL Epoch: 255 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1329
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456955
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292904
INFO:root:FL Epoch: 255 Norm Difference for worker 1329 is 1.222849
INFO:root:FL Epoch: 255 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :88
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 88 is 1.302847
INFO:root:FL Epoch: 255 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1317
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623237
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482694
INFO:root:FL Epoch: 255 Norm Difference for worker 1317 is 1.267313
INFO:root:FL Epoch: 255 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1582
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661880
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493631
INFO:root:FL Epoch: 255 Norm Difference for worker 1582 is 1.35285
INFO:root:FL Epoch: 255 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427392
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463295
INFO:root:FL Epoch: 255 Norm Difference for worker 1124 is 1.215977
INFO:root:FL Epoch: 255 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.5851921903736451 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.4429575900236766                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1806
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822570
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703976
INFO:root:FL Epoch: 256 Norm Difference for worker 1806 is 1.300034
INFO:root:FL Epoch: 256 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :864
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341597
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528655
INFO:root:FL Epoch: 256 Norm Difference for worker 864 is 1.364774
INFO:root:FL Epoch: 256 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1226
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695954
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347309
INFO:root:FL Epoch: 256 Norm Difference for worker 1226 is 1.312704
INFO:root:FL Epoch: 256 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :325
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502059
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 325 is 1.336979
INFO:root:FL Epoch: 256 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :424
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267175
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241620
INFO:root:FL Epoch: 256 Norm Difference for worker 424 is 1.116339
INFO:root:FL Epoch: 256 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1188
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316595
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676534
INFO:root:FL Epoch: 256 Norm Difference for worker 1188 is 1.351303
INFO:root:FL Epoch: 256 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1760
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 1.149430
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396202
INFO:root:FL Epoch: 256 Norm Difference for worker 1760 is 1.474876
INFO:root:FL Epoch: 256 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :100
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.768474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 100 is 1.43899
INFO:root:FL Epoch: 256 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1464
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651684
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311284
INFO:root:FL Epoch: 256 Norm Difference for worker 1464 is 1.189318
INFO:root:FL Epoch: 256 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :887
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795735
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317090
INFO:root:FL Epoch: 256 Norm Difference for worker 887 is 1.364568
INFO:root:FL Epoch: 256 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.5502137980040382 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.3507489413022995                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1443
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750098
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614872
INFO:root:FL Epoch: 257 Norm Difference for worker 1443 is 1.244084
INFO:root:FL Epoch: 257 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :3
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 3 is 1.240828
INFO:root:FL Epoch: 257 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :324
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 324 is 1.142864
INFO:root:FL Epoch: 257 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :653
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274209
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447649
INFO:root:FL Epoch: 257 Norm Difference for worker 653 is 1.138341
INFO:root:FL Epoch: 257 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :780
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454327
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448440
INFO:root:FL Epoch: 257 Norm Difference for worker 780 is 1.145204
INFO:root:FL Epoch: 257 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :610
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677966
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547615
INFO:root:FL Epoch: 257 Norm Difference for worker 610 is 1.144384
INFO:root:FL Epoch: 257 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :309
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 309 is 1.23046
INFO:root:FL Epoch: 257 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :393
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576312
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502772
INFO:root:FL Epoch: 257 Norm Difference for worker 393 is 1.163466
INFO:root:FL Epoch: 257 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1556
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522837
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510587
INFO:root:FL Epoch: 257 Norm Difference for worker 1556 is 1.124655
INFO:root:FL Epoch: 257 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :602
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675883
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269432
INFO:root:FL Epoch: 257 Norm Difference for worker 602 is 1.140726
INFO:root:FL Epoch: 257 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 653
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.536487572333392 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.3724050521850586                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1162
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499291
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549928
INFO:root:FL Epoch: 258 Norm Difference for worker 1162 is 1.024685
INFO:root:FL Epoch: 258 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1887
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414928
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426380
INFO:root:FL Epoch: 258 Norm Difference for worker 1887 is 0.930543
INFO:root:FL Epoch: 258 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1228
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468188
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454451
INFO:root:FL Epoch: 258 Norm Difference for worker 1228 is 1.07624
INFO:root:FL Epoch: 258 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1028
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456208
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417485
INFO:root:FL Epoch: 258 Norm Difference for worker 1028 is 0.94624
INFO:root:FL Epoch: 258 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1657
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447633
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410033
INFO:root:FL Epoch: 258 Norm Difference for worker 1657 is 1.072128
INFO:root:FL Epoch: 258 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1687
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726305
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671753
INFO:root:FL Epoch: 258 Norm Difference for worker 1687 is 1.078918
INFO:root:FL Epoch: 258 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1086
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514861
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380412
INFO:root:FL Epoch: 258 Norm Difference for worker 1086 is 0.901561
INFO:root:FL Epoch: 258 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :388
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594129
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318939
INFO:root:FL Epoch: 258 Norm Difference for worker 388 is 1.013792
INFO:root:FL Epoch: 258 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :429
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353298
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495507
INFO:root:FL Epoch: 258 Norm Difference for worker 429 is 0.984219
INFO:root:FL Epoch: 258 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :973
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603844
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473821
INFO:root:FL Epoch: 258 Norm Difference for worker 973 is 1.094234
INFO:root:FL Epoch: 258 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.5456183447557337 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.47455303370952606                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 259 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :9
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 9 is 1.012583
INFO:root:FL Epoch: 259 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1195
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429921
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598610
INFO:root:FL Epoch: 259 Norm Difference for worker 1195 is 1.021252
INFO:root:FL Epoch: 259 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :213
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 213 is 1.050604
INFO:root:FL Epoch: 259 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :53
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500818
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 53 is 0.984465
INFO:root:FL Epoch: 259 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :147
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 147 is 0.944929
INFO:root:FL Epoch: 259 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1859
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542395
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644126
INFO:root:FL Epoch: 259 Norm Difference for worker 1859 is 0.995169
INFO:root:FL Epoch: 259 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :429
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433611
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464574
INFO:root:FL Epoch: 259 Norm Difference for worker 429 is 1.037995
INFO:root:FL Epoch: 259 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1183
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659809
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740273
INFO:root:FL Epoch: 259 Norm Difference for worker 1183 is 1.033382
INFO:root:FL Epoch: 259 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1225
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766632
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586387
INFO:root:FL Epoch: 259 Norm Difference for worker 1225 is 1.027844
INFO:root:FL Epoch: 259 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1102
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437835
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521022
INFO:root:FL Epoch: 259 Norm Difference for worker 1102 is 1.031126
INFO:root:FL Epoch: 259 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 147
INFO:root:Norm of Aggregated Model: 5154.96923828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.5396213671740364 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.3909289240837097                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1793
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585391
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389378
INFO:root:FL Epoch: 260 Norm Difference for worker 1793 is 0.983144
INFO:root:FL Epoch: 260 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1652
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390813
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484699
INFO:root:FL Epoch: 260 Norm Difference for worker 1652 is 0.991072
INFO:root:FL Epoch: 260 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1184
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839383
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596912
INFO:root:FL Epoch: 260 Norm Difference for worker 1184 is 0.989591
INFO:root:FL Epoch: 260 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1482
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315398
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325505
INFO:root:FL Epoch: 260 Norm Difference for worker 1482 is 0.892618
INFO:root:FL Epoch: 260 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1085
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502405
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489104
INFO:root:FL Epoch: 260 Norm Difference for worker 1085 is 0.946283
INFO:root:FL Epoch: 260 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :257
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 257 is 1.012284
INFO:root:FL Epoch: 260 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1289
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407854
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438189
INFO:root:FL Epoch: 260 Norm Difference for worker 1289 is 0.914095
INFO:root:FL Epoch: 260 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1365
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341610
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300987
INFO:root:FL Epoch: 260 Norm Difference for worker 1365 is 0.97894
INFO:root:FL Epoch: 260 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :864
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695778
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568745
INFO:root:FL Epoch: 260 Norm Difference for worker 864 is 0.975496
INFO:root:FL Epoch: 260 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1611
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608628
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543106
INFO:root:FL Epoch: 260 Norm Difference for worker 1611 is 0.958142
INFO:root:FL Epoch: 260 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9697265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.550100598265143 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.4558324987689654                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433314
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417348
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.24126685907443365 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.2491896152496338 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.274324
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488941
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272638
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.23530209933718046 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.2491294965147972 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.277582
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402651
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269687
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.25797998160123825 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.2503883853554726 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.256602
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :947
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427553
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612352
INFO:root:FL Epoch: 261 Norm Difference for worker 947 is 1.118741
INFO:root:FL Epoch: 261 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1647
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606297
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435754
INFO:root:FL Epoch: 261 Norm Difference for worker 1647 is 1.3015
INFO:root:FL Epoch: 261 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :422
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642131
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547556
INFO:root:FL Epoch: 261 Norm Difference for worker 422 is 1.152983
INFO:root:FL Epoch: 261 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :127
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317440
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 127 is 1.132247
INFO:root:FL Epoch: 261 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1270
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446584
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231183
INFO:root:FL Epoch: 261 Norm Difference for worker 1270 is 0.957598
INFO:root:FL Epoch: 261 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1475
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476873
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473822
INFO:root:FL Epoch: 261 Norm Difference for worker 1475 is 1.171849
INFO:root:FL Epoch: 261 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1332
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824677
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556331
INFO:root:FL Epoch: 261 Norm Difference for worker 1332 is 1.213676
INFO:root:FL Epoch: 261 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9697265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.5409714649705326 and Test Accuracy:75.0 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.25797998160123825                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 262 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1712
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732576
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463236
INFO:root:FL Epoch: 262 Norm Difference for worker 1712 is 1.22864
INFO:root:FL Epoch: 262 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :818
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574024
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289730
INFO:root:FL Epoch: 262 Norm Difference for worker 818 is 1.125577
INFO:root:FL Epoch: 262 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :28
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 28 is 1.160553
INFO:root:FL Epoch: 262 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :800
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738024
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484241
INFO:root:FL Epoch: 262 Norm Difference for worker 800 is 1.232882
INFO:root:FL Epoch: 262 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :258
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.847064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 258 is 1.312469
INFO:root:FL Epoch: 262 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1584
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569258
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532227
INFO:root:FL Epoch: 262 Norm Difference for worker 1584 is 1.155945
INFO:root:FL Epoch: 262 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1423
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322708
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264521
INFO:root:FL Epoch: 262 Norm Difference for worker 1423 is 1.13944
INFO:root:FL Epoch: 262 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1175
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614120
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515463
INFO:root:FL Epoch: 262 Norm Difference for worker 1175 is 1.270189
INFO:root:FL Epoch: 262 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :625
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557047
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464703
INFO:root:FL Epoch: 262 Norm Difference for worker 625 is 1.236837
INFO:root:FL Epoch: 262 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1520
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497137
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379003
INFO:root:FL Epoch: 262 Norm Difference for worker 1520 is 1.15332
INFO:root:FL Epoch: 262 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 818
INFO:root:Norm of Aggregated Model: 5154.9697265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.5464309857172125 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.31438122938076657                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :979
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830436
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449406
INFO:root:FL Epoch: 263 Norm Difference for worker 979 is 1.323662
INFO:root:FL Epoch: 263 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1707
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896108
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508836
INFO:root:FL Epoch: 263 Norm Difference for worker 1707 is 1.211746
INFO:root:FL Epoch: 263 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :50
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 50 is 1.201321
INFO:root:FL Epoch: 263 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :20
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472296
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 20 is 1.118926
INFO:root:FL Epoch: 263 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :945
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258448
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330301
INFO:root:FL Epoch: 263 Norm Difference for worker 945 is 0.890289
INFO:root:FL Epoch: 263 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :232
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 232 is 1.248461
INFO:root:FL Epoch: 263 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1938
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457101
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697631
INFO:root:FL Epoch: 263 Norm Difference for worker 1938 is 1.301898
INFO:root:FL Epoch: 263 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1500
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756198
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357609
INFO:root:FL Epoch: 263 Norm Difference for worker 1500 is 1.067326
INFO:root:FL Epoch: 263 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :705
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469889
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369586
INFO:root:FL Epoch: 263 Norm Difference for worker 705 is 1.230733
INFO:root:FL Epoch: 263 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :970
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711259
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562823
INFO:root:FL Epoch: 263 Norm Difference for worker 970 is 1.279454
INFO:root:FL Epoch: 263 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.9697265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.5634004587636274 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.2582985044767459                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1333
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902267
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475743
INFO:root:FL Epoch: 264 Norm Difference for worker 1333 is 1.555421
INFO:root:FL Epoch: 264 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1041
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768061
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633336
INFO:root:FL Epoch: 264 Norm Difference for worker 1041 is 1.492379
INFO:root:FL Epoch: 264 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :704
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492351
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619118
INFO:root:FL Epoch: 264 Norm Difference for worker 704 is 1.420387
INFO:root:FL Epoch: 264 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :272
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 272 is 1.311026
INFO:root:FL Epoch: 264 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1412
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594607
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583605
INFO:root:FL Epoch: 264 Norm Difference for worker 1412 is 1.575064
INFO:root:FL Epoch: 264 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1475
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379118
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457503
INFO:root:FL Epoch: 264 Norm Difference for worker 1475 is 1.505973
INFO:root:FL Epoch: 264 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1352
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355011
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545262
INFO:root:FL Epoch: 264 Norm Difference for worker 1352 is 1.525044
INFO:root:FL Epoch: 264 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1251
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668120
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363334
INFO:root:FL Epoch: 264 Norm Difference for worker 1251 is 1.506711
INFO:root:FL Epoch: 264 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :162
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.288089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 162 is 1.551103
INFO:root:FL Epoch: 264 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :202
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.820160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 202 is 1.535509
INFO:root:FL Epoch: 264 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 704
INFO:root:Norm of Aggregated Model: 5154.9697265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.5277225322583142 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.3120070770382881                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :1078
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484613
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384234
INFO:root:FL Epoch: 265 Norm Difference for worker 1078 is 1.150242
INFO:root:FL Epoch: 265 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :339
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 339 is 1.029089
INFO:root:FL Epoch: 265 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1327
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596812
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635750
INFO:root:FL Epoch: 265 Norm Difference for worker 1327 is 1.06045
INFO:root:FL Epoch: 265 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1482
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.157531
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.120484
INFO:root:FL Epoch: 265 Norm Difference for worker 1482 is 0.832484
INFO:root:FL Epoch: 265 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1713
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453674
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419939
INFO:root:FL Epoch: 265 Norm Difference for worker 1713 is 1.070351
INFO:root:FL Epoch: 265 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1622
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647474
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581189
INFO:root:FL Epoch: 265 Norm Difference for worker 1622 is 1.116197
INFO:root:FL Epoch: 265 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1408
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695551
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392419
INFO:root:FL Epoch: 265 Norm Difference for worker 1408 is 1.11326
INFO:root:FL Epoch: 265 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1865
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528584
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363464
INFO:root:FL Epoch: 265 Norm Difference for worker 1865 is 1.10013
INFO:root:FL Epoch: 265 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1421
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634501
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394104
INFO:root:FL Epoch: 265 Norm Difference for worker 1421 is 1.038251
INFO:root:FL Epoch: 265 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :325
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 325 is 1.11016
INFO:root:FL Epoch: 265 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.5689842998981476 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.37545387322704                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437470
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487053
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 1.38151
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :857
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709903
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678488
INFO:root:FL Epoch: 266 Norm Difference for worker 857 is 1.549338
INFO:root:FL Epoch: 266 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :104
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 104 is 1.446134
INFO:root:FL Epoch: 266 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1713
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539470
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282178
INFO:root:FL Epoch: 266 Norm Difference for worker 1713 is 1.343684
INFO:root:FL Epoch: 266 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1448
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526631
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521502
INFO:root:FL Epoch: 266 Norm Difference for worker 1448 is 1.370167
INFO:root:FL Epoch: 266 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :21
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 21 is 1.346599
INFO:root:FL Epoch: 266 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :596
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 1.051460
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314236
INFO:root:FL Epoch: 266 Norm Difference for worker 596 is 1.519964
INFO:root:FL Epoch: 266 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :894
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435434
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396688
INFO:root:FL Epoch: 266 Norm Difference for worker 894 is 1.385603
INFO:root:FL Epoch: 266 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1708
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766794
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423654
INFO:root:FL Epoch: 266 Norm Difference for worker 1708 is 1.440892
INFO:root:FL Epoch: 266 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1086
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301094
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183425
INFO:root:FL Epoch: 266 Norm Difference for worker 1086 is 1.052993
INFO:root:FL Epoch: 266 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.5865088841494392 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.3893609493970871                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598224
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528788
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 1.407529
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1281
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384888
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310460
INFO:root:FL Epoch: 267 Norm Difference for worker 1281 is 1.39611
INFO:root:FL Epoch: 267 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :462
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702456
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504137
INFO:root:FL Epoch: 267 Norm Difference for worker 462 is 1.409041
INFO:root:FL Epoch: 267 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1092
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461861
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537565
INFO:root:FL Epoch: 267 Norm Difference for worker 1092 is 1.512059
INFO:root:FL Epoch: 267 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :606
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585182
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498778
INFO:root:FL Epoch: 267 Norm Difference for worker 606 is 1.359931
INFO:root:FL Epoch: 267 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1605
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697720
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765087
INFO:root:FL Epoch: 267 Norm Difference for worker 1605 is 1.539957
INFO:root:FL Epoch: 267 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :925
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217115
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374338
INFO:root:FL Epoch: 267 Norm Difference for worker 925 is 1.18659
INFO:root:FL Epoch: 267 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :434
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744120
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.844640
INFO:root:FL Epoch: 267 Norm Difference for worker 434 is 1.451273
INFO:root:FL Epoch: 267 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :484
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418705
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286238
INFO:root:FL Epoch: 267 Norm Difference for worker 484 is 1.474173
INFO:root:FL Epoch: 267 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :348
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493004
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456663
INFO:root:FL Epoch: 267 Norm Difference for worker 348 is 1.419955
INFO:root:FL Epoch: 267 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.5571064352989197 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.4357818166414897                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1881
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721630
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419288
INFO:root:FL Epoch: 268 Norm Difference for worker 1881 is 1.148908
INFO:root:FL Epoch: 268 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :711
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766481
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513941
INFO:root:FL Epoch: 268 Norm Difference for worker 711 is 1.251805
INFO:root:FL Epoch: 268 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1677
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714530
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572878
INFO:root:FL Epoch: 268 Norm Difference for worker 1677 is 1.115491
INFO:root:FL Epoch: 268 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :664
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884010
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515156
INFO:root:FL Epoch: 268 Norm Difference for worker 664 is 1.270331
INFO:root:FL Epoch: 268 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :661
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606974
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498921
INFO:root:FL Epoch: 268 Norm Difference for worker 661 is 1.252479
INFO:root:FL Epoch: 268 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1595
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457587
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605607
INFO:root:FL Epoch: 268 Norm Difference for worker 1595 is 1.110139
INFO:root:FL Epoch: 268 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :304
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 304 is 1.227506
INFO:root:FL Epoch: 268 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1712
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832495
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574857
INFO:root:FL Epoch: 268 Norm Difference for worker 1712 is 1.162528
INFO:root:FL Epoch: 268 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1175
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750256
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533502
INFO:root:FL Epoch: 268 Norm Difference for worker 1175 is 1.273283
INFO:root:FL Epoch: 268 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1844
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403885
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283523
INFO:root:FL Epoch: 268 Norm Difference for worker 1844 is 1.116695
INFO:root:FL Epoch: 268 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.5311645400874755 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.3244817778468132                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1376
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646460
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438882
INFO:root:FL Epoch: 269 Norm Difference for worker 1376 is 1.071475
INFO:root:FL Epoch: 269 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :336
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 336 is 1.052922
INFO:root:FL Epoch: 269 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1276
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719637
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500758
INFO:root:FL Epoch: 269 Norm Difference for worker 1276 is 1.157686
INFO:root:FL Epoch: 269 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1589
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525104
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338248
INFO:root:FL Epoch: 269 Norm Difference for worker 1589 is 1.15791
INFO:root:FL Epoch: 269 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :673
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583105
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553705
INFO:root:FL Epoch: 269 Norm Difference for worker 673 is 1.159622
INFO:root:FL Epoch: 269 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :525
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828331
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418036
INFO:root:FL Epoch: 269 Norm Difference for worker 525 is 1.213245
INFO:root:FL Epoch: 269 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :278
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 278 is 1.258
INFO:root:FL Epoch: 269 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1929
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438507
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287515
INFO:root:FL Epoch: 269 Norm Difference for worker 1929 is 0.982182
INFO:root:FL Epoch: 269 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :883
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490496
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553356
INFO:root:FL Epoch: 269 Norm Difference for worker 883 is 1.160375
INFO:root:FL Epoch: 269 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :602
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551422
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318117
INFO:root:FL Epoch: 269 Norm Difference for worker 602 is 1.124902
INFO:root:FL Epoch: 269 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.5508935732000014 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.3291724274555842                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :642
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678127
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481910
INFO:root:FL Epoch: 270 Norm Difference for worker 642 is 1.280493
INFO:root:FL Epoch: 270 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :292
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.872736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518565
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 292 is 1.235291
INFO:root:FL Epoch: 270 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1822
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399287
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281912
INFO:root:FL Epoch: 270 Norm Difference for worker 1822 is 1.108334
INFO:root:FL Epoch: 270 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :896
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567003
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364122
INFO:root:FL Epoch: 270 Norm Difference for worker 896 is 1.239695
INFO:root:FL Epoch: 270 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :733
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839171
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734511
INFO:root:FL Epoch: 270 Norm Difference for worker 733 is 1.247571
INFO:root:FL Epoch: 270 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :899
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573538
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419137
INFO:root:FL Epoch: 270 Norm Difference for worker 899 is 1.226467
INFO:root:FL Epoch: 270 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :640
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461141
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537217
INFO:root:FL Epoch: 270 Norm Difference for worker 640 is 1.200957
INFO:root:FL Epoch: 270 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1499
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642307
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383061
INFO:root:FL Epoch: 270 Norm Difference for worker 1499 is 1.236357
INFO:root:FL Epoch: 270 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :203
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.841160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.732041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 203 is 1.225161
INFO:root:FL Epoch: 270 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :906
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486446
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232858
INFO:root:FL Epoch: 270 Norm Difference for worker 906 is 1.18247
INFO:root:FL Epoch: 270 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1822
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.5597415461259729 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.33820098141829175                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318810
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205556
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.23051299154758453 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.2388547070324421 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.206205
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206487
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152626
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.23993179202079773 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.2359612315893173 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.211281
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256970
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210098
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.23022151614228883 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.2362053468823433 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.215803
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1386
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771744
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440157
INFO:root:FL Epoch: 271 Norm Difference for worker 1386 is 1.153449
INFO:root:FL Epoch: 271 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :312
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 312 is 1.192497
INFO:root:FL Epoch: 271 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :273
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 273 is 1.19589
INFO:root:FL Epoch: 271 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :324
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.734802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 324 is 1.230059
INFO:root:FL Epoch: 271 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :868
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334846
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394299
INFO:root:FL Epoch: 271 Norm Difference for worker 868 is 1.187636
INFO:root:FL Epoch: 271 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :587
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473762
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563878
INFO:root:FL Epoch: 271 Norm Difference for worker 587 is 1.112868
INFO:root:FL Epoch: 271 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1406
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644311
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426297
INFO:root:FL Epoch: 271 Norm Difference for worker 1406 is 1.161399
INFO:root:FL Epoch: 271 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.566236723871792 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.23051299154758453                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1369
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601212
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575804
INFO:root:FL Epoch: 272 Norm Difference for worker 1369 is 1.34614
INFO:root:FL Epoch: 272 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1078
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542726
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579596
INFO:root:FL Epoch: 272 Norm Difference for worker 1078 is 1.267389
INFO:root:FL Epoch: 272 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :946
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792362
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332895
INFO:root:FL Epoch: 272 Norm Difference for worker 946 is 1.214654
INFO:root:FL Epoch: 272 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1596
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612719
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592809
INFO:root:FL Epoch: 272 Norm Difference for worker 1596 is 1.239949
INFO:root:FL Epoch: 272 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1754
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417462
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511705
INFO:root:FL Epoch: 272 Norm Difference for worker 1754 is 1.144764
INFO:root:FL Epoch: 272 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1893
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451561
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343214
INFO:root:FL Epoch: 272 Norm Difference for worker 1893 is 1.319016
INFO:root:FL Epoch: 272 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :76
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 76 is 1.269147
INFO:root:FL Epoch: 272 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397634
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 1.23339
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1514
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908358
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516841
INFO:root:FL Epoch: 272 Norm Difference for worker 1514 is 1.306638
INFO:root:FL Epoch: 272 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :134
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 134 is 1.1711
INFO:root:FL Epoch: 272 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.5530922255095314 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.21604316184918085                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1624
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457158
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583198
INFO:root:FL Epoch: 273 Norm Difference for worker 1624 is 1.120859
INFO:root:FL Epoch: 273 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1303
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436834
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583518
INFO:root:FL Epoch: 273 Norm Difference for worker 1303 is 1.117429
INFO:root:FL Epoch: 273 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1603
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479928
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589176
INFO:root:FL Epoch: 273 Norm Difference for worker 1603 is 1.103179
INFO:root:FL Epoch: 273 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :789
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577289
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572058
INFO:root:FL Epoch: 273 Norm Difference for worker 789 is 1.145844
INFO:root:FL Epoch: 273 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1461
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230722
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442818
INFO:root:FL Epoch: 273 Norm Difference for worker 1461 is 1.067734
INFO:root:FL Epoch: 273 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1439
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472645
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732607
INFO:root:FL Epoch: 273 Norm Difference for worker 1439 is 1.063424
INFO:root:FL Epoch: 273 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :566
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728281
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444808
INFO:root:FL Epoch: 273 Norm Difference for worker 566 is 1.095634
INFO:root:FL Epoch: 273 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :614
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786407
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378524
INFO:root:FL Epoch: 273 Norm Difference for worker 614 is 1.089772
INFO:root:FL Epoch: 273 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :747
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630147
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536887
INFO:root:FL Epoch: 273 Norm Difference for worker 747 is 1.166545
INFO:root:FL Epoch: 273 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1857
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414374
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359914
INFO:root:FL Epoch: 273 Norm Difference for worker 1857 is 1.096296
INFO:root:FL Epoch: 273 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1439
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.5557968511300928 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.31155575563510257                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :722
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635415
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580462
INFO:root:FL Epoch: 274 Norm Difference for worker 722 is 1.050753
INFO:root:FL Epoch: 274 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1292
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523872
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366768
INFO:root:FL Epoch: 274 Norm Difference for worker 1292 is 1.017813
INFO:root:FL Epoch: 274 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :200
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704883
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 200 is 0.977268
INFO:root:FL Epoch: 274 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1745
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823265
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394011
INFO:root:FL Epoch: 274 Norm Difference for worker 1745 is 0.916492
INFO:root:FL Epoch: 274 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1317
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644102
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568439
INFO:root:FL Epoch: 274 Norm Difference for worker 1317 is 1.03239
INFO:root:FL Epoch: 274 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :888
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601602
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417835
INFO:root:FL Epoch: 274 Norm Difference for worker 888 is 1.077225
INFO:root:FL Epoch: 274 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :600
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453431
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387134
INFO:root:FL Epoch: 274 Norm Difference for worker 600 is 0.966611
INFO:root:FL Epoch: 274 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1582
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409790
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585640
INFO:root:FL Epoch: 274 Norm Difference for worker 1582 is 1.025378
INFO:root:FL Epoch: 274 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :122
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531747
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 122 is 0.983818
INFO:root:FL Epoch: 274 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1276
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382634
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596869
INFO:root:FL Epoch: 274 Norm Difference for worker 1276 is 1.02418
INFO:root:FL Epoch: 274 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.535510192899143 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.22771096229553223                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :1037
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678718
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517655
INFO:root:FL Epoch: 275 Norm Difference for worker 1037 is 1.007818
INFO:root:FL Epoch: 275 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1924
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517055
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412149
INFO:root:FL Epoch: 275 Norm Difference for worker 1924 is 0.965602
INFO:root:FL Epoch: 275 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1138
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808773
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613995
INFO:root:FL Epoch: 275 Norm Difference for worker 1138 is 1.089614
INFO:root:FL Epoch: 275 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :939
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452490
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527106
INFO:root:FL Epoch: 275 Norm Difference for worker 939 is 1.009263
INFO:root:FL Epoch: 275 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :622
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658449
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479889
INFO:root:FL Epoch: 275 Norm Difference for worker 622 is 0.968401
INFO:root:FL Epoch: 275 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1818
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683496
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553556
INFO:root:FL Epoch: 275 Norm Difference for worker 1818 is 1.025499
INFO:root:FL Epoch: 275 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :213
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464586
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 213 is 1.04052
INFO:root:FL Epoch: 275 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1662
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407505
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644596
INFO:root:FL Epoch: 275 Norm Difference for worker 1662 is 0.961
INFO:root:FL Epoch: 275 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :829
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523771
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550992
INFO:root:FL Epoch: 275 Norm Difference for worker 829 is 1.054324
INFO:root:FL Epoch: 275 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :968
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457403
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326732
INFO:root:FL Epoch: 275 Norm Difference for worker 968 is 1.005338
INFO:root:FL Epoch: 275 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1662
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.5317412281737608 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.352028767267863                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 276 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :20
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 20 is 0.898134
INFO:root:FL Epoch: 276 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1906
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849539
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656758
INFO:root:FL Epoch: 276 Norm Difference for worker 1906 is 1.028628
INFO:root:FL Epoch: 276 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :168
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 168 is 1.074195
INFO:root:FL Epoch: 276 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :97
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 97 is 1.034108
INFO:root:FL Epoch: 276 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :947
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435410
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525247
INFO:root:FL Epoch: 276 Norm Difference for worker 947 is 0.936631
INFO:root:FL Epoch: 276 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :950
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434234
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410446
INFO:root:FL Epoch: 276 Norm Difference for worker 950 is 1.004005
INFO:root:FL Epoch: 276 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1018
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421146
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496316
INFO:root:FL Epoch: 276 Norm Difference for worker 1018 is 0.944661
INFO:root:FL Epoch: 276 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :477
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686785
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504048
INFO:root:FL Epoch: 276 Norm Difference for worker 477 is 0.930093
INFO:root:FL Epoch: 276 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1388
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704874
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474342
INFO:root:FL Epoch: 276 Norm Difference for worker 1388 is 0.929755
INFO:root:FL Epoch: 276 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1776
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733963
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331719
INFO:root:FL Epoch: 276 Norm Difference for worker 1776 is 0.941965
INFO:root:FL Epoch: 276 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.511895486537148 and Test Accuracy:75.0 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.25416983912388486                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :140
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513356
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 140 is 0.905122
INFO:root:FL Epoch: 277 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1142
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551220
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578447
INFO:root:FL Epoch: 277 Norm Difference for worker 1142 is 0.942151
INFO:root:FL Epoch: 277 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :362
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418148
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542253
INFO:root:FL Epoch: 277 Norm Difference for worker 362 is 0.982289
INFO:root:FL Epoch: 277 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :200
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544026
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 200 is 0.994452
INFO:root:FL Epoch: 277 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :503
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378956
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534339
INFO:root:FL Epoch: 277 Norm Difference for worker 503 is 0.97599
INFO:root:FL Epoch: 277 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1050
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632286
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.821769
INFO:root:FL Epoch: 277 Norm Difference for worker 1050 is 1.001375
INFO:root:FL Epoch: 277 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :405
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584000
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522834
INFO:root:FL Epoch: 277 Norm Difference for worker 405 is 0.953584
INFO:root:FL Epoch: 277 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1577
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635044
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636648
INFO:root:FL Epoch: 277 Norm Difference for worker 1577 is 0.906862
INFO:root:FL Epoch: 277 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1490
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392611
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657533
INFO:root:FL Epoch: 277 Norm Difference for worker 1490 is 0.974183
INFO:root:FL Epoch: 277 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483841
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290093
INFO:root:FL Epoch: 277 Norm Difference for worker 1483 is 0.909495
INFO:root:FL Epoch: 277 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 405
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.5268311535610872 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.38074538856744766                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 278 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :103
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 103 is 0.990055
INFO:root:FL Epoch: 278 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :304
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632049
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 304 is 0.90777
INFO:root:FL Epoch: 278 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1032
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384693
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624419
INFO:root:FL Epoch: 278 Norm Difference for worker 1032 is 0.952167
INFO:root:FL Epoch: 278 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :468
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483854
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546935
INFO:root:FL Epoch: 278 Norm Difference for worker 468 is 0.936933
INFO:root:FL Epoch: 278 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1597
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447610
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366994
INFO:root:FL Epoch: 278 Norm Difference for worker 1597 is 0.989242
INFO:root:FL Epoch: 278 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :227
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 227 is 0.938815
INFO:root:FL Epoch: 278 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :380
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651943
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591133
INFO:root:FL Epoch: 278 Norm Difference for worker 380 is 1.015043
INFO:root:FL Epoch: 278 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :825
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621941
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356589
INFO:root:FL Epoch: 278 Norm Difference for worker 825 is 0.914608
INFO:root:FL Epoch: 278 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1670
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564461
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247599
INFO:root:FL Epoch: 278 Norm Difference for worker 1670 is 0.878341
INFO:root:FL Epoch: 278 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1007
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324841
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511181
INFO:root:FL Epoch: 278 Norm Difference for worker 1007 is 0.965065
INFO:root:FL Epoch: 278 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 304
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.5181266612866345 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.2246588170528412                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1013
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792569
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460637
INFO:root:FL Epoch: 279 Norm Difference for worker 1013 is 0.909464
INFO:root:FL Epoch: 279 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :873
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483669
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406358
INFO:root:FL Epoch: 279 Norm Difference for worker 873 is 0.925547
INFO:root:FL Epoch: 279 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1343
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431445
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291960
INFO:root:FL Epoch: 279 Norm Difference for worker 1343 is 0.957833
INFO:root:FL Epoch: 279 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1746
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513387
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415563
INFO:root:FL Epoch: 279 Norm Difference for worker 1746 is 0.995839
INFO:root:FL Epoch: 279 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :499
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640828
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389608
INFO:root:FL Epoch: 279 Norm Difference for worker 499 is 0.981974
INFO:root:FL Epoch: 279 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1131
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776937
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632761
INFO:root:FL Epoch: 279 Norm Difference for worker 1131 is 1.026047
INFO:root:FL Epoch: 279 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :310
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 310 is 0.927823
INFO:root:FL Epoch: 279 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :223
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 223 is 0.969483
INFO:root:FL Epoch: 279 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1692
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705526
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537819
INFO:root:FL Epoch: 279 Norm Difference for worker 1692 is 0.993692
INFO:root:FL Epoch: 279 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1352
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533274
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374807
INFO:root:FL Epoch: 279 Norm Difference for worker 1352 is 0.994105
INFO:root:FL Epoch: 279 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1013
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.5159404645947849 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.3048686906695366                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1925
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686922
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533979
INFO:root:FL Epoch: 280 Norm Difference for worker 1925 is 0.866298
INFO:root:FL Epoch: 280 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1145
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774115
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421829
INFO:root:FL Epoch: 280 Norm Difference for worker 1145 is 0.876755
INFO:root:FL Epoch: 280 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :636
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917642
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370411
INFO:root:FL Epoch: 280 Norm Difference for worker 636 is 0.881244
INFO:root:FL Epoch: 280 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1906
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505182
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629374
INFO:root:FL Epoch: 280 Norm Difference for worker 1906 is 0.865516
INFO:root:FL Epoch: 280 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1542
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784660
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522251
INFO:root:FL Epoch: 280 Norm Difference for worker 1542 is 0.841747
INFO:root:FL Epoch: 280 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :348
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535476
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730101
INFO:root:FL Epoch: 280 Norm Difference for worker 348 is 0.881636
INFO:root:FL Epoch: 280 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :704
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352207
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384301
INFO:root:FL Epoch: 280 Norm Difference for worker 704 is 0.79837
INFO:root:FL Epoch: 280 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1809
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677351
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627196
INFO:root:FL Epoch: 280 Norm Difference for worker 1809 is 0.858111
INFO:root:FL Epoch: 280 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1212
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374908
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353304
INFO:root:FL Epoch: 280 Norm Difference for worker 1212 is 0.859535
INFO:root:FL Epoch: 280 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1390
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471551
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516898
INFO:root:FL Epoch: 280 Norm Difference for worker 1390 is 0.830782
INFO:root:FL Epoch: 280 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 704
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.5388239166315865 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.3540334925055504                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.188034
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545172
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.20776977638403574 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.2284988448023796 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.244731
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284174
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309250
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.20779522135853767 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.23031243234872817 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.238658
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.163939
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223843
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.21343035623431206 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.23094946891069412 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.232421
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :907
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408027
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340445
INFO:root:FL Epoch: 281 Norm Difference for worker 907 is 1.081509
INFO:root:FL Epoch: 281 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :330
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561055
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 330 is 1.075399
INFO:root:FL Epoch: 281 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1916
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600131
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561060
INFO:root:FL Epoch: 281 Norm Difference for worker 1916 is 1.167151
INFO:root:FL Epoch: 281 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1435
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560299
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370914
INFO:root:FL Epoch: 281 Norm Difference for worker 1435 is 1.106551
INFO:root:FL Epoch: 281 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1385
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366684
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290966
INFO:root:FL Epoch: 281 Norm Difference for worker 1385 is 1.018922
INFO:root:FL Epoch: 281 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1108
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787648
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523430
INFO:root:FL Epoch: 281 Norm Difference for worker 1108 is 1.149158
INFO:root:FL Epoch: 281 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :449
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520667
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358878
INFO:root:FL Epoch: 281 Norm Difference for worker 449 is 1.081332
INFO:root:FL Epoch: 281 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.5184533929123598 and Test Accuracy:75.0 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.21343035623431206                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 282 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :194
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430425
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 194 is 1.154311
INFO:root:FL Epoch: 282 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1670
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291361
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522535
INFO:root:FL Epoch: 282 Norm Difference for worker 1670 is 1.0891
INFO:root:FL Epoch: 282 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :368
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623183
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446492
INFO:root:FL Epoch: 282 Norm Difference for worker 368 is 1.161813
INFO:root:FL Epoch: 282 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1195
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756974
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432563
INFO:root:FL Epoch: 282 Norm Difference for worker 1195 is 1.114456
INFO:root:FL Epoch: 282 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1701
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573199
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435218
INFO:root:FL Epoch: 282 Norm Difference for worker 1701 is 1.158995
INFO:root:FL Epoch: 282 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :24
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 24 is 1.121321
INFO:root:FL Epoch: 282 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1893
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654780
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529799
INFO:root:FL Epoch: 282 Norm Difference for worker 1893 is 1.173432
INFO:root:FL Epoch: 282 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1109
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392845
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494521
INFO:root:FL Epoch: 282 Norm Difference for worker 1109 is 1.151722
INFO:root:FL Epoch: 282 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1734
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494631
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403148
INFO:root:FL Epoch: 282 Norm Difference for worker 1734 is 1.18115
INFO:root:FL Epoch: 282 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 1.179401
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.5178510564215043 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.23171789199113846                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :177
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 177 is 0.991665
INFO:root:FL Epoch: 283 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :4
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 4 is 0.89471
INFO:root:FL Epoch: 283 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1015
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536480
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390964
INFO:root:FL Epoch: 283 Norm Difference for worker 1015 is 0.901475
INFO:root:FL Epoch: 283 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :346
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795625
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594749
INFO:root:FL Epoch: 283 Norm Difference for worker 346 is 0.946301
INFO:root:FL Epoch: 283 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :215
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.764248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 215 is 0.917962
INFO:root:FL Epoch: 283 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :938
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741626
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457011
INFO:root:FL Epoch: 283 Norm Difference for worker 938 is 0.932203
INFO:root:FL Epoch: 283 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1805
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507793
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778679
INFO:root:FL Epoch: 283 Norm Difference for worker 1805 is 0.972535
INFO:root:FL Epoch: 283 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :495
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743711
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538421
INFO:root:FL Epoch: 283 Norm Difference for worker 495 is 0.997366
INFO:root:FL Epoch: 283 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :999
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416651
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488531
INFO:root:FL Epoch: 283 Norm Difference for worker 999 is 0.953556
INFO:root:FL Epoch: 283 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1886
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502480
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225526
INFO:root:FL Epoch: 283 Norm Difference for worker 1886 is 0.941377
INFO:root:FL Epoch: 283 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.5254611653440139 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.2693168943126996                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :386
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418635
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441640
INFO:root:FL Epoch: 284 Norm Difference for worker 386 is 0.85321
INFO:root:FL Epoch: 284 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1503
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580986
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429139
INFO:root:FL Epoch: 284 Norm Difference for worker 1503 is 0.89525
INFO:root:FL Epoch: 284 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1701
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662284
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750339
INFO:root:FL Epoch: 284 Norm Difference for worker 1701 is 0.939533
INFO:root:FL Epoch: 284 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :862
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643159
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525652
INFO:root:FL Epoch: 284 Norm Difference for worker 862 is 0.929105
INFO:root:FL Epoch: 284 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1169
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804848
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303448
INFO:root:FL Epoch: 284 Norm Difference for worker 1169 is 0.889043
INFO:root:FL Epoch: 284 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :346
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365839
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671616
INFO:root:FL Epoch: 284 Norm Difference for worker 346 is 0.916443
INFO:root:FL Epoch: 284 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358612
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429756
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 0.875596
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1492
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524288
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477439
INFO:root:FL Epoch: 284 Norm Difference for worker 1492 is 0.891899
INFO:root:FL Epoch: 284 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1401
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619988
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602265
INFO:root:FL Epoch: 284 Norm Difference for worker 1401 is 0.890528
INFO:root:FL Epoch: 284 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :424
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507453
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532878
INFO:root:FL Epoch: 284 Norm Difference for worker 424 is 0.846324
INFO:root:FL Epoch: 284 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.5322267343016232 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.2268043557802836                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :1837
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552204
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533666
INFO:root:FL Epoch: 285 Norm Difference for worker 1837 is 0.993301
INFO:root:FL Epoch: 285 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :824
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501120
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533546
INFO:root:FL Epoch: 285 Norm Difference for worker 824 is 0.936831
INFO:root:FL Epoch: 285 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1007
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324346
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486393
INFO:root:FL Epoch: 285 Norm Difference for worker 1007 is 1.036626
INFO:root:FL Epoch: 285 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :253
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 253 is 0.970006
INFO:root:FL Epoch: 285 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1875
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531475
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502936
INFO:root:FL Epoch: 285 Norm Difference for worker 1875 is 0.997267
INFO:root:FL Epoch: 285 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :985
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532054
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497688
INFO:root:FL Epoch: 285 Norm Difference for worker 985 is 0.98993
INFO:root:FL Epoch: 285 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1657
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490427
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573654
INFO:root:FL Epoch: 285 Norm Difference for worker 1657 is 1.010782
INFO:root:FL Epoch: 285 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :468
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411861
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426853
INFO:root:FL Epoch: 285 Norm Difference for worker 468 is 0.959729
INFO:root:FL Epoch: 285 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1548
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641616
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372771
INFO:root:FL Epoch: 285 Norm Difference for worker 1548 is 0.934542
INFO:root:FL Epoch: 285 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1947
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634395
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437166
INFO:root:FL Epoch: 285 Norm Difference for worker 1947 is 0.950192
INFO:root:FL Epoch: 285 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 824
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.5386854059555951 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.2977066958944003                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1275
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459951
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380534
INFO:root:FL Epoch: 286 Norm Difference for worker 1275 is 0.89335
INFO:root:FL Epoch: 286 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1599
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654896
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588640
INFO:root:FL Epoch: 286 Norm Difference for worker 1599 is 0.883405
INFO:root:FL Epoch: 286 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :419
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587769
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435498
INFO:root:FL Epoch: 286 Norm Difference for worker 419 is 0.890464
INFO:root:FL Epoch: 286 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :900
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434633
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476228
INFO:root:FL Epoch: 286 Norm Difference for worker 900 is 0.966382
INFO:root:FL Epoch: 286 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :474
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468018
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483989
INFO:root:FL Epoch: 286 Norm Difference for worker 474 is 0.859801
INFO:root:FL Epoch: 286 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :471
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659571
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395305
INFO:root:FL Epoch: 286 Norm Difference for worker 471 is 0.907776
INFO:root:FL Epoch: 286 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1727
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452744
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730125
INFO:root:FL Epoch: 286 Norm Difference for worker 1727 is 0.898898
INFO:root:FL Epoch: 286 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :881
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558453
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426459
INFO:root:FL Epoch: 286 Norm Difference for worker 881 is 0.856267
INFO:root:FL Epoch: 286 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :697
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761485
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577964
INFO:root:FL Epoch: 286 Norm Difference for worker 697 is 0.955509
INFO:root:FL Epoch: 286 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :483
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460607
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331766
INFO:root:FL Epoch: 286 Norm Difference for worker 483 is 0.865688
INFO:root:FL Epoch: 286 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 483
INFO:root:Norm of Aggregated Model: 5154.97021484375
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.5258525066515979 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.20164968570073447                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1262
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663270
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713210
INFO:root:FL Epoch: 287 Norm Difference for worker 1262 is 1.114902
INFO:root:FL Epoch: 287 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :690
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392789
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361059
INFO:root:FL Epoch: 287 Norm Difference for worker 690 is 1.055134
INFO:root:FL Epoch: 287 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :59
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 59 is 1.022138
INFO:root:FL Epoch: 287 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1825
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324953
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424532
INFO:root:FL Epoch: 287 Norm Difference for worker 1825 is 0.993638
INFO:root:FL Epoch: 287 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578758
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474582
INFO:root:FL Epoch: 287 Norm Difference for worker 509 is 1.111665
INFO:root:FL Epoch: 287 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :444
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427203
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468461
INFO:root:FL Epoch: 287 Norm Difference for worker 444 is 1.028767
INFO:root:FL Epoch: 287 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :246
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 246 is 1.006843
INFO:root:FL Epoch: 287 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :841
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401195
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451541
INFO:root:FL Epoch: 287 Norm Difference for worker 841 is 1.062678
INFO:root:FL Epoch: 287 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :417
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498668
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448692
INFO:root:FL Epoch: 287 Norm Difference for worker 417 is 0.996836
INFO:root:FL Epoch: 287 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385150
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394733
INFO:root:FL Epoch: 287 Norm Difference for worker 1509 is 1.046582
INFO:root:FL Epoch: 287 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 246
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.5203037472332225 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.2876773352424304                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :893
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672628
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543853
INFO:root:FL Epoch: 288 Norm Difference for worker 893 is 0.853953
INFO:root:FL Epoch: 288 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :133
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 133 is 0.828262
INFO:root:FL Epoch: 288 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :732
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487850
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377134
INFO:root:FL Epoch: 288 Norm Difference for worker 732 is 0.829305
INFO:root:FL Epoch: 288 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501903
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492307
INFO:root:FL Epoch: 288 Norm Difference for worker 912 is 0.810733
INFO:root:FL Epoch: 288 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :831
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348011
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313979
INFO:root:FL Epoch: 288 Norm Difference for worker 831 is 0.903753
INFO:root:FL Epoch: 288 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1258
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536403
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386977
INFO:root:FL Epoch: 288 Norm Difference for worker 1258 is 0.845575
INFO:root:FL Epoch: 288 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1406
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568724
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413434
INFO:root:FL Epoch: 288 Norm Difference for worker 1406 is 0.849928
INFO:root:FL Epoch: 288 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :510
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502287
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558985
INFO:root:FL Epoch: 288 Norm Difference for worker 510 is 0.808378
INFO:root:FL Epoch: 288 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :75
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 75 is 0.882068
INFO:root:FL Epoch: 288 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1065
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362036
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411545
INFO:root:FL Epoch: 288 Norm Difference for worker 1065 is 0.88083
INFO:root:FL Epoch: 288 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 510
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.5154538662994609 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.222642091413339                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :444
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810579
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558533
INFO:root:FL Epoch: 289 Norm Difference for worker 444 is 0.950438
INFO:root:FL Epoch: 289 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1645
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491197
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479918
INFO:root:FL Epoch: 289 Norm Difference for worker 1645 is 0.888035
INFO:root:FL Epoch: 289 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :199
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425174
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 199 is 0.909899
INFO:root:FL Epoch: 289 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :500
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502208
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465723
INFO:root:FL Epoch: 289 Norm Difference for worker 500 is 0.834483
INFO:root:FL Epoch: 289 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :917
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558804
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479793
INFO:root:FL Epoch: 289 Norm Difference for worker 917 is 0.953717
INFO:root:FL Epoch: 289 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1421
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508711
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406000
INFO:root:FL Epoch: 289 Norm Difference for worker 1421 is 0.844528
INFO:root:FL Epoch: 289 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1485
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561769
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368207
INFO:root:FL Epoch: 289 Norm Difference for worker 1485 is 0.819503
INFO:root:FL Epoch: 289 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :306
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.680954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 306 is 0.8912
INFO:root:FL Epoch: 289 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :638
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487098
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462159
INFO:root:FL Epoch: 289 Norm Difference for worker 638 is 0.852492
INFO:root:FL Epoch: 289 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1471
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534579
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523406
INFO:root:FL Epoch: 289 Norm Difference for worker 1471 is 0.934778
INFO:root:FL Epoch: 289 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1485
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.5146225348991507 and Test Accuracy:75.0 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.2646612549821536                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1328
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423362
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532098
INFO:root:FL Epoch: 290 Norm Difference for worker 1328 is 0.855329
INFO:root:FL Epoch: 290 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :498
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422521
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383269
INFO:root:FL Epoch: 290 Norm Difference for worker 498 is 0.860548
INFO:root:FL Epoch: 290 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1566
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706877
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426999
INFO:root:FL Epoch: 290 Norm Difference for worker 1566 is 0.83219
INFO:root:FL Epoch: 290 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1908
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473002
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483021
INFO:root:FL Epoch: 290 Norm Difference for worker 1908 is 0.874655
INFO:root:FL Epoch: 290 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1688
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413867
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418768
INFO:root:FL Epoch: 290 Norm Difference for worker 1688 is 0.869939
INFO:root:FL Epoch: 290 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :885
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299301
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551517
INFO:root:FL Epoch: 290 Norm Difference for worker 885 is 0.887103
INFO:root:FL Epoch: 290 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :907
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583626
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344125
INFO:root:FL Epoch: 290 Norm Difference for worker 907 is 0.929229
INFO:root:FL Epoch: 290 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1256
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653867
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607067
INFO:root:FL Epoch: 290 Norm Difference for worker 1256 is 0.856052
INFO:root:FL Epoch: 290 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1058
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601462
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661821
INFO:root:FL Epoch: 290 Norm Difference for worker 1058 is 0.842239
INFO:root:FL Epoch: 290 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1876
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781938
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766922
INFO:root:FL Epoch: 290 Norm Difference for worker 1876 is 0.973623
INFO:root:FL Epoch: 290 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 498
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.5236439424402574 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.32142332941293716                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476374
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307904
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.23947698871294656 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.26818942874670026 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.195558
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312970
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224628
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.2274573209385077 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.2702441722154617 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.195554
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250670
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245293
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.23507695396741232 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.2694806054234505 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.192508
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1366
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428355
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531690
INFO:root:FL Epoch: 291 Norm Difference for worker 1366 is 0.825242
INFO:root:FL Epoch: 291 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1025
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809366
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395646
INFO:root:FL Epoch: 291 Norm Difference for worker 1025 is 0.831725
INFO:root:FL Epoch: 291 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1801
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369193
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524904
INFO:root:FL Epoch: 291 Norm Difference for worker 1801 is 0.839706
INFO:root:FL Epoch: 291 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1023
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611342
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559512
INFO:root:FL Epoch: 291 Norm Difference for worker 1023 is 0.82216
INFO:root:FL Epoch: 291 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :476
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657899
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416079
INFO:root:FL Epoch: 291 Norm Difference for worker 476 is 0.787868
INFO:root:FL Epoch: 291 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383115
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415662
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 0.774931
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1114
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500628
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645678
INFO:root:FL Epoch: 291 Norm Difference for worker 1114 is 0.999097
INFO:root:FL Epoch: 291 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.5222280113136067 and Test Accuracy:75.0 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.2274573209385077                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1472
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718648
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544932
INFO:root:FL Epoch: 292 Norm Difference for worker 1472 is 0.949121
INFO:root:FL Epoch: 292 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1744
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452089
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343327
INFO:root:FL Epoch: 292 Norm Difference for worker 1744 is 0.859569
INFO:root:FL Epoch: 292 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :373
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635038
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669545
INFO:root:FL Epoch: 292 Norm Difference for worker 373 is 0.898803
INFO:root:FL Epoch: 292 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1755
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301684
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367592
INFO:root:FL Epoch: 292 Norm Difference for worker 1755 is 0.890221
INFO:root:FL Epoch: 292 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1251
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496955
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330906
INFO:root:FL Epoch: 292 Norm Difference for worker 1251 is 0.894306
INFO:root:FL Epoch: 292 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :364
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511923
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259191
INFO:root:FL Epoch: 292 Norm Difference for worker 364 is 0.896788
INFO:root:FL Epoch: 292 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :894
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543315
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417261
INFO:root:FL Epoch: 292 Norm Difference for worker 894 is 0.883911
INFO:root:FL Epoch: 292 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1005
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568208
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398938
INFO:root:FL Epoch: 292 Norm Difference for worker 1005 is 0.892869
INFO:root:FL Epoch: 292 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :388
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514402
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502575
INFO:root:FL Epoch: 292 Norm Difference for worker 388 is 0.862541
INFO:root:FL Epoch: 292 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1242
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413085
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571132
INFO:root:FL Epoch: 292 Norm Difference for worker 1242 is 0.852575
INFO:root:FL Epoch: 292 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1242
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.5189272147767684 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.2504374111692111                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1224
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560769
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453153
INFO:root:FL Epoch: 293 Norm Difference for worker 1224 is 0.802989
INFO:root:FL Epoch: 293 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :983
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448161
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.799119
INFO:root:FL Epoch: 293 Norm Difference for worker 983 is 0.936835
INFO:root:FL Epoch: 293 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1414
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296576
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512150
INFO:root:FL Epoch: 293 Norm Difference for worker 1414 is 0.843652
INFO:root:FL Epoch: 293 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1763
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405119
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530169
INFO:root:FL Epoch: 293 Norm Difference for worker 1763 is 0.833565
INFO:root:FL Epoch: 293 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :305
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 305 is 0.834591
INFO:root:FL Epoch: 293 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :650
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655023
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648732
INFO:root:FL Epoch: 293 Norm Difference for worker 650 is 0.898827
INFO:root:FL Epoch: 293 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1660
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655156
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524760
INFO:root:FL Epoch: 293 Norm Difference for worker 1660 is 0.869092
INFO:root:FL Epoch: 293 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1700
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673456
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514237
INFO:root:FL Epoch: 293 Norm Difference for worker 1700 is 0.884855
INFO:root:FL Epoch: 293 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1483
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614639
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393295
INFO:root:FL Epoch: 293 Norm Difference for worker 1483 is 0.836523
INFO:root:FL Epoch: 293 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :860
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854343
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638184
INFO:root:FL Epoch: 293 Norm Difference for worker 860 is 0.901748
INFO:root:FL Epoch: 293 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1224
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.517566393403446 and Test Accuracy:75.0 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.2922505810856819                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :318
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 318 is 0.752695
INFO:root:FL Epoch: 294 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1700
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486815
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455085
INFO:root:FL Epoch: 294 Norm Difference for worker 1700 is 0.841461
INFO:root:FL Epoch: 294 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :951
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539556
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619537
INFO:root:FL Epoch: 294 Norm Difference for worker 951 is 0.837506
INFO:root:FL Epoch: 294 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1022
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491870
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362426
INFO:root:FL Epoch: 294 Norm Difference for worker 1022 is 0.785919
INFO:root:FL Epoch: 294 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1087
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592549
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446941
INFO:root:FL Epoch: 294 Norm Difference for worker 1087 is 0.858415
INFO:root:FL Epoch: 294 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :931
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564422
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577003
INFO:root:FL Epoch: 294 Norm Difference for worker 931 is 0.889191
INFO:root:FL Epoch: 294 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :653
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556230
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309622
INFO:root:FL Epoch: 294 Norm Difference for worker 653 is 0.792817
INFO:root:FL Epoch: 294 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :272
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428742
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 272 is 0.844343
INFO:root:FL Epoch: 294 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1459
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647331
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647768
INFO:root:FL Epoch: 294 Norm Difference for worker 1459 is 0.891382
INFO:root:FL Epoch: 294 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1399
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550445
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475784
INFO:root:FL Epoch: 294 Norm Difference for worker 1399 is 0.868817
INFO:root:FL Epoch: 294 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.5317608661511365 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.3186296919981639                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :675
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.951805
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478825
INFO:root:FL Epoch: 295 Norm Difference for worker 675 is 0.967604
INFO:root:FL Epoch: 295 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1942
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490469
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670995
INFO:root:FL Epoch: 295 Norm Difference for worker 1942 is 0.971426
INFO:root:FL Epoch: 295 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1406
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648686
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475608
INFO:root:FL Epoch: 295 Norm Difference for worker 1406 is 0.948783
INFO:root:FL Epoch: 295 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1321
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780398
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387750
INFO:root:FL Epoch: 295 Norm Difference for worker 1321 is 0.936503
INFO:root:FL Epoch: 295 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :443
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740065
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458864
INFO:root:FL Epoch: 295 Norm Difference for worker 443 is 0.972294
INFO:root:FL Epoch: 295 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :427
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549007
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549701
INFO:root:FL Epoch: 295 Norm Difference for worker 427 is 0.915183
INFO:root:FL Epoch: 295 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1883
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269324
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403363
INFO:root:FL Epoch: 295 Norm Difference for worker 1883 is 0.87998
INFO:root:FL Epoch: 295 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :918
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536144
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548568
INFO:root:FL Epoch: 295 Norm Difference for worker 918 is 0.944917
INFO:root:FL Epoch: 295 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :638
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547038
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441863
INFO:root:FL Epoch: 295 Norm Difference for worker 638 is 0.91947
INFO:root:FL Epoch: 295 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1630
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805291
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552358
INFO:root:FL Epoch: 295 Norm Difference for worker 1630 is 0.966723
INFO:root:FL Epoch: 295 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1883
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.5274092765415416 and Test Accuracy:75.0 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.2804522265990575                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1480
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582269
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556004
INFO:root:FL Epoch: 296 Norm Difference for worker 1480 is 0.959126
INFO:root:FL Epoch: 296 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :79
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 79 is 0.855521
INFO:root:FL Epoch: 296 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1343
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264137
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363429
INFO:root:FL Epoch: 296 Norm Difference for worker 1343 is 0.922205
INFO:root:FL Epoch: 296 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1312
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472453
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305943
INFO:root:FL Epoch: 296 Norm Difference for worker 1312 is 0.917687
INFO:root:FL Epoch: 296 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :198
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 198 is 0.918095
INFO:root:FL Epoch: 296 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457800
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529758
INFO:root:FL Epoch: 296 Norm Difference for worker 1941 is 0.855749
INFO:root:FL Epoch: 296 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :975
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506192
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509871
INFO:root:FL Epoch: 296 Norm Difference for worker 975 is 0.951248
INFO:root:FL Epoch: 296 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :496
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797990
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553010
INFO:root:FL Epoch: 296 Norm Difference for worker 496 is 0.889602
INFO:root:FL Epoch: 296 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493488
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349986
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 0.936536
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1032
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601155
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443646
INFO:root:FL Epoch: 296 Norm Difference for worker 1032 is 0.960217
INFO:root:FL Epoch: 296 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1941
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.5246275032267851 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.3327556947867076                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :1570
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447618
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480637
INFO:root:FL Epoch: 297 Norm Difference for worker 1570 is 0.867499
INFO:root:FL Epoch: 297 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1715
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616419
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536664
INFO:root:FL Epoch: 297 Norm Difference for worker 1715 is 0.919861
INFO:root:FL Epoch: 297 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554942
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635638
INFO:root:FL Epoch: 297 Norm Difference for worker 1205 is 0.882081
INFO:root:FL Epoch: 297 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1159
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539417
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487125
INFO:root:FL Epoch: 297 Norm Difference for worker 1159 is 0.834221
INFO:root:FL Epoch: 297 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1186
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393522
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659339
INFO:root:FL Epoch: 297 Norm Difference for worker 1186 is 0.881227
INFO:root:FL Epoch: 297 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :734
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469347
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499766
INFO:root:FL Epoch: 297 Norm Difference for worker 734 is 0.860711
INFO:root:FL Epoch: 297 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1461
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473165
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576097
INFO:root:FL Epoch: 297 Norm Difference for worker 1461 is 0.860054
INFO:root:FL Epoch: 297 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :100
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 100 is 0.887147
INFO:root:FL Epoch: 297 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :989
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782132
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516425
INFO:root:FL Epoch: 297 Norm Difference for worker 989 is 0.853672
INFO:root:FL Epoch: 297 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1614
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527285
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527652
INFO:root:FL Epoch: 297 Norm Difference for worker 1614 is 0.940755
INFO:root:FL Epoch: 297 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1159
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.5122756116530475 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.3142170086503029                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :535
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839208
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370722
INFO:root:FL Epoch: 298 Norm Difference for worker 535 is 0.87611
INFO:root:FL Epoch: 298 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :268
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710860
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591449
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 268 is 0.860198
INFO:root:FL Epoch: 298 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :968
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640105
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654686
INFO:root:FL Epoch: 298 Norm Difference for worker 968 is 0.919919
INFO:root:FL Epoch: 298 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :728
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492603
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693599
INFO:root:FL Epoch: 298 Norm Difference for worker 728 is 0.88042
INFO:root:FL Epoch: 298 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :188
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 188 is 0.871095
INFO:root:FL Epoch: 298 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1851
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444213
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369792
INFO:root:FL Epoch: 298 Norm Difference for worker 1851 is 0.927447
INFO:root:FL Epoch: 298 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1892
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529673
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537306
INFO:root:FL Epoch: 298 Norm Difference for worker 1892 is 0.864984
INFO:root:FL Epoch: 298 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :580
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533988
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691457
INFO:root:FL Epoch: 298 Norm Difference for worker 580 is 0.8972
INFO:root:FL Epoch: 298 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1226
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657106
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625131
INFO:root:FL Epoch: 298 Norm Difference for worker 1226 is 0.885823
INFO:root:FL Epoch: 298 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1003
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590150
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432538
INFO:root:FL Epoch: 298 Norm Difference for worker 1003 is 0.859302
INFO:root:FL Epoch: 298 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1003
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.517170241650413 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.2964126964410146                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1318
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475630
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420909
INFO:root:FL Epoch: 299 Norm Difference for worker 1318 is 0.901872
INFO:root:FL Epoch: 299 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556981
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579225
INFO:root:FL Epoch: 299 Norm Difference for worker 1648 is 0.90649
INFO:root:FL Epoch: 299 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :781
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623164
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498353
INFO:root:FL Epoch: 299 Norm Difference for worker 781 is 0.849541
INFO:root:FL Epoch: 299 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1817
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532616
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590220
INFO:root:FL Epoch: 299 Norm Difference for worker 1817 is 0.867158
INFO:root:FL Epoch: 299 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594341
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493163
INFO:root:FL Epoch: 299 Norm Difference for worker 648 is 0.883146
INFO:root:FL Epoch: 299 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :144
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737255
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607929
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 144 is 0.869587
INFO:root:FL Epoch: 299 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1139
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505034
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333482
INFO:root:FL Epoch: 299 Norm Difference for worker 1139 is 0.808388
INFO:root:FL Epoch: 299 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1156
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409225
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568671
INFO:root:FL Epoch: 299 Norm Difference for worker 1156 is 0.843182
INFO:root:FL Epoch: 299 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :598
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568093
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468037
INFO:root:FL Epoch: 299 Norm Difference for worker 598 is 0.857496
INFO:root:FL Epoch: 299 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :650
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522628
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533891
INFO:root:FL Epoch: 299 Norm Difference for worker 650 is 0.888056
INFO:root:FL Epoch: 299 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.5194995420820573 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.3181038424372673                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1467
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943660
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561749
INFO:root:FL Epoch: 300 Norm Difference for worker 1467 is 0.911857
INFO:root:FL Epoch: 300 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1937
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382745
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402817
INFO:root:FL Epoch: 300 Norm Difference for worker 1937 is 0.967123
INFO:root:FL Epoch: 300 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1312
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584475
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389055
INFO:root:FL Epoch: 300 Norm Difference for worker 1312 is 0.907247
INFO:root:FL Epoch: 300 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1780
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389317
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638095
INFO:root:FL Epoch: 300 Norm Difference for worker 1780 is 0.897877
INFO:root:FL Epoch: 300 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :228
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.367483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668248
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 228 is 0.896009
INFO:root:FL Epoch: 300 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :852
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453093
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377080
INFO:root:FL Epoch: 300 Norm Difference for worker 852 is 0.919969
INFO:root:FL Epoch: 300 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :941
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529482
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361167
INFO:root:FL Epoch: 300 Norm Difference for worker 941 is 0.909038
INFO:root:FL Epoch: 300 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1896
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862730
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685039
INFO:root:FL Epoch: 300 Norm Difference for worker 1896 is 0.955562
INFO:root:FL Epoch: 300 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :414
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447220
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478867
INFO:root:FL Epoch: 300 Norm Difference for worker 414 is 0.929939
INFO:root:FL Epoch: 300 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1088
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502533
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442332
INFO:root:FL Epoch: 300 Norm Difference for worker 1088 is 0.868362
INFO:root:FL Epoch: 300 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.512819544357412 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.30119243760903675                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 1443, 486, 588, 551, 1025, 195, 320]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276987
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239468
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.22546101982394853 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.2117352992296219 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.183119
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383350
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283959
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.21991759414474168 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.210321082174778 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.190687
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.185851
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199156
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.21478028347094855 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.21250534504652024 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.184631
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1443
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657725
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704360
INFO:root:FL Epoch: 301 Norm Difference for worker 1443 is 1.028851
INFO:root:FL Epoch: 301 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :486
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 1.016818
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672068
INFO:root:FL Epoch: 301 Norm Difference for worker 486 is 1.019985
INFO:root:FL Epoch: 301 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :588
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474565
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626185
INFO:root:FL Epoch: 301 Norm Difference for worker 588 is 1.117965
INFO:root:FL Epoch: 301 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :551
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627819
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326338
INFO:root:FL Epoch: 301 Norm Difference for worker 551 is 0.953881
INFO:root:FL Epoch: 301 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1025
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809356
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425248
INFO:root:FL Epoch: 301 Norm Difference for worker 1025 is 1.064188
INFO:root:FL Epoch: 301 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :195
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 195 is 1.041103
INFO:root:FL Epoch: 301 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :320
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 320 is 0.95962
INFO:root:FL Epoch: 301 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 301 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 301 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.519389915115693 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.22546101982394853                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [905, 877, 1238, 1840, 1610, 287, 910, 204, 609, 1756]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :905
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511702
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370905
INFO:root:FL Epoch: 302 Norm Difference for worker 905 is 1.039743
INFO:root:FL Epoch: 302 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :877
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622850
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496570
INFO:root:FL Epoch: 302 Norm Difference for worker 877 is 1.131466
INFO:root:FL Epoch: 302 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1238
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716358
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469045
INFO:root:FL Epoch: 302 Norm Difference for worker 1238 is 1.134258
INFO:root:FL Epoch: 302 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1840
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.953040
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577517
INFO:root:FL Epoch: 302 Norm Difference for worker 1840 is 1.080975
INFO:root:FL Epoch: 302 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1610
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613008
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592153
INFO:root:FL Epoch: 302 Norm Difference for worker 1610 is 1.061166
INFO:root:FL Epoch: 302 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :287
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437595
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 287 is 1.049489
INFO:root:FL Epoch: 302 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :910
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374525
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435904
INFO:root:FL Epoch: 302 Norm Difference for worker 910 is 1.104751
INFO:root:FL Epoch: 302 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :204
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 204 is 1.093393
INFO:root:FL Epoch: 302 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :609
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567642
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376472
INFO:root:FL Epoch: 302 Norm Difference for worker 609 is 1.023237
INFO:root:FL Epoch: 302 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1756
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417968
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551663
INFO:root:FL Epoch: 302 Norm Difference for worker 1756 is 1.08625
INFO:root:FL Epoch: 302 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 609
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.5131621518555809 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.27705958237250644                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1753, 1756, 1355, 139, 584, 1564, 174, 1418, 1113, 648]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1753
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293248
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377538
INFO:root:FL Epoch: 303 Norm Difference for worker 1753 is 0.772499
INFO:root:FL Epoch: 303 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1756
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638583
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355158
INFO:root:FL Epoch: 303 Norm Difference for worker 1756 is 0.929939
INFO:root:FL Epoch: 303 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1355
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529910
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439278
INFO:root:FL Epoch: 303 Norm Difference for worker 1355 is 0.95206
INFO:root:FL Epoch: 303 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :139
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357542
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 139 is 0.885
INFO:root:FL Epoch: 303 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :584
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478519
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522955
INFO:root:FL Epoch: 303 Norm Difference for worker 584 is 0.878508
INFO:root:FL Epoch: 303 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1564
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464320
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511946
INFO:root:FL Epoch: 303 Norm Difference for worker 1564 is 0.882842
INFO:root:FL Epoch: 303 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :174
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 174 is 0.898318
INFO:root:FL Epoch: 303 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1418
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476712
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460515
INFO:root:FL Epoch: 303 Norm Difference for worker 1418 is 0.924037
INFO:root:FL Epoch: 303 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1113
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463517
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576607
INFO:root:FL Epoch: 303 Norm Difference for worker 1113 is 0.876854
INFO:root:FL Epoch: 303 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :648
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561770
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803255
INFO:root:FL Epoch: 303 Norm Difference for worker 648 is 0.899398
INFO:root:FL Epoch: 303 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.5442507968229406 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.3471245790521304                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [315, 691, 657, 599, 1341, 285, 1303, 1544, 468, 755]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 304 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :315
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 315 is 0.953175
INFO:root:FL Epoch: 304 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :691
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419005
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537052
INFO:root:FL Epoch: 304 Norm Difference for worker 691 is 0.907817
INFO:root:FL Epoch: 304 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :657
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666660
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462209
INFO:root:FL Epoch: 304 Norm Difference for worker 657 is 0.926222
INFO:root:FL Epoch: 304 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :599
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480962
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523476
INFO:root:FL Epoch: 304 Norm Difference for worker 599 is 0.960086
INFO:root:FL Epoch: 304 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1341
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556417
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513656
INFO:root:FL Epoch: 304 Norm Difference for worker 1341 is 0.985936
INFO:root:FL Epoch: 304 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :285
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 285 is 0.930321
INFO:root:FL Epoch: 304 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1303
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330509
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660848
INFO:root:FL Epoch: 304 Norm Difference for worker 1303 is 0.949734
INFO:root:FL Epoch: 304 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1544
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557549
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630872
INFO:root:FL Epoch: 304 Norm Difference for worker 1544 is 1.025646
INFO:root:FL Epoch: 304 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :468
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401801
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512290
INFO:root:FL Epoch: 304 Norm Difference for worker 468 is 1.005118
INFO:root:FL Epoch: 304 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :755
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821646
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372902
INFO:root:FL Epoch: 304 Norm Difference for worker 755 is 1.080726
INFO:root:FL Epoch: 304 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 691
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.5155505958725425 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.23225720475117365                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [28, 1394, 832, 101, 1000, 1708, 385, 352, 1307, 941]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 305 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :28
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 28 is 0.805937
INFO:root:FL Epoch: 305 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1394
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587910
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553984
INFO:root:FL Epoch: 305 Norm Difference for worker 1394 is 0.963216
INFO:root:FL Epoch: 305 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :832
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782439
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508168
INFO:root:FL Epoch: 305 Norm Difference for worker 832 is 0.944557
INFO:root:FL Epoch: 305 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :101
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 101 is 0.956896
INFO:root:FL Epoch: 305 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1000
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651970
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484880
INFO:root:FL Epoch: 305 Norm Difference for worker 1000 is 0.899624
INFO:root:FL Epoch: 305 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1708
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447416
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368302
INFO:root:FL Epoch: 305 Norm Difference for worker 1708 is 0.874134
INFO:root:FL Epoch: 305 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :385
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504540
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359027
INFO:root:FL Epoch: 305 Norm Difference for worker 385 is 0.886185
INFO:root:FL Epoch: 305 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :352
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600347
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561419
INFO:root:FL Epoch: 305 Norm Difference for worker 352 is 0.915901
INFO:root:FL Epoch: 305 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1307
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460470
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657501
INFO:root:FL Epoch: 305 Norm Difference for worker 1307 is 0.892234
INFO:root:FL Epoch: 305 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :941
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678339
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575186
INFO:root:FL Epoch: 305 Norm Difference for worker 941 is 0.892762
INFO:root:FL Epoch: 305 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.5168826737824608 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.25242763509353                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [1489, 606, 1775, 681, 834, 643, 1374, 711, 1459, 538]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 306 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :1489
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711003
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429390
INFO:root:FL Epoch: 306 Norm Difference for worker 1489 is 0.994502
INFO:root:FL Epoch: 306 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :606
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801234
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510283
INFO:root:FL Epoch: 306 Norm Difference for worker 606 is 0.863919
INFO:root:FL Epoch: 306 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1775
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436309
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359932
INFO:root:FL Epoch: 306 Norm Difference for worker 1775 is 0.910741
INFO:root:FL Epoch: 306 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :681
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617444
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490125
INFO:root:FL Epoch: 306 Norm Difference for worker 681 is 0.94293
INFO:root:FL Epoch: 306 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :834
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814289
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400846
INFO:root:FL Epoch: 306 Norm Difference for worker 834 is 0.910738
INFO:root:FL Epoch: 306 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :643
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397863
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284201
INFO:root:FL Epoch: 306 Norm Difference for worker 643 is 0.908054
INFO:root:FL Epoch: 306 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1374
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641806
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432732
INFO:root:FL Epoch: 306 Norm Difference for worker 1374 is 0.831984
INFO:root:FL Epoch: 306 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :711
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614801
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561869
INFO:root:FL Epoch: 306 Norm Difference for worker 711 is 0.86085
INFO:root:FL Epoch: 306 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1459
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599778
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638982
INFO:root:FL Epoch: 306 Norm Difference for worker 1459 is 0.941601
INFO:root:FL Epoch: 306 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :538
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614478
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382185
INFO:root:FL Epoch: 306 Norm Difference for worker 538 is 0.859328
INFO:root:FL Epoch: 306 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1374
INFO:root:Norm of Aggregated Model: 5154.970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.5136724061825696 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.2779898817340533                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [906, 614, 1894, 1327, 596, 1690, 1186, 1923, 510, 784]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :906
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399190
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252520
INFO:root:FL Epoch: 307 Norm Difference for worker 906 is 0.862728
INFO:root:FL Epoch: 307 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :614
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534101
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480612
INFO:root:FL Epoch: 307 Norm Difference for worker 614 is 0.877961
INFO:root:FL Epoch: 307 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1894
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461498
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416340
INFO:root:FL Epoch: 307 Norm Difference for worker 1894 is 0.911236
INFO:root:FL Epoch: 307 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1327
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301088
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316487
INFO:root:FL Epoch: 307 Norm Difference for worker 1327 is 0.834326
INFO:root:FL Epoch: 307 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :596
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677072
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505365
INFO:root:FL Epoch: 307 Norm Difference for worker 596 is 0.917102
INFO:root:FL Epoch: 307 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1690
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773539
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667249
INFO:root:FL Epoch: 307 Norm Difference for worker 1690 is 0.891293
INFO:root:FL Epoch: 307 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1186
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543811
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484612
INFO:root:FL Epoch: 307 Norm Difference for worker 1186 is 0.907848
INFO:root:FL Epoch: 307 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1923
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522795
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492000
INFO:root:FL Epoch: 307 Norm Difference for worker 1923 is 0.858546
INFO:root:FL Epoch: 307 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :510
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399678
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640098
INFO:root:FL Epoch: 307 Norm Difference for worker 510 is 0.849511
INFO:root:FL Epoch: 307 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :784
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397037
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421781
INFO:root:FL Epoch: 307 Norm Difference for worker 784 is 0.935836
INFO:root:FL Epoch: 307 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 510
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.5012543788727593 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.15176833172639212                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [1266, 207, 1584, 252, 1605, 1486, 1617, 525, 1340, 1914]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 308 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :1266
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964090
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462806
INFO:root:FL Epoch: 308 Norm Difference for worker 1266 is 1.057343
INFO:root:FL Epoch: 308 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :207
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 207 is 1.086354
INFO:root:FL Epoch: 308 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1584
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617749
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315187
INFO:root:FL Epoch: 308 Norm Difference for worker 1584 is 1.036972
INFO:root:FL Epoch: 308 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :252
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620025
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 252 is 1.086793
INFO:root:FL Epoch: 308 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1605
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728476
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345123
INFO:root:FL Epoch: 308 Norm Difference for worker 1605 is 1.006117
INFO:root:FL Epoch: 308 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1486
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671001
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305836
INFO:root:FL Epoch: 308 Norm Difference for worker 1486 is 1.102277
INFO:root:FL Epoch: 308 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1617
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447442
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276905
INFO:root:FL Epoch: 308 Norm Difference for worker 1617 is 1.013366
INFO:root:FL Epoch: 308 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :525
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520972
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406948
INFO:root:FL Epoch: 308 Norm Difference for worker 525 is 1.099831
INFO:root:FL Epoch: 308 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1340
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523164
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442508
INFO:root:FL Epoch: 308 Norm Difference for worker 1340 is 1.006967
INFO:root:FL Epoch: 308 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1914
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397790
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447397
INFO:root:FL Epoch: 308 Norm Difference for worker 1914 is 1.034391
INFO:root:FL Epoch: 308 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1617
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.5008397715933183 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.2458200454711914                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [21, 1041, 1494, 370, 1006, 19, 1204, 583, 1772, 502]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 309 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :21
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 21 is 0.866169
INFO:root:FL Epoch: 309 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1041
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657058
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579964
INFO:root:FL Epoch: 309 Norm Difference for worker 1041 is 0.848063
INFO:root:FL Epoch: 309 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1494
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395747
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577458
INFO:root:FL Epoch: 309 Norm Difference for worker 1494 is 0.816704
INFO:root:FL Epoch: 309 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :370
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416971
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364232
INFO:root:FL Epoch: 309 Norm Difference for worker 370 is 0.797882
INFO:root:FL Epoch: 309 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1006
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538029
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477355
INFO:root:FL Epoch: 309 Norm Difference for worker 1006 is 0.792091
INFO:root:FL Epoch: 309 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :19
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496704
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 19 is 0.901626
INFO:root:FL Epoch: 309 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1204
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536612
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469099
INFO:root:FL Epoch: 309 Norm Difference for worker 1204 is 0.923476
INFO:root:FL Epoch: 309 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :583
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791996
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468080
INFO:root:FL Epoch: 309 Norm Difference for worker 583 is 0.877829
INFO:root:FL Epoch: 309 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1772
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651121
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659373
INFO:root:FL Epoch: 309 Norm Difference for worker 1772 is 0.87525
INFO:root:FL Epoch: 309 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :502
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588207
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521493
INFO:root:FL Epoch: 309 Norm Difference for worker 502 is 0.844312
INFO:root:FL Epoch: 309 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1494
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.5355710141799029 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.4530445684989293                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [167, 201, 537, 1676, 1913, 909, 1534, 585, 658, 1332]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 310 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :167
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.367925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 167 is 0.788617
INFO:root:FL Epoch: 310 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :201
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554536
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 201 is 0.817766
INFO:root:FL Epoch: 310 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :537
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540387
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740595
INFO:root:FL Epoch: 310 Norm Difference for worker 537 is 0.841544
INFO:root:FL Epoch: 310 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1676
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737823
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576524
INFO:root:FL Epoch: 310 Norm Difference for worker 1676 is 0.823039
INFO:root:FL Epoch: 310 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1913
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642644
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508184
INFO:root:FL Epoch: 310 Norm Difference for worker 1913 is 0.809773
INFO:root:FL Epoch: 310 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :909
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619734
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568426
INFO:root:FL Epoch: 310 Norm Difference for worker 909 is 0.790835
INFO:root:FL Epoch: 310 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1534
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456690
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618401
INFO:root:FL Epoch: 310 Norm Difference for worker 1534 is 0.843863
INFO:root:FL Epoch: 310 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :585
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545552
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469634
INFO:root:FL Epoch: 310 Norm Difference for worker 585 is 0.798689
INFO:root:FL Epoch: 310 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :658
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443463
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353969
INFO:root:FL Epoch: 310 Norm Difference for worker 658 is 0.840672
INFO:root:FL Epoch: 310 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1332
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864534
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568973
INFO:root:FL Epoch: 310 Norm Difference for worker 1332 is 0.758801
INFO:root:FL Epoch: 310 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 909
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 310 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 310 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.504796128062641 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.3570372313261032                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 1910, 621, 208, 1255, 860, 680, 1770]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392550
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396838
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.2714735120534897 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.2854334130883217 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.208079
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325670
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260738
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.26359646022319794 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.2839969232678413 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.214733
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421176
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284484
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.2746625964840253 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.2839309796690941 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.213185
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1910
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525017
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458791
INFO:root:FL Epoch: 311 Norm Difference for worker 1910 is 0.740065
INFO:root:FL Epoch: 311 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :621
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497132
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405619
INFO:root:FL Epoch: 311 Norm Difference for worker 621 is 0.748757
INFO:root:FL Epoch: 311 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :208
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 208 is 0.730308
INFO:root:FL Epoch: 311 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1255
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778319
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504133
INFO:root:FL Epoch: 311 Norm Difference for worker 1255 is 0.693634
INFO:root:FL Epoch: 311 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :860
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643005
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668153
INFO:root:FL Epoch: 311 Norm Difference for worker 860 is 0.696031
INFO:root:FL Epoch: 311 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :680
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667540
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727861
INFO:root:FL Epoch: 311 Norm Difference for worker 680 is 0.719033
INFO:root:FL Epoch: 311 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1770
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482518
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509607
INFO:root:FL Epoch: 311 Norm Difference for worker 1770 is 0.742495
INFO:root:FL Epoch: 311 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.4922485754770391 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.2746625964840253                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [682, 445, 1687, 664, 651, 289, 709, 742, 1093, 800]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :682
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854490
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606217
INFO:root:FL Epoch: 312 Norm Difference for worker 682 is 0.827092
INFO:root:FL Epoch: 312 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :445
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602737
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403472
INFO:root:FL Epoch: 312 Norm Difference for worker 445 is 0.789279
INFO:root:FL Epoch: 312 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1687
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345384
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717004
INFO:root:FL Epoch: 312 Norm Difference for worker 1687 is 0.860642
INFO:root:FL Epoch: 312 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :664
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566178
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719893
INFO:root:FL Epoch: 312 Norm Difference for worker 664 is 0.829456
INFO:root:FL Epoch: 312 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :651
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432895
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526456
INFO:root:FL Epoch: 312 Norm Difference for worker 651 is 0.812614
INFO:root:FL Epoch: 312 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :289
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.330605
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 289 is 0.814694
INFO:root:FL Epoch: 312 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :709
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524739
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623937
INFO:root:FL Epoch: 312 Norm Difference for worker 709 is 0.851153
INFO:root:FL Epoch: 312 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :742
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459302
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504019
INFO:root:FL Epoch: 312 Norm Difference for worker 742 is 0.858137
INFO:root:FL Epoch: 312 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1093
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581365
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455576
INFO:root:FL Epoch: 312 Norm Difference for worker 1093 is 0.772727
INFO:root:FL Epoch: 312 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :800
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574474
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558850
INFO:root:FL Epoch: 312 Norm Difference for worker 800 is 0.784557
INFO:root:FL Epoch: 312 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1093
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.49715592230067535 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.2948596154650052                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [1508, 834, 1190, 29, 1700, 246, 1120, 1788, 578, 729]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :1508
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605580
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500503
INFO:root:FL Epoch: 313 Norm Difference for worker 1508 is 0.821941
INFO:root:FL Epoch: 313 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :834
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444796
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696389
INFO:root:FL Epoch: 313 Norm Difference for worker 834 is 0.777599
INFO:root:FL Epoch: 313 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1190
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362424
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312031
INFO:root:FL Epoch: 313 Norm Difference for worker 1190 is 0.776916
INFO:root:FL Epoch: 313 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :29
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704780
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 29 is 0.804685
INFO:root:FL Epoch: 313 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1700
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450635
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244424
INFO:root:FL Epoch: 313 Norm Difference for worker 1700 is 0.80038
INFO:root:FL Epoch: 313 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :246
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 246 is 0.768708
INFO:root:FL Epoch: 313 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1120
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455361
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496551
INFO:root:FL Epoch: 313 Norm Difference for worker 1120 is 0.786107
INFO:root:FL Epoch: 313 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1788
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831931
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569468
INFO:root:FL Epoch: 313 Norm Difference for worker 1788 is 0.862227
INFO:root:FL Epoch: 313 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :578
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672211
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326436
INFO:root:FL Epoch: 313 Norm Difference for worker 578 is 0.820418
INFO:root:FL Epoch: 313 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :729
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610582
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532201
INFO:root:FL Epoch: 313 Norm Difference for worker 729 is 0.854144
INFO:root:FL Epoch: 313 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.5006787286085241 and Test Accuracy:75.0 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.19207686682542166                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [1599, 1102, 743, 1678, 1810, 800, 1839, 750, 1145, 1449]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :1599
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509463
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299909
INFO:root:FL Epoch: 314 Norm Difference for worker 1599 is 1.128862
INFO:root:FL Epoch: 314 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1102
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649176
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363464
INFO:root:FL Epoch: 314 Norm Difference for worker 1102 is 1.178932
INFO:root:FL Epoch: 314 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :743
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678217
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290640
INFO:root:FL Epoch: 314 Norm Difference for worker 743 is 1.013851
INFO:root:FL Epoch: 314 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1678
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363886
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697821
INFO:root:FL Epoch: 314 Norm Difference for worker 1678 is 1.041185
INFO:root:FL Epoch: 314 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1810
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410819
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329198
INFO:root:FL Epoch: 314 Norm Difference for worker 1810 is 0.92998
INFO:root:FL Epoch: 314 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :800
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830827
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371514
INFO:root:FL Epoch: 314 Norm Difference for worker 800 is 1.145842
INFO:root:FL Epoch: 314 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1839
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.945760
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336448
INFO:root:FL Epoch: 314 Norm Difference for worker 1839 is 1.153526
INFO:root:FL Epoch: 314 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :750
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624033
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379940
INFO:root:FL Epoch: 314 Norm Difference for worker 750 is 1.196899
INFO:root:FL Epoch: 314 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1145
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 1.033547
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476197
INFO:root:FL Epoch: 314 Norm Difference for worker 1145 is 1.102593
INFO:root:FL Epoch: 314 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1449
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313003
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467304
INFO:root:FL Epoch: 314 Norm Difference for worker 1449 is 1.148954
INFO:root:FL Epoch: 314 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.5019048469908097 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.19226140901446342                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [984, 720, 1397, 1394, 1003, 1673, 1271, 1114, 1740, 185]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 315 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :984
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378913
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374203
INFO:root:FL Epoch: 315 Norm Difference for worker 984 is 1.117163
INFO:root:FL Epoch: 315 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :720
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557603
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.774227
INFO:root:FL Epoch: 315 Norm Difference for worker 720 is 1.05826
INFO:root:FL Epoch: 315 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1397
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556709
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331196
INFO:root:FL Epoch: 315 Norm Difference for worker 1397 is 1.070271
INFO:root:FL Epoch: 315 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1394
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242915
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499467
INFO:root:FL Epoch: 315 Norm Difference for worker 1394 is 1.13483
INFO:root:FL Epoch: 315 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1003
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411625
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381778
INFO:root:FL Epoch: 315 Norm Difference for worker 1003 is 0.936813
INFO:root:FL Epoch: 315 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1673
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553369
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534660
INFO:root:FL Epoch: 315 Norm Difference for worker 1673 is 1.087584
INFO:root:FL Epoch: 315 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1271
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324771
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538355
INFO:root:FL Epoch: 315 Norm Difference for worker 1271 is 1.029403
INFO:root:FL Epoch: 315 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1114
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604261
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417197
INFO:root:FL Epoch: 315 Norm Difference for worker 1114 is 1.109343
INFO:root:FL Epoch: 315 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1740
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619993
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366542
INFO:root:FL Epoch: 315 Norm Difference for worker 1740 is 0.95215
INFO:root:FL Epoch: 315 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :185
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402547
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 185 is 1.029436
INFO:root:FL Epoch: 315 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1003
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.5218348713482127 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.28790632635354996                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [1324, 1278, 397, 409, 691, 951, 145, 665, 1649, 1550]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :1324
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720288
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709497
INFO:root:FL Epoch: 316 Norm Difference for worker 1324 is 1.05149
INFO:root:FL Epoch: 316 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1278
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630462
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566301
INFO:root:FL Epoch: 316 Norm Difference for worker 1278 is 1.048102
INFO:root:FL Epoch: 316 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :397
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532700
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461326
INFO:root:FL Epoch: 316 Norm Difference for worker 397 is 1.040676
INFO:root:FL Epoch: 316 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :409
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668043
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474635
INFO:root:FL Epoch: 316 Norm Difference for worker 409 is 0.980506
INFO:root:FL Epoch: 316 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :691
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403529
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350402
INFO:root:FL Epoch: 316 Norm Difference for worker 691 is 0.845592
INFO:root:FL Epoch: 316 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :951
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381299
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370275
INFO:root:FL Epoch: 316 Norm Difference for worker 951 is 0.991876
INFO:root:FL Epoch: 316 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :145
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 145 is 1.03212
INFO:root:FL Epoch: 316 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :665
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540032
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342905
INFO:root:FL Epoch: 316 Norm Difference for worker 665 is 1.051607
INFO:root:FL Epoch: 316 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1649
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685369
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444597
INFO:root:FL Epoch: 316 Norm Difference for worker 1649 is 0.998884
INFO:root:FL Epoch: 316 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1550
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477116
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371490
INFO:root:FL Epoch: 316 Norm Difference for worker 1550 is 1.013989
INFO:root:FL Epoch: 316 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 691
INFO:root:Norm of Aggregated Model: 5154.97119140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.5417123016189126 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.26845842103163403                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [596, 425, 327, 614, 1586, 1405, 196, 226, 526, 243]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :596
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584541
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539816
INFO:root:FL Epoch: 317 Norm Difference for worker 596 is 1.206567
INFO:root:FL Epoch: 317 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :425
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473393
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353097
INFO:root:FL Epoch: 317 Norm Difference for worker 425 is 1.200073
INFO:root:FL Epoch: 317 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :327
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 327 is 1.1661
INFO:root:FL Epoch: 317 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :614
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499635
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528345
INFO:root:FL Epoch: 317 Norm Difference for worker 614 is 1.124524
INFO:root:FL Epoch: 317 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1586
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698149
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476325
INFO:root:FL Epoch: 317 Norm Difference for worker 1586 is 1.072268
INFO:root:FL Epoch: 317 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1405
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447245
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522811
INFO:root:FL Epoch: 317 Norm Difference for worker 1405 is 1.07633
INFO:root:FL Epoch: 317 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :196
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 196 is 1.07205
INFO:root:FL Epoch: 317 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :226
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.778418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461356
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 226 is 1.055678
INFO:root:FL Epoch: 317 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :526
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782349
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506093
INFO:root:FL Epoch: 317 Norm Difference for worker 526 is 1.154938
INFO:root:FL Epoch: 317 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :243
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 243 is 0.919985
INFO:root:FL Epoch: 317 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 243
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.5447434239527759 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.3819032857815425                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [253, 748, 1265, 1438, 1466, 1310, 171, 1495, 820, 920]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :253
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.743951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 253 is 0.979634
INFO:root:FL Epoch: 318 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :748
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473419
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474953
INFO:root:FL Epoch: 318 Norm Difference for worker 748 is 1.056296
INFO:root:FL Epoch: 318 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1265
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819625
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524367
INFO:root:FL Epoch: 318 Norm Difference for worker 1265 is 1.022839
INFO:root:FL Epoch: 318 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1438
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676546
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668841
INFO:root:FL Epoch: 318 Norm Difference for worker 1438 is 1.109924
INFO:root:FL Epoch: 318 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1466
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849435
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435353
INFO:root:FL Epoch: 318 Norm Difference for worker 1466 is 1.107383
INFO:root:FL Epoch: 318 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1310
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376253
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405889
INFO:root:FL Epoch: 318 Norm Difference for worker 1310 is 1.048706
INFO:root:FL Epoch: 318 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :171
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629339
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 171 is 1.04622
INFO:root:FL Epoch: 318 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1495
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727045
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458874
INFO:root:FL Epoch: 318 Norm Difference for worker 1495 is 1.047406
INFO:root:FL Epoch: 318 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :820
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594435
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458105
INFO:root:FL Epoch: 318 Norm Difference for worker 820 is 0.964075
INFO:root:FL Epoch: 318 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :920
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527059
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610619
INFO:root:FL Epoch: 318 Norm Difference for worker 920 is 1.094144
INFO:root:FL Epoch: 318 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.513828274081735 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.2965517168243726                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1365, 504, 564, 1732, 1905, 1719, 1514, 629, 929, 1382]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1365
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642113
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766925
INFO:root:FL Epoch: 319 Norm Difference for worker 1365 is 0.862722
INFO:root:FL Epoch: 319 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :504
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562037
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443421
INFO:root:FL Epoch: 319 Norm Difference for worker 504 is 0.828427
INFO:root:FL Epoch: 319 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :564
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658266
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412508
INFO:root:FL Epoch: 319 Norm Difference for worker 564 is 0.874239
INFO:root:FL Epoch: 319 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1732
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780898
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469692
INFO:root:FL Epoch: 319 Norm Difference for worker 1732 is 0.889619
INFO:root:FL Epoch: 319 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1905
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372156
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384012
INFO:root:FL Epoch: 319 Norm Difference for worker 1905 is 0.852065
INFO:root:FL Epoch: 319 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1719
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437531
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481337
INFO:root:FL Epoch: 319 Norm Difference for worker 1719 is 0.873104
INFO:root:FL Epoch: 319 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1514
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347865
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327896
INFO:root:FL Epoch: 319 Norm Difference for worker 1514 is 0.915067
INFO:root:FL Epoch: 319 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :629
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703958
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541073
INFO:root:FL Epoch: 319 Norm Difference for worker 629 is 0.946283
INFO:root:FL Epoch: 319 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :929
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499134
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371060
INFO:root:FL Epoch: 319 Norm Difference for worker 929 is 0.909636
INFO:root:FL Epoch: 319 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1382
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628477
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574020
INFO:root:FL Epoch: 319 Norm Difference for worker 1382 is 0.913935
INFO:root:FL Epoch: 319 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 504
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.5067742239026463 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.22815128912528357                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [64, 124, 326, 1653, 535, 1504, 1731, 1934, 1210, 1637]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 320 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :64
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 64 is 0.975173
INFO:root:FL Epoch: 320 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :124
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 124 is 0.941171
INFO:root:FL Epoch: 320 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :326
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 326 is 1.065067
INFO:root:FL Epoch: 320 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1653
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669015
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492355
INFO:root:FL Epoch: 320 Norm Difference for worker 1653 is 0.925631
INFO:root:FL Epoch: 320 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :535
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387105
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608976
INFO:root:FL Epoch: 320 Norm Difference for worker 535 is 0.937018
INFO:root:FL Epoch: 320 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1504
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480781
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600833
INFO:root:FL Epoch: 320 Norm Difference for worker 1504 is 0.907405
INFO:root:FL Epoch: 320 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1731
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319631
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592080
INFO:root:FL Epoch: 320 Norm Difference for worker 1731 is 0.865283
INFO:root:FL Epoch: 320 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1934
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407300
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694569
INFO:root:FL Epoch: 320 Norm Difference for worker 1934 is 0.933311
INFO:root:FL Epoch: 320 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1210
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671286
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313775
INFO:root:FL Epoch: 320 Norm Difference for worker 1210 is 0.994661
INFO:root:FL Epoch: 320 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1637
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556575
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290790
INFO:root:FL Epoch: 320 Norm Difference for worker 1637 is 0.873164
INFO:root:FL Epoch: 320 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.5162432859925663 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.37872189780076343                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 1219, 1730, 471, 792, 1830, 1466, 619]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246230
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248104
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.24308323115110397 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.21821822971105576 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.197531
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365936
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342491
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.24485039710998535 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.2190689340233803 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.195738
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407762
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202085
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.23365977903207144 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.21669376716017724 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.209196
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1219
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523219
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349593
INFO:root:FL Epoch: 321 Norm Difference for worker 1219 is 0.96324
INFO:root:FL Epoch: 321 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1730
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644197
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432658
INFO:root:FL Epoch: 321 Norm Difference for worker 1730 is 0.979128
INFO:root:FL Epoch: 321 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :471
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298958
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457057
INFO:root:FL Epoch: 321 Norm Difference for worker 471 is 0.997853
INFO:root:FL Epoch: 321 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :792
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394043
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404287
INFO:root:FL Epoch: 321 Norm Difference for worker 792 is 0.840626
INFO:root:FL Epoch: 321 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1830
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605286
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541221
INFO:root:FL Epoch: 321 Norm Difference for worker 1830 is 0.921482
INFO:root:FL Epoch: 321 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1466
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796656
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604958
INFO:root:FL Epoch: 321 Norm Difference for worker 1466 is 0.950174
INFO:root:FL Epoch: 321 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :619
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546541
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467461
INFO:root:FL Epoch: 321 Norm Difference for worker 619 is 0.965952
INFO:root:FL Epoch: 321 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.5073201796587776 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.24485039710998535                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [832, 612, 600, 982, 1725, 1224, 539, 3, 1510, 673]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :832
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638707
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462321
INFO:root:FL Epoch: 322 Norm Difference for worker 832 is 1.039885
INFO:root:FL Epoch: 322 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :612
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418521
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514151
INFO:root:FL Epoch: 322 Norm Difference for worker 612 is 0.968459
INFO:root:FL Epoch: 322 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :600
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400321
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294183
INFO:root:FL Epoch: 322 Norm Difference for worker 600 is 0.851141
INFO:root:FL Epoch: 322 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :982
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458722
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309326
INFO:root:FL Epoch: 322 Norm Difference for worker 982 is 0.929778
INFO:root:FL Epoch: 322 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1725
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572529
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499641
INFO:root:FL Epoch: 322 Norm Difference for worker 1725 is 1.047536
INFO:root:FL Epoch: 322 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1224
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487608
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540240
INFO:root:FL Epoch: 322 Norm Difference for worker 1224 is 0.811615
INFO:root:FL Epoch: 322 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :539
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739707
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567173
INFO:root:FL Epoch: 322 Norm Difference for worker 539 is 1.00586
INFO:root:FL Epoch: 322 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :3
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318423
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 3 is 1.002659
INFO:root:FL Epoch: 322 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1510
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506188
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507104
INFO:root:FL Epoch: 322 Norm Difference for worker 1510 is 1.011868
INFO:root:FL Epoch: 322 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :673
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815594
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544971
INFO:root:FL Epoch: 322 Norm Difference for worker 673 is 1.022849
INFO:root:FL Epoch: 322 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1224
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.502877926125246 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.2619450290997823                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [888, 344, 814, 1493, 639, 1448, 256, 461, 1908, 337]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :888
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300612
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417666
INFO:root:FL Epoch: 323 Norm Difference for worker 888 is 1.022471
INFO:root:FL Epoch: 323 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :344
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678145
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543688
INFO:root:FL Epoch: 323 Norm Difference for worker 344 is 1.00368
INFO:root:FL Epoch: 323 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :814
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565801
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484757
INFO:root:FL Epoch: 323 Norm Difference for worker 814 is 0.971672
INFO:root:FL Epoch: 323 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1493
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778548
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495521
INFO:root:FL Epoch: 323 Norm Difference for worker 1493 is 1.007913
INFO:root:FL Epoch: 323 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :639
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656311
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408989
INFO:root:FL Epoch: 323 Norm Difference for worker 639 is 1.005161
INFO:root:FL Epoch: 323 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1448
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564813
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480724
INFO:root:FL Epoch: 323 Norm Difference for worker 1448 is 0.970051
INFO:root:FL Epoch: 323 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :256
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546597
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355304
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 256 is 0.996464
INFO:root:FL Epoch: 323 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :461
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494350
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314294
INFO:root:FL Epoch: 323 Norm Difference for worker 461 is 1.04181
INFO:root:FL Epoch: 323 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1908
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433966
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562186
INFO:root:FL Epoch: 323 Norm Difference for worker 1908 is 1.022015
INFO:root:FL Epoch: 323 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :337
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386036
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 337 is 0.954925
INFO:root:FL Epoch: 323 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 814
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.49356449176283446 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.28623369087775546                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1471, 1574, 1571, 563, 1944, 1599, 1205, 843, 1897, 1775]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1471
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293118
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540091
INFO:root:FL Epoch: 324 Norm Difference for worker 1471 is 0.932994
INFO:root:FL Epoch: 324 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1574
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558211
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524932
INFO:root:FL Epoch: 324 Norm Difference for worker 1574 is 0.933291
INFO:root:FL Epoch: 324 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1571
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399943
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468058
INFO:root:FL Epoch: 324 Norm Difference for worker 1571 is 0.876843
INFO:root:FL Epoch: 324 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :563
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462437
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363960
INFO:root:FL Epoch: 324 Norm Difference for worker 563 is 0.939618
INFO:root:FL Epoch: 324 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1944
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404704
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532947
INFO:root:FL Epoch: 324 Norm Difference for worker 1944 is 0.877883
INFO:root:FL Epoch: 324 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1599
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552207
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559407
INFO:root:FL Epoch: 324 Norm Difference for worker 1599 is 0.899992
INFO:root:FL Epoch: 324 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1205
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525351
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513534
INFO:root:FL Epoch: 324 Norm Difference for worker 1205 is 0.960289
INFO:root:FL Epoch: 324 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :843
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414903
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555547
INFO:root:FL Epoch: 324 Norm Difference for worker 843 is 0.973915
INFO:root:FL Epoch: 324 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1897
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716554
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451018
INFO:root:FL Epoch: 324 Norm Difference for worker 1897 is 0.942649
INFO:root:FL Epoch: 324 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1775
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533188
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557400
INFO:root:FL Epoch: 324 Norm Difference for worker 1775 is 0.899886
INFO:root:FL Epoch: 324 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1571
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.49426981894408956 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.3027764434615771                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [1096, 570, 779, 298, 1125, 1322, 856, 1417, 826, 661]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :1096
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501520
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410478
INFO:root:FL Epoch: 325 Norm Difference for worker 1096 is 0.853596
INFO:root:FL Epoch: 325 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :570
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522374
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479892
INFO:root:FL Epoch: 325 Norm Difference for worker 570 is 0.838422
INFO:root:FL Epoch: 325 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :779
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844203
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355005
INFO:root:FL Epoch: 325 Norm Difference for worker 779 is 0.959027
INFO:root:FL Epoch: 325 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :298
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349869
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 298 is 0.902328
INFO:root:FL Epoch: 325 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1125
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513834
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487654
INFO:root:FL Epoch: 325 Norm Difference for worker 1125 is 0.917942
INFO:root:FL Epoch: 325 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1322
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697394
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477567
INFO:root:FL Epoch: 325 Norm Difference for worker 1322 is 0.936367
INFO:root:FL Epoch: 325 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :856
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664082
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464959
INFO:root:FL Epoch: 325 Norm Difference for worker 856 is 0.984562
INFO:root:FL Epoch: 325 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1417
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620895
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510562
INFO:root:FL Epoch: 325 Norm Difference for worker 1417 is 0.920765
INFO:root:FL Epoch: 325 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :826
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384400
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584987
INFO:root:FL Epoch: 325 Norm Difference for worker 826 is 0.953607
INFO:root:FL Epoch: 325 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :661
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551564
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549199
INFO:root:FL Epoch: 325 Norm Difference for worker 661 is 0.936527
INFO:root:FL Epoch: 325 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.4817523728398716 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.32887444645166397                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [354, 951, 1777, 867, 1140, 1467, 525, 13, 1011, 386]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :354
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721541
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500127
INFO:root:FL Epoch: 326 Norm Difference for worker 354 is 0.940808
INFO:root:FL Epoch: 326 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :951
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.980818
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508469
INFO:root:FL Epoch: 326 Norm Difference for worker 951 is 0.921204
INFO:root:FL Epoch: 326 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1777
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478987
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489460
INFO:root:FL Epoch: 326 Norm Difference for worker 1777 is 0.945933
INFO:root:FL Epoch: 326 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :867
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849681
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386190
INFO:root:FL Epoch: 326 Norm Difference for worker 867 is 0.894656
INFO:root:FL Epoch: 326 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1140
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507194
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465899
INFO:root:FL Epoch: 326 Norm Difference for worker 1140 is 0.95785
INFO:root:FL Epoch: 326 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1467
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325144
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339263
INFO:root:FL Epoch: 326 Norm Difference for worker 1467 is 0.922809
INFO:root:FL Epoch: 326 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :525
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596200
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511099
INFO:root:FL Epoch: 326 Norm Difference for worker 525 is 0.974844
INFO:root:FL Epoch: 326 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :13
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 13 is 1.004867
INFO:root:FL Epoch: 326 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1011
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599836
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528129
INFO:root:FL Epoch: 326 Norm Difference for worker 1011 is 0.906065
INFO:root:FL Epoch: 326 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :386
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452732
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535819
INFO:root:FL Epoch: 326 Norm Difference for worker 386 is 0.899921
INFO:root:FL Epoch: 326 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 867
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.4920404272920945 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.4259778559207916                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [394, 43, 1946, 202, 357, 879, 365, 105, 548, 1176]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 327 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :394
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552442
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347586
INFO:root:FL Epoch: 327 Norm Difference for worker 394 is 0.897282
INFO:root:FL Epoch: 327 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :43
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617139
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 43 is 0.826609
INFO:root:FL Epoch: 327 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1946
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403206
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522579
INFO:root:FL Epoch: 327 Norm Difference for worker 1946 is 0.825742
INFO:root:FL Epoch: 327 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :202
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648846
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 202 is 0.876389
INFO:root:FL Epoch: 327 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :357
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545207
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417587
INFO:root:FL Epoch: 327 Norm Difference for worker 357 is 0.831522
INFO:root:FL Epoch: 327 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :879
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435744
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391945
INFO:root:FL Epoch: 327 Norm Difference for worker 879 is 0.828228
INFO:root:FL Epoch: 327 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :365
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462922
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698947
INFO:root:FL Epoch: 327 Norm Difference for worker 365 is 0.851163
INFO:root:FL Epoch: 327 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :105
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 105 is 0.873646
INFO:root:FL Epoch: 327 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :548
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729816
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529693
INFO:root:FL Epoch: 327 Norm Difference for worker 548 is 0.840222
INFO:root:FL Epoch: 327 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1176
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811888
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475804
INFO:root:FL Epoch: 327 Norm Difference for worker 1176 is 0.867902
INFO:root:FL Epoch: 327 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 43
INFO:root:Norm of Aggregated Model: 5154.9716796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.48151200834442587 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.35225145518779755                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [1232, 710, 1540, 1486, 1881, 795, 1174, 1718, 1621, 1011]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 328 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :1232
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508806
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358432
INFO:root:FL Epoch: 328 Norm Difference for worker 1232 is 0.823067
INFO:root:FL Epoch: 328 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :710
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633883
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337249
INFO:root:FL Epoch: 328 Norm Difference for worker 710 is 0.797659
INFO:root:FL Epoch: 328 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1540
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703601
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419215
INFO:root:FL Epoch: 328 Norm Difference for worker 1540 is 0.844811
INFO:root:FL Epoch: 328 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1486
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727447
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585867
INFO:root:FL Epoch: 328 Norm Difference for worker 1486 is 0.836876
INFO:root:FL Epoch: 328 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1881
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529299
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406925
INFO:root:FL Epoch: 328 Norm Difference for worker 1881 is 0.808071
INFO:root:FL Epoch: 328 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :795
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328567
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402869
INFO:root:FL Epoch: 328 Norm Difference for worker 795 is 0.804201
INFO:root:FL Epoch: 328 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1174
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550545
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431589
INFO:root:FL Epoch: 328 Norm Difference for worker 1174 is 0.828065
INFO:root:FL Epoch: 328 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1718
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500119
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478914
INFO:root:FL Epoch: 328 Norm Difference for worker 1718 is 0.845088
INFO:root:FL Epoch: 328 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1621
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573437
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491591
INFO:root:FL Epoch: 328 Norm Difference for worker 1621 is 0.850261
INFO:root:FL Epoch: 328 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1011
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441319
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591103
INFO:root:FL Epoch: 328 Norm Difference for worker 1011 is 0.810931
INFO:root:FL Epoch: 328 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.5346159426605 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.5203156371911367                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [991, 1293, 318, 707, 1256, 1006, 474, 1060, 1599, 1142]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 329 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :991
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809855
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446166
INFO:root:FL Epoch: 329 Norm Difference for worker 991 is 1.007332
INFO:root:FL Epoch: 329 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1293
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699276
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324342
INFO:root:FL Epoch: 329 Norm Difference for worker 1293 is 0.88819
INFO:root:FL Epoch: 329 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :318
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 318 is 0.794313
INFO:root:FL Epoch: 329 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :707
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625851
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547527
INFO:root:FL Epoch: 329 Norm Difference for worker 707 is 0.955872
INFO:root:FL Epoch: 329 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1256
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456743
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542467
INFO:root:FL Epoch: 329 Norm Difference for worker 1256 is 0.934269
INFO:root:FL Epoch: 329 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1006
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753073
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497688
INFO:root:FL Epoch: 329 Norm Difference for worker 1006 is 0.960168
INFO:root:FL Epoch: 329 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :474
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524200
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325962
INFO:root:FL Epoch: 329 Norm Difference for worker 474 is 0.916376
INFO:root:FL Epoch: 329 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1060
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680432
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663970
INFO:root:FL Epoch: 329 Norm Difference for worker 1060 is 0.963585
INFO:root:FL Epoch: 329 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1599
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505297
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741518
INFO:root:FL Epoch: 329 Norm Difference for worker 1599 is 0.976525
INFO:root:FL Epoch: 329 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1142
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444815
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646918
INFO:root:FL Epoch: 329 Norm Difference for worker 1142 is 0.945143
INFO:root:FL Epoch: 329 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.525669210973908 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.41661912202835083                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [824, 956, 806, 259, 128, 1910, 388, 1464, 189, 1100]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :824
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684842
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366883
INFO:root:FL Epoch: 330 Norm Difference for worker 824 is 0.918101
INFO:root:FL Epoch: 330 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :956
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619382
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525011
INFO:root:FL Epoch: 330 Norm Difference for worker 956 is 1.099341
INFO:root:FL Epoch: 330 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :806
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.905754
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750169
INFO:root:FL Epoch: 330 Norm Difference for worker 806 is 1.188026
INFO:root:FL Epoch: 330 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :259
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 259 is 1.11012
INFO:root:FL Epoch: 330 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :128
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 128 is 1.113199
INFO:root:FL Epoch: 330 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1910
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828947
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665458
INFO:root:FL Epoch: 330 Norm Difference for worker 1910 is 1.090282
INFO:root:FL Epoch: 330 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :388
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739768
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315356
INFO:root:FL Epoch: 330 Norm Difference for worker 388 is 1.038818
INFO:root:FL Epoch: 330 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1464
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362372
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513625
INFO:root:FL Epoch: 330 Norm Difference for worker 1464 is 0.880329
INFO:root:FL Epoch: 330 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :189
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 189 is 1.038322
INFO:root:FL Epoch: 330 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1100
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400369
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633396
INFO:root:FL Epoch: 330 Norm Difference for worker 1100 is 1.061936
INFO:root:FL Epoch: 330 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.5199820416815141 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.2860540474454562                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 218, 858, 782, 846, 1181, 420, 726]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302003
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139682
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.22097835689783096 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.1893876701593399 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.173389
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.207756
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388112
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.2181170918047428 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.18798219189047813 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.177684
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258659
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148280
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.21032254894574484 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.18742847070097923 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.190551
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :218
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 218 is 1.075679
INFO:root:FL Epoch: 331 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :858
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548021
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.855713
INFO:root:FL Epoch: 331 Norm Difference for worker 858 is 1.077842
INFO:root:FL Epoch: 331 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :782
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634728
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613197
INFO:root:FL Epoch: 331 Norm Difference for worker 782 is 1.23523
INFO:root:FL Epoch: 331 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :846
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844065
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598434
INFO:root:FL Epoch: 331 Norm Difference for worker 846 is 1.193575
INFO:root:FL Epoch: 331 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1181
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472707
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381895
INFO:root:FL Epoch: 331 Norm Difference for worker 1181 is 1.037911
INFO:root:FL Epoch: 331 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :420
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710124
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349376
INFO:root:FL Epoch: 331 Norm Difference for worker 420 is 1.252953
INFO:root:FL Epoch: 331 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :726
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550812
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268390
INFO:root:FL Epoch: 331 Norm Difference for worker 726 is 1.168596
INFO:root:FL Epoch: 331 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.5281795754152185 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.22097835689783096                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1137, 943, 1384, 478, 1853, 836, 1335, 1385, 333, 848]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1137
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799762
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280826
INFO:root:FL Epoch: 332 Norm Difference for worker 1137 is 1.216725
INFO:root:FL Epoch: 332 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :943
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616426
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692827
INFO:root:FL Epoch: 332 Norm Difference for worker 943 is 1.17925
INFO:root:FL Epoch: 332 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1384
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634399
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345419
INFO:root:FL Epoch: 332 Norm Difference for worker 1384 is 1.202022
INFO:root:FL Epoch: 332 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :478
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598498
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446230
INFO:root:FL Epoch: 332 Norm Difference for worker 478 is 1.134571
INFO:root:FL Epoch: 332 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1853
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732669
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357288
INFO:root:FL Epoch: 332 Norm Difference for worker 1853 is 1.185412
INFO:root:FL Epoch: 332 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :836
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520163
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677329
INFO:root:FL Epoch: 332 Norm Difference for worker 836 is 1.155745
INFO:root:FL Epoch: 332 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1335
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 1.009051
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352871
INFO:root:FL Epoch: 332 Norm Difference for worker 1335 is 1.081762
INFO:root:FL Epoch: 332 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1385
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657922
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491933
INFO:root:FL Epoch: 332 Norm Difference for worker 1385 is 1.117955
INFO:root:FL Epoch: 332 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :333
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 333 is 1.216446
INFO:root:FL Epoch: 332 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :848
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920545
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473630
INFO:root:FL Epoch: 332 Norm Difference for worker 848 is 1.192275
INFO:root:FL Epoch: 332 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1385
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.5206638259046218 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.32391124218702316                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [754, 1821, 539, 906, 684, 557, 1509, 1785, 340, 645]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :754
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375900
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359594
INFO:root:FL Epoch: 333 Norm Difference for worker 754 is 0.89113
INFO:root:FL Epoch: 333 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1821
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665928
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720603
INFO:root:FL Epoch: 333 Norm Difference for worker 1821 is 1.000146
INFO:root:FL Epoch: 333 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :539
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551743
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458700
INFO:root:FL Epoch: 333 Norm Difference for worker 539 is 1.020461
INFO:root:FL Epoch: 333 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :906
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589611
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428602
INFO:root:FL Epoch: 333 Norm Difference for worker 906 is 0.926488
INFO:root:FL Epoch: 333 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :684
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783018
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469630
INFO:root:FL Epoch: 333 Norm Difference for worker 684 is 0.948252
INFO:root:FL Epoch: 333 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :557
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622168
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586684
INFO:root:FL Epoch: 333 Norm Difference for worker 557 is 0.918064
INFO:root:FL Epoch: 333 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1509
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648110
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602012
INFO:root:FL Epoch: 333 Norm Difference for worker 1509 is 1.0831
INFO:root:FL Epoch: 333 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1785
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572211
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529601
INFO:root:FL Epoch: 333 Norm Difference for worker 1785 is 0.926127
INFO:root:FL Epoch: 333 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :340
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421317
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587078
INFO:root:FL Epoch: 333 Norm Difference for worker 340 is 0.99976
INFO:root:FL Epoch: 333 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :645
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749283
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536475
INFO:root:FL Epoch: 333 Norm Difference for worker 645 is 1.027749
INFO:root:FL Epoch: 333 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 754
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.5316535883090076 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.31561433772246045                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1885, 480, 103, 583, 1552, 1728, 265, 35, 1513, 218]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1885
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464713
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373450
INFO:root:FL Epoch: 334 Norm Difference for worker 1885 is 1.054846
INFO:root:FL Epoch: 334 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :480
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665291
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371162
INFO:root:FL Epoch: 334 Norm Difference for worker 480 is 1.077194
INFO:root:FL Epoch: 334 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :103
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 103 is 0.980458
INFO:root:FL Epoch: 334 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :583
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440979
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539440
INFO:root:FL Epoch: 334 Norm Difference for worker 583 is 1.017685
INFO:root:FL Epoch: 334 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1552
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600574
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537106
INFO:root:FL Epoch: 334 Norm Difference for worker 1552 is 1.016159
INFO:root:FL Epoch: 334 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1728
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720113
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422041
INFO:root:FL Epoch: 334 Norm Difference for worker 1728 is 1.057639
INFO:root:FL Epoch: 334 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :265
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.892236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 265 is 1.075781
INFO:root:FL Epoch: 334 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :35
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 35 is 1.018004
INFO:root:FL Epoch: 334 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1513
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302079
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437239
INFO:root:FL Epoch: 334 Norm Difference for worker 1513 is 1.076545
INFO:root:FL Epoch: 334 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :218
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466811
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345026
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 218 is 1.016602
INFO:root:FL Epoch: 334 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 103
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.5112167500397738 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.26801522076129913                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [1862, 981, 783, 483, 92, 332, 409, 1407, 210, 1936]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 335 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :1862
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348521
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466776
INFO:root:FL Epoch: 335 Norm Difference for worker 1862 is 0.98748
INFO:root:FL Epoch: 335 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :981
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602298
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309275
INFO:root:FL Epoch: 335 Norm Difference for worker 981 is 1.121834
INFO:root:FL Epoch: 335 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :783
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635297
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430486
INFO:root:FL Epoch: 335 Norm Difference for worker 783 is 0.977078
INFO:root:FL Epoch: 335 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :483
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312055
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376476
INFO:root:FL Epoch: 335 Norm Difference for worker 483 is 1.341992
INFO:root:FL Epoch: 335 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :92
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 92 is 1.009014
INFO:root:FL Epoch: 335 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :332
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481846
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 332 is 1.014626
INFO:root:FL Epoch: 335 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :409
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700758
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594347
INFO:root:FL Epoch: 335 Norm Difference for worker 409 is 1.058646
INFO:root:FL Epoch: 335 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1407
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693199
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278667
INFO:root:FL Epoch: 335 Norm Difference for worker 1407 is 0.996665
INFO:root:FL Epoch: 335 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :210
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.821225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 210 is 1.034709
INFO:root:FL Epoch: 335 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1936
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351935
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644712
INFO:root:FL Epoch: 335 Norm Difference for worker 1936 is 1.041847
INFO:root:FL Epoch: 335 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.5198879277004915 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.3989555239677429                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [1219, 607, 222, 931, 772, 1596, 769, 484, 896, 852]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 336 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :1219
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464566
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617850
INFO:root:FL Epoch: 336 Norm Difference for worker 1219 is 0.872148
INFO:root:FL Epoch: 336 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :607
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469311
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556758
INFO:root:FL Epoch: 336 Norm Difference for worker 607 is 0.840725
INFO:root:FL Epoch: 336 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :222
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337104
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 222 is 0.865514
INFO:root:FL Epoch: 336 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :931
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383705
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471363
INFO:root:FL Epoch: 336 Norm Difference for worker 931 is 0.956308
INFO:root:FL Epoch: 336 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :772
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591102
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523996
INFO:root:FL Epoch: 336 Norm Difference for worker 772 is 0.917404
INFO:root:FL Epoch: 336 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1596
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420277
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364029
INFO:root:FL Epoch: 336 Norm Difference for worker 1596 is 0.914846
INFO:root:FL Epoch: 336 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :769
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632755
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469689
INFO:root:FL Epoch: 336 Norm Difference for worker 769 is 0.883331
INFO:root:FL Epoch: 336 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :484
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626462
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764570
INFO:root:FL Epoch: 336 Norm Difference for worker 484 is 0.946342
INFO:root:FL Epoch: 336 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :896
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549876
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264295
INFO:root:FL Epoch: 336 Norm Difference for worker 896 is 0.893057
INFO:root:FL Epoch: 336 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :852
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436464
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598214
INFO:root:FL Epoch: 336 Norm Difference for worker 852 is 0.974366
INFO:root:FL Epoch: 336 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.5064077447442448 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.25343115876118344                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [1915, 136, 1458, 1617, 113, 225, 258, 144, 640, 920]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 337 Num points on workers: [200 201 200 200 201 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :1915
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654133
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615639
INFO:root:FL Epoch: 337 Norm Difference for worker 1915 is 1.071506
INFO:root:FL Epoch: 337 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :136
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 136 is 0.968814
INFO:root:FL Epoch: 337 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1458
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665228
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506183
INFO:root:FL Epoch: 337 Norm Difference for worker 1458 is 1.032482
INFO:root:FL Epoch: 337 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1617
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438104
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310869
INFO:root:FL Epoch: 337 Norm Difference for worker 1617 is 0.867946
INFO:root:FL Epoch: 337 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :113
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 113 is 0.942039
INFO:root:FL Epoch: 337 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :225
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 225 is 1.072923
INFO:root:FL Epoch: 337 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :258
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 258 is 1.056648
INFO:root:FL Epoch: 337 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :144
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 144 is 1.048181
INFO:root:FL Epoch: 337 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :640
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518026
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387986
INFO:root:FL Epoch: 337 Norm Difference for worker 640 is 0.998824
INFO:root:FL Epoch: 337 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :920
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623511
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530936
INFO:root:FL Epoch: 337 Norm Difference for worker 920 is 1.045212
INFO:root:FL Epoch: 337 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1617
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.5073117271942251 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.2997935861349106                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [483, 1773, 692, 125, 896, 1694, 899, 1396, 1318, 1791]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :483
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437422
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314826
INFO:root:FL Epoch: 338 Norm Difference for worker 483 is 0.862549
INFO:root:FL Epoch: 338 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1773
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865342
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396257
INFO:root:FL Epoch: 338 Norm Difference for worker 1773 is 1.061913
INFO:root:FL Epoch: 338 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :692
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617297
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445079
INFO:root:FL Epoch: 338 Norm Difference for worker 692 is 1.078246
INFO:root:FL Epoch: 338 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :125
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 125 is 0.89759
INFO:root:FL Epoch: 338 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :896
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488504
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357814
INFO:root:FL Epoch: 338 Norm Difference for worker 896 is 0.965961
INFO:root:FL Epoch: 338 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1694
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523300
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.785515
INFO:root:FL Epoch: 338 Norm Difference for worker 1694 is 1.004638
INFO:root:FL Epoch: 338 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :899
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406525
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345583
INFO:root:FL Epoch: 338 Norm Difference for worker 899 is 0.991346
INFO:root:FL Epoch: 338 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1396
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251283
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543499
INFO:root:FL Epoch: 338 Norm Difference for worker 1396 is 1.072555
INFO:root:FL Epoch: 338 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1318
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693408
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531483
INFO:root:FL Epoch: 338 Norm Difference for worker 1318 is 0.990102
INFO:root:FL Epoch: 338 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1791
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463107
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510743
INFO:root:FL Epoch: 338 Norm Difference for worker 1791 is 1.050952
INFO:root:FL Epoch: 338 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 483
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.51140395508093 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.25638482719659805                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [1629, 745, 1002, 1359, 619, 1907, 21, 1557, 205, 802]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 339 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :1629
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369124
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350026
INFO:root:FL Epoch: 339 Norm Difference for worker 1629 is 1.178647
INFO:root:FL Epoch: 339 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :745
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540301
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389525
INFO:root:FL Epoch: 339 Norm Difference for worker 745 is 1.175429
INFO:root:FL Epoch: 339 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1002
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575547
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289389
INFO:root:FL Epoch: 339 Norm Difference for worker 1002 is 1.029476
INFO:root:FL Epoch: 339 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1359
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729065
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424269
INFO:root:FL Epoch: 339 Norm Difference for worker 1359 is 1.11176
INFO:root:FL Epoch: 339 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :619
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671416
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420966
INFO:root:FL Epoch: 339 Norm Difference for worker 619 is 1.065426
INFO:root:FL Epoch: 339 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1907
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642263
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456454
INFO:root:FL Epoch: 339 Norm Difference for worker 1907 is 1.047472
INFO:root:FL Epoch: 339 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :21
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.849259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 21 is 0.993135
INFO:root:FL Epoch: 339 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1557
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367491
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367723
INFO:root:FL Epoch: 339 Norm Difference for worker 1557 is 1.04195
INFO:root:FL Epoch: 339 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :205
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.804241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527381
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 205 is 1.175318
INFO:root:FL Epoch: 339 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :802
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.989136
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358354
INFO:root:FL Epoch: 339 Norm Difference for worker 802 is 1.109736
INFO:root:FL Epoch: 339 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 21
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.49762018638498645 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.3045611505707105                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [871, 60, 930, 1124, 733, 1016, 689, 214, 319, 1111]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 340 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :871
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287310
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364557
INFO:root:FL Epoch: 340 Norm Difference for worker 871 is 1.03605
INFO:root:FL Epoch: 340 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :60
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.760265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 60 is 0.991132
INFO:root:FL Epoch: 340 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :930
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444648
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402577
INFO:root:FL Epoch: 340 Norm Difference for worker 930 is 1.003629
INFO:root:FL Epoch: 340 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1124
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753467
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532029
INFO:root:FL Epoch: 340 Norm Difference for worker 1124 is 1.053764
INFO:root:FL Epoch: 340 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :733
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581448
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514882
INFO:root:FL Epoch: 340 Norm Difference for worker 733 is 1.091559
INFO:root:FL Epoch: 340 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1016
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792828
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571729
INFO:root:FL Epoch: 340 Norm Difference for worker 1016 is 1.096477
INFO:root:FL Epoch: 340 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :689
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775837
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655169
INFO:root:FL Epoch: 340 Norm Difference for worker 689 is 1.104328
INFO:root:FL Epoch: 340 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :214
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651040
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 214 is 1.023819
INFO:root:FL Epoch: 340 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :319
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 319 is 1.003785
INFO:root:FL Epoch: 340 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1111
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790245
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624821
INFO:root:FL Epoch: 340 Norm Difference for worker 1111 is 1.096819
INFO:root:FL Epoch: 340 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 930
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.4835701444569756 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.31932787597179413                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 472, 1059, 560, 655, 898, 1664, 1277]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395006
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180164
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.25633137424786884 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.2322770059108734 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.165728
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397822
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206531
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.26003849506378174 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.23286215364933013 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.162301
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271182
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196207
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.24936664352814356 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.23230307996273042 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.166144
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :472
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509559
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547799
INFO:root:FL Epoch: 341 Norm Difference for worker 472 is 0.924496
INFO:root:FL Epoch: 341 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1059
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456945
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511960
INFO:root:FL Epoch: 341 Norm Difference for worker 1059 is 0.925357
INFO:root:FL Epoch: 341 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :560
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780363
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578414
INFO:root:FL Epoch: 341 Norm Difference for worker 560 is 0.881014
INFO:root:FL Epoch: 341 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :655
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408741
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498269
INFO:root:FL Epoch: 341 Norm Difference for worker 655 is 0.884798
INFO:root:FL Epoch: 341 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :898
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514600
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566836
INFO:root:FL Epoch: 341 Norm Difference for worker 898 is 0.892254
INFO:root:FL Epoch: 341 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1664
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409804
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332325
INFO:root:FL Epoch: 341 Norm Difference for worker 1664 is 0.869195
INFO:root:FL Epoch: 341 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1277
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599846
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443080
INFO:root:FL Epoch: 341 Norm Difference for worker 1277 is 0.92519
INFO:root:FL Epoch: 341 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.48609607710557823 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.25633137424786884                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1085, 431, 1019, 17, 671, 163, 1750, 1316, 365, 535]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 342 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1085
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319407
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284142
INFO:root:FL Epoch: 342 Norm Difference for worker 1085 is 0.858396
INFO:root:FL Epoch: 342 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :431
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969674
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494108
INFO:root:FL Epoch: 342 Norm Difference for worker 431 is 0.956744
INFO:root:FL Epoch: 342 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1019
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495597
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318359
INFO:root:FL Epoch: 342 Norm Difference for worker 1019 is 0.854624
INFO:root:FL Epoch: 342 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :17
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.802346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 17 is 0.952965
INFO:root:FL Epoch: 342 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :671
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623020
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440586
INFO:root:FL Epoch: 342 Norm Difference for worker 671 is 0.965686
INFO:root:FL Epoch: 342 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :163
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454964
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 163 is 0.976641
INFO:root:FL Epoch: 342 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1750
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718717
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431355
INFO:root:FL Epoch: 342 Norm Difference for worker 1750 is 0.969417
INFO:root:FL Epoch: 342 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1316
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652072
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604996
INFO:root:FL Epoch: 342 Norm Difference for worker 1316 is 0.982348
INFO:root:FL Epoch: 342 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :365
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719253
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659983
INFO:root:FL Epoch: 342 Norm Difference for worker 365 is 0.910717
INFO:root:FL Epoch: 342 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :535
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592882
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589236
INFO:root:FL Epoch: 342 Norm Difference for worker 535 is 0.946017
INFO:root:FL Epoch: 342 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1019
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 342 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 342 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.48119767448481393 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.29009823501110077                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [807, 1321, 608, 1300, 1732, 245, 865, 1286, 1311, 189]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :807
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483599
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422659
INFO:root:FL Epoch: 343 Norm Difference for worker 807 is 0.918184
INFO:root:FL Epoch: 343 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1321
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412371
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415715
INFO:root:FL Epoch: 343 Norm Difference for worker 1321 is 0.883003
INFO:root:FL Epoch: 343 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :608
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745382
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464430
INFO:root:FL Epoch: 343 Norm Difference for worker 608 is 0.969818
INFO:root:FL Epoch: 343 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1300
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555793
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427563
INFO:root:FL Epoch: 343 Norm Difference for worker 1300 is 0.866982
INFO:root:FL Epoch: 343 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1732
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586590
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396559
INFO:root:FL Epoch: 343 Norm Difference for worker 1732 is 0.871762
INFO:root:FL Epoch: 343 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :245
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 245 is 0.900495
INFO:root:FL Epoch: 343 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :865
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428721
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436254
INFO:root:FL Epoch: 343 Norm Difference for worker 865 is 0.894685
INFO:root:FL Epoch: 343 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1286
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892188
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347503
INFO:root:FL Epoch: 343 Norm Difference for worker 1286 is 0.961658
INFO:root:FL Epoch: 343 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1311
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615855
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373115
INFO:root:FL Epoch: 343 Norm Difference for worker 1311 is 0.916798
INFO:root:FL Epoch: 343 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :189
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.278920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484210
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 189 is 0.912679
INFO:root:FL Epoch: 343 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1300
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.48041131391244773 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.304806150496006                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1045, 1586, 604, 485, 1560, 43, 1653, 8, 197, 1076]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1045
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726754
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362226
INFO:root:FL Epoch: 344 Norm Difference for worker 1045 is 0.783085
INFO:root:FL Epoch: 344 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1586
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635977
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766067
INFO:root:FL Epoch: 344 Norm Difference for worker 1586 is 0.853235
INFO:root:FL Epoch: 344 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :604
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358326
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397306
INFO:root:FL Epoch: 344 Norm Difference for worker 604 is 0.915974
INFO:root:FL Epoch: 344 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :485
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577889
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449758
INFO:root:FL Epoch: 344 Norm Difference for worker 485 is 0.848883
INFO:root:FL Epoch: 344 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1560
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431532
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440183
INFO:root:FL Epoch: 344 Norm Difference for worker 1560 is 0.899334
INFO:root:FL Epoch: 344 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :43
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528343
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 43 is 0.806687
INFO:root:FL Epoch: 344 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1653
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417329
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398614
INFO:root:FL Epoch: 344 Norm Difference for worker 1653 is 0.869979
INFO:root:FL Epoch: 344 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :8
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.364801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 8 is 0.844575
INFO:root:FL Epoch: 344 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :197
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539482
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 197 is 0.908286
INFO:root:FL Epoch: 344 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1076
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392859
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497933
INFO:root:FL Epoch: 344 Norm Difference for worker 1076 is 0.833899
INFO:root:FL Epoch: 344 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1045
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.4884263347176945 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.26219572375218075                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [1887, 1618, 192, 1922, 853, 409, 37, 1797, 1173, 354]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 345 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :1887
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414636
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392475
INFO:root:FL Epoch: 345 Norm Difference for worker 1887 is 0.730724
INFO:root:FL Epoch: 345 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1618
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627658
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666417
INFO:root:FL Epoch: 345 Norm Difference for worker 1618 is 0.823725
INFO:root:FL Epoch: 345 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :192
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 192 is 0.850351
INFO:root:FL Epoch: 345 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1922
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591528
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457842
INFO:root:FL Epoch: 345 Norm Difference for worker 1922 is 0.808373
INFO:root:FL Epoch: 345 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :853
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469568
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532179
INFO:root:FL Epoch: 345 Norm Difference for worker 853 is 0.883703
INFO:root:FL Epoch: 345 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :409
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378596
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532471
INFO:root:FL Epoch: 345 Norm Difference for worker 409 is 0.876043
INFO:root:FL Epoch: 345 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :37
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 37 is 0.846823
INFO:root:FL Epoch: 345 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1797
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395160
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712289
INFO:root:FL Epoch: 345 Norm Difference for worker 1797 is 0.850679
INFO:root:FL Epoch: 345 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1173
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470836
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324653
INFO:root:FL Epoch: 345 Norm Difference for worker 1173 is 0.760627
INFO:root:FL Epoch: 345 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :354
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643980
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536156
INFO:root:FL Epoch: 345 Norm Difference for worker 354 is 0.830576
INFO:root:FL Epoch: 345 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.4933018509079428 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.33984525005022687                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [1581, 1807, 1605, 445, 1804, 852, 67, 1870, 1033, 1199]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :1581
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774944
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455908
INFO:root:FL Epoch: 346 Norm Difference for worker 1581 is 0.899462
INFO:root:FL Epoch: 346 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1807
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523794
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550472
INFO:root:FL Epoch: 346 Norm Difference for worker 1807 is 0.943458
INFO:root:FL Epoch: 346 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1605
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751267
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496902
INFO:root:FL Epoch: 346 Norm Difference for worker 1605 is 0.834336
INFO:root:FL Epoch: 346 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :445
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479864
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527741
INFO:root:FL Epoch: 346 Norm Difference for worker 445 is 0.94101
INFO:root:FL Epoch: 346 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1804
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549172
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530442
INFO:root:FL Epoch: 346 Norm Difference for worker 1804 is 0.923943
INFO:root:FL Epoch: 346 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :852
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631603
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609529
INFO:root:FL Epoch: 346 Norm Difference for worker 852 is 0.920264
INFO:root:FL Epoch: 346 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :67
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 67 is 0.915204
INFO:root:FL Epoch: 346 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1870
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471984
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508771
INFO:root:FL Epoch: 346 Norm Difference for worker 1870 is 0.998194
INFO:root:FL Epoch: 346 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1033
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721784
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710644
INFO:root:FL Epoch: 346 Norm Difference for worker 1033 is 0.869829
INFO:root:FL Epoch: 346 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1199
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528403
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427847
INFO:root:FL Epoch: 346 Norm Difference for worker 1199 is 0.910111
INFO:root:FL Epoch: 346 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1605
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.48396825264481935 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.27278157075246173                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [623, 1667, 1748, 1473, 484, 422, 1584, 1257, 247, 1862]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :623
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612409
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403500
INFO:root:FL Epoch: 347 Norm Difference for worker 623 is 0.849878
INFO:root:FL Epoch: 347 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1667
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408448
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476969
INFO:root:FL Epoch: 347 Norm Difference for worker 1667 is 0.828677
INFO:root:FL Epoch: 347 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1748
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410513
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533772
INFO:root:FL Epoch: 347 Norm Difference for worker 1748 is 0.869544
INFO:root:FL Epoch: 347 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1473
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597888
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568419
INFO:root:FL Epoch: 347 Norm Difference for worker 1473 is 0.892719
INFO:root:FL Epoch: 347 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :484
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546425
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482808
INFO:root:FL Epoch: 347 Norm Difference for worker 484 is 0.846041
INFO:root:FL Epoch: 347 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :422
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722337
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395111
INFO:root:FL Epoch: 347 Norm Difference for worker 422 is 0.845942
INFO:root:FL Epoch: 347 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1584
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572049
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653049
INFO:root:FL Epoch: 347 Norm Difference for worker 1584 is 0.773417
INFO:root:FL Epoch: 347 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1257
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671374
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458412
INFO:root:FL Epoch: 347 Norm Difference for worker 1257 is 0.815122
INFO:root:FL Epoch: 347 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :247
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 247 is 0.864929
INFO:root:FL Epoch: 347 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1862
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445849
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421139
INFO:root:FL Epoch: 347 Norm Difference for worker 1862 is 0.816908
INFO:root:FL Epoch: 347 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1584
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.476270631832235 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.27360978722572327                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1637, 1052, 976, 1674, 1323, 573, 1785, 1911, 105, 1649]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1637
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416640
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388470
INFO:root:FL Epoch: 348 Norm Difference for worker 1637 is 0.784611
INFO:root:FL Epoch: 348 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1052
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558655
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520973
INFO:root:FL Epoch: 348 Norm Difference for worker 1052 is 0.819716
INFO:root:FL Epoch: 348 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :976
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623059
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.768239
INFO:root:FL Epoch: 348 Norm Difference for worker 976 is 0.926025
INFO:root:FL Epoch: 348 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1674
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653992
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430457
INFO:root:FL Epoch: 348 Norm Difference for worker 1674 is 0.849074
INFO:root:FL Epoch: 348 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1323
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434333
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503307
INFO:root:FL Epoch: 348 Norm Difference for worker 1323 is 0.84936
INFO:root:FL Epoch: 348 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :573
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566839
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562073
INFO:root:FL Epoch: 348 Norm Difference for worker 573 is 0.851555
INFO:root:FL Epoch: 348 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1785
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693045
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433736
INFO:root:FL Epoch: 348 Norm Difference for worker 1785 is 0.846867
INFO:root:FL Epoch: 348 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1911
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589308
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352459
INFO:root:FL Epoch: 348 Norm Difference for worker 1911 is 0.902095
INFO:root:FL Epoch: 348 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :105
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415525
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.944436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 105 is 0.885266
INFO:root:FL Epoch: 348 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1649
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350483
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553212
INFO:root:FL Epoch: 348 Norm Difference for worker 1649 is 0.848007
INFO:root:FL Epoch: 348 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.47977134760688334 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.29093022644519806                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [1916, 646, 69, 999, 995, 1098, 338, 1684, 334, 1847]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :1916
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560228
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356941
INFO:root:FL Epoch: 349 Norm Difference for worker 1916 is 0.870979
INFO:root:FL Epoch: 349 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :646
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738824
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209450
INFO:root:FL Epoch: 349 Norm Difference for worker 646 is 0.900956
INFO:root:FL Epoch: 349 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :69
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318130
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 69 is 0.850698
INFO:root:FL Epoch: 349 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :999
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639831
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513991
INFO:root:FL Epoch: 349 Norm Difference for worker 999 is 0.891433
INFO:root:FL Epoch: 349 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :995
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642054
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281590
INFO:root:FL Epoch: 349 Norm Difference for worker 995 is 0.927116
INFO:root:FL Epoch: 349 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1098
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415806
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358723
INFO:root:FL Epoch: 349 Norm Difference for worker 1098 is 0.856859
INFO:root:FL Epoch: 349 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :338
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 338 is 0.811244
INFO:root:FL Epoch: 349 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1684
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535535
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549816
INFO:root:FL Epoch: 349 Norm Difference for worker 1684 is 0.946362
INFO:root:FL Epoch: 349 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :334
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568014
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254198
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 334 is 0.797332
INFO:root:FL Epoch: 349 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1847
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426604
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416463
INFO:root:FL Epoch: 349 Norm Difference for worker 1847 is 0.829527
INFO:root:FL Epoch: 349 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 334
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.4823310620644513 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.30550621449947357                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1040, 598, 1751, 1280, 1514, 131, 1654, 1021, 35, 475]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 350 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1040
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526746
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437680
INFO:root:FL Epoch: 350 Norm Difference for worker 1040 is 0.938754
INFO:root:FL Epoch: 350 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :598
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796829
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595706
INFO:root:FL Epoch: 350 Norm Difference for worker 598 is 0.912975
INFO:root:FL Epoch: 350 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1751
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503052
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371955
INFO:root:FL Epoch: 350 Norm Difference for worker 1751 is 0.953561
INFO:root:FL Epoch: 350 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1280
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609144
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400156
INFO:root:FL Epoch: 350 Norm Difference for worker 1280 is 0.918537
INFO:root:FL Epoch: 350 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1514
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601309
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551232
INFO:root:FL Epoch: 350 Norm Difference for worker 1514 is 0.993974
INFO:root:FL Epoch: 350 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :131
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489334
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 131 is 0.986001
INFO:root:FL Epoch: 350 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1654
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017081
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625047
INFO:root:FL Epoch: 350 Norm Difference for worker 1654 is 0.976654
INFO:root:FL Epoch: 350 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1021
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709370
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367828
INFO:root:FL Epoch: 350 Norm Difference for worker 1021 is 0.892992
INFO:root:FL Epoch: 350 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :35
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691402
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 35 is 0.998735
INFO:root:FL Epoch: 350 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :475
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350661
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313576
INFO:root:FL Epoch: 350 Norm Difference for worker 475 is 0.895588
INFO:root:FL Epoch: 350 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1021
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.4719790062483619 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.35419370234012604                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 1925, 712, 218, 1646, 399, 1451, 456]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294382
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288050
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.24253010749816895 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.21835495233535768 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.180422
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.215788
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220699
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.23893233140309653 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.2187030702829361 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.179354
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212371
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206053
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.23994451761245728 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.21960248351097106 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.176719
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1925
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560829
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536106
INFO:root:FL Epoch: 351 Norm Difference for worker 1925 is 0.900084
INFO:root:FL Epoch: 351 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :712
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478721
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503307
INFO:root:FL Epoch: 351 Norm Difference for worker 712 is 0.915653
INFO:root:FL Epoch: 351 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :218
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462490
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 218 is 0.892457
INFO:root:FL Epoch: 351 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1646
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721308
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522660
INFO:root:FL Epoch: 351 Norm Difference for worker 1646 is 0.839402
INFO:root:FL Epoch: 351 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :399
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573659
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307909
INFO:root:FL Epoch: 351 Norm Difference for worker 399 is 0.885958
INFO:root:FL Epoch: 351 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1451
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650178
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460607
INFO:root:FL Epoch: 351 Norm Difference for worker 1451 is 0.875736
INFO:root:FL Epoch: 351 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :456
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464509
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651283
INFO:root:FL Epoch: 351 Norm Difference for worker 456 is 0.855625
INFO:root:FL Epoch: 351 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.47110650469275084 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.23994451761245728                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [588, 721, 1883, 1861, 358, 1909, 374, 1674, 1237, 72]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :588
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664096
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506738
INFO:root:FL Epoch: 352 Norm Difference for worker 588 is 0.92523
INFO:root:FL Epoch: 352 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :721
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642770
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259029
INFO:root:FL Epoch: 352 Norm Difference for worker 721 is 0.948104
INFO:root:FL Epoch: 352 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1883
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458125
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511408
INFO:root:FL Epoch: 352 Norm Difference for worker 1883 is 0.792649
INFO:root:FL Epoch: 352 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1861
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665072
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534922
INFO:root:FL Epoch: 352 Norm Difference for worker 1861 is 0.95657
INFO:root:FL Epoch: 352 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :358
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296564
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317704
INFO:root:FL Epoch: 352 Norm Difference for worker 358 is 0.890863
INFO:root:FL Epoch: 352 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1909
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543145
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494438
INFO:root:FL Epoch: 352 Norm Difference for worker 1909 is 0.895081
INFO:root:FL Epoch: 352 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :374
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249402
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405524
INFO:root:FL Epoch: 352 Norm Difference for worker 374 is 0.931482
INFO:root:FL Epoch: 352 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1674
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498113
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390508
INFO:root:FL Epoch: 352 Norm Difference for worker 1674 is 0.91739
INFO:root:FL Epoch: 352 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1237
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477446
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381507
INFO:root:FL Epoch: 352 Norm Difference for worker 1237 is 0.953223
INFO:root:FL Epoch: 352 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :72
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378037
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 72 is 0.862292
INFO:root:FL Epoch: 352 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1883
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.4817536631051232 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.24441181123256683                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1237, 882, 946, 571, 1547, 1187, 1344, 1663, 105, 1843]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1237
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710903
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535067
INFO:root:FL Epoch: 353 Norm Difference for worker 1237 is 0.917124
INFO:root:FL Epoch: 353 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :882
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759293
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518144
INFO:root:FL Epoch: 353 Norm Difference for worker 882 is 0.928217
INFO:root:FL Epoch: 353 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :946
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508311
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457135
INFO:root:FL Epoch: 353 Norm Difference for worker 946 is 0.920476
INFO:root:FL Epoch: 353 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :571
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391635
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436263
INFO:root:FL Epoch: 353 Norm Difference for worker 571 is 0.899157
INFO:root:FL Epoch: 353 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1547
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597803
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426366
INFO:root:FL Epoch: 353 Norm Difference for worker 1547 is 0.863049
INFO:root:FL Epoch: 353 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1187
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573212
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411965
INFO:root:FL Epoch: 353 Norm Difference for worker 1187 is 0.853932
INFO:root:FL Epoch: 353 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1344
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531506
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453051
INFO:root:FL Epoch: 353 Norm Difference for worker 1344 is 0.903726
INFO:root:FL Epoch: 353 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1663
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600862
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648735
INFO:root:FL Epoch: 353 Norm Difference for worker 1663 is 0.848969
INFO:root:FL Epoch: 353 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :105
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463294
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 105 is 0.979797
INFO:root:FL Epoch: 353 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1843
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581845
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232964
INFO:root:FL Epoch: 353 Norm Difference for worker 1843 is 0.854862
INFO:root:FL Epoch: 353 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.48835378008730274 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.2909086321791013                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [660, 1494, 1242, 1335, 1418, 184, 1837, 178, 10, 14]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 201 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :660
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585182
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451237
INFO:root:FL Epoch: 354 Norm Difference for worker 660 is 0.760546
INFO:root:FL Epoch: 354 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1494
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545189
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354730
INFO:root:FL Epoch: 354 Norm Difference for worker 1494 is 0.713931
INFO:root:FL Epoch: 354 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1242
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406074
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299978
INFO:root:FL Epoch: 354 Norm Difference for worker 1242 is 0.755377
INFO:root:FL Epoch: 354 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1335
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597067
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491018
INFO:root:FL Epoch: 354 Norm Difference for worker 1335 is 0.753546
INFO:root:FL Epoch: 354 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1418
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613259
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619573
INFO:root:FL Epoch: 354 Norm Difference for worker 1418 is 0.748637
INFO:root:FL Epoch: 354 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :184
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 184 is 0.72074
INFO:root:FL Epoch: 354 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1837
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420932
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483635
INFO:root:FL Epoch: 354 Norm Difference for worker 1837 is 0.777526
INFO:root:FL Epoch: 354 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :178
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 178 is 0.765081
INFO:root:FL Epoch: 354 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :10
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369928
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374181
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 10 is 0.793618
INFO:root:FL Epoch: 354 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :14
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 14 is 0.804056
INFO:root:FL Epoch: 354 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.4896395609659307 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.21985386808713278                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [196, 1723, 1727, 1583, 929, 174, 1542, 1680, 696, 659]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :196
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.381623
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 196 is 0.864889
INFO:root:FL Epoch: 355 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1723
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422575
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448828
INFO:root:FL Epoch: 355 Norm Difference for worker 1723 is 0.846277
INFO:root:FL Epoch: 355 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1727
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638599
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412596
INFO:root:FL Epoch: 355 Norm Difference for worker 1727 is 0.825866
INFO:root:FL Epoch: 355 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1583
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476129
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716452
INFO:root:FL Epoch: 355 Norm Difference for worker 1583 is 0.88852
INFO:root:FL Epoch: 355 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :929
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406636
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251008
INFO:root:FL Epoch: 355 Norm Difference for worker 929 is 0.86229
INFO:root:FL Epoch: 355 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :174
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516830
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 174 is 0.882123
INFO:root:FL Epoch: 355 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1542
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505336
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444903
INFO:root:FL Epoch: 355 Norm Difference for worker 1542 is 0.938453
INFO:root:FL Epoch: 355 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1680
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544709
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473176
INFO:root:FL Epoch: 355 Norm Difference for worker 1680 is 0.803655
INFO:root:FL Epoch: 355 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :696
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423879
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571338
INFO:root:FL Epoch: 355 Norm Difference for worker 696 is 0.905562
INFO:root:FL Epoch: 355 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :659
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623953
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568483
INFO:root:FL Epoch: 355 Norm Difference for worker 659 is 0.942947
INFO:root:FL Epoch: 355 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1727
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.4953570330844206 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.36633826792240143                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [65, 648, 1515, 64, 1041, 823, 1336, 1648, 1233, 54]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 356 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :65
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 65 is 0.760036
INFO:root:FL Epoch: 356 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468224
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604963
INFO:root:FL Epoch: 356 Norm Difference for worker 648 is 0.711437
INFO:root:FL Epoch: 356 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1515
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679498
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688826
INFO:root:FL Epoch: 356 Norm Difference for worker 1515 is 0.694597
INFO:root:FL Epoch: 356 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :64
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 64 is 0.71205
INFO:root:FL Epoch: 356 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1041
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680179
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639352
INFO:root:FL Epoch: 356 Norm Difference for worker 1041 is 0.697817
INFO:root:FL Epoch: 356 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :823
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576172
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469111
INFO:root:FL Epoch: 356 Norm Difference for worker 823 is 0.778457
INFO:root:FL Epoch: 356 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1336
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490729
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680012
INFO:root:FL Epoch: 356 Norm Difference for worker 1336 is 0.741238
INFO:root:FL Epoch: 356 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501938
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510730
INFO:root:FL Epoch: 356 Norm Difference for worker 1648 is 0.748815
INFO:root:FL Epoch: 356 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1233
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491399
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571233
INFO:root:FL Epoch: 356 Norm Difference for worker 1233 is 0.773326
INFO:root:FL Epoch: 356 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :54
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404382
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 54 is 0.765539
INFO:root:FL Epoch: 356 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1515
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.4979150470565347 and Test Accuracy:75.0 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.35684039692083996                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1333, 1745, 1844, 1776, 288, 308, 1198, 441, 1571, 614]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1333
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660908
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541623
INFO:root:FL Epoch: 357 Norm Difference for worker 1333 is 0.718959
INFO:root:FL Epoch: 357 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1745
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533276
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538169
INFO:root:FL Epoch: 357 Norm Difference for worker 1745 is 0.740035
INFO:root:FL Epoch: 357 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1844
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662522
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326488
INFO:root:FL Epoch: 357 Norm Difference for worker 1844 is 0.797983
INFO:root:FL Epoch: 357 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1776
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623855
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587361
INFO:root:FL Epoch: 357 Norm Difference for worker 1776 is 0.727435
INFO:root:FL Epoch: 357 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :288
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 288 is 0.753433
INFO:root:FL Epoch: 357 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :308
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.795733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 308 is 0.668483
INFO:root:FL Epoch: 357 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1198
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429809
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446489
INFO:root:FL Epoch: 357 Norm Difference for worker 1198 is 0.714355
INFO:root:FL Epoch: 357 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :441
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576339
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478805
INFO:root:FL Epoch: 357 Norm Difference for worker 441 is 0.791987
INFO:root:FL Epoch: 357 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1571
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506641
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295945
INFO:root:FL Epoch: 357 Norm Difference for worker 1571 is 0.74836
INFO:root:FL Epoch: 357 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :614
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410297
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454228
INFO:root:FL Epoch: 357 Norm Difference for worker 614 is 0.757486
INFO:root:FL Epoch: 357 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 308
INFO:root:Norm of Aggregated Model: 5154.97216796875
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.49272944296107574 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.3767840812603633                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1581, 104, 380, 887, 392, 1518, 120, 905, 1181, 65]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1581
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607488
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449387
INFO:root:FL Epoch: 358 Norm Difference for worker 1581 is 0.78683
INFO:root:FL Epoch: 358 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :104
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 104 is 0.7067
INFO:root:FL Epoch: 358 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :380
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661174
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466429
INFO:root:FL Epoch: 358 Norm Difference for worker 380 is 0.766452
INFO:root:FL Epoch: 358 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :887
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548121
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447845
INFO:root:FL Epoch: 358 Norm Difference for worker 887 is 0.764408
INFO:root:FL Epoch: 358 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :392
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583290
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472117
INFO:root:FL Epoch: 358 Norm Difference for worker 392 is 0.726442
INFO:root:FL Epoch: 358 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1518
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493192
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376099
INFO:root:FL Epoch: 358 Norm Difference for worker 1518 is 0.721398
INFO:root:FL Epoch: 358 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :120
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 120 is 0.824925
INFO:root:FL Epoch: 358 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :905
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544928
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481254
INFO:root:FL Epoch: 358 Norm Difference for worker 905 is 0.741516
INFO:root:FL Epoch: 358 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1181
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607195
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420246
INFO:root:FL Epoch: 358 Norm Difference for worker 1181 is 0.778974
INFO:root:FL Epoch: 358 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :65
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 65 is 0.687537
INFO:root:FL Epoch: 358 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.5002389339839711 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.4092533042033513                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [676, 755, 955, 1854, 1219, 281, 1836, 832, 953, 1498]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :676
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583718
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483166
INFO:root:FL Epoch: 359 Norm Difference for worker 676 is 0.688895
INFO:root:FL Epoch: 359 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :755
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624403
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555495
INFO:root:FL Epoch: 359 Norm Difference for worker 755 is 0.747276
INFO:root:FL Epoch: 359 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :955
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489473
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586408
INFO:root:FL Epoch: 359 Norm Difference for worker 955 is 0.761634
INFO:root:FL Epoch: 359 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1854
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648660
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376417
INFO:root:FL Epoch: 359 Norm Difference for worker 1854 is 0.750065
INFO:root:FL Epoch: 359 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1219
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551406
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424421
INFO:root:FL Epoch: 359 Norm Difference for worker 1219 is 0.726281
INFO:root:FL Epoch: 359 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :281
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 281 is 0.6586
INFO:root:FL Epoch: 359 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1836
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630162
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551425
INFO:root:FL Epoch: 359 Norm Difference for worker 1836 is 0.68779
INFO:root:FL Epoch: 359 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :832
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742124
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616807
INFO:root:FL Epoch: 359 Norm Difference for worker 832 is 0.701725
INFO:root:FL Epoch: 359 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :953
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385947
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548561
INFO:root:FL Epoch: 359 Norm Difference for worker 953 is 0.762141
INFO:root:FL Epoch: 359 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1498
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515115
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395670
INFO:root:FL Epoch: 359 Norm Difference for worker 1498 is 0.678797
INFO:root:FL Epoch: 359 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 281
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.4850883168332717 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.3129742021361987                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [752, 1335, 1381, 1057, 813, 767, 214, 100, 80, 1821]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :752
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386183
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394120
INFO:root:FL Epoch: 360 Norm Difference for worker 752 is 0.756747
INFO:root:FL Epoch: 360 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1335
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787071
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438048
INFO:root:FL Epoch: 360 Norm Difference for worker 1335 is 0.712472
INFO:root:FL Epoch: 360 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1381
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462711
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608703
INFO:root:FL Epoch: 360 Norm Difference for worker 1381 is 0.797686
INFO:root:FL Epoch: 360 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1057
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775382
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735148
INFO:root:FL Epoch: 360 Norm Difference for worker 1057 is 0.782048
INFO:root:FL Epoch: 360 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :813
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625151
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402227
INFO:root:FL Epoch: 360 Norm Difference for worker 813 is 0.784419
INFO:root:FL Epoch: 360 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :767
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408800
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580671
INFO:root:FL Epoch: 360 Norm Difference for worker 767 is 0.765711
INFO:root:FL Epoch: 360 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :214
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 214 is 0.756154
INFO:root:FL Epoch: 360 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :100
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 100 is 0.754894
INFO:root:FL Epoch: 360 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :80
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 80 is 0.802368
INFO:root:FL Epoch: 360 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1821
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508942
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589221
INFO:root:FL Epoch: 360 Norm Difference for worker 1821 is 0.778849
INFO:root:FL Epoch: 360 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1335
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.4875779292162727 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.30373021960258484                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 1618, 643, 1710, 966, 640, 1848, 1504]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221065
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238576
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.22469035784403482 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.24248564392328262 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.180879
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289607
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349059
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.22835262616475424 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.24297012388706207 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.177414
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285668
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352473
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.22181115299463272 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.24330366551876068 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.179786
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1618
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381951
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260278
INFO:root:FL Epoch: 361 Norm Difference for worker 1618 is 0.752054
INFO:root:FL Epoch: 361 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :643
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534114
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334507
INFO:root:FL Epoch: 361 Norm Difference for worker 643 is 0.821491
INFO:root:FL Epoch: 361 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1710
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402351
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494145
INFO:root:FL Epoch: 361 Norm Difference for worker 1710 is 0.796616
INFO:root:FL Epoch: 361 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :966
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551204
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445723
INFO:root:FL Epoch: 361 Norm Difference for worker 966 is 0.800347
INFO:root:FL Epoch: 361 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :640
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523354
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712134
INFO:root:FL Epoch: 361 Norm Difference for worker 640 is 0.786222
INFO:root:FL Epoch: 361 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1848
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533177
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293331
INFO:root:FL Epoch: 361 Norm Difference for worker 1848 is 0.764795
INFO:root:FL Epoch: 361 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1504
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558706
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523585
INFO:root:FL Epoch: 361 Norm Difference for worker 1504 is 0.757387
INFO:root:FL Epoch: 361 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.48709309802335854 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.22469035784403482                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [648, 714, 824, 991, 1179, 1599, 585, 1926, 50, 1021]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :648
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564916
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485346
INFO:root:FL Epoch: 362 Norm Difference for worker 648 is 0.860181
INFO:root:FL Epoch: 362 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :714
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750816
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409038
INFO:root:FL Epoch: 362 Norm Difference for worker 714 is 0.908487
INFO:root:FL Epoch: 362 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :824
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552413
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375344
INFO:root:FL Epoch: 362 Norm Difference for worker 824 is 0.791133
INFO:root:FL Epoch: 362 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :991
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876902
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725661
INFO:root:FL Epoch: 362 Norm Difference for worker 991 is 0.920709
INFO:root:FL Epoch: 362 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1179
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433535
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462043
INFO:root:FL Epoch: 362 Norm Difference for worker 1179 is 0.762647
INFO:root:FL Epoch: 362 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1599
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504725
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582462
INFO:root:FL Epoch: 362 Norm Difference for worker 1599 is 0.817836
INFO:root:FL Epoch: 362 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :585
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481071
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382400
INFO:root:FL Epoch: 362 Norm Difference for worker 585 is 0.843229
INFO:root:FL Epoch: 362 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1926
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650473
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557704
INFO:root:FL Epoch: 362 Norm Difference for worker 1926 is 0.861853
INFO:root:FL Epoch: 362 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :50
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325611
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 50 is 0.859311
INFO:root:FL Epoch: 362 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1021
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343390
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365203
INFO:root:FL Epoch: 362 Norm Difference for worker 1021 is 0.783865
INFO:root:FL Epoch: 362 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1021
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.4799874968388501 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.2556731378038724                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [1332, 1401, 480, 1193, 838, 313, 1411, 1295, 877, 456]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :1332
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896359
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293743
INFO:root:FL Epoch: 363 Norm Difference for worker 1332 is 0.917185
INFO:root:FL Epoch: 363 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1401
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534216
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563383
INFO:root:FL Epoch: 363 Norm Difference for worker 1401 is 0.864283
INFO:root:FL Epoch: 363 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :480
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809272
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522596
INFO:root:FL Epoch: 363 Norm Difference for worker 480 is 1.003037
INFO:root:FL Epoch: 363 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1193
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573432
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509963
INFO:root:FL Epoch: 363 Norm Difference for worker 1193 is 1.010825
INFO:root:FL Epoch: 363 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :838
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808953
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719799
INFO:root:FL Epoch: 363 Norm Difference for worker 838 is 1.018787
INFO:root:FL Epoch: 363 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :313
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.338723
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 313 is 0.982982
INFO:root:FL Epoch: 363 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1411
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466192
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327679
INFO:root:FL Epoch: 363 Norm Difference for worker 1411 is 0.894504
INFO:root:FL Epoch: 363 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1295
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485200
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245637
INFO:root:FL Epoch: 363 Norm Difference for worker 1295 is 0.864467
INFO:root:FL Epoch: 363 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :877
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686424
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248698
INFO:root:FL Epoch: 363 Norm Difference for worker 877 is 0.947393
INFO:root:FL Epoch: 363 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :456
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473970
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379105
INFO:root:FL Epoch: 363 Norm Difference for worker 456 is 0.922557
INFO:root:FL Epoch: 363 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1401
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.47054742890245776 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.2584687074025472                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [161, 1851, 1054, 165, 574, 185, 319, 539, 667, 303]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.10024938 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 364 Num points on workers: [201 200 200 201 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :161
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500305
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 161 is 0.866579
INFO:root:FL Epoch: 364 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1851
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657815
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397397
INFO:root:FL Epoch: 364 Norm Difference for worker 1851 is 0.901473
INFO:root:FL Epoch: 364 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1054
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429592
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525911
INFO:root:FL Epoch: 364 Norm Difference for worker 1054 is 0.907562
INFO:root:FL Epoch: 364 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :165
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 165 is 0.880077
INFO:root:FL Epoch: 364 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :574
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798731
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420059
INFO:root:FL Epoch: 364 Norm Difference for worker 574 is 0.944175
INFO:root:FL Epoch: 364 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :185
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527712
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 185 is 0.879236
INFO:root:FL Epoch: 364 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :319
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 319 is 0.926179
INFO:root:FL Epoch: 364 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :539
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.953183
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612447
INFO:root:FL Epoch: 364 Norm Difference for worker 539 is 0.984614
INFO:root:FL Epoch: 364 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :667
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516325
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332390
INFO:root:FL Epoch: 364 Norm Difference for worker 667 is 0.87036
INFO:root:FL Epoch: 364 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :303
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 303 is 0.865995
INFO:root:FL Epoch: 364 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 303
INFO:root:Norm of Aggregated Model: 5154.97265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.4642898177399355 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.34203679859638214                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [184, 1587, 703, 353, 1442, 1376, 959, 669, 1830, 1102]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 365 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :184
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.226051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.195147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 184 is 0.654963
INFO:root:FL Epoch: 365 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1587
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388486
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326978
INFO:root:FL Epoch: 365 Norm Difference for worker 1587 is 0.782444
INFO:root:FL Epoch: 365 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :703
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563975
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468551
INFO:root:FL Epoch: 365 Norm Difference for worker 703 is 0.760683
INFO:root:FL Epoch: 365 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :353
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698515
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486864
INFO:root:FL Epoch: 365 Norm Difference for worker 353 is 0.83883
INFO:root:FL Epoch: 365 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1442
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616125
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427472
INFO:root:FL Epoch: 365 Norm Difference for worker 1442 is 0.774648
INFO:root:FL Epoch: 365 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1376
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784748
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598629
INFO:root:FL Epoch: 365 Norm Difference for worker 1376 is 0.791661
INFO:root:FL Epoch: 365 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :959
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742246
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444750
INFO:root:FL Epoch: 365 Norm Difference for worker 959 is 0.820332
INFO:root:FL Epoch: 365 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :669
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348157
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359407
INFO:root:FL Epoch: 365 Norm Difference for worker 669 is 0.841435
INFO:root:FL Epoch: 365 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1830
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445618
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613254
INFO:root:FL Epoch: 365 Norm Difference for worker 1830 is 0.807595
INFO:root:FL Epoch: 365 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1102
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589203
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432195
INFO:root:FL Epoch: 365 Norm Difference for worker 1102 is 0.821117
INFO:root:FL Epoch: 365 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.4695986123646007 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.27769962946573895                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1351, 1724, 887, 1192, 624, 1905, 629, 890, 1653, 1794]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1351
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756037
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364742
INFO:root:FL Epoch: 366 Norm Difference for worker 1351 is 0.901648
INFO:root:FL Epoch: 366 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1724
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718864
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309909
INFO:root:FL Epoch: 366 Norm Difference for worker 1724 is 1.001046
INFO:root:FL Epoch: 366 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :887
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 1.062462
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391702
INFO:root:FL Epoch: 366 Norm Difference for worker 887 is 0.971748
INFO:root:FL Epoch: 366 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1192
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638376
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358758
INFO:root:FL Epoch: 366 Norm Difference for worker 1192 is 1.05537
INFO:root:FL Epoch: 366 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :624
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627583
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455761
INFO:root:FL Epoch: 366 Norm Difference for worker 624 is 0.887775
INFO:root:FL Epoch: 366 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1905
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499351
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168799
INFO:root:FL Epoch: 366 Norm Difference for worker 1905 is 0.929031
INFO:root:FL Epoch: 366 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :629
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539878
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429283
INFO:root:FL Epoch: 366 Norm Difference for worker 629 is 0.882904
INFO:root:FL Epoch: 366 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :890
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414273
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462183
INFO:root:FL Epoch: 366 Norm Difference for worker 890 is 1.01306
INFO:root:FL Epoch: 366 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1653
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719757
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413412
INFO:root:FL Epoch: 366 Norm Difference for worker 1653 is 0.900821
INFO:root:FL Epoch: 366 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1794
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549781
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274486
INFO:root:FL Epoch: 366 Norm Difference for worker 1794 is 0.982637
INFO:root:FL Epoch: 366 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 629
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.4686261976466459 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.3118496611714363                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [1509, 1066, 558, 1605, 399, 1525, 1148, 677, 1492, 327]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 367 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :1509
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662798
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555134
INFO:root:FL Epoch: 367 Norm Difference for worker 1509 is 0.930552
INFO:root:FL Epoch: 367 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1066
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530855
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624157
INFO:root:FL Epoch: 367 Norm Difference for worker 1066 is 0.933657
INFO:root:FL Epoch: 367 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :558
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567017
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780033
INFO:root:FL Epoch: 367 Norm Difference for worker 558 is 0.939472
INFO:root:FL Epoch: 367 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1605
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299444
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510806
INFO:root:FL Epoch: 367 Norm Difference for worker 1605 is 0.765992
INFO:root:FL Epoch: 367 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :399
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783723
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506744
INFO:root:FL Epoch: 367 Norm Difference for worker 399 is 0.849313
INFO:root:FL Epoch: 367 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1525
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504554
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500604
INFO:root:FL Epoch: 367 Norm Difference for worker 1525 is 0.859332
INFO:root:FL Epoch: 367 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1148
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463725
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501073
INFO:root:FL Epoch: 367 Norm Difference for worker 1148 is 0.891416
INFO:root:FL Epoch: 367 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :677
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477571
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480552
INFO:root:FL Epoch: 367 Norm Difference for worker 677 is 0.831705
INFO:root:FL Epoch: 367 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1492
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617843
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355302
INFO:root:FL Epoch: 367 Norm Difference for worker 1492 is 0.859816
INFO:root:FL Epoch: 367 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :327
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 327 is 0.955462
INFO:root:FL Epoch: 367 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1605
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.47014469258925495 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.27309824526309967                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [783, 277, 1708, 1063, 169, 1279, 247, 1366, 304, 1678]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 368 Num points on workers: [200 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :783
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570731
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482086
INFO:root:FL Epoch: 368 Norm Difference for worker 783 is 0.948225
INFO:root:FL Epoch: 368 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :277
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 277 is 0.943328
INFO:root:FL Epoch: 368 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1708
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552751
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444687
INFO:root:FL Epoch: 368 Norm Difference for worker 1708 is 1.004243
INFO:root:FL Epoch: 368 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1063
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672126
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405486
INFO:root:FL Epoch: 368 Norm Difference for worker 1063 is 0.98759
INFO:root:FL Epoch: 368 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :169
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 169 is 0.958783
INFO:root:FL Epoch: 368 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1279
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589149
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674987
INFO:root:FL Epoch: 368 Norm Difference for worker 1279 is 0.937823
INFO:root:FL Epoch: 368 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :247
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495636
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 247 is 1.029364
INFO:root:FL Epoch: 368 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1366
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639525
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667104
INFO:root:FL Epoch: 368 Norm Difference for worker 1366 is 0.939124
INFO:root:FL Epoch: 368 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :304
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 304 is 0.840059
INFO:root:FL Epoch: 368 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1678
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641542
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381462
INFO:root:FL Epoch: 368 Norm Difference for worker 1678 is 0.841292
INFO:root:FL Epoch: 368 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1678
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.47477148999186125 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.36113037168979645                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [897, 768, 199, 1231, 1007, 245, 1031, 439, 680, 841]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :897
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691179
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549721
INFO:root:FL Epoch: 369 Norm Difference for worker 897 is 0.900331
INFO:root:FL Epoch: 369 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :768
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463495
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467626
INFO:root:FL Epoch: 369 Norm Difference for worker 768 is 0.885379
INFO:root:FL Epoch: 369 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :199
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 199 is 0.932651
INFO:root:FL Epoch: 369 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1231
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455202
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325680
INFO:root:FL Epoch: 369 Norm Difference for worker 1231 is 0.882937
INFO:root:FL Epoch: 369 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1007
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398813
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338462
INFO:root:FL Epoch: 369 Norm Difference for worker 1007 is 0.870798
INFO:root:FL Epoch: 369 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :245
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 245 is 0.949137
INFO:root:FL Epoch: 369 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1031
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426646
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648978
INFO:root:FL Epoch: 369 Norm Difference for worker 1031 is 0.909953
INFO:root:FL Epoch: 369 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :439
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741994
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574930
INFO:root:FL Epoch: 369 Norm Difference for worker 439 is 0.827042
INFO:root:FL Epoch: 369 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :680
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560498
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394408
INFO:root:FL Epoch: 369 Norm Difference for worker 680 is 0.940288
INFO:root:FL Epoch: 369 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :841
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823497
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469713
INFO:root:FL Epoch: 369 Norm Difference for worker 841 is 0.948428
INFO:root:FL Epoch: 369 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 439
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.4739507620825487 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.3772371709346771                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [78, 158, 1509, 571, 30, 818, 201, 1021, 185, 750]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 370 Num points on workers: [201 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :78
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 78 is 0.735687
INFO:root:FL Epoch: 370 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :158
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 158 is 0.832376
INFO:root:FL Epoch: 370 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1509
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385262
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516347
INFO:root:FL Epoch: 370 Norm Difference for worker 1509 is 0.807256
INFO:root:FL Epoch: 370 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :571
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639215
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546345
INFO:root:FL Epoch: 370 Norm Difference for worker 571 is 0.804108
INFO:root:FL Epoch: 370 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :30
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 30 is 0.847136
INFO:root:FL Epoch: 370 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :818
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475026
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205239
INFO:root:FL Epoch: 370 Norm Difference for worker 818 is 0.789462
INFO:root:FL Epoch: 370 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :201
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 201 is 0.854666
INFO:root:FL Epoch: 370 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1021
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272005
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403945
INFO:root:FL Epoch: 370 Norm Difference for worker 1021 is 0.663988
INFO:root:FL Epoch: 370 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :185
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 185 is 0.758957
INFO:root:FL Epoch: 370 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :750
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413046
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509895
INFO:root:FL Epoch: 370 Norm Difference for worker 750 is 0.846063
INFO:root:FL Epoch: 370 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1021
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.48252957621041465 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.34498467793067294                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 1061, 1042, 1852, 1271, 1167, 671, 986]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.216643
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277644
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.1962940109272798 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.19292572215199472 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.181844
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238621
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150040
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.19576563189427057 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.18856899738311766 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.191762
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347817
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129368
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.21201820174853006 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.19033937081694602 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.174988
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1061
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567422
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764754
INFO:root:FL Epoch: 371 Norm Difference for worker 1061 is 1.058572
INFO:root:FL Epoch: 371 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1042
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604586
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623428
INFO:root:FL Epoch: 371 Norm Difference for worker 1042 is 1.084755
INFO:root:FL Epoch: 371 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1852
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608999
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371381
INFO:root:FL Epoch: 371 Norm Difference for worker 1852 is 1.076364
INFO:root:FL Epoch: 371 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1271
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.926379
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.798524
INFO:root:FL Epoch: 371 Norm Difference for worker 1271 is 1.031947
INFO:root:FL Epoch: 371 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1167
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475417
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340803
INFO:root:FL Epoch: 371 Norm Difference for worker 1167 is 1.076167
INFO:root:FL Epoch: 371 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :671
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684625
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487586
INFO:root:FL Epoch: 371 Norm Difference for worker 671 is 0.984214
INFO:root:FL Epoch: 371 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :986
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409328
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462595
INFO:root:FL Epoch: 371 Norm Difference for worker 986 is 1.109316
INFO:root:FL Epoch: 371 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.48411108378101797 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.1962940109272798                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1304, 439, 523, 1858, 473, 17, 1491, 1571, 364, 119]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1304
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749845
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446657
INFO:root:FL Epoch: 372 Norm Difference for worker 1304 is 1.085807
INFO:root:FL Epoch: 372 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :439
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292949
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319707
INFO:root:FL Epoch: 372 Norm Difference for worker 439 is 0.910838
INFO:root:FL Epoch: 372 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :523
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551013
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468686
INFO:root:FL Epoch: 372 Norm Difference for worker 523 is 1.227996
INFO:root:FL Epoch: 372 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1858
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557825
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373273
INFO:root:FL Epoch: 372 Norm Difference for worker 1858 is 1.197141
INFO:root:FL Epoch: 372 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :473
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581640
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591644
INFO:root:FL Epoch: 372 Norm Difference for worker 473 is 1.146359
INFO:root:FL Epoch: 372 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :17
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.903937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 17 is 1.211649
INFO:root:FL Epoch: 372 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1491
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524133
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452460
INFO:root:FL Epoch: 372 Norm Difference for worker 1491 is 1.1096
INFO:root:FL Epoch: 372 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1571
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279425
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424404
INFO:root:FL Epoch: 372 Norm Difference for worker 1571 is 1.065232
INFO:root:FL Epoch: 372 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :364
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526997
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276547
INFO:root:FL Epoch: 372 Norm Difference for worker 364 is 1.172995
INFO:root:FL Epoch: 372 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :119
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 119 is 1.168881
INFO:root:FL Epoch: 372 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 439
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.49963459547828226 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.22106622159481049                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [1519, 1509, 112, 1748, 415, 1017, 782, 1715, 1356, 1342]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :1519
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585981
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342604
INFO:root:FL Epoch: 373 Norm Difference for worker 1519 is 0.9546
INFO:root:FL Epoch: 373 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1509
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589664
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414328
INFO:root:FL Epoch: 373 Norm Difference for worker 1509 is 1.177167
INFO:root:FL Epoch: 373 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :112
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.823139
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 112 is 1.147907
INFO:root:FL Epoch: 373 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1748
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783535
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482987
INFO:root:FL Epoch: 373 Norm Difference for worker 1748 is 1.122421
INFO:root:FL Epoch: 373 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :415
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636390
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380617
INFO:root:FL Epoch: 373 Norm Difference for worker 415 is 1.054078
INFO:root:FL Epoch: 373 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1017
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639232
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467018
INFO:root:FL Epoch: 373 Norm Difference for worker 1017 is 1.080582
INFO:root:FL Epoch: 373 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :782
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735033
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443941
INFO:root:FL Epoch: 373 Norm Difference for worker 782 is 1.164544
INFO:root:FL Epoch: 373 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1715
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633315
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448355
INFO:root:FL Epoch: 373 Norm Difference for worker 1715 is 1.114686
INFO:root:FL Epoch: 373 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1356
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552145
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570485
INFO:root:FL Epoch: 373 Norm Difference for worker 1356 is 1.178768
INFO:root:FL Epoch: 373 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1342
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.209855
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387463
INFO:root:FL Epoch: 373 Norm Difference for worker 1342 is 1.063843
INFO:root:FL Epoch: 373 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1519
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.489026253714281 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.29437241206566495                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1498, 804, 643, 1075, 1437, 74, 979, 516, 1748, 1798]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1498
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486370
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431249
INFO:root:FL Epoch: 374 Norm Difference for worker 1498 is 0.87321
INFO:root:FL Epoch: 374 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :804
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446938
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600823
INFO:root:FL Epoch: 374 Norm Difference for worker 804 is 1.010072
INFO:root:FL Epoch: 374 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :643
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491223
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477046
INFO:root:FL Epoch: 374 Norm Difference for worker 643 is 0.942888
INFO:root:FL Epoch: 374 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1075
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485442
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528234
INFO:root:FL Epoch: 374 Norm Difference for worker 1075 is 0.857884
INFO:root:FL Epoch: 374 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1437
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551656
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375569
INFO:root:FL Epoch: 374 Norm Difference for worker 1437 is 0.877656
INFO:root:FL Epoch: 374 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :74
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.760756
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 74 is 0.88106
INFO:root:FL Epoch: 374 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :979
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484826
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599936
INFO:root:FL Epoch: 374 Norm Difference for worker 979 is 0.893361
INFO:root:FL Epoch: 374 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :516
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628644
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441376
INFO:root:FL Epoch: 374 Norm Difference for worker 516 is 0.903796
INFO:root:FL Epoch: 374 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1748
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692133
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548219
INFO:root:FL Epoch: 374 Norm Difference for worker 1748 is 0.942906
INFO:root:FL Epoch: 374 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1798
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576137
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473858
INFO:root:FL Epoch: 374 Norm Difference for worker 1798 is 0.938124
INFO:root:FL Epoch: 374 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1437
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.4803279655821183 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.38751011590162915                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [317, 105, 1425, 1249, 401, 243, 53, 960, 1525, 1533]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 375 Num points on workers: [201 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :317
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.711846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 317 is 0.880347
INFO:root:FL Epoch: 375 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :105
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.836701
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612082
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 105 is 0.80907
INFO:root:FL Epoch: 375 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1425
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446370
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517355
INFO:root:FL Epoch: 375 Norm Difference for worker 1425 is 0.794122
INFO:root:FL Epoch: 375 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1249
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528010
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506605
INFO:root:FL Epoch: 375 Norm Difference for worker 1249 is 0.852595
INFO:root:FL Epoch: 375 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :401
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579327
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510037
INFO:root:FL Epoch: 375 Norm Difference for worker 401 is 0.804345
INFO:root:FL Epoch: 375 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :243
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.287582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 243 is 0.747699
INFO:root:FL Epoch: 375 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :53
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 53 is 0.822949
INFO:root:FL Epoch: 375 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :960
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349764
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416348
INFO:root:FL Epoch: 375 Norm Difference for worker 960 is 0.840388
INFO:root:FL Epoch: 375 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1525
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525562
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574298
INFO:root:FL Epoch: 375 Norm Difference for worker 1525 is 0.760448
INFO:root:FL Epoch: 375 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1533
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451061
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517863
INFO:root:FL Epoch: 375 Norm Difference for worker 1533 is 0.808144
INFO:root:FL Epoch: 375 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 243
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.4950740828233607 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.3976722111304601                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1397, 18, 956, 910, 205, 740, 1557, 1744, 425, 1208]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 376 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1397
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451305
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472224
INFO:root:FL Epoch: 376 Norm Difference for worker 1397 is 0.977389
INFO:root:FL Epoch: 376 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :18
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.795836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 18 is 0.94585
INFO:root:FL Epoch: 376 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :956
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578194
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740825
INFO:root:FL Epoch: 376 Norm Difference for worker 956 is 0.981999
INFO:root:FL Epoch: 376 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :910
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398109
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528672
INFO:root:FL Epoch: 376 Norm Difference for worker 910 is 0.960845
INFO:root:FL Epoch: 376 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :205
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.381071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 205 is 0.950543
INFO:root:FL Epoch: 376 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :740
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589167
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520058
INFO:root:FL Epoch: 376 Norm Difference for worker 740 is 1.011948
INFO:root:FL Epoch: 376 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1557
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700917
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526810
INFO:root:FL Epoch: 376 Norm Difference for worker 1557 is 0.965727
INFO:root:FL Epoch: 376 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1744
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588836
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354184
INFO:root:FL Epoch: 376 Norm Difference for worker 1744 is 0.907841
INFO:root:FL Epoch: 376 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :425
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688799
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663733
INFO:root:FL Epoch: 376 Norm Difference for worker 425 is 1.021025
INFO:root:FL Epoch: 376 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1208
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587517
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443032
INFO:root:FL Epoch: 376 Norm Difference for worker 1208 is 1.031112
INFO:root:FL Epoch: 376 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1744
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.4824568979880389 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.33584926277399063                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [1407, 59, 1055, 261, 1932, 581, 1253, 23, 462, 1153]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :1407
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414164
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377849
INFO:root:FL Epoch: 377 Norm Difference for worker 1407 is 0.849792
INFO:root:FL Epoch: 377 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :59
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583477
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 59 is 0.88306
INFO:root:FL Epoch: 377 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1055
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698513
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308340
INFO:root:FL Epoch: 377 Norm Difference for worker 1055 is 0.913982
INFO:root:FL Epoch: 377 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :261
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 261 is 0.847708
INFO:root:FL Epoch: 377 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1932
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375143
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421309
INFO:root:FL Epoch: 377 Norm Difference for worker 1932 is 0.870637
INFO:root:FL Epoch: 377 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :581
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415283
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552891
INFO:root:FL Epoch: 377 Norm Difference for worker 581 is 0.948558
INFO:root:FL Epoch: 377 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1253
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470545
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346292
INFO:root:FL Epoch: 377 Norm Difference for worker 1253 is 0.958766
INFO:root:FL Epoch: 377 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :23
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.776783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 23 is 0.93401
INFO:root:FL Epoch: 377 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :462
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653197
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787883
INFO:root:FL Epoch: 377 Norm Difference for worker 462 is 0.890197
INFO:root:FL Epoch: 377 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1153
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482530
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345098
INFO:root:FL Epoch: 377 Norm Difference for worker 1153 is 0.931235
INFO:root:FL Epoch: 377 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 261
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.48655238046365623 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.3386242588361104                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1066, 1905, 777, 1310, 1028, 1906, 169, 573, 888, 1462]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1066
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425222
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469765
INFO:root:FL Epoch: 378 Norm Difference for worker 1066 is 0.875801
INFO:root:FL Epoch: 378 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1905
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320160
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414755
INFO:root:FL Epoch: 378 Norm Difference for worker 1905 is 0.827996
INFO:root:FL Epoch: 378 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :777
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670018
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607795
INFO:root:FL Epoch: 378 Norm Difference for worker 777 is 0.898996
INFO:root:FL Epoch: 378 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1310
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734831
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415334
INFO:root:FL Epoch: 378 Norm Difference for worker 1310 is 0.892382
INFO:root:FL Epoch: 378 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1028
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510308
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559983
INFO:root:FL Epoch: 378 Norm Difference for worker 1028 is 0.834022
INFO:root:FL Epoch: 378 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1906
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876290
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413777
INFO:root:FL Epoch: 378 Norm Difference for worker 1906 is 0.826913
INFO:root:FL Epoch: 378 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :169
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.759591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 169 is 0.886201
INFO:root:FL Epoch: 378 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :573
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654098
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666485
INFO:root:FL Epoch: 378 Norm Difference for worker 573 is 0.897756
INFO:root:FL Epoch: 378 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :888
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724446
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413870
INFO:root:FL Epoch: 378 Norm Difference for worker 888 is 0.90012
INFO:root:FL Epoch: 378 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1462
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749309
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426508
INFO:root:FL Epoch: 378 Norm Difference for worker 1462 is 0.908113
INFO:root:FL Epoch: 378 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.4878680933924282 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.48069657882054645                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1554, 794, 1231, 1576, 294, 838, 310, 790, 612, 300]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1554
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386293
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308386
INFO:root:FL Epoch: 379 Norm Difference for worker 1554 is 0.796196
INFO:root:FL Epoch: 379 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :794
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626878
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457411
INFO:root:FL Epoch: 379 Norm Difference for worker 794 is 0.835584
INFO:root:FL Epoch: 379 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1231
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482307
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484549
INFO:root:FL Epoch: 379 Norm Difference for worker 1231 is 0.795992
INFO:root:FL Epoch: 379 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1576
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535511
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587842
INFO:root:FL Epoch: 379 Norm Difference for worker 1576 is 0.839157
INFO:root:FL Epoch: 379 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :294
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 294 is 0.853832
INFO:root:FL Epoch: 379 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :838
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543885
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430308
INFO:root:FL Epoch: 379 Norm Difference for worker 838 is 0.844332
INFO:root:FL Epoch: 379 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :310
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 310 is 0.802887
INFO:root:FL Epoch: 379 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :790
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758099
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501108
INFO:root:FL Epoch: 379 Norm Difference for worker 790 is 0.890211
INFO:root:FL Epoch: 379 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :612
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696872
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498910
INFO:root:FL Epoch: 379 Norm Difference for worker 612 is 0.836926
INFO:root:FL Epoch: 379 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :300
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.883847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 300 is 0.885214
INFO:root:FL Epoch: 379 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1554
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.48824641634436217 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.34337597091992694                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [932, 1259, 1268, 1635, 1840, 651, 1586, 332, 1409, 1110]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :932
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399196
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341832
INFO:root:FL Epoch: 380 Norm Difference for worker 932 is 0.902141
INFO:root:FL Epoch: 380 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1259
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738391
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425970
INFO:root:FL Epoch: 380 Norm Difference for worker 1259 is 0.912767
INFO:root:FL Epoch: 380 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1268
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673598
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484179
INFO:root:FL Epoch: 380 Norm Difference for worker 1268 is 0.821462
INFO:root:FL Epoch: 380 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1635
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652020
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488119
INFO:root:FL Epoch: 380 Norm Difference for worker 1635 is 0.898503
INFO:root:FL Epoch: 380 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1840
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570404
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254900
INFO:root:FL Epoch: 380 Norm Difference for worker 1840 is 0.931893
INFO:root:FL Epoch: 380 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :651
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439773
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569532
INFO:root:FL Epoch: 380 Norm Difference for worker 651 is 0.907376
INFO:root:FL Epoch: 380 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1586
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661604
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549984
INFO:root:FL Epoch: 380 Norm Difference for worker 1586 is 0.965933
INFO:root:FL Epoch: 380 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :332
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.891176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507103
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 332 is 0.9481
INFO:root:FL Epoch: 380 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1409
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634830
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540127
INFO:root:FL Epoch: 380 Norm Difference for worker 1409 is 0.908469
INFO:root:FL Epoch: 380 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1110
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661838
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657826
INFO:root:FL Epoch: 380 Norm Difference for worker 1110 is 0.97361
INFO:root:FL Epoch: 380 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1268
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.49015884714968067 and Test Accuracy:75.0 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.3972909450531006                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 1679, 116, 928, 1045, 563, 1144, 438]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254472
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222451
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.262772577504317 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.18744400441646575 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.180312
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251695
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283101
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.2490090106924375 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.1886262707412243 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.188358
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212003
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198642
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.25058963894844055 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.18740008994936944 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.183224
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1679
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646999
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395297
INFO:root:FL Epoch: 381 Norm Difference for worker 1679 is 1.027927
INFO:root:FL Epoch: 381 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :116
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397859
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 116 is 0.998146
INFO:root:FL Epoch: 381 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :928
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407172
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416012
INFO:root:FL Epoch: 381 Norm Difference for worker 928 is 0.817091
INFO:root:FL Epoch: 381 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1045
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508705
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277141
INFO:root:FL Epoch: 381 Norm Difference for worker 1045 is 0.853524
INFO:root:FL Epoch: 381 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :563
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435684
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394619
INFO:root:FL Epoch: 381 Norm Difference for worker 563 is 0.961796
INFO:root:FL Epoch: 381 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1144
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652614
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603053
INFO:root:FL Epoch: 381 Norm Difference for worker 1144 is 0.997085
INFO:root:FL Epoch: 381 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :438
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245796
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398867
INFO:root:FL Epoch: 381 Norm Difference for worker 438 is 0.929728
INFO:root:FL Epoch: 381 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.4946462143869961 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.25058963894844055                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [305, 780, 1929, 1520, 481, 1295, 101, 560, 999, 452]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 382 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :305
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.798650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 305 is 0.993771
INFO:root:FL Epoch: 382 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :780
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540574
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389156
INFO:root:FL Epoch: 382 Norm Difference for worker 780 is 0.953697
INFO:root:FL Epoch: 382 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1929
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352548
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305510
INFO:root:FL Epoch: 382 Norm Difference for worker 1929 is 0.841659
INFO:root:FL Epoch: 382 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1520
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523975
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414168
INFO:root:FL Epoch: 382 Norm Difference for worker 1520 is 0.974918
INFO:root:FL Epoch: 382 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :481
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620526
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430338
INFO:root:FL Epoch: 382 Norm Difference for worker 481 is 1.038937
INFO:root:FL Epoch: 382 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1295
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578471
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612901
INFO:root:FL Epoch: 382 Norm Difference for worker 1295 is 0.934953
INFO:root:FL Epoch: 382 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :101
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 101 is 0.981416
INFO:root:FL Epoch: 382 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :560
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613036
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.795494
INFO:root:FL Epoch: 382 Norm Difference for worker 560 is 1.049947
INFO:root:FL Epoch: 382 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :999
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726936
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640965
INFO:root:FL Epoch: 382 Norm Difference for worker 999 is 1.02679
INFO:root:FL Epoch: 382 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :452
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262161
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350318
INFO:root:FL Epoch: 382 Norm Difference for worker 452 is 0.946348
INFO:root:FL Epoch: 382 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.5247516965164858 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.23338446393609047                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [1594, 712, 1782, 1693, 835, 153, 986, 618, 24, 1431]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :1594
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656742
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434963
INFO:root:FL Epoch: 383 Norm Difference for worker 1594 is 1.086197
INFO:root:FL Epoch: 383 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :712
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865668
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440067
INFO:root:FL Epoch: 383 Norm Difference for worker 712 is 1.083864
INFO:root:FL Epoch: 383 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1782
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642915
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350274
INFO:root:FL Epoch: 383 Norm Difference for worker 1782 is 1.101199
INFO:root:FL Epoch: 383 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1693
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479572
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446335
INFO:root:FL Epoch: 383 Norm Difference for worker 1693 is 1.123798
INFO:root:FL Epoch: 383 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :835
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509913
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435349
INFO:root:FL Epoch: 383 Norm Difference for worker 835 is 0.94421
INFO:root:FL Epoch: 383 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :153
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.229520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222070
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 153 is 1.029504
INFO:root:FL Epoch: 383 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :986
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403191
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518036
INFO:root:FL Epoch: 383 Norm Difference for worker 986 is 1.176486
INFO:root:FL Epoch: 383 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :618
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305564
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282187
INFO:root:FL Epoch: 383 Norm Difference for worker 618 is 1.091079
INFO:root:FL Epoch: 383 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :24
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483875
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 24 is 1.089171
INFO:root:FL Epoch: 383 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1431
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669546
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420680
INFO:root:FL Epoch: 383 Norm Difference for worker 1431 is 1.118007
INFO:root:FL Epoch: 383 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 835
INFO:root:Norm of Aggregated Model: 5154.97314453125
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.5143307824345196 and Test Accuracy:75.0 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.20728137840827307                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [459, 540, 192, 1368, 424, 223, 444, 1119, 917, 1924]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :459
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510121
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402540
INFO:root:FL Epoch: 384 Norm Difference for worker 459 is 1.031712
INFO:root:FL Epoch: 384 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :540
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627037
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251535
INFO:root:FL Epoch: 384 Norm Difference for worker 540 is 1.078721
INFO:root:FL Epoch: 384 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :192
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.344837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 192 is 1.056863
INFO:root:FL Epoch: 384 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1368
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651722
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373058
INFO:root:FL Epoch: 384 Norm Difference for worker 1368 is 0.933249
INFO:root:FL Epoch: 384 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :424
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435466
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268612
INFO:root:FL Epoch: 384 Norm Difference for worker 424 is 0.812828
INFO:root:FL Epoch: 384 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :223
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 223 is 1.153316
INFO:root:FL Epoch: 384 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :444
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797192
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310153
INFO:root:FL Epoch: 384 Norm Difference for worker 444 is 1.019553
INFO:root:FL Epoch: 384 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1119
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472648
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220855
INFO:root:FL Epoch: 384 Norm Difference for worker 1119 is 0.987721
INFO:root:FL Epoch: 384 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :917
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718853
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629415
INFO:root:FL Epoch: 384 Norm Difference for worker 917 is 1.07371
INFO:root:FL Epoch: 384 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1924
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896333
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443998
INFO:root:FL Epoch: 384 Norm Difference for worker 1924 is 1.043234
INFO:root:FL Epoch: 384 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.9736328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.5281642710461336 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.23623267685373625                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [1334, 1921, 1397, 757, 1041, 1479, 1249, 1807, 357, 1506]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 385 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :1334
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608731
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539347
INFO:root:FL Epoch: 385 Norm Difference for worker 1334 is 1.091991
INFO:root:FL Epoch: 385 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1921
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313485
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357344
INFO:root:FL Epoch: 385 Norm Difference for worker 1921 is 1.11945
INFO:root:FL Epoch: 385 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1397
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330563
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479130
INFO:root:FL Epoch: 385 Norm Difference for worker 1397 is 1.094423
INFO:root:FL Epoch: 385 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :757
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751351
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542237
INFO:root:FL Epoch: 385 Norm Difference for worker 757 is 1.143058
INFO:root:FL Epoch: 385 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1041
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383494
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400619
INFO:root:FL Epoch: 385 Norm Difference for worker 1041 is 1.133645
INFO:root:FL Epoch: 385 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1479
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612992
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434453
INFO:root:FL Epoch: 385 Norm Difference for worker 1479 is 1.025566
INFO:root:FL Epoch: 385 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1249
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 1.079314
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707176
INFO:root:FL Epoch: 385 Norm Difference for worker 1249 is 1.102296
INFO:root:FL Epoch: 385 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1807
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723619
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533270
INFO:root:FL Epoch: 385 Norm Difference for worker 1807 is 1.176832
INFO:root:FL Epoch: 385 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :357
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764406
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518636
INFO:root:FL Epoch: 385 Norm Difference for worker 357 is 0.938726
INFO:root:FL Epoch: 385 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1506
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560562
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285708
INFO:root:FL Epoch: 385 Norm Difference for worker 1506 is 0.944552
INFO:root:FL Epoch: 385 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 357
INFO:root:Norm of Aggregated Model: 5154.9736328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.5282915287158069 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.23772786060969034                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [546, 1815, 707, 353, 765, 248, 1947, 1395, 1735, 1729]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :546
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692394
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307573
INFO:root:FL Epoch: 386 Norm Difference for worker 546 is 1.031041
INFO:root:FL Epoch: 386 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1815
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713250
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303701
INFO:root:FL Epoch: 386 Norm Difference for worker 1815 is 0.982389
INFO:root:FL Epoch: 386 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :707
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328823
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410933
INFO:root:FL Epoch: 386 Norm Difference for worker 707 is 1.032305
INFO:root:FL Epoch: 386 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :353
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510261
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673943
INFO:root:FL Epoch: 386 Norm Difference for worker 353 is 1.052407
INFO:root:FL Epoch: 386 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :765
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676062
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227612
INFO:root:FL Epoch: 386 Norm Difference for worker 765 is 1.117102
INFO:root:FL Epoch: 386 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :248
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 248 is 0.962512
INFO:root:FL Epoch: 386 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1947
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633077
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357213
INFO:root:FL Epoch: 386 Norm Difference for worker 1947 is 0.960531
INFO:root:FL Epoch: 386 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1395
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506577
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562426
INFO:root:FL Epoch: 386 Norm Difference for worker 1395 is 1.000302
INFO:root:FL Epoch: 386 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1735
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583124
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497944
INFO:root:FL Epoch: 386 Norm Difference for worker 1735 is 0.989613
INFO:root:FL Epoch: 386 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1729
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427657
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505809
INFO:root:FL Epoch: 386 Norm Difference for worker 1729 is 1.051044
INFO:root:FL Epoch: 386 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 248
INFO:root:Norm of Aggregated Model: 5154.9736328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.5199102917138267 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.33296052118142444                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [134, 1507, 700, 1293, 1148, 473, 855, 1266, 170, 422]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 387 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :134
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 134 is 0.866286
INFO:root:FL Epoch: 387 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1507
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626498
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631343
INFO:root:FL Epoch: 387 Norm Difference for worker 1507 is 0.943818
INFO:root:FL Epoch: 387 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :700
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394435
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560269
INFO:root:FL Epoch: 387 Norm Difference for worker 700 is 0.991753
INFO:root:FL Epoch: 387 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1293
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614092
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404118
INFO:root:FL Epoch: 387 Norm Difference for worker 1293 is 0.881855
INFO:root:FL Epoch: 387 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1148
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492226
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604939
INFO:root:FL Epoch: 387 Norm Difference for worker 1148 is 0.955201
INFO:root:FL Epoch: 387 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :473
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683994
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256145
INFO:root:FL Epoch: 387 Norm Difference for worker 473 is 0.886612
INFO:root:FL Epoch: 387 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :855
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755504
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586982
INFO:root:FL Epoch: 387 Norm Difference for worker 855 is 0.935206
INFO:root:FL Epoch: 387 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1266
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575306
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459331
INFO:root:FL Epoch: 387 Norm Difference for worker 1266 is 0.930262
INFO:root:FL Epoch: 387 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :170
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468756
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 170 is 0.919896
INFO:root:FL Epoch: 387 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :422
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556745
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565895
INFO:root:FL Epoch: 387 Norm Difference for worker 422 is 1.011024
INFO:root:FL Epoch: 387 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1293
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.494061843437307 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.24991904944181442                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [832, 1256, 1254, 1459, 72, 786, 887, 1099, 1137, 333]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 388 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :832
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767368
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417265
INFO:root:FL Epoch: 388 Norm Difference for worker 832 is 0.889802
INFO:root:FL Epoch: 388 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1256
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407821
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642964
INFO:root:FL Epoch: 388 Norm Difference for worker 1256 is 0.809185
INFO:root:FL Epoch: 388 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1254
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744186
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447536
INFO:root:FL Epoch: 388 Norm Difference for worker 1254 is 0.833763
INFO:root:FL Epoch: 388 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1459
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579295
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712589
INFO:root:FL Epoch: 388 Norm Difference for worker 1459 is 0.842152
INFO:root:FL Epoch: 388 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :72
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 72 is 0.804264
INFO:root:FL Epoch: 388 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :786
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648595
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726736
INFO:root:FL Epoch: 388 Norm Difference for worker 786 is 0.830796
INFO:root:FL Epoch: 388 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :887
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468716
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562460
INFO:root:FL Epoch: 388 Norm Difference for worker 887 is 0.87582
INFO:root:FL Epoch: 388 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1099
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590413
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439449
INFO:root:FL Epoch: 388 Norm Difference for worker 1099 is 0.827778
INFO:root:FL Epoch: 388 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1137
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680046
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514065
INFO:root:FL Epoch: 388 Norm Difference for worker 1137 is 0.858179
INFO:root:FL Epoch: 388 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :333
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.991441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 333 is 0.836931
INFO:root:FL Epoch: 388 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1256
INFO:root:Norm of Aggregated Model: 5154.9736328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.4977913428755367 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.32894320289293927                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [1513, 991, 1679, 1102, 716, 905, 546, 26, 1404, 1045]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :1513
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407527
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636545
INFO:root:FL Epoch: 389 Norm Difference for worker 1513 is 0.776062
INFO:root:FL Epoch: 389 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :991
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696474
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494186
INFO:root:FL Epoch: 389 Norm Difference for worker 991 is 0.795693
INFO:root:FL Epoch: 389 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1679
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718161
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481169
INFO:root:FL Epoch: 389 Norm Difference for worker 1679 is 0.793772
INFO:root:FL Epoch: 389 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1102
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639121
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472056
INFO:root:FL Epoch: 389 Norm Difference for worker 1102 is 0.788515
INFO:root:FL Epoch: 389 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :716
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495285
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308983
INFO:root:FL Epoch: 389 Norm Difference for worker 716 is 0.706643
INFO:root:FL Epoch: 389 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :905
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706663
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465394
INFO:root:FL Epoch: 389 Norm Difference for worker 905 is 0.747554
INFO:root:FL Epoch: 389 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :546
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558194
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580992
INFO:root:FL Epoch: 389 Norm Difference for worker 546 is 0.793206
INFO:root:FL Epoch: 389 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :26
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 26 is 0.763741
INFO:root:FL Epoch: 389 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1404
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723393
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363219
INFO:root:FL Epoch: 389 Norm Difference for worker 1404 is 0.746421
INFO:root:FL Epoch: 389 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1045
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309894
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408890
INFO:root:FL Epoch: 389 Norm Difference for worker 1045 is 0.724277
INFO:root:FL Epoch: 389 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1045
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.4981338031151715 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.19415152817964554                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [481, 1862, 29, 100, 807, 1488, 787, 447, 839, 251]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 390 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :481
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409024
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284441
INFO:root:FL Epoch: 390 Norm Difference for worker 481 is 0.873032
INFO:root:FL Epoch: 390 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1862
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598853
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389617
INFO:root:FL Epoch: 390 Norm Difference for worker 1862 is 0.803471
INFO:root:FL Epoch: 390 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :29
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424817
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 29 is 0.940423
INFO:root:FL Epoch: 390 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :100
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.949849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 100 is 0.913836
INFO:root:FL Epoch: 390 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :807
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544947
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362253
INFO:root:FL Epoch: 390 Norm Difference for worker 807 is 0.895088
INFO:root:FL Epoch: 390 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1488
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661112
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438443
INFO:root:FL Epoch: 390 Norm Difference for worker 1488 is 0.839499
INFO:root:FL Epoch: 390 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :787
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517483
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390893
INFO:root:FL Epoch: 390 Norm Difference for worker 787 is 0.880627
INFO:root:FL Epoch: 390 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :447
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574629
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558896
INFO:root:FL Epoch: 390 Norm Difference for worker 447 is 0.887771
INFO:root:FL Epoch: 390 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :839
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458053
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404366
INFO:root:FL Epoch: 390 Norm Difference for worker 839 is 0.946153
INFO:root:FL Epoch: 390 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :251
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587616
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 251 is 0.915421
INFO:root:FL Epoch: 390 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1862
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.5007978186887854 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.26371197402477264                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 586, 541, 389, 613, 1869, 1176, 937]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267369
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212632
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.2047733614842097 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.2035006746649742 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.148353
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.165814
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237695
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.20675190289815268 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.20341768562793733 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.150121
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279970
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282857
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.21149254714449248 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.20176450535655022 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.15374
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :586
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448528
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483113
INFO:root:FL Epoch: 391 Norm Difference for worker 586 is 0.823248
INFO:root:FL Epoch: 391 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :541
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390750
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542773
INFO:root:FL Epoch: 391 Norm Difference for worker 541 is 0.827318
INFO:root:FL Epoch: 391 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :389
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752939
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352268
INFO:root:FL Epoch: 391 Norm Difference for worker 389 is 0.837551
INFO:root:FL Epoch: 391 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :613
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634308
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521003
INFO:root:FL Epoch: 391 Norm Difference for worker 613 is 0.842624
INFO:root:FL Epoch: 391 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1869
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710391
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707223
INFO:root:FL Epoch: 391 Norm Difference for worker 1869 is 0.839045
INFO:root:FL Epoch: 391 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1176
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508045
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508863
INFO:root:FL Epoch: 391 Norm Difference for worker 1176 is 0.836618
INFO:root:FL Epoch: 391 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :937
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249621
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215797
INFO:root:FL Epoch: 391 Norm Difference for worker 937 is 0.826487
INFO:root:FL Epoch: 391 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.503490043037078 and Test Accuracy:75.0 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.20675190289815268                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [70, 1309, 1645, 252, 695, 1298, 1816, 1469, 1559, 596]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 392 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :70
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 70 is 0.796365
INFO:root:FL Epoch: 392 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1309
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630195
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271876
INFO:root:FL Epoch: 392 Norm Difference for worker 1309 is 0.847215
INFO:root:FL Epoch: 392 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1645
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504507
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658092
INFO:root:FL Epoch: 392 Norm Difference for worker 1645 is 0.943703
INFO:root:FL Epoch: 392 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :252
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 252 is 0.908721
INFO:root:FL Epoch: 392 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :695
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635989
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362978
INFO:root:FL Epoch: 392 Norm Difference for worker 695 is 0.915829
INFO:root:FL Epoch: 392 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1298
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612173
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628328
INFO:root:FL Epoch: 392 Norm Difference for worker 1298 is 0.858204
INFO:root:FL Epoch: 392 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1816
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380523
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562913
INFO:root:FL Epoch: 392 Norm Difference for worker 1816 is 0.908212
INFO:root:FL Epoch: 392 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1469
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418690
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467939
INFO:root:FL Epoch: 392 Norm Difference for worker 1469 is 0.886261
INFO:root:FL Epoch: 392 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1559
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516518
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540264
INFO:root:FL Epoch: 392 Norm Difference for worker 1559 is 0.893394
INFO:root:FL Epoch: 392 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :596
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655125
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657480
INFO:root:FL Epoch: 392 Norm Difference for worker 596 is 1.024795
INFO:root:FL Epoch: 392 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.5111564275096444 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.20328388984004656                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [1910, 681, 119, 86, 1536, 40, 1747, 1300, 59, 902]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :1910
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626729
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356707
INFO:root:FL Epoch: 393 Norm Difference for worker 1910 is 0.894674
INFO:root:FL Epoch: 393 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :681
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532908
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601976
INFO:root:FL Epoch: 393 Norm Difference for worker 681 is 0.847125
INFO:root:FL Epoch: 393 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :119
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 119 is 0.872614
INFO:root:FL Epoch: 393 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :86
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 86 is 0.791576
INFO:root:FL Epoch: 393 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1536
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576658
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588965
INFO:root:FL Epoch: 393 Norm Difference for worker 1536 is 0.964676
INFO:root:FL Epoch: 393 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :40
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559566
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 40 is 0.913321
INFO:root:FL Epoch: 393 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1747
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669505
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352912
INFO:root:FL Epoch: 393 Norm Difference for worker 1747 is 0.891879
INFO:root:FL Epoch: 393 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1300
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421821
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619347
INFO:root:FL Epoch: 393 Norm Difference for worker 1300 is 0.809531
INFO:root:FL Epoch: 393 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :59
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442098
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 59 is 0.889932
INFO:root:FL Epoch: 393 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :902
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548683
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428096
INFO:root:FL Epoch: 393 Norm Difference for worker 902 is 0.81417
INFO:root:FL Epoch: 393 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.49824754280202527 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.20312371477484703                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [774, 1926, 1801, 399, 1725, 1837, 123, 912, 1829, 387]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 394 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :774
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586014
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430310
INFO:root:FL Epoch: 394 Norm Difference for worker 774 is 0.892883
INFO:root:FL Epoch: 394 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1926
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445111
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306085
INFO:root:FL Epoch: 394 Norm Difference for worker 1926 is 0.849129
INFO:root:FL Epoch: 394 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1801
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599320
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549612
INFO:root:FL Epoch: 394 Norm Difference for worker 1801 is 0.866798
INFO:root:FL Epoch: 394 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :399
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425853
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466206
INFO:root:FL Epoch: 394 Norm Difference for worker 399 is 0.958409
INFO:root:FL Epoch: 394 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1725
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607932
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726680
INFO:root:FL Epoch: 394 Norm Difference for worker 1725 is 0.905554
INFO:root:FL Epoch: 394 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1837
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473008
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509356
INFO:root:FL Epoch: 394 Norm Difference for worker 1837 is 0.898213
INFO:root:FL Epoch: 394 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :123
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.328904
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 123 is 0.907142
INFO:root:FL Epoch: 394 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :912
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789873
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567714
INFO:root:FL Epoch: 394 Norm Difference for worker 912 is 0.880441
INFO:root:FL Epoch: 394 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1829
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367096
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462621
INFO:root:FL Epoch: 394 Norm Difference for worker 1829 is 0.844143
INFO:root:FL Epoch: 394 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :387
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490601
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460376
INFO:root:FL Epoch: 394 Norm Difference for worker 387 is 0.899565
INFO:root:FL Epoch: 394 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1801
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.4997512505334966 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.2812747706969579                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [291, 813, 50, 1335, 830, 653, 483, 1654, 1248, 274]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 395 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :291
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 291 is 0.72563
INFO:root:FL Epoch: 395 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :813
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475247
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490415
INFO:root:FL Epoch: 395 Norm Difference for worker 813 is 0.788356
INFO:root:FL Epoch: 395 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :50
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475628
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 50 is 0.825804
INFO:root:FL Epoch: 395 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1335
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433072
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254946
INFO:root:FL Epoch: 395 Norm Difference for worker 1335 is 0.744362
INFO:root:FL Epoch: 395 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :830
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415821
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396906
INFO:root:FL Epoch: 395 Norm Difference for worker 830 is 0.787095
INFO:root:FL Epoch: 395 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :653
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486375
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385513
INFO:root:FL Epoch: 395 Norm Difference for worker 653 is 0.732455
INFO:root:FL Epoch: 395 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :483
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347625
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304529
INFO:root:FL Epoch: 395 Norm Difference for worker 483 is 0.746209
INFO:root:FL Epoch: 395 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1654
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697991
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527830
INFO:root:FL Epoch: 395 Norm Difference for worker 1654 is 0.787364
INFO:root:FL Epoch: 395 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1248
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610647
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513758
INFO:root:FL Epoch: 395 Norm Difference for worker 1248 is 0.848294
INFO:root:FL Epoch: 395 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :274
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.848852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 274 is 0.760015
INFO:root:FL Epoch: 395 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1335
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.49082770768333883 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.17780358344316483                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [1385, 108, 1824, 1767, 1165, 138, 227, 1226, 114, 486]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 201 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :1385
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559570
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485274
INFO:root:FL Epoch: 396 Norm Difference for worker 1385 is 0.760655
INFO:root:FL Epoch: 396 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :108
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.366222
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 108 is 0.833849
INFO:root:FL Epoch: 396 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1824
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661567
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613850
INFO:root:FL Epoch: 396 Norm Difference for worker 1824 is 0.966089
INFO:root:FL Epoch: 396 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1767
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542043
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647231
INFO:root:FL Epoch: 396 Norm Difference for worker 1767 is 0.863873
INFO:root:FL Epoch: 396 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1165
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399911
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500283
INFO:root:FL Epoch: 396 Norm Difference for worker 1165 is 0.975848
INFO:root:FL Epoch: 396 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :138
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 138 is 0.848286
INFO:root:FL Epoch: 396 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :227
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306013
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 227 is 0.814729
INFO:root:FL Epoch: 396 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1226
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475909
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495568
INFO:root:FL Epoch: 396 Norm Difference for worker 1226 is 0.930335
INFO:root:FL Epoch: 396 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :114
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.902306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 114 is 0.948689
INFO:root:FL Epoch: 396 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :486
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633507
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529120
INFO:root:FL Epoch: 396 Norm Difference for worker 486 is 0.933468
INFO:root:FL Epoch: 396 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 227
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.5245895824011635 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.36418627699216205                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [337, 1927, 777, 117, 1379, 1198, 527, 1053, 1645, 917]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :337
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 337 is 0.741946
INFO:root:FL Epoch: 397 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1927
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495254
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418214
INFO:root:FL Epoch: 397 Norm Difference for worker 1927 is 0.701061
INFO:root:FL Epoch: 397 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :777
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576708
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585092
INFO:root:FL Epoch: 397 Norm Difference for worker 777 is 0.768785
INFO:root:FL Epoch: 397 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :117
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 117 is 0.763467
INFO:root:FL Epoch: 397 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1379
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651618
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532286
INFO:root:FL Epoch: 397 Norm Difference for worker 1379 is 0.72885
INFO:root:FL Epoch: 397 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1198
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242682
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448763
INFO:root:FL Epoch: 397 Norm Difference for worker 1198 is 0.715079
INFO:root:FL Epoch: 397 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :527
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629959
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660785
INFO:root:FL Epoch: 397 Norm Difference for worker 527 is 0.767707
INFO:root:FL Epoch: 397 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1053
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583644
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506112
INFO:root:FL Epoch: 397 Norm Difference for worker 1053 is 0.762148
INFO:root:FL Epoch: 397 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1645
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456170
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449513
INFO:root:FL Epoch: 397 Norm Difference for worker 1645 is 0.824589
INFO:root:FL Epoch: 397 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :917
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875890
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474657
INFO:root:FL Epoch: 397 Norm Difference for worker 917 is 0.787443
INFO:root:FL Epoch: 397 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1927
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.5002001971006393 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.255258912841479                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1469, 1630, 1186, 1921, 1671, 732, 997, 506, 1188, 398]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 398 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1469
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589557
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583752
INFO:root:FL Epoch: 398 Norm Difference for worker 1469 is 0.786098
INFO:root:FL Epoch: 398 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1630
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335446
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502662
INFO:root:FL Epoch: 398 Norm Difference for worker 1630 is 0.854126
INFO:root:FL Epoch: 398 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1186
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549575
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593413
INFO:root:FL Epoch: 398 Norm Difference for worker 1186 is 0.893305
INFO:root:FL Epoch: 398 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1921
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741213
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439967
INFO:root:FL Epoch: 398 Norm Difference for worker 1921 is 0.820367
INFO:root:FL Epoch: 398 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1671
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662602
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561118
INFO:root:FL Epoch: 398 Norm Difference for worker 1671 is 0.808071
INFO:root:FL Epoch: 398 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :732
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908713
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664399
INFO:root:FL Epoch: 398 Norm Difference for worker 732 is 0.798786
INFO:root:FL Epoch: 398 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :997
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374910
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677558
INFO:root:FL Epoch: 398 Norm Difference for worker 997 is 0.835012
INFO:root:FL Epoch: 398 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :506
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594111
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759207
INFO:root:FL Epoch: 398 Norm Difference for worker 506 is 0.831851
INFO:root:FL Epoch: 398 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1188
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564444
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723784
INFO:root:FL Epoch: 398 Norm Difference for worker 1188 is 0.799068
INFO:root:FL Epoch: 398 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :398
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588563
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579330
INFO:root:FL Epoch: 398 Norm Difference for worker 398 is 0.883693
INFO:root:FL Epoch: 398 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 732
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.49605007557307973 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.2413430983821551                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [33, 656, 758, 379, 1800, 821, 1258, 725, 768, 46]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 399 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :33
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 33 is 0.757662
INFO:root:FL Epoch: 399 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :656
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505515
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625356
INFO:root:FL Epoch: 399 Norm Difference for worker 656 is 0.80343
INFO:root:FL Epoch: 399 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :758
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571170
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526692
INFO:root:FL Epoch: 399 Norm Difference for worker 758 is 0.7089
INFO:root:FL Epoch: 399 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :379
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350172
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555425
INFO:root:FL Epoch: 399 Norm Difference for worker 379 is 0.734998
INFO:root:FL Epoch: 399 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1800
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580559
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478505
INFO:root:FL Epoch: 399 Norm Difference for worker 1800 is 0.733535
INFO:root:FL Epoch: 399 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :821
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572446
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720670
INFO:root:FL Epoch: 399 Norm Difference for worker 821 is 0.739121
INFO:root:FL Epoch: 399 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1258
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498494
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558729
INFO:root:FL Epoch: 399 Norm Difference for worker 1258 is 0.734194
INFO:root:FL Epoch: 399 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :725
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524597
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379296
INFO:root:FL Epoch: 399 Norm Difference for worker 725 is 0.702846
INFO:root:FL Epoch: 399 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :768
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.240809
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443619
INFO:root:FL Epoch: 399 Norm Difference for worker 768 is 0.758415
INFO:root:FL Epoch: 399 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :46
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 46 is 0.731853
INFO:root:FL Epoch: 399 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 725
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.49037501128280864 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.28006544212500256                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [1374, 653, 800, 738, 1855, 248, 298, 573, 1627, 1083]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :1374
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490164
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405579
INFO:root:FL Epoch: 400 Norm Difference for worker 1374 is 0.655793
INFO:root:FL Epoch: 400 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :653
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490934
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412234
INFO:root:FL Epoch: 400 Norm Difference for worker 653 is 0.666027
INFO:root:FL Epoch: 400 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :800
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776141
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357604
INFO:root:FL Epoch: 400 Norm Difference for worker 800 is 0.695117
INFO:root:FL Epoch: 400 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :738
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319184
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534108
INFO:root:FL Epoch: 400 Norm Difference for worker 738 is 0.72806
INFO:root:FL Epoch: 400 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1855
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503410
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553310
INFO:root:FL Epoch: 400 Norm Difference for worker 1855 is 0.745562
INFO:root:FL Epoch: 400 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :248
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 248 is 0.660393
INFO:root:FL Epoch: 400 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :298
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.329311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 298 is 0.704689
INFO:root:FL Epoch: 400 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :573
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596056
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511153
INFO:root:FL Epoch: 400 Norm Difference for worker 573 is 0.736813
INFO:root:FL Epoch: 400 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1627
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283538
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437751
INFO:root:FL Epoch: 400 Norm Difference for worker 1627 is 0.693385
INFO:root:FL Epoch: 400 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1083
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471673
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327561
INFO:root:FL Epoch: 400 Norm Difference for worker 1083 is 0.666078
INFO:root:FL Epoch: 400 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1374
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.4784746240167057 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.20559024810791016                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 163, 138, 1190, 701, 1254, 563, 1004]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380550
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203351
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.1801165516177813 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.2060312584042549 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.140406
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524421
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171205
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.17824539045492807 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.2049172967672348 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.143079
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277475
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220346
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.17627838253974915 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.20390055924654008 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.145951
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :163
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 163 is 0.778004
INFO:root:FL Epoch: 401 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :138
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 138 is 0.810137
INFO:root:FL Epoch: 401 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1190
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315604
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242944
INFO:root:FL Epoch: 401 Norm Difference for worker 1190 is 0.683748
INFO:root:FL Epoch: 401 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :701
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343862
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289550
INFO:root:FL Epoch: 401 Norm Difference for worker 701 is 0.806604
INFO:root:FL Epoch: 401 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1254
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384339
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455856
INFO:root:FL Epoch: 401 Norm Difference for worker 1254 is 0.865879
INFO:root:FL Epoch: 401 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :563
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622023
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281416
INFO:root:FL Epoch: 401 Norm Difference for worker 563 is 0.804517
INFO:root:FL Epoch: 401 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1004
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 1.002685
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408599
INFO:root:FL Epoch: 401 Norm Difference for worker 1004 is 0.813523
INFO:root:FL Epoch: 401 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.48399293422698975 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.17824539045492807                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [607, 1517, 1264, 1385, 623, 1075, 1805, 731, 742, 1898]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :607
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267656
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463871
INFO:root:FL Epoch: 402 Norm Difference for worker 607 is 0.828863
INFO:root:FL Epoch: 402 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1517
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542947
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397438
INFO:root:FL Epoch: 402 Norm Difference for worker 1517 is 0.914469
INFO:root:FL Epoch: 402 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1264
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573432
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257656
INFO:root:FL Epoch: 402 Norm Difference for worker 1264 is 0.888183
INFO:root:FL Epoch: 402 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1385
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444246
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404032
INFO:root:FL Epoch: 402 Norm Difference for worker 1385 is 0.760554
INFO:root:FL Epoch: 402 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :623
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648257
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717874
INFO:root:FL Epoch: 402 Norm Difference for worker 623 is 0.928553
INFO:root:FL Epoch: 402 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1075
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573813
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398100
INFO:root:FL Epoch: 402 Norm Difference for worker 1075 is 0.861852
INFO:root:FL Epoch: 402 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1805
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835076
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456508
INFO:root:FL Epoch: 402 Norm Difference for worker 1805 is 0.891149
INFO:root:FL Epoch: 402 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :731
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689314
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293627
INFO:root:FL Epoch: 402 Norm Difference for worker 731 is 0.843065
INFO:root:FL Epoch: 402 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :742
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479714
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264268
INFO:root:FL Epoch: 402 Norm Difference for worker 742 is 0.851859
INFO:root:FL Epoch: 402 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1898
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613691
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541050
INFO:root:FL Epoch: 402 Norm Difference for worker 1898 is 0.877705
INFO:root:FL Epoch: 402 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1385
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.48655342266840096 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.19603003561496735                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1697, 438, 1000, 1152, 674, 1882, 1176, 1868, 78, 1171]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1697
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359111
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596059
INFO:root:FL Epoch: 403 Norm Difference for worker 1697 is 0.93373
INFO:root:FL Epoch: 403 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :438
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568182
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686585
INFO:root:FL Epoch: 403 Norm Difference for worker 438 is 0.964925
INFO:root:FL Epoch: 403 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1000
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671290
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501657
INFO:root:FL Epoch: 403 Norm Difference for worker 1000 is 1.074345
INFO:root:FL Epoch: 403 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1152
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259901
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548555
INFO:root:FL Epoch: 403 Norm Difference for worker 1152 is 1.04475
INFO:root:FL Epoch: 403 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :674
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496756
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343717
INFO:root:FL Epoch: 403 Norm Difference for worker 674 is 0.900138
INFO:root:FL Epoch: 403 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1882
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479830
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427069
INFO:root:FL Epoch: 403 Norm Difference for worker 1882 is 0.918174
INFO:root:FL Epoch: 403 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1176
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740526
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451088
INFO:root:FL Epoch: 403 Norm Difference for worker 1176 is 0.89754
INFO:root:FL Epoch: 403 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1868
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369688
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433189
INFO:root:FL Epoch: 403 Norm Difference for worker 1868 is 0.95488
INFO:root:FL Epoch: 403 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :78
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 78 is 0.773401
INFO:root:FL Epoch: 403 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1171
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344902
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515988
INFO:root:FL Epoch: 403 Norm Difference for worker 1171 is 0.909665
INFO:root:FL Epoch: 403 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.48706581662682924 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.19904986148079237                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [42, 1565, 994, 591, 1772, 1731, 767, 1854, 1609, 1682]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 404 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :42
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214968
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 42 is 0.748552
INFO:root:FL Epoch: 404 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1565
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629999
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.835273
INFO:root:FL Epoch: 404 Norm Difference for worker 1565 is 0.934966
INFO:root:FL Epoch: 404 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :994
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627605
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556444
INFO:root:FL Epoch: 404 Norm Difference for worker 994 is 0.821378
INFO:root:FL Epoch: 404 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :591
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415348
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827616
INFO:root:FL Epoch: 404 Norm Difference for worker 591 is 0.912296
INFO:root:FL Epoch: 404 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1772
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575183
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704327
INFO:root:FL Epoch: 404 Norm Difference for worker 1772 is 0.881041
INFO:root:FL Epoch: 404 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1731
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493472
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297975
INFO:root:FL Epoch: 404 Norm Difference for worker 1731 is 0.774915
INFO:root:FL Epoch: 404 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :767
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704759
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226092
INFO:root:FL Epoch: 404 Norm Difference for worker 767 is 0.89036
INFO:root:FL Epoch: 404 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1854
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731720
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551080
INFO:root:FL Epoch: 404 Norm Difference for worker 1854 is 1.001068
INFO:root:FL Epoch: 404 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1609
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415661
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298625
INFO:root:FL Epoch: 404 Norm Difference for worker 1609 is 0.873339
INFO:root:FL Epoch: 404 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1682
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520921
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324407
INFO:root:FL Epoch: 404 Norm Difference for worker 1682 is 0.890939
INFO:root:FL Epoch: 404 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.5036406262832529 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.2102285996079445                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1229, 1879, 783, 290, 1711, 787, 1366, 1837, 1562, 898]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1229
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934515
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511442
INFO:root:FL Epoch: 405 Norm Difference for worker 1229 is 0.943978
INFO:root:FL Epoch: 405 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1879
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471855
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536987
INFO:root:FL Epoch: 405 Norm Difference for worker 1879 is 0.918126
INFO:root:FL Epoch: 405 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :783
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533342
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300013
INFO:root:FL Epoch: 405 Norm Difference for worker 783 is 0.934471
INFO:root:FL Epoch: 405 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :290
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.754779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505127
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 290 is 0.970867
INFO:root:FL Epoch: 405 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1711
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645018
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330521
INFO:root:FL Epoch: 405 Norm Difference for worker 1711 is 0.920863
INFO:root:FL Epoch: 405 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :787
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539503
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492074
INFO:root:FL Epoch: 405 Norm Difference for worker 787 is 0.975914
INFO:root:FL Epoch: 405 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1366
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756832
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523402
INFO:root:FL Epoch: 405 Norm Difference for worker 1366 is 0.893736
INFO:root:FL Epoch: 405 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1837
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756555
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.805626
INFO:root:FL Epoch: 405 Norm Difference for worker 1837 is 0.971097
INFO:root:FL Epoch: 405 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1562
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660399
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478492
INFO:root:FL Epoch: 405 Norm Difference for worker 1562 is 0.952645
INFO:root:FL Epoch: 405 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :898
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790155
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346306
INFO:root:FL Epoch: 405 Norm Difference for worker 898 is 0.943039
INFO:root:FL Epoch: 405 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1711
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.5206003320567748 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.35170533259709674                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [43, 1346, 1944, 1012, 832, 366, 1013, 1230, 475, 495]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 406 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :43
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629663
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 43 is 0.814142
INFO:root:FL Epoch: 406 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1346
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540171
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490774
INFO:root:FL Epoch: 406 Norm Difference for worker 1346 is 0.848316
INFO:root:FL Epoch: 406 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1944
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.975339
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465833
INFO:root:FL Epoch: 406 Norm Difference for worker 1944 is 0.777373
INFO:root:FL Epoch: 406 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1012
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617363
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544736
INFO:root:FL Epoch: 406 Norm Difference for worker 1012 is 0.774653
INFO:root:FL Epoch: 406 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :832
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561593
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588826
INFO:root:FL Epoch: 406 Norm Difference for worker 832 is 0.860308
INFO:root:FL Epoch: 406 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :366
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795092
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387852
INFO:root:FL Epoch: 406 Norm Difference for worker 366 is 0.783611
INFO:root:FL Epoch: 406 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1013
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490545
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606987
INFO:root:FL Epoch: 406 Norm Difference for worker 1013 is 0.788254
INFO:root:FL Epoch: 406 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1230
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745309
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342404
INFO:root:FL Epoch: 406 Norm Difference for worker 1230 is 0.858855
INFO:root:FL Epoch: 406 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :475
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568508
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477364
INFO:root:FL Epoch: 406 Norm Difference for worker 475 is 0.814009
INFO:root:FL Epoch: 406 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :495
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760651
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592617
INFO:root:FL Epoch: 406 Norm Difference for worker 495 is 0.845215
INFO:root:FL Epoch: 406 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1944
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.5165258356753517 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.2173583135008812                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1183, 943, 1373, 1473, 992, 757, 1475, 680, 491, 1743]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1183
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458632
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339282
INFO:root:FL Epoch: 407 Norm Difference for worker 1183 is 0.802497
INFO:root:FL Epoch: 407 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :943
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507027
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516139
INFO:root:FL Epoch: 407 Norm Difference for worker 943 is 0.901978
INFO:root:FL Epoch: 407 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1373
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426569
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602142
INFO:root:FL Epoch: 407 Norm Difference for worker 1373 is 0.878939
INFO:root:FL Epoch: 407 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1473
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424430
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655203
INFO:root:FL Epoch: 407 Norm Difference for worker 1473 is 0.883253
INFO:root:FL Epoch: 407 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :992
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415398
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356847
INFO:root:FL Epoch: 407 Norm Difference for worker 992 is 0.879763
INFO:root:FL Epoch: 407 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :757
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832305
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533843
INFO:root:FL Epoch: 407 Norm Difference for worker 757 is 0.85606
INFO:root:FL Epoch: 407 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1475
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755042
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371005
INFO:root:FL Epoch: 407 Norm Difference for worker 1475 is 0.823326
INFO:root:FL Epoch: 407 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :680
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420788
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459319
INFO:root:FL Epoch: 407 Norm Difference for worker 680 is 0.792715
INFO:root:FL Epoch: 407 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :491
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515717
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283031
INFO:root:FL Epoch: 407 Norm Difference for worker 491 is 0.821436
INFO:root:FL Epoch: 407 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1743
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586012
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560656
INFO:root:FL Epoch: 407 Norm Difference for worker 1743 is 0.86578
INFO:root:FL Epoch: 407 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1475
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.5303530061946196 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.33700482298930484                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [1623, 1108, 1748, 150, 1450, 611, 673, 1016, 676, 1248]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :1623
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487264
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329562
INFO:root:FL Epoch: 408 Norm Difference for worker 1623 is 0.850716
INFO:root:FL Epoch: 408 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1108
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804246
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554874
INFO:root:FL Epoch: 408 Norm Difference for worker 1108 is 0.871086
INFO:root:FL Epoch: 408 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1748
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758776
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725702
INFO:root:FL Epoch: 408 Norm Difference for worker 1748 is 0.875425
INFO:root:FL Epoch: 408 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :150
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 150 is 0.861747
INFO:root:FL Epoch: 408 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1450
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519025
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684944
INFO:root:FL Epoch: 408 Norm Difference for worker 1450 is 0.82533
INFO:root:FL Epoch: 408 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :611
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454366
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456876
INFO:root:FL Epoch: 408 Norm Difference for worker 611 is 0.881284
INFO:root:FL Epoch: 408 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :673
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342396
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370649
INFO:root:FL Epoch: 408 Norm Difference for worker 673 is 0.84543
INFO:root:FL Epoch: 408 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1016
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417707
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450529
INFO:root:FL Epoch: 408 Norm Difference for worker 1016 is 0.854539
INFO:root:FL Epoch: 408 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :676
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650046
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632197
INFO:root:FL Epoch: 408 Norm Difference for worker 676 is 0.837353
INFO:root:FL Epoch: 408 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1248
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461662
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325625
INFO:root:FL Epoch: 408 Norm Difference for worker 1248 is 0.835278
INFO:root:FL Epoch: 408 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1248
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.5000677687280318 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.271081085006396                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1095, 1034, 884, 1106, 854, 1812, 1365, 1153, 368, 741]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1095
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777094
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455487
INFO:root:FL Epoch: 409 Norm Difference for worker 1095 is 0.756426
INFO:root:FL Epoch: 409 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1034
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530670
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453632
INFO:root:FL Epoch: 409 Norm Difference for worker 1034 is 0.766932
INFO:root:FL Epoch: 409 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :884
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767340
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542915
INFO:root:FL Epoch: 409 Norm Difference for worker 884 is 0.782234
INFO:root:FL Epoch: 409 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1106
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666290
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362925
INFO:root:FL Epoch: 409 Norm Difference for worker 1106 is 0.73379
INFO:root:FL Epoch: 409 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :854
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514859
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386969
INFO:root:FL Epoch: 409 Norm Difference for worker 854 is 0.774018
INFO:root:FL Epoch: 409 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1812
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692037
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492367
INFO:root:FL Epoch: 409 Norm Difference for worker 1812 is 0.772904
INFO:root:FL Epoch: 409 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1365
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752680
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458247
INFO:root:FL Epoch: 409 Norm Difference for worker 1365 is 0.751445
INFO:root:FL Epoch: 409 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1153
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605307
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436123
INFO:root:FL Epoch: 409 Norm Difference for worker 1153 is 0.763199
INFO:root:FL Epoch: 409 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :368
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585693
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738279
INFO:root:FL Epoch: 409 Norm Difference for worker 368 is 0.772523
INFO:root:FL Epoch: 409 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :741
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546843
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644321
INFO:root:FL Epoch: 409 Norm Difference for worker 741 is 0.790691
INFO:root:FL Epoch: 409 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1106
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.494908423984752 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.27418696880340576                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [1588, 1566, 1373, 38, 609, 48, 1939, 569, 905, 90]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :1588
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465192
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428880
INFO:root:FL Epoch: 410 Norm Difference for worker 1588 is 0.732933
INFO:root:FL Epoch: 410 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1566
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536628
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487955
INFO:root:FL Epoch: 410 Norm Difference for worker 1566 is 0.728573
INFO:root:FL Epoch: 410 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1373
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569390
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453392
INFO:root:FL Epoch: 410 Norm Difference for worker 1373 is 0.799199
INFO:root:FL Epoch: 410 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :38
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 38 is 0.757322
INFO:root:FL Epoch: 410 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :609
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274269
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305206
INFO:root:FL Epoch: 410 Norm Difference for worker 609 is 0.765942
INFO:root:FL Epoch: 410 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :48
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.338335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605482
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 48 is 0.75755
INFO:root:FL Epoch: 410 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1939
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734455
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598775
INFO:root:FL Epoch: 410 Norm Difference for worker 1939 is 0.784228
INFO:root:FL Epoch: 410 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :569
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444845
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345927
INFO:root:FL Epoch: 410 Norm Difference for worker 569 is 0.799629
INFO:root:FL Epoch: 410 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :905
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661005
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481849
INFO:root:FL Epoch: 410 Norm Difference for worker 905 is 0.760436
INFO:root:FL Epoch: 410 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :90
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 90 is 0.801935
INFO:root:FL Epoch: 410 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.5018380705048057 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.23103985438744226                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 1347, 1697, 1523, 1370, 1900, 1837, 1578]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327866
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210327
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.21336332708597183 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.2229807421565056 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.16312
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266961
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285722
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.21314793328444162 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.22277104780077933 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.162494
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296283
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385151
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.20434787372748056 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.22399191409349442 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.15482
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1347
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704405
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405226
INFO:root:FL Epoch: 411 Norm Difference for worker 1347 is 0.769452
INFO:root:FL Epoch: 411 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1697
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708732
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337943
INFO:root:FL Epoch: 411 Norm Difference for worker 1697 is 0.771608
INFO:root:FL Epoch: 411 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1523
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589065
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637181
INFO:root:FL Epoch: 411 Norm Difference for worker 1523 is 0.737158
INFO:root:FL Epoch: 411 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1370
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618219
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528115
INFO:root:FL Epoch: 411 Norm Difference for worker 1370 is 0.75445
INFO:root:FL Epoch: 411 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1900
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382952
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506575
INFO:root:FL Epoch: 411 Norm Difference for worker 1900 is 0.789467
INFO:root:FL Epoch: 411 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1837
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579926
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434277
INFO:root:FL Epoch: 411 Norm Difference for worker 1837 is 0.773216
INFO:root:FL Epoch: 411 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1578
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673057
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489349
INFO:root:FL Epoch: 411 Norm Difference for worker 1578 is 0.672833
INFO:root:FL Epoch: 411 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.49760228570769816 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.21314793328444162                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1440, 141, 1453, 738, 655, 1904, 396, 1209, 903, 881]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 412 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1440
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516792
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533536
INFO:root:FL Epoch: 412 Norm Difference for worker 1440 is 0.823053
INFO:root:FL Epoch: 412 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :141
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306657
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 141 is 0.781103
INFO:root:FL Epoch: 412 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1453
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801654
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461664
INFO:root:FL Epoch: 412 Norm Difference for worker 1453 is 0.753911
INFO:root:FL Epoch: 412 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :738
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499053
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482846
INFO:root:FL Epoch: 412 Norm Difference for worker 738 is 0.803186
INFO:root:FL Epoch: 412 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :655
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274430
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539191
INFO:root:FL Epoch: 412 Norm Difference for worker 655 is 0.73915
INFO:root:FL Epoch: 412 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1904
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428841
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546794
INFO:root:FL Epoch: 412 Norm Difference for worker 1904 is 0.788676
INFO:root:FL Epoch: 412 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :396
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581625
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297120
INFO:root:FL Epoch: 412 Norm Difference for worker 396 is 0.82353
INFO:root:FL Epoch: 412 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1209
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625272
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661901
INFO:root:FL Epoch: 412 Norm Difference for worker 1209 is 0.76608
INFO:root:FL Epoch: 412 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :903
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542681
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467528
INFO:root:FL Epoch: 412 Norm Difference for worker 903 is 0.826633
INFO:root:FL Epoch: 412 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :881
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564615
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409658
INFO:root:FL Epoch: 412 Norm Difference for worker 881 is 0.66841
INFO:root:FL Epoch: 412 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.49027055326630087 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.2199394628405571                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [459, 6, 1260, 1890, 606, 1654, 276, 718, 1641, 1195]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 413 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :459
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473303
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333916
INFO:root:FL Epoch: 413 Norm Difference for worker 459 is 0.847665
INFO:root:FL Epoch: 413 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :6
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 6 is 0.805495
INFO:root:FL Epoch: 413 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1260
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629921
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585166
INFO:root:FL Epoch: 413 Norm Difference for worker 1260 is 0.778919
INFO:root:FL Epoch: 413 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1890
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667972
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402129
INFO:root:FL Epoch: 413 Norm Difference for worker 1890 is 0.862566
INFO:root:FL Epoch: 413 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :606
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497787
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531911
INFO:root:FL Epoch: 413 Norm Difference for worker 606 is 0.844581
INFO:root:FL Epoch: 413 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1654
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617253
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476465
INFO:root:FL Epoch: 413 Norm Difference for worker 1654 is 0.876566
INFO:root:FL Epoch: 413 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :276
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298628
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 276 is 0.887736
INFO:root:FL Epoch: 413 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :718
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477564
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533254
INFO:root:FL Epoch: 413 Norm Difference for worker 718 is 0.783686
INFO:root:FL Epoch: 413 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1641
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463688
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461832
INFO:root:FL Epoch: 413 Norm Difference for worker 1641 is 0.886005
INFO:root:FL Epoch: 413 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1195
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487355
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481818
INFO:root:FL Epoch: 413 Norm Difference for worker 1195 is 0.836593
INFO:root:FL Epoch: 413 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1260
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.4864397495985031 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.22393056750297546                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [1250, 1532, 1790, 1295, 290, 1589, 1759, 1893, 1747, 1008]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :1250
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548935
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371774
INFO:root:FL Epoch: 414 Norm Difference for worker 1250 is 0.825512
INFO:root:FL Epoch: 414 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1532
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422398
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517778
INFO:root:FL Epoch: 414 Norm Difference for worker 1532 is 0.744127
INFO:root:FL Epoch: 414 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1790
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400283
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486594
INFO:root:FL Epoch: 414 Norm Difference for worker 1790 is 0.749933
INFO:root:FL Epoch: 414 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1295
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332468
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400256
INFO:root:FL Epoch: 414 Norm Difference for worker 1295 is 0.768071
INFO:root:FL Epoch: 414 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :290
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 290 is 0.843067
INFO:root:FL Epoch: 414 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1589
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525250
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676759
INFO:root:FL Epoch: 414 Norm Difference for worker 1589 is 0.762162
INFO:root:FL Epoch: 414 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1759
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714921
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583293
INFO:root:FL Epoch: 414 Norm Difference for worker 1759 is 0.817267
INFO:root:FL Epoch: 414 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1893
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937309
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369617
INFO:root:FL Epoch: 414 Norm Difference for worker 1893 is 0.826795
INFO:root:FL Epoch: 414 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1747
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568570
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534627
INFO:root:FL Epoch: 414 Norm Difference for worker 1747 is 0.817673
INFO:root:FL Epoch: 414 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1008
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759049
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486013
INFO:root:FL Epoch: 414 Norm Difference for worker 1008 is 0.810946
INFO:root:FL Epoch: 414 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1790
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.4998411404735902 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.3324181040128072                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [1413, 172, 86, 370, 1824, 1386, 472, 1000, 637, 1934]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 415 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :1413
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457978
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494819
INFO:root:FL Epoch: 415 Norm Difference for worker 1413 is 0.755609
INFO:root:FL Epoch: 415 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :172
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 172 is 0.699362
INFO:root:FL Epoch: 415 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :86
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.281942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 86 is 0.65268
INFO:root:FL Epoch: 415 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :370
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524041
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599009
INFO:root:FL Epoch: 415 Norm Difference for worker 370 is 0.694448
INFO:root:FL Epoch: 415 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1824
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496534
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535911
INFO:root:FL Epoch: 415 Norm Difference for worker 1824 is 0.747262
INFO:root:FL Epoch: 415 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1386
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519280
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531560
INFO:root:FL Epoch: 415 Norm Difference for worker 1386 is 0.760528
INFO:root:FL Epoch: 415 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :472
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479034
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465523
INFO:root:FL Epoch: 415 Norm Difference for worker 472 is 0.729177
INFO:root:FL Epoch: 415 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1000
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445126
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518879
INFO:root:FL Epoch: 415 Norm Difference for worker 1000 is 0.783665
INFO:root:FL Epoch: 415 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :637
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660466
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457573
INFO:root:FL Epoch: 415 Norm Difference for worker 637 is 0.83517
INFO:root:FL Epoch: 415 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1934
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326826
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398227
INFO:root:FL Epoch: 415 Norm Difference for worker 1934 is 0.779649
INFO:root:FL Epoch: 415 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.4940786913913839 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.25428347537914914                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [337, 431, 1785, 716, 52, 758, 1794, 162, 1203, 898]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 416 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :337
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449511
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 337 is 0.846098
INFO:root:FL Epoch: 416 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :431
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636819
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363994
INFO:root:FL Epoch: 416 Norm Difference for worker 431 is 0.846106
INFO:root:FL Epoch: 416 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1785
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350766
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400320
INFO:root:FL Epoch: 416 Norm Difference for worker 1785 is 0.899497
INFO:root:FL Epoch: 416 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :716
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448940
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492898
INFO:root:FL Epoch: 416 Norm Difference for worker 716 is 0.893235
INFO:root:FL Epoch: 416 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :52
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 52 is 0.918073
INFO:root:FL Epoch: 416 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :758
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555923
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330753
INFO:root:FL Epoch: 416 Norm Difference for worker 758 is 0.862258
INFO:root:FL Epoch: 416 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1794
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441043
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574332
INFO:root:FL Epoch: 416 Norm Difference for worker 1794 is 0.858324
INFO:root:FL Epoch: 416 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :162
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.409551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 162 is 0.870805
INFO:root:FL Epoch: 416 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1203
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726429
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486373
INFO:root:FL Epoch: 416 Norm Difference for worker 1203 is 0.929705
INFO:root:FL Epoch: 416 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :898
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747296
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372721
INFO:root:FL Epoch: 416 Norm Difference for worker 898 is 0.87555
INFO:root:FL Epoch: 416 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 431
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.4828998946091708 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.18357575684785843                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1578, 1877, 1722, 1440, 1829, 671, 994, 651, 1136, 1386]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1578
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373591
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431030
INFO:root:FL Epoch: 417 Norm Difference for worker 1578 is 0.780127
INFO:root:FL Epoch: 417 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1877
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537015
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412287
INFO:root:FL Epoch: 417 Norm Difference for worker 1877 is 0.84052
INFO:root:FL Epoch: 417 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1722
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579139
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562695
INFO:root:FL Epoch: 417 Norm Difference for worker 1722 is 0.867628
INFO:root:FL Epoch: 417 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1440
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533181
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475109
INFO:root:FL Epoch: 417 Norm Difference for worker 1440 is 0.866182
INFO:root:FL Epoch: 417 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1829
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535879
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508136
INFO:root:FL Epoch: 417 Norm Difference for worker 1829 is 0.770962
INFO:root:FL Epoch: 417 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :671
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584875
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444552
INFO:root:FL Epoch: 417 Norm Difference for worker 671 is 0.867615
INFO:root:FL Epoch: 417 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :994
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456593
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562989
INFO:root:FL Epoch: 417 Norm Difference for worker 994 is 0.819591
INFO:root:FL Epoch: 417 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :651
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586050
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445666
INFO:root:FL Epoch: 417 Norm Difference for worker 651 is 0.803306
INFO:root:FL Epoch: 417 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1136
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760553
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504272
INFO:root:FL Epoch: 417 Norm Difference for worker 1136 is 0.85972
INFO:root:FL Epoch: 417 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1386
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658867
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524123
INFO:root:FL Epoch: 417 Norm Difference for worker 1386 is 0.818171
INFO:root:FL Epoch: 417 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.4786396745373221 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.27643706401189166                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [1394, 446, 1001, 597, 430, 98, 478, 1158, 171, 285]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :1394
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399525
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491206
INFO:root:FL Epoch: 418 Norm Difference for worker 1394 is 0.806807
INFO:root:FL Epoch: 418 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :446
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455437
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335447
INFO:root:FL Epoch: 418 Norm Difference for worker 446 is 0.766792
INFO:root:FL Epoch: 418 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1001
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472615
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337811
INFO:root:FL Epoch: 418 Norm Difference for worker 1001 is 0.679866
INFO:root:FL Epoch: 418 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :597
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602751
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387453
INFO:root:FL Epoch: 418 Norm Difference for worker 597 is 0.734912
INFO:root:FL Epoch: 418 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :430
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724244
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424025
INFO:root:FL Epoch: 418 Norm Difference for worker 430 is 0.724489
INFO:root:FL Epoch: 418 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :98
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667390
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440266
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 98 is 0.767243
INFO:root:FL Epoch: 418 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :478
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336263
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368654
INFO:root:FL Epoch: 418 Norm Difference for worker 478 is 0.717945
INFO:root:FL Epoch: 418 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1158
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514142
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435612
INFO:root:FL Epoch: 418 Norm Difference for worker 1158 is 0.689498
INFO:root:FL Epoch: 418 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :171
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 171 is 0.692374
INFO:root:FL Epoch: 418 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :285
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.299272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 285 is 0.692655
INFO:root:FL Epoch: 418 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1001
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.48064693633247824 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.23597520093123117                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [1565, 1770, 855, 807, 185, 421, 1904, 1529, 162, 1104]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :1565
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396158
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545591
INFO:root:FL Epoch: 419 Norm Difference for worker 1565 is 0.760069
INFO:root:FL Epoch: 419 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1770
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703435
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509204
INFO:root:FL Epoch: 419 Norm Difference for worker 1770 is 0.740833
INFO:root:FL Epoch: 419 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :855
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424459
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642378
INFO:root:FL Epoch: 419 Norm Difference for worker 855 is 0.785368
INFO:root:FL Epoch: 419 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :807
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420594
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306389
INFO:root:FL Epoch: 419 Norm Difference for worker 807 is 0.771291
INFO:root:FL Epoch: 419 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :185
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 185 is 0.726097
INFO:root:FL Epoch: 419 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :421
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602654
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493788
INFO:root:FL Epoch: 419 Norm Difference for worker 421 is 0.727287
INFO:root:FL Epoch: 419 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1904
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457715
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294758
INFO:root:FL Epoch: 419 Norm Difference for worker 1904 is 0.770441
INFO:root:FL Epoch: 419 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1529
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490124
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299772
INFO:root:FL Epoch: 419 Norm Difference for worker 1529 is 0.742229
INFO:root:FL Epoch: 419 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :162
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.801661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 162 is 0.740786
INFO:root:FL Epoch: 419 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1104
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630656
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616913
INFO:root:FL Epoch: 419 Norm Difference for worker 1104 is 0.750971
INFO:root:FL Epoch: 419 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1770
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.5088778006679872 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.315012348194917                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1780, 132, 501, 1727, 1308, 1584, 1596, 1485, 854, 363]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 420 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1780
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483645
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454127
INFO:root:FL Epoch: 420 Norm Difference for worker 1780 is 0.755072
INFO:root:FL Epoch: 420 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :132
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 132 is 0.825046
INFO:root:FL Epoch: 420 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :501
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224131
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365452
INFO:root:FL Epoch: 420 Norm Difference for worker 501 is 0.726286
INFO:root:FL Epoch: 420 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1727
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303297
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365867
INFO:root:FL Epoch: 420 Norm Difference for worker 1727 is 0.68822
INFO:root:FL Epoch: 420 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1308
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639694
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580255
INFO:root:FL Epoch: 420 Norm Difference for worker 1308 is 0.813342
INFO:root:FL Epoch: 420 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1584
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537677
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491348
INFO:root:FL Epoch: 420 Norm Difference for worker 1584 is 0.783499
INFO:root:FL Epoch: 420 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1596
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719084
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628558
INFO:root:FL Epoch: 420 Norm Difference for worker 1596 is 0.771683
INFO:root:FL Epoch: 420 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1485
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475177
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446681
INFO:root:FL Epoch: 420 Norm Difference for worker 1485 is 0.769531
INFO:root:FL Epoch: 420 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :854
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536973
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430754
INFO:root:FL Epoch: 420 Norm Difference for worker 854 is 0.810084
INFO:root:FL Epoch: 420 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :363
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.919614
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685362
INFO:root:FL Epoch: 420 Norm Difference for worker 363 is 0.969923
INFO:root:FL Epoch: 420 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1727
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.4841443493085749 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.2809193854530652                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 331, 252, 1598, 852, 1672, 738, 1413]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206456
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202985
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.2334532489379247 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.20456361174583435 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.149221
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278391
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200878
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.2270954300959905 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.20398855358362197 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.152513
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316731
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231458
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.227389062444369 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.20561271160840988 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.145508
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :331
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412811
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 331 is 0.71345
INFO:root:FL Epoch: 421 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :252
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 252 is 0.753972
INFO:root:FL Epoch: 421 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1598
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363122
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228771
INFO:root:FL Epoch: 421 Norm Difference for worker 1598 is 0.733126
INFO:root:FL Epoch: 421 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :852
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420267
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625609
INFO:root:FL Epoch: 421 Norm Difference for worker 852 is 0.758545
INFO:root:FL Epoch: 421 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1672
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452265
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394909
INFO:root:FL Epoch: 421 Norm Difference for worker 1672 is 0.654043
INFO:root:FL Epoch: 421 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :738
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630307
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443657
INFO:root:FL Epoch: 421 Norm Difference for worker 738 is 0.750205
INFO:root:FL Epoch: 421 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1413
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510143
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692824
INFO:root:FL Epoch: 421 Norm Difference for worker 1413 is 0.782806
INFO:root:FL Epoch: 421 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.4841969723210615 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.227389062444369                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [265, 1432, 207, 1520, 890, 723, 1096, 1450, 440, 1471]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 422 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :265
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.855615
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 265 is 0.848641
INFO:root:FL Epoch: 422 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1432
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519940
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533823
INFO:root:FL Epoch: 422 Norm Difference for worker 1432 is 0.754731
INFO:root:FL Epoch: 422 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :207
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 207 is 0.844534
INFO:root:FL Epoch: 422 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1520
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511893
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397659
INFO:root:FL Epoch: 422 Norm Difference for worker 1520 is 0.750351
INFO:root:FL Epoch: 422 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :890
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864274
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353911
INFO:root:FL Epoch: 422 Norm Difference for worker 890 is 0.835846
INFO:root:FL Epoch: 422 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :723
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420451
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569448
INFO:root:FL Epoch: 422 Norm Difference for worker 723 is 0.771832
INFO:root:FL Epoch: 422 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1096
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548058
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280299
INFO:root:FL Epoch: 422 Norm Difference for worker 1096 is 0.752649
INFO:root:FL Epoch: 422 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1450
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551512
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358549
INFO:root:FL Epoch: 422 Norm Difference for worker 1450 is 0.8518
INFO:root:FL Epoch: 422 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :440
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606514
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323057
INFO:root:FL Epoch: 422 Norm Difference for worker 440 is 0.75622
INFO:root:FL Epoch: 422 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1471
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648190
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603338
INFO:root:FL Epoch: 422 Norm Difference for worker 1471 is 0.819169
INFO:root:FL Epoch: 422 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1432
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.47923141717910767 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.2653345912694931                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [1477, 1688, 190, 1382, 1904, 742, 1629, 178, 1346, 1406]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 423 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :1477
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407504
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484680
INFO:root:FL Epoch: 423 Norm Difference for worker 1477 is 0.788835
INFO:root:FL Epoch: 423 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1688
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368897
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456793
INFO:root:FL Epoch: 423 Norm Difference for worker 1688 is 0.738957
INFO:root:FL Epoch: 423 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :190
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 190 is 0.772605
INFO:root:FL Epoch: 423 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1382
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503476
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547693
INFO:root:FL Epoch: 423 Norm Difference for worker 1382 is 0.748137
INFO:root:FL Epoch: 423 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1904
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470150
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396335
INFO:root:FL Epoch: 423 Norm Difference for worker 1904 is 0.768949
INFO:root:FL Epoch: 423 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :742
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424560
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352689
INFO:root:FL Epoch: 423 Norm Difference for worker 742 is 0.805097
INFO:root:FL Epoch: 423 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1629
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581903
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429986
INFO:root:FL Epoch: 423 Norm Difference for worker 1629 is 0.811403
INFO:root:FL Epoch: 423 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :178
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.346466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 178 is 0.734057
INFO:root:FL Epoch: 423 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1346
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486795
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463067
INFO:root:FL Epoch: 423 Norm Difference for worker 1346 is 0.761579
INFO:root:FL Epoch: 423 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1406
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452514
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429073
INFO:root:FL Epoch: 423 Norm Difference for worker 1406 is 0.761704
INFO:root:FL Epoch: 423 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 178
INFO:root:Norm of Aggregated Model: 5154.97412109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.4770110494950238 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.25919823348522186                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [1005, 998, 1599, 1223, 719, 279, 1149, 66, 805, 1920]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :1005
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503715
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352743
INFO:root:FL Epoch: 424 Norm Difference for worker 1005 is 0.730849
INFO:root:FL Epoch: 424 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :998
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443988
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678033
INFO:root:FL Epoch: 424 Norm Difference for worker 998 is 0.715813
INFO:root:FL Epoch: 424 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1599
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531726
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394645
INFO:root:FL Epoch: 424 Norm Difference for worker 1599 is 0.747297
INFO:root:FL Epoch: 424 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1223
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327851
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434531
INFO:root:FL Epoch: 424 Norm Difference for worker 1223 is 0.837039
INFO:root:FL Epoch: 424 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :719
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479700
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475310
INFO:root:FL Epoch: 424 Norm Difference for worker 719 is 0.764112
INFO:root:FL Epoch: 424 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :279
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 279 is 0.677718
INFO:root:FL Epoch: 424 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1149
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608544
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477196
INFO:root:FL Epoch: 424 Norm Difference for worker 1149 is 0.791407
INFO:root:FL Epoch: 424 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :66
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350642
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 66 is 0.768094
INFO:root:FL Epoch: 424 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :805
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727871
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373188
INFO:root:FL Epoch: 424 Norm Difference for worker 805 is 0.751565
INFO:root:FL Epoch: 424 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1920
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562278
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435087
INFO:root:FL Epoch: 424 Norm Difference for worker 1920 is 0.735047
INFO:root:FL Epoch: 424 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 279
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.4726566672325134 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.2887638211250305                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [125, 315, 593, 250, 1008, 1364, 824, 487, 695, 198]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 425 Num points on workers: [201 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :125
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 125 is 0.772505
INFO:root:FL Epoch: 425 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :315
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644959
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 315 is 0.779213
INFO:root:FL Epoch: 425 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :593
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699726
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515272
INFO:root:FL Epoch: 425 Norm Difference for worker 593 is 0.777154
INFO:root:FL Epoch: 425 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :250
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692014
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 250 is 0.778658
INFO:root:FL Epoch: 425 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1008
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574216
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442751
INFO:root:FL Epoch: 425 Norm Difference for worker 1008 is 0.742112
INFO:root:FL Epoch: 425 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1364
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502330
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543447
INFO:root:FL Epoch: 425 Norm Difference for worker 1364 is 0.772655
INFO:root:FL Epoch: 425 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :824
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525904
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490817
INFO:root:FL Epoch: 425 Norm Difference for worker 824 is 0.74369
INFO:root:FL Epoch: 425 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :487
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529387
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500090
INFO:root:FL Epoch: 425 Norm Difference for worker 487 is 0.675493
INFO:root:FL Epoch: 425 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :695
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496061
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504207
INFO:root:FL Epoch: 425 Norm Difference for worker 695 is 0.743141
INFO:root:FL Epoch: 425 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :198
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611209
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364181
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 198 is 0.738394
INFO:root:FL Epoch: 425 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.48651709363741036 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.33386387676000595                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [1053, 684, 410, 840, 477, 530, 660, 1267, 513, 296]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 426 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :1053
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471211
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330045
INFO:root:FL Epoch: 426 Norm Difference for worker 1053 is 0.733109
INFO:root:FL Epoch: 426 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :684
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353434
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643113
INFO:root:FL Epoch: 426 Norm Difference for worker 684 is 0.776747
INFO:root:FL Epoch: 426 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :410
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498357
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641901
INFO:root:FL Epoch: 426 Norm Difference for worker 410 is 0.806287
INFO:root:FL Epoch: 426 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :840
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651831
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475488
INFO:root:FL Epoch: 426 Norm Difference for worker 840 is 0.794671
INFO:root:FL Epoch: 426 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :477
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408525
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512496
INFO:root:FL Epoch: 426 Norm Difference for worker 477 is 0.780436
INFO:root:FL Epoch: 426 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :530
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696198
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408166
INFO:root:FL Epoch: 426 Norm Difference for worker 530 is 0.955892
INFO:root:FL Epoch: 426 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :660
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481486
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408374
INFO:root:FL Epoch: 426 Norm Difference for worker 660 is 0.765404
INFO:root:FL Epoch: 426 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1267
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427744
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308946
INFO:root:FL Epoch: 426 Norm Difference for worker 1267 is 0.850975
INFO:root:FL Epoch: 426 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :513
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543547
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473918
INFO:root:FL Epoch: 426 Norm Difference for worker 513 is 0.866749
INFO:root:FL Epoch: 426 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :296
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 296 is 0.828199
INFO:root:FL Epoch: 426 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1053
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.48978793445755453 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.2913723637660344                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [358, 1702, 890, 850, 371, 1285, 1450, 49, 1623, 1502]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :358
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484183
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312029
INFO:root:FL Epoch: 427 Norm Difference for worker 358 is 0.735389
INFO:root:FL Epoch: 427 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1702
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313635
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282145
INFO:root:FL Epoch: 427 Norm Difference for worker 1702 is 0.825547
INFO:root:FL Epoch: 427 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :890
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547097
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453294
INFO:root:FL Epoch: 427 Norm Difference for worker 890 is 0.871428
INFO:root:FL Epoch: 427 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :850
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465241
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534831
INFO:root:FL Epoch: 427 Norm Difference for worker 850 is 0.796278
INFO:root:FL Epoch: 427 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :371
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419701
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387584
INFO:root:FL Epoch: 427 Norm Difference for worker 371 is 0.774181
INFO:root:FL Epoch: 427 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1285
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496311
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435227
INFO:root:FL Epoch: 427 Norm Difference for worker 1285 is 0.788913
INFO:root:FL Epoch: 427 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1450
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382603
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459527
INFO:root:FL Epoch: 427 Norm Difference for worker 1450 is 0.794325
INFO:root:FL Epoch: 427 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :49
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376409
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 49 is 0.837667
INFO:root:FL Epoch: 427 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1623
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467871
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388403
INFO:root:FL Epoch: 427 Norm Difference for worker 1623 is 0.820692
INFO:root:FL Epoch: 427 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1502
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654218
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569474
INFO:root:FL Epoch: 427 Norm Difference for worker 1502 is 0.775409
INFO:root:FL Epoch: 427 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 358
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.48207609443103566 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.252838355799516                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [1496, 1175, 188, 1530, 250, 1880, 417, 73, 781, 931]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 428 Num points on workers: [200 200 201 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :1496
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462240
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219040
INFO:root:FL Epoch: 428 Norm Difference for worker 1496 is 0.78296
INFO:root:FL Epoch: 428 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1175
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360371
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255661
INFO:root:FL Epoch: 428 Norm Difference for worker 1175 is 0.839868
INFO:root:FL Epoch: 428 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :188
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 188 is 0.844945
INFO:root:FL Epoch: 428 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1530
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518672
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202645
INFO:root:FL Epoch: 428 Norm Difference for worker 1530 is 0.938377
INFO:root:FL Epoch: 428 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :250
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.759481
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 250 is 0.979712
INFO:root:FL Epoch: 428 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1880
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534751
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552775
INFO:root:FL Epoch: 428 Norm Difference for worker 1880 is 0.848307
INFO:root:FL Epoch: 428 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :417
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505653
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544246
INFO:root:FL Epoch: 428 Norm Difference for worker 417 is 0.984625
INFO:root:FL Epoch: 428 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :73
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687636
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 73 is 0.888787
INFO:root:FL Epoch: 428 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :781
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.976701
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498700
INFO:root:FL Epoch: 428 Norm Difference for worker 781 is 0.889851
INFO:root:FL Epoch: 428 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :931
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749121
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700706
INFO:root:FL Epoch: 428 Norm Difference for worker 931 is 0.869274
INFO:root:FL Epoch: 428 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1496
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.49305807492312265 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.3042241260409355                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [573, 1218, 1481, 1222, 962, 866, 753, 639, 467, 1324]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :573
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321048
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424627
INFO:root:FL Epoch: 429 Norm Difference for worker 573 is 0.749352
INFO:root:FL Epoch: 429 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1218
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517233
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346610
INFO:root:FL Epoch: 429 Norm Difference for worker 1218 is 0.764431
INFO:root:FL Epoch: 429 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1481
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552343
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.831526
INFO:root:FL Epoch: 429 Norm Difference for worker 1481 is 0.849948
INFO:root:FL Epoch: 429 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1222
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304801
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469924
INFO:root:FL Epoch: 429 Norm Difference for worker 1222 is 0.815468
INFO:root:FL Epoch: 429 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :962
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761419
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473430
INFO:root:FL Epoch: 429 Norm Difference for worker 962 is 0.800327
INFO:root:FL Epoch: 429 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :866
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536457
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648180
INFO:root:FL Epoch: 429 Norm Difference for worker 866 is 0.84917
INFO:root:FL Epoch: 429 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :753
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579525
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498427
INFO:root:FL Epoch: 429 Norm Difference for worker 753 is 0.784019
INFO:root:FL Epoch: 429 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :639
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485553
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473302
INFO:root:FL Epoch: 429 Norm Difference for worker 639 is 0.743769
INFO:root:FL Epoch: 429 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :467
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446487
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473439
INFO:root:FL Epoch: 429 Norm Difference for worker 467 is 0.746276
INFO:root:FL Epoch: 429 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1324
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515916
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586586
INFO:root:FL Epoch: 429 Norm Difference for worker 1324 is 0.829492
INFO:root:FL Epoch: 429 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.47759054688846364 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.27617532511552173                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [510, 1930, 1874, 1305, 567, 1866, 16, 1329, 1868, 483]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 430 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :510
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474563
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528922
INFO:root:FL Epoch: 430 Norm Difference for worker 510 is 0.729274
INFO:root:FL Epoch: 430 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1930
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556729
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458629
INFO:root:FL Epoch: 430 Norm Difference for worker 1930 is 0.837109
INFO:root:FL Epoch: 430 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1874
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413381
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459074
INFO:root:FL Epoch: 430 Norm Difference for worker 1874 is 0.713096
INFO:root:FL Epoch: 430 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1305
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577445
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451800
INFO:root:FL Epoch: 430 Norm Difference for worker 1305 is 0.760755
INFO:root:FL Epoch: 430 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :567
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622756
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467549
INFO:root:FL Epoch: 430 Norm Difference for worker 567 is 0.668476
INFO:root:FL Epoch: 430 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1866
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337494
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403346
INFO:root:FL Epoch: 430 Norm Difference for worker 1866 is 0.794218
INFO:root:FL Epoch: 430 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :16
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 16 is 0.76848
INFO:root:FL Epoch: 430 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1329
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650260
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376037
INFO:root:FL Epoch: 430 Norm Difference for worker 1329 is 0.684932
INFO:root:FL Epoch: 430 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1868
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601847
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504682
INFO:root:FL Epoch: 430 Norm Difference for worker 1868 is 0.749855
INFO:root:FL Epoch: 430 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :483
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550476
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261612
INFO:root:FL Epoch: 430 Norm Difference for worker 483 is 0.674079
INFO:root:FL Epoch: 430 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 483
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.48898501255932975 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.22436531633138657                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 1386, 1380, 347, 1315, 1866, 1628, 201]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.128556
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115343
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.197194284449021 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.16303959414362906 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.118491
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.145005
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188805
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.19031585504611334 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.16355858370661736 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.116616
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.179054
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171035
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.19291144361098608 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.16037611290812492 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.129007
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1386
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440467
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396379
INFO:root:FL Epoch: 431 Norm Difference for worker 1386 is 0.89965
INFO:root:FL Epoch: 431 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1380
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554507
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681010
INFO:root:FL Epoch: 431 Norm Difference for worker 1380 is 0.888356
INFO:root:FL Epoch: 431 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :347
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567443
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393368
INFO:root:FL Epoch: 431 Norm Difference for worker 347 is 0.940075
INFO:root:FL Epoch: 431 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1315
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264324
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445958
INFO:root:FL Epoch: 431 Norm Difference for worker 1315 is 0.849928
INFO:root:FL Epoch: 431 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1866
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263113
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315704
INFO:root:FL Epoch: 431 Norm Difference for worker 1866 is 0.892226
INFO:root:FL Epoch: 431 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1628
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432950
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359810
INFO:root:FL Epoch: 431 Norm Difference for worker 1628 is 0.938053
INFO:root:FL Epoch: 431 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :201
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 201 is 0.965582
INFO:root:FL Epoch: 431 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.4961655806092655 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.197194284449021                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1163, 172, 1453, 1739, 840, 1608, 371, 1040, 702, 1686]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 432 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1163
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305303
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551324
INFO:root:FL Epoch: 432 Norm Difference for worker 1163 is 0.967017
INFO:root:FL Epoch: 432 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :172
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.872487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471750
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 172 is 0.849586
INFO:root:FL Epoch: 432 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1453
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655139
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383757
INFO:root:FL Epoch: 432 Norm Difference for worker 1453 is 0.89024
INFO:root:FL Epoch: 432 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1739
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587701
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428611
INFO:root:FL Epoch: 432 Norm Difference for worker 1739 is 0.886272
INFO:root:FL Epoch: 432 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :840
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394823
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396481
INFO:root:FL Epoch: 432 Norm Difference for worker 840 is 0.911234
INFO:root:FL Epoch: 432 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1608
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741078
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412692
INFO:root:FL Epoch: 432 Norm Difference for worker 1608 is 0.951956
INFO:root:FL Epoch: 432 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :371
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813385
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421050
INFO:root:FL Epoch: 432 Norm Difference for worker 371 is 0.938051
INFO:root:FL Epoch: 432 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1040
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442362
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381241
INFO:root:FL Epoch: 432 Norm Difference for worker 1040 is 0.948924
INFO:root:FL Epoch: 432 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :702
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345048
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256205
INFO:root:FL Epoch: 432 Norm Difference for worker 702 is 0.882853
INFO:root:FL Epoch: 432 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1686
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420290
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397336
INFO:root:FL Epoch: 432 Norm Difference for worker 1686 is 0.860681
INFO:root:FL Epoch: 432 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 172
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.4818543651524712 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.2373552272717158                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [936, 1529, 428, 1022, 1797, 133, 96, 1201, 1407, 422]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :936
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383901
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421853
INFO:root:FL Epoch: 433 Norm Difference for worker 936 is 0.880817
INFO:root:FL Epoch: 433 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1529
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810702
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300976
INFO:root:FL Epoch: 433 Norm Difference for worker 1529 is 0.836255
INFO:root:FL Epoch: 433 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :428
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473167
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355099
INFO:root:FL Epoch: 433 Norm Difference for worker 428 is 0.777269
INFO:root:FL Epoch: 433 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1022
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294842
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456195
INFO:root:FL Epoch: 433 Norm Difference for worker 1022 is 0.718061
INFO:root:FL Epoch: 433 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1797
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.240910
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376053
INFO:root:FL Epoch: 433 Norm Difference for worker 1797 is 0.851795
INFO:root:FL Epoch: 433 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :133
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350497
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 133 is 0.779984
INFO:root:FL Epoch: 433 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :96
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587928
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 96 is 0.90413
INFO:root:FL Epoch: 433 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1201
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597619
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419877
INFO:root:FL Epoch: 433 Norm Difference for worker 1201 is 0.800918
INFO:root:FL Epoch: 433 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1407
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454141
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499847
INFO:root:FL Epoch: 433 Norm Difference for worker 1407 is 0.817554
INFO:root:FL Epoch: 433 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :422
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677006
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486753
INFO:root:FL Epoch: 433 Norm Difference for worker 422 is 0.779108
INFO:root:FL Epoch: 433 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.48996348153142366 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.24999230851729712                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1767, 1620, 569, 55, 953, 253, 598, 295, 1199, 545]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1767
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469554
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384224
INFO:root:FL Epoch: 434 Norm Difference for worker 1767 is 0.803319
INFO:root:FL Epoch: 434 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1620
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312581
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416833
INFO:root:FL Epoch: 434 Norm Difference for worker 1620 is 0.805167
INFO:root:FL Epoch: 434 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :569
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395972
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502629
INFO:root:FL Epoch: 434 Norm Difference for worker 569 is 0.853279
INFO:root:FL Epoch: 434 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :55
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 55 is 0.818412
INFO:root:FL Epoch: 434 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :953
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458460
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417505
INFO:root:FL Epoch: 434 Norm Difference for worker 953 is 0.837579
INFO:root:FL Epoch: 434 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :253
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.360847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 253 is 0.839085
INFO:root:FL Epoch: 434 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :598
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571485
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605169
INFO:root:FL Epoch: 434 Norm Difference for worker 598 is 0.924494
INFO:root:FL Epoch: 434 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :295
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 295 is 0.946359
INFO:root:FL Epoch: 434 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1199
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505774
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562472
INFO:root:FL Epoch: 434 Norm Difference for worker 1199 is 0.87676
INFO:root:FL Epoch: 434 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :545
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382402
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331091
INFO:root:FL Epoch: 434 Norm Difference for worker 545 is 0.854288
INFO:root:FL Epoch: 434 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1767
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.4957978234571569 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.24554648995399475                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [444, 1452, 461, 140, 1000, 1210, 747, 33, 1773, 375]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :444
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515932
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326769
INFO:root:FL Epoch: 435 Norm Difference for worker 444 is 0.766343
INFO:root:FL Epoch: 435 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1452
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653592
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327909
INFO:root:FL Epoch: 435 Norm Difference for worker 1452 is 0.792146
INFO:root:FL Epoch: 435 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :461
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575294
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330565
INFO:root:FL Epoch: 435 Norm Difference for worker 461 is 0.76172
INFO:root:FL Epoch: 435 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :140
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.769368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 140 is 0.814819
INFO:root:FL Epoch: 435 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1000
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598478
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440864
INFO:root:FL Epoch: 435 Norm Difference for worker 1000 is 0.769062
INFO:root:FL Epoch: 435 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1210
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391139
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568631
INFO:root:FL Epoch: 435 Norm Difference for worker 1210 is 0.807321
INFO:root:FL Epoch: 435 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :747
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308372
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452424
INFO:root:FL Epoch: 435 Norm Difference for worker 747 is 0.830695
INFO:root:FL Epoch: 435 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :33
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.209060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 33 is 0.850443
INFO:root:FL Epoch: 435 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1773
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854410
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266145
INFO:root:FL Epoch: 435 Norm Difference for worker 1773 is 0.825349
INFO:root:FL Epoch: 435 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :375
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625144
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494989
INFO:root:FL Epoch: 435 Norm Difference for worker 375 is 0.858471
INFO:root:FL Epoch: 435 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 444
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.5013062980245141 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.2838361784815788                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1596, 104, 1138, 367, 1834, 289, 475, 1888, 1798, 51]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 436 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1596
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464448
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585792
INFO:root:FL Epoch: 436 Norm Difference for worker 1596 is 0.75986
INFO:root:FL Epoch: 436 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :104
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 104 is 0.710225
INFO:root:FL Epoch: 436 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1138
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663323
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739383
INFO:root:FL Epoch: 436 Norm Difference for worker 1138 is 0.764657
INFO:root:FL Epoch: 436 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :367
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642706
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615661
INFO:root:FL Epoch: 436 Norm Difference for worker 367 is 0.727906
INFO:root:FL Epoch: 436 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1834
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692102
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381876
INFO:root:FL Epoch: 436 Norm Difference for worker 1834 is 0.73583
INFO:root:FL Epoch: 436 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :289
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552423
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 289 is 0.688819
INFO:root:FL Epoch: 436 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :475
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528859
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555117
INFO:root:FL Epoch: 436 Norm Difference for worker 475 is 0.672026
INFO:root:FL Epoch: 436 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1888
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481784
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474141
INFO:root:FL Epoch: 436 Norm Difference for worker 1888 is 0.749716
INFO:root:FL Epoch: 436 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1798
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683445
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556131
INFO:root:FL Epoch: 436 Norm Difference for worker 1798 is 0.858744
INFO:root:FL Epoch: 436 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :51
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 51 is 0.728715
INFO:root:FL Epoch: 436 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 475
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.49781349827261534 and Test Accuracy:75.0 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.261949102083842                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [945, 15, 304, 957, 1361, 1848, 1090, 284, 1715, 208]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 437 Num points on workers: [200 201 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :945
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484006
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300473
INFO:root:FL Epoch: 437 Norm Difference for worker 945 is 0.663954
INFO:root:FL Epoch: 437 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :15
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 15 is 0.73858
INFO:root:FL Epoch: 437 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :304
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568452
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 304 is 0.73722
INFO:root:FL Epoch: 437 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :957
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639710
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632658
INFO:root:FL Epoch: 437 Norm Difference for worker 957 is 0.782394
INFO:root:FL Epoch: 437 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1361
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512353
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670895
INFO:root:FL Epoch: 437 Norm Difference for worker 1361 is 0.728725
INFO:root:FL Epoch: 437 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1848
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263445
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743242
INFO:root:FL Epoch: 437 Norm Difference for worker 1848 is 0.879172
INFO:root:FL Epoch: 437 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1090
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415453
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341723
INFO:root:FL Epoch: 437 Norm Difference for worker 1090 is 0.706994
INFO:root:FL Epoch: 437 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :284
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.296539
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 284 is 0.785885
INFO:root:FL Epoch: 437 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1715
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417219
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689169
INFO:root:FL Epoch: 437 Norm Difference for worker 1715 is 0.728083
INFO:root:FL Epoch: 437 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :208
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595672
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 208 is 0.734953
INFO:root:FL Epoch: 437 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1715
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.5037598224247203 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.26216014722983044                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [421, 1169, 907, 1176, 1511, 288, 1524, 1826, 1157, 919]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :421
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428481
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522542
INFO:root:FL Epoch: 438 Norm Difference for worker 421 is 0.59972
INFO:root:FL Epoch: 438 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1169
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586065
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450766
INFO:root:FL Epoch: 438 Norm Difference for worker 1169 is 0.656546
INFO:root:FL Epoch: 438 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :907
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563578
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490926
INFO:root:FL Epoch: 438 Norm Difference for worker 907 is 0.629819
INFO:root:FL Epoch: 438 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1176
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606404
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721110
INFO:root:FL Epoch: 438 Norm Difference for worker 1176 is 0.624327
INFO:root:FL Epoch: 438 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1511
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630578
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492490
INFO:root:FL Epoch: 438 Norm Difference for worker 1511 is 0.649246
INFO:root:FL Epoch: 438 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :288
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630022
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 288 is 0.674736
INFO:root:FL Epoch: 438 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1524
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.906590
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456438
INFO:root:FL Epoch: 438 Norm Difference for worker 1524 is 0.656798
INFO:root:FL Epoch: 438 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1826
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409324
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345380
INFO:root:FL Epoch: 438 Norm Difference for worker 1826 is 0.629219
INFO:root:FL Epoch: 438 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1157
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439544
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477980
INFO:root:FL Epoch: 438 Norm Difference for worker 1157 is 0.610288
INFO:root:FL Epoch: 438 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :919
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684910
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401982
INFO:root:FL Epoch: 438 Norm Difference for worker 919 is 0.666233
INFO:root:FL Epoch: 438 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1176
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.5200438727350796 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.367668092250824                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1124, 583, 333, 158, 126, 459, 786, 991, 1294, 367]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1124
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430576
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555803
INFO:root:FL Epoch: 439 Norm Difference for worker 1124 is 0.612499
INFO:root:FL Epoch: 439 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :583
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554660
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509422
INFO:root:FL Epoch: 439 Norm Difference for worker 583 is 0.686093
INFO:root:FL Epoch: 439 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :333
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777555
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 333 is 0.586092
INFO:root:FL Epoch: 439 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :158
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 158 is 0.592746
INFO:root:FL Epoch: 439 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :126
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428829
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.788799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 126 is 0.613654
INFO:root:FL Epoch: 439 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :459
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405845
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463658
INFO:root:FL Epoch: 439 Norm Difference for worker 459 is 0.623795
INFO:root:FL Epoch: 439 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :786
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435437
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660409
INFO:root:FL Epoch: 439 Norm Difference for worker 786 is 0.751112
INFO:root:FL Epoch: 439 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :991
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712864
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542930
INFO:root:FL Epoch: 439 Norm Difference for worker 991 is 0.677625
INFO:root:FL Epoch: 439 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1294
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807299
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466210
INFO:root:FL Epoch: 439 Norm Difference for worker 1294 is 0.679297
INFO:root:FL Epoch: 439 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :367
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455098
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538742
INFO:root:FL Epoch: 439 Norm Difference for worker 367 is 0.628767
INFO:root:FL Epoch: 439 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 158
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.5163271935547099 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.3210209980607033                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1829, 1217, 584, 1479, 451, 1313, 1673, 401, 885, 1525]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1829
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603575
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558869
INFO:root:FL Epoch: 440 Norm Difference for worker 1829 is 0.705383
INFO:root:FL Epoch: 440 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1217
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682223
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518668
INFO:root:FL Epoch: 440 Norm Difference for worker 1217 is 0.941373
INFO:root:FL Epoch: 440 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :584
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503586
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531854
INFO:root:FL Epoch: 440 Norm Difference for worker 584 is 0.668338
INFO:root:FL Epoch: 440 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1479
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632419
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473286
INFO:root:FL Epoch: 440 Norm Difference for worker 1479 is 0.605589
INFO:root:FL Epoch: 440 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :451
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445904
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511213
INFO:root:FL Epoch: 440 Norm Difference for worker 451 is 0.668212
INFO:root:FL Epoch: 440 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1313
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486915
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528881
INFO:root:FL Epoch: 440 Norm Difference for worker 1313 is 0.700757
INFO:root:FL Epoch: 440 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1673
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.994779
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438638
INFO:root:FL Epoch: 440 Norm Difference for worker 1673 is 0.630701
INFO:root:FL Epoch: 440 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :401
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654646
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716144
INFO:root:FL Epoch: 440 Norm Difference for worker 401 is 0.683762
INFO:root:FL Epoch: 440 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :885
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602029
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622962
INFO:root:FL Epoch: 440 Norm Difference for worker 885 is 0.661565
INFO:root:FL Epoch: 440 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1525
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506853
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399393
INFO:root:FL Epoch: 440 Norm Difference for worker 1525 is 0.640034
INFO:root:FL Epoch: 440 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1673
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.498595853062237 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.3048601547876994                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 1644, 1050, 1137, 72, 1710, 325, 74]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221920
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278734
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.24067153533299765 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.20893137007951737 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.15905
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235550
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246377
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.23417318612337112 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.20666630417108536 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.166946
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237022
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271537
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.24061198780934015 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.20976638793945312 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.156136
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1644
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396337
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494607
INFO:root:FL Epoch: 441 Norm Difference for worker 1644 is 0.606155
INFO:root:FL Epoch: 441 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1050
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603063
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451363
INFO:root:FL Epoch: 441 Norm Difference for worker 1050 is 0.658957
INFO:root:FL Epoch: 441 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1137
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503460
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496720
INFO:root:FL Epoch: 441 Norm Difference for worker 1137 is 0.676261
INFO:root:FL Epoch: 441 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :72
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 72 is 0.673926
INFO:root:FL Epoch: 441 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1710
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656469
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511789
INFO:root:FL Epoch: 441 Norm Difference for worker 1710 is 0.69126
INFO:root:FL Epoch: 441 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :325
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495098
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 325 is 0.697682
INFO:root:FL Epoch: 441 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :74
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 74 is 0.65768
INFO:root:FL Epoch: 441 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.497229442876928 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.23417318612337112                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1904, 830, 1706, 724, 105, 669, 1838, 1426, 1525, 348]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1904
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477493
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529930
INFO:root:FL Epoch: 442 Norm Difference for worker 1904 is 0.732283
INFO:root:FL Epoch: 442 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :830
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389399
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434216
INFO:root:FL Epoch: 442 Norm Difference for worker 830 is 0.702078
INFO:root:FL Epoch: 442 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1706
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795802
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704216
INFO:root:FL Epoch: 442 Norm Difference for worker 1706 is 0.673868
INFO:root:FL Epoch: 442 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :724
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534553
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464822
INFO:root:FL Epoch: 442 Norm Difference for worker 724 is 0.738084
INFO:root:FL Epoch: 442 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :105
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 105 is 0.754587
INFO:root:FL Epoch: 442 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :669
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613318
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400850
INFO:root:FL Epoch: 442 Norm Difference for worker 669 is 0.943197
INFO:root:FL Epoch: 442 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1838
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788395
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594042
INFO:root:FL Epoch: 442 Norm Difference for worker 1838 is 0.696733
INFO:root:FL Epoch: 442 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1426
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803235
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409204
INFO:root:FL Epoch: 442 Norm Difference for worker 1426 is 0.733525
INFO:root:FL Epoch: 442 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1525
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550600
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468423
INFO:root:FL Epoch: 442 Norm Difference for worker 1525 is 0.725255
INFO:root:FL Epoch: 442 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :348
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682039
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486638
INFO:root:FL Epoch: 442 Norm Difference for worker 348 is 0.730206
INFO:root:FL Epoch: 442 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1706
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.4989692095447989 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.2740994269649188                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1577, 779, 512, 235, 243, 191, 1671, 634, 443, 1020]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1577
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748067
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376233
INFO:root:FL Epoch: 443 Norm Difference for worker 1577 is 0.642042
INFO:root:FL Epoch: 443 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :779
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567897
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366964
INFO:root:FL Epoch: 443 Norm Difference for worker 779 is 0.742384
INFO:root:FL Epoch: 443 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :512
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448549
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531477
INFO:root:FL Epoch: 443 Norm Difference for worker 512 is 0.808924
INFO:root:FL Epoch: 443 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :235
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 235 is 0.73112
INFO:root:FL Epoch: 443 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :243
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.366025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 243 is 0.657877
INFO:root:FL Epoch: 443 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :191
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444957
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 191 is 0.700015
INFO:root:FL Epoch: 443 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1671
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536753
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426769
INFO:root:FL Epoch: 443 Norm Difference for worker 1671 is 0.651441
INFO:root:FL Epoch: 443 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :634
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534545
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557667
INFO:root:FL Epoch: 443 Norm Difference for worker 634 is 0.636645
INFO:root:FL Epoch: 443 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :443
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405783
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379286
INFO:root:FL Epoch: 443 Norm Difference for worker 443 is 0.706381
INFO:root:FL Epoch: 443 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1020
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506964
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481837
INFO:root:FL Epoch: 443 Norm Difference for worker 1020 is 0.68301
INFO:root:FL Epoch: 443 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 634
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.5015909198452445 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.28649676591157913                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [563, 1407, 1882, 1071, 1689, 574, 1118, 399, 1608, 1747]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :563
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424138
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497441
INFO:root:FL Epoch: 444 Norm Difference for worker 563 is 0.80782
INFO:root:FL Epoch: 444 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1407
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427616
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366932
INFO:root:FL Epoch: 444 Norm Difference for worker 1407 is 0.696824
INFO:root:FL Epoch: 444 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1882
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503495
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527324
INFO:root:FL Epoch: 444 Norm Difference for worker 1882 is 0.730746
INFO:root:FL Epoch: 444 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1071
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687479
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484662
INFO:root:FL Epoch: 444 Norm Difference for worker 1071 is 0.932117
INFO:root:FL Epoch: 444 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1689
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487827
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523524
INFO:root:FL Epoch: 444 Norm Difference for worker 1689 is 0.769436
INFO:root:FL Epoch: 444 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :574
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430638
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240935
INFO:root:FL Epoch: 444 Norm Difference for worker 574 is 0.7092
INFO:root:FL Epoch: 444 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1118
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448394
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581664
INFO:root:FL Epoch: 444 Norm Difference for worker 1118 is 0.77061
INFO:root:FL Epoch: 444 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :399
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747122
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328323
INFO:root:FL Epoch: 444 Norm Difference for worker 399 is 0.736439
INFO:root:FL Epoch: 444 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1608
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550340
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514664
INFO:root:FL Epoch: 444 Norm Difference for worker 1608 is 0.743446
INFO:root:FL Epoch: 444 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1747
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569844
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392455
INFO:root:FL Epoch: 444 Norm Difference for worker 1747 is 0.756591
INFO:root:FL Epoch: 444 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 574
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.5077258909449858 and Test Accuracy:75.0 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.35450132191181183                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [1111, 1878, 1505, 1084, 1040, 1173, 1446, 805, 871, 453]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 445 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :1111
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459648
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339177
INFO:root:FL Epoch: 445 Norm Difference for worker 1111 is 0.666349
INFO:root:FL Epoch: 445 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1878
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625102
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480918
INFO:root:FL Epoch: 445 Norm Difference for worker 1878 is 0.687271
INFO:root:FL Epoch: 445 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1505
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654954
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672343
INFO:root:FL Epoch: 445 Norm Difference for worker 1505 is 0.725961
INFO:root:FL Epoch: 445 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1084
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493687
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514399
INFO:root:FL Epoch: 445 Norm Difference for worker 1084 is 0.674036
INFO:root:FL Epoch: 445 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1040
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636794
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295744
INFO:root:FL Epoch: 445 Norm Difference for worker 1040 is 0.655085
INFO:root:FL Epoch: 445 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1173
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498955
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465845
INFO:root:FL Epoch: 445 Norm Difference for worker 1173 is 0.677123
INFO:root:FL Epoch: 445 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1446
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501533
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545013
INFO:root:FL Epoch: 445 Norm Difference for worker 1446 is 0.714254
INFO:root:FL Epoch: 445 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :805
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546509
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488502
INFO:root:FL Epoch: 445 Norm Difference for worker 805 is 0.791798
INFO:root:FL Epoch: 445 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :871
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568772
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551826
INFO:root:FL Epoch: 445 Norm Difference for worker 871 is 0.738005
INFO:root:FL Epoch: 445 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :453
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515379
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462639
INFO:root:FL Epoch: 445 Norm Difference for worker 453 is 0.657069
INFO:root:FL Epoch: 445 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 453
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.4904489341904135 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.32538390159606934                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [1056, 1824, 1566, 228, 917, 527, 169, 279, 1402, 1605]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :1056
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489565
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462512
INFO:root:FL Epoch: 446 Norm Difference for worker 1056 is 0.644456
INFO:root:FL Epoch: 446 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1824
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667010
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495734
INFO:root:FL Epoch: 446 Norm Difference for worker 1824 is 0.584081
INFO:root:FL Epoch: 446 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1566
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476611
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432423
INFO:root:FL Epoch: 446 Norm Difference for worker 1566 is 0.632184
INFO:root:FL Epoch: 446 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :228
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563266
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298285
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 228 is 0.614368
INFO:root:FL Epoch: 446 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :917
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577813
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675218
INFO:root:FL Epoch: 446 Norm Difference for worker 917 is 0.605731
INFO:root:FL Epoch: 446 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :527
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508028
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460102
INFO:root:FL Epoch: 446 Norm Difference for worker 527 is 0.656391
INFO:root:FL Epoch: 446 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :169
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483705
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 169 is 0.595659
INFO:root:FL Epoch: 446 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :279
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 279 is 0.552209
INFO:root:FL Epoch: 446 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1402
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463209
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456218
INFO:root:FL Epoch: 446 Norm Difference for worker 1402 is 0.579034
INFO:root:FL Epoch: 446 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1605
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495695
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478092
INFO:root:FL Epoch: 446 Norm Difference for worker 1605 is 0.616813
INFO:root:FL Epoch: 446 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 279
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.4836859475163853 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.2711027090748151                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [4, 146, 1929, 1862, 226, 1490, 914, 1000, 1175, 116]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 447 Num points on workers: [201 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :4
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 4 is 0.761062
INFO:root:FL Epoch: 447 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :146
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 146 is 0.83674
INFO:root:FL Epoch: 447 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1929
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324455
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208552
INFO:root:FL Epoch: 447 Norm Difference for worker 1929 is 0.663393
INFO:root:FL Epoch: 447 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1862
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478788
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737213
INFO:root:FL Epoch: 447 Norm Difference for worker 1862 is 0.75803
INFO:root:FL Epoch: 447 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :226
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 226 is 0.781935
INFO:root:FL Epoch: 447 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1490
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788645
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678191
INFO:root:FL Epoch: 447 Norm Difference for worker 1490 is 0.694509
INFO:root:FL Epoch: 447 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :914
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633237
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622990
INFO:root:FL Epoch: 447 Norm Difference for worker 914 is 0.836353
INFO:root:FL Epoch: 447 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1000
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531176
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478207
INFO:root:FL Epoch: 447 Norm Difference for worker 1000 is 0.750934
INFO:root:FL Epoch: 447 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1175
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676177
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436441
INFO:root:FL Epoch: 447 Norm Difference for worker 1175 is 0.782196
INFO:root:FL Epoch: 447 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :116
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470548
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 116 is 0.872086
INFO:root:FL Epoch: 447 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.5076315262738396 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.22476445138454437                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [949, 1443, 890, 852, 689, 1895, 1574, 607, 277, 950]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :949
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440308
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196262
INFO:root:FL Epoch: 448 Norm Difference for worker 949 is 0.881424
INFO:root:FL Epoch: 448 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1443
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539265
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543595
INFO:root:FL Epoch: 448 Norm Difference for worker 1443 is 0.991741
INFO:root:FL Epoch: 448 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :890
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601131
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444867
INFO:root:FL Epoch: 448 Norm Difference for worker 890 is 0.948053
INFO:root:FL Epoch: 448 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :852
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.203497
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628979
INFO:root:FL Epoch: 448 Norm Difference for worker 852 is 0.892394
INFO:root:FL Epoch: 448 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :689
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664311
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538289
INFO:root:FL Epoch: 448 Norm Difference for worker 689 is 0.902666
INFO:root:FL Epoch: 448 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1895
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412584
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611640
INFO:root:FL Epoch: 448 Norm Difference for worker 1895 is 0.90051
INFO:root:FL Epoch: 448 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1574
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447239
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277749
INFO:root:FL Epoch: 448 Norm Difference for worker 1574 is 0.871356
INFO:root:FL Epoch: 448 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :607
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629886
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465897
INFO:root:FL Epoch: 448 Norm Difference for worker 607 is 0.894009
INFO:root:FL Epoch: 448 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :277
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 277 is 0.86793
INFO:root:FL Epoch: 448 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :950
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485936
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425904
INFO:root:FL Epoch: 448 Norm Difference for worker 950 is 0.888554
INFO:root:FL Epoch: 448 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 277
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.47734281070092144 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.23800903062025705                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [1522, 782, 758, 912, 1379, 1210, 1104, 1023, 1212, 1352]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :1522
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725530
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627722
INFO:root:FL Epoch: 449 Norm Difference for worker 1522 is 0.744175
INFO:root:FL Epoch: 449 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :782
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455259
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538136
INFO:root:FL Epoch: 449 Norm Difference for worker 782 is 0.752028
INFO:root:FL Epoch: 449 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :758
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404587
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512764
INFO:root:FL Epoch: 449 Norm Difference for worker 758 is 0.741506
INFO:root:FL Epoch: 449 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :912
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694362
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417995
INFO:root:FL Epoch: 449 Norm Difference for worker 912 is 0.757324
INFO:root:FL Epoch: 449 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1379
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363503
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483841
INFO:root:FL Epoch: 449 Norm Difference for worker 1379 is 0.715523
INFO:root:FL Epoch: 449 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1210
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568290
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635953
INFO:root:FL Epoch: 449 Norm Difference for worker 1210 is 0.773189
INFO:root:FL Epoch: 449 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1104
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330895
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424870
INFO:root:FL Epoch: 449 Norm Difference for worker 1104 is 0.745074
INFO:root:FL Epoch: 449 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1023
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488773
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430489
INFO:root:FL Epoch: 449 Norm Difference for worker 1023 is 0.689188
INFO:root:FL Epoch: 449 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1212
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367023
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430793
INFO:root:FL Epoch: 449 Norm Difference for worker 1212 is 0.673478
INFO:root:FL Epoch: 449 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1352
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577231
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528891
INFO:root:FL Epoch: 449 Norm Difference for worker 1352 is 0.792152
INFO:root:FL Epoch: 449 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.4685298730345333 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.29254088302453357                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [389, 411, 375, 1747, 319, 522, 1311, 1796, 76, 1590]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :389
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467472
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508769
INFO:root:FL Epoch: 450 Norm Difference for worker 389 is 0.669697
INFO:root:FL Epoch: 450 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :411
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711729
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443461
INFO:root:FL Epoch: 450 Norm Difference for worker 411 is 0.703573
INFO:root:FL Epoch: 450 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :375
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619405
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420123
INFO:root:FL Epoch: 450 Norm Difference for worker 375 is 0.746719
INFO:root:FL Epoch: 450 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1747
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517757
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650805
INFO:root:FL Epoch: 450 Norm Difference for worker 1747 is 0.685861
INFO:root:FL Epoch: 450 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :319
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 319 is 0.684581
INFO:root:FL Epoch: 450 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :522
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627650
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704358
INFO:root:FL Epoch: 450 Norm Difference for worker 522 is 0.637569
INFO:root:FL Epoch: 450 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1311
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490822
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430930
INFO:root:FL Epoch: 450 Norm Difference for worker 1311 is 0.698253
INFO:root:FL Epoch: 450 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1796
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576462
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488333
INFO:root:FL Epoch: 450 Norm Difference for worker 1796 is 0.683185
INFO:root:FL Epoch: 450 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :76
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 76 is 0.690786
INFO:root:FL Epoch: 450 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1590
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561969
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468459
INFO:root:FL Epoch: 450 Norm Difference for worker 1590 is 0.731836
INFO:root:FL Epoch: 450 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 522
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.46333162223591523 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.2814209635059039                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 1108, 1097, 1433, 1247, 1404, 1313, 684]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278172
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251512
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.24177018056313196 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.2175736352801323 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.151165
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219796
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312092
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.23749922464291254 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.21628197580575942 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.154088
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257135
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344456
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.24408604204654694 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.2180193156003952 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.15071
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1108
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574099
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565643
INFO:root:FL Epoch: 451 Norm Difference for worker 1108 is 0.654227
INFO:root:FL Epoch: 451 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1097
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446355
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699454
INFO:root:FL Epoch: 451 Norm Difference for worker 1097 is 0.633634
INFO:root:FL Epoch: 451 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1433
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444028
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437768
INFO:root:FL Epoch: 451 Norm Difference for worker 1433 is 0.668414
INFO:root:FL Epoch: 451 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1247
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391621
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492528
INFO:root:FL Epoch: 451 Norm Difference for worker 1247 is 0.636272
INFO:root:FL Epoch: 451 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1404
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483887
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576986
INFO:root:FL Epoch: 451 Norm Difference for worker 1404 is 0.603661
INFO:root:FL Epoch: 451 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1313
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439469
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400528
INFO:root:FL Epoch: 451 Norm Difference for worker 1313 is 0.685943
INFO:root:FL Epoch: 451 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :684
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486525
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367225
INFO:root:FL Epoch: 451 Norm Difference for worker 684 is 0.614099
INFO:root:FL Epoch: 451 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.45959948266253753 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.24177018056313196                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1459, 1133, 1333, 1274, 6, 1294, 853, 1204, 312, 111]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1459
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823671
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620613
INFO:root:FL Epoch: 452 Norm Difference for worker 1459 is 0.736208
INFO:root:FL Epoch: 452 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1133
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631371
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340021
INFO:root:FL Epoch: 452 Norm Difference for worker 1133 is 0.787653
INFO:root:FL Epoch: 452 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1333
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754936
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494890
INFO:root:FL Epoch: 452 Norm Difference for worker 1333 is 0.716045
INFO:root:FL Epoch: 452 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1274
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727302
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551705
INFO:root:FL Epoch: 452 Norm Difference for worker 1274 is 0.685483
INFO:root:FL Epoch: 452 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :6
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 6 is 0.664587
INFO:root:FL Epoch: 452 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1294
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498897
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503874
INFO:root:FL Epoch: 452 Norm Difference for worker 1294 is 0.691119
INFO:root:FL Epoch: 452 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :853
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412540
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371288
INFO:root:FL Epoch: 452 Norm Difference for worker 853 is 0.705243
INFO:root:FL Epoch: 452 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1204
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616603
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495327
INFO:root:FL Epoch: 452 Norm Difference for worker 1204 is 0.704351
INFO:root:FL Epoch: 452 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :312
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 312 is 0.696347
INFO:root:FL Epoch: 452 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :111
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 111 is 0.754251
INFO:root:FL Epoch: 452 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1274
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.4700346711803885 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.2758528267343839                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1448, 287, 1140, 793, 1896, 421, 213, 1873, 1936, 764]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 453 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1448
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626809
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480588
INFO:root:FL Epoch: 453 Norm Difference for worker 1448 is 0.639214
INFO:root:FL Epoch: 453 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :287
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 287 is 0.605278
INFO:root:FL Epoch: 453 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1140
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467152
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344982
INFO:root:FL Epoch: 453 Norm Difference for worker 1140 is 0.637244
INFO:root:FL Epoch: 453 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :793
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584843
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423405
INFO:root:FL Epoch: 453 Norm Difference for worker 793 is 0.636193
INFO:root:FL Epoch: 453 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1896
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682098
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441213
INFO:root:FL Epoch: 453 Norm Difference for worker 1896 is 0.608911
INFO:root:FL Epoch: 453 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :421
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448895
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410271
INFO:root:FL Epoch: 453 Norm Difference for worker 421 is 0.641079
INFO:root:FL Epoch: 453 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :213
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 213 is 0.65476
INFO:root:FL Epoch: 453 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1873
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504321
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434159
INFO:root:FL Epoch: 453 Norm Difference for worker 1873 is 0.66458
INFO:root:FL Epoch: 453 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1936
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754036
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358107
INFO:root:FL Epoch: 453 Norm Difference for worker 1936 is 0.610896
INFO:root:FL Epoch: 453 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :764
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616519
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494834
INFO:root:FL Epoch: 453 Norm Difference for worker 764 is 0.642212
INFO:root:FL Epoch: 453 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 287
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.49161478526452007 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.3910522361596425                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [20, 53, 1915, 859, 1637, 1037, 375, 528, 1448, 1070]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 454 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :20
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 20 is 0.651862
INFO:root:FL Epoch: 454 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :53
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 53 is 0.682975
INFO:root:FL Epoch: 454 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1915
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615157
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587446
INFO:root:FL Epoch: 454 Norm Difference for worker 1915 is 0.74104
INFO:root:FL Epoch: 454 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :859
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505812
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448842
INFO:root:FL Epoch: 454 Norm Difference for worker 859 is 0.634541
INFO:root:FL Epoch: 454 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1637
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795828
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307401
INFO:root:FL Epoch: 454 Norm Difference for worker 1637 is 0.677104
INFO:root:FL Epoch: 454 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1037
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.914507
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585188
INFO:root:FL Epoch: 454 Norm Difference for worker 1037 is 0.719769
INFO:root:FL Epoch: 454 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :375
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384641
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536752
INFO:root:FL Epoch: 454 Norm Difference for worker 375 is 0.619623
INFO:root:FL Epoch: 454 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :528
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882970
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587824
INFO:root:FL Epoch: 454 Norm Difference for worker 528 is 0.75574
INFO:root:FL Epoch: 454 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1448
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725812
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706422
INFO:root:FL Epoch: 454 Norm Difference for worker 1448 is 0.675396
INFO:root:FL Epoch: 454 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1070
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568339
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419578
INFO:root:FL Epoch: 454 Norm Difference for worker 1070 is 0.698243
INFO:root:FL Epoch: 454 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.4649385178790373 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.1948258951306343                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [248, 1827, 377, 1118, 1287, 306, 1415, 336, 1237, 1124]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 455 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :248
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 248 is 0.704972
INFO:root:FL Epoch: 455 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1827
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548271
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723226
INFO:root:FL Epoch: 455 Norm Difference for worker 1827 is 0.675491
INFO:root:FL Epoch: 455 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :377
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735164
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703023
INFO:root:FL Epoch: 455 Norm Difference for worker 377 is 0.684569
INFO:root:FL Epoch: 455 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1118
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469244
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346553
INFO:root:FL Epoch: 455 Norm Difference for worker 1118 is 0.720396
INFO:root:FL Epoch: 455 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1287
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465929
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454796
INFO:root:FL Epoch: 455 Norm Difference for worker 1287 is 0.71867
INFO:root:FL Epoch: 455 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :306
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242305
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 306 is 0.699424
INFO:root:FL Epoch: 455 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1415
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457280
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630375
INFO:root:FL Epoch: 455 Norm Difference for worker 1415 is 0.724053
INFO:root:FL Epoch: 455 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :336
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491820
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 336 is 0.69491
INFO:root:FL Epoch: 455 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1237
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520522
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610810
INFO:root:FL Epoch: 455 Norm Difference for worker 1237 is 0.703928
INFO:root:FL Epoch: 455 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1124
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530681
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571441
INFO:root:FL Epoch: 455 Norm Difference for worker 1124 is 0.75039
INFO:root:FL Epoch: 455 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1827
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.47014299210380106 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.32483215630054474                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1208, 847, 1418, 97, 558, 674, 1098, 1624, 983, 1079]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1208
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384035
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355645
INFO:root:FL Epoch: 456 Norm Difference for worker 1208 is 0.609763
INFO:root:FL Epoch: 456 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :847
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712618
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441641
INFO:root:FL Epoch: 456 Norm Difference for worker 847 is 0.605784
INFO:root:FL Epoch: 456 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1418
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579115
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354502
INFO:root:FL Epoch: 456 Norm Difference for worker 1418 is 0.61472
INFO:root:FL Epoch: 456 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :97
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 97 is 0.682997
INFO:root:FL Epoch: 456 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :558
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613843
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700313
INFO:root:FL Epoch: 456 Norm Difference for worker 558 is 0.649289
INFO:root:FL Epoch: 456 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :674
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638520
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353968
INFO:root:FL Epoch: 456 Norm Difference for worker 674 is 0.651295
INFO:root:FL Epoch: 456 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1098
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445120
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446127
INFO:root:FL Epoch: 456 Norm Difference for worker 1098 is 0.636767
INFO:root:FL Epoch: 456 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1624
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390319
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509984
INFO:root:FL Epoch: 456 Norm Difference for worker 1624 is 0.66243
INFO:root:FL Epoch: 456 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :983
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629200
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491372
INFO:root:FL Epoch: 456 Norm Difference for worker 983 is 0.677993
INFO:root:FL Epoch: 456 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1079
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541512
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496003
INFO:root:FL Epoch: 456 Norm Difference for worker 1079 is 0.676131
INFO:root:FL Epoch: 456 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1208
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.4835314698079053 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.342207873860995                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [301, 892, 1357, 946, 1812, 217, 198, 160, 97, 78]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.0997009 0.1001994 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 457 Num points on workers: [201 200 200 200 200 201 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :301
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 301 is 0.718351
INFO:root:FL Epoch: 457 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :892
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737588
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450238
INFO:root:FL Epoch: 457 Norm Difference for worker 892 is 0.679951
INFO:root:FL Epoch: 457 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1357
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360360
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344539
INFO:root:FL Epoch: 457 Norm Difference for worker 1357 is 0.684369
INFO:root:FL Epoch: 457 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :946
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637760
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372170
INFO:root:FL Epoch: 457 Norm Difference for worker 946 is 0.737445
INFO:root:FL Epoch: 457 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1812
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510576
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412248
INFO:root:FL Epoch: 457 Norm Difference for worker 1812 is 0.742694
INFO:root:FL Epoch: 457 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :217
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 217 is 0.71783
INFO:root:FL Epoch: 457 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :198
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 198 is 0.75274
INFO:root:FL Epoch: 457 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :160
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 160 is 0.697702
INFO:root:FL Epoch: 457 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :97
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741090
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286048
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 97 is 0.697111
INFO:root:FL Epoch: 457 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :78
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353909
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 78 is 0.619347
INFO:root:FL Epoch: 457 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.48055154961698193 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.2129854510227839                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [993, 92, 497, 26, 364, 1508, 1296, 1117, 1009, 867]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 458 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :993
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564376
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377603
INFO:root:FL Epoch: 458 Norm Difference for worker 993 is 0.721982
INFO:root:FL Epoch: 458 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :92
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.305994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 92 is 0.710428
INFO:root:FL Epoch: 458 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :497
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647881
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394299
INFO:root:FL Epoch: 458 Norm Difference for worker 497 is 0.785537
INFO:root:FL Epoch: 458 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :26
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.739989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 26 is 0.791419
INFO:root:FL Epoch: 458 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :364
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415913
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286319
INFO:root:FL Epoch: 458 Norm Difference for worker 364 is 0.771136
INFO:root:FL Epoch: 458 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1508
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292548
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354239
INFO:root:FL Epoch: 458 Norm Difference for worker 1508 is 0.736432
INFO:root:FL Epoch: 458 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1296
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544232
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588647
INFO:root:FL Epoch: 458 Norm Difference for worker 1296 is 0.770093
INFO:root:FL Epoch: 458 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1117
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582362
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524913
INFO:root:FL Epoch: 458 Norm Difference for worker 1117 is 0.807859
INFO:root:FL Epoch: 458 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1009
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378137
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304977
INFO:root:FL Epoch: 458 Norm Difference for worker 1009 is 0.7947
INFO:root:FL Epoch: 458 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :867
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356499
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299551
INFO:root:FL Epoch: 458 Norm Difference for worker 867 is 0.700805
INFO:root:FL Epoch: 458 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 867
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.4987107059534858 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.26345838358004886                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [1706, 1346, 133, 699, 374, 827, 367, 1408, 741, 952]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 459 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :1706
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400538
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339452
INFO:root:FL Epoch: 459 Norm Difference for worker 1706 is 0.617644
INFO:root:FL Epoch: 459 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1346
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706481
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367009
INFO:root:FL Epoch: 459 Norm Difference for worker 1346 is 0.757813
INFO:root:FL Epoch: 459 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :133
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 133 is 0.757842
INFO:root:FL Epoch: 459 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :699
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520014
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425053
INFO:root:FL Epoch: 459 Norm Difference for worker 699 is 0.745841
INFO:root:FL Epoch: 459 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :374
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485222
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674384
INFO:root:FL Epoch: 459 Norm Difference for worker 374 is 0.7389
INFO:root:FL Epoch: 459 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :827
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525967
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294693
INFO:root:FL Epoch: 459 Norm Difference for worker 827 is 0.745555
INFO:root:FL Epoch: 459 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :367
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312973
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403105
INFO:root:FL Epoch: 459 Norm Difference for worker 367 is 0.742947
INFO:root:FL Epoch: 459 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1408
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564568
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558087
INFO:root:FL Epoch: 459 Norm Difference for worker 1408 is 0.800758
INFO:root:FL Epoch: 459 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :741
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867448
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424494
INFO:root:FL Epoch: 459 Norm Difference for worker 741 is 0.807379
INFO:root:FL Epoch: 459 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :952
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395265
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509893
INFO:root:FL Epoch: 459 Norm Difference for worker 952 is 0.811514
INFO:root:FL Epoch: 459 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1706
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.4985900871893939 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.21750343715151152                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [580, 445, 1191, 908, 25, 749, 812, 244, 593, 618]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :580
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722640
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447253
INFO:root:FL Epoch: 460 Norm Difference for worker 580 is 0.876828
INFO:root:FL Epoch: 460 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :445
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639201
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572873
INFO:root:FL Epoch: 460 Norm Difference for worker 445 is 0.852111
INFO:root:FL Epoch: 460 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1191
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631193
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309931
INFO:root:FL Epoch: 460 Norm Difference for worker 1191 is 0.81221
INFO:root:FL Epoch: 460 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :908
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626689
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248057
INFO:root:FL Epoch: 460 Norm Difference for worker 908 is 0.802176
INFO:root:FL Epoch: 460 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :25
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 25 is 0.774362
INFO:root:FL Epoch: 460 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :749
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384179
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450833
INFO:root:FL Epoch: 460 Norm Difference for worker 749 is 0.745097
INFO:root:FL Epoch: 460 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :812
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601037
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539788
INFO:root:FL Epoch: 460 Norm Difference for worker 812 is 0.797706
INFO:root:FL Epoch: 460 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :244
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 244 is 0.780683
INFO:root:FL Epoch: 460 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :593
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584792
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532113
INFO:root:FL Epoch: 460 Norm Difference for worker 593 is 0.84375
INFO:root:FL Epoch: 460 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :618
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359630
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498444
INFO:root:FL Epoch: 460 Norm Difference for worker 618 is 0.858695
INFO:root:FL Epoch: 460 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 749
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.5061435252428055 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.2400433470805486                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 607, 837, 17, 896, 1404, 909, 1212]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204691
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152568
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.18706875294446945 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.1482947938144207 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.129331
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195022
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188818
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.18592205519477525 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.15202687084674835 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.128753
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.134689
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238024
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.18863867595791817 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.1517598032951355 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.135079
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :607
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363105
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337749
INFO:root:FL Epoch: 461 Norm Difference for worker 607 is 0.805556
INFO:root:FL Epoch: 461 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :837
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674133
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323243
INFO:root:FL Epoch: 461 Norm Difference for worker 837 is 0.838402
INFO:root:FL Epoch: 461 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :17
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349472
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 17 is 0.902637
INFO:root:FL Epoch: 461 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :896
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524740
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367092
INFO:root:FL Epoch: 461 Norm Difference for worker 896 is 0.81998
INFO:root:FL Epoch: 461 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1404
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438940
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314942
INFO:root:FL Epoch: 461 Norm Difference for worker 1404 is 0.763996
INFO:root:FL Epoch: 461 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :909
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655481
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391964
INFO:root:FL Epoch: 461 Norm Difference for worker 909 is 0.779942
INFO:root:FL Epoch: 461 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1212
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347919
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375037
INFO:root:FL Epoch: 461 Norm Difference for worker 1212 is 0.75549
INFO:root:FL Epoch: 461 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.5084532113636241 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.18706875294446945                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [1587, 831, 1744, 981, 535, 1490, 1495, 634, 1243, 571]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :1587
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399385
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557952
INFO:root:FL Epoch: 462 Norm Difference for worker 1587 is 0.842499
INFO:root:FL Epoch: 462 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :831
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402077
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512827
INFO:root:FL Epoch: 462 Norm Difference for worker 831 is 0.848255
INFO:root:FL Epoch: 462 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1744
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243336
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494752
INFO:root:FL Epoch: 462 Norm Difference for worker 1744 is 0.692045
INFO:root:FL Epoch: 462 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :981
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728159
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543636
INFO:root:FL Epoch: 462 Norm Difference for worker 981 is 0.909183
INFO:root:FL Epoch: 462 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :535
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314704
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241900
INFO:root:FL Epoch: 462 Norm Difference for worker 535 is 0.779862
INFO:root:FL Epoch: 462 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1490
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444934
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679410
INFO:root:FL Epoch: 462 Norm Difference for worker 1490 is 0.83549
INFO:root:FL Epoch: 462 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1495
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662159
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337848
INFO:root:FL Epoch: 462 Norm Difference for worker 1495 is 0.883528
INFO:root:FL Epoch: 462 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :634
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314758
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486885
INFO:root:FL Epoch: 462 Norm Difference for worker 634 is 0.788897
INFO:root:FL Epoch: 462 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1243
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569646
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429708
INFO:root:FL Epoch: 462 Norm Difference for worker 1243 is 0.947741
INFO:root:FL Epoch: 462 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :571
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370601
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424972
INFO:root:FL Epoch: 462 Norm Difference for worker 571 is 0.804889
INFO:root:FL Epoch: 462 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1744
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.5087526300374199 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.15733764072259268                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [335, 1320, 78, 417, 3, 371, 1139, 1410, 1867, 738]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 463 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :335
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.862037
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 335 is 0.957014
INFO:root:FL Epoch: 463 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1320
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591397
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381604
INFO:root:FL Epoch: 463 Norm Difference for worker 1320 is 0.927633
INFO:root:FL Epoch: 463 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :78
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 78 is 0.623615
INFO:root:FL Epoch: 463 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :417
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529490
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679133
INFO:root:FL Epoch: 463 Norm Difference for worker 417 is 0.895484
INFO:root:FL Epoch: 463 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :3
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 3 is 0.952371
INFO:root:FL Epoch: 463 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :371
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407367
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610358
INFO:root:FL Epoch: 463 Norm Difference for worker 371 is 0.881881
INFO:root:FL Epoch: 463 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1139
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408477
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340074
INFO:root:FL Epoch: 463 Norm Difference for worker 1139 is 0.818741
INFO:root:FL Epoch: 463 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1410
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566164
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234922
INFO:root:FL Epoch: 463 Norm Difference for worker 1410 is 0.743496
INFO:root:FL Epoch: 463 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1867
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520340
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599261
INFO:root:FL Epoch: 463 Norm Difference for worker 1867 is 0.831989
INFO:root:FL Epoch: 463 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :738
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574265
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226109
INFO:root:FL Epoch: 463 Norm Difference for worker 738 is 1.004259
INFO:root:FL Epoch: 463 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.5537178235895494 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.21036222328742346                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [740, 258, 895, 807, 468, 1002, 239, 675, 1571, 1007]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 464 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :740
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727271
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393880
INFO:root:FL Epoch: 464 Norm Difference for worker 740 is 1.006065
INFO:root:FL Epoch: 464 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :258
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 1.005139
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 258 is 1.054051
INFO:root:FL Epoch: 464 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :895
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731535
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353832
INFO:root:FL Epoch: 464 Norm Difference for worker 895 is 1.009703
INFO:root:FL Epoch: 464 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :807
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515557
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398220
INFO:root:FL Epoch: 464 Norm Difference for worker 807 is 0.935311
INFO:root:FL Epoch: 464 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :468
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286443
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341776
INFO:root:FL Epoch: 464 Norm Difference for worker 468 is 0.920055
INFO:root:FL Epoch: 464 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1002
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605677
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746678
INFO:root:FL Epoch: 464 Norm Difference for worker 1002 is 1.034758
INFO:root:FL Epoch: 464 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :239
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.840920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 239 is 1.020988
INFO:root:FL Epoch: 464 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :675
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470627
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376119
INFO:root:FL Epoch: 464 Norm Difference for worker 675 is 0.968423
INFO:root:FL Epoch: 464 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1571
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422822
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483040
INFO:root:FL Epoch: 464 Norm Difference for worker 1571 is 0.843974
INFO:root:FL Epoch: 464 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1007
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681863
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271468
INFO:root:FL Epoch: 464 Norm Difference for worker 1007 is 0.867007
INFO:root:FL Epoch: 464 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1571
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.5232960871037315 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.2074290675421556                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [81, 351, 1764, 1030, 751, 1163, 582, 323, 1265, 143]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 465 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :81
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564594
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 81 is 0.925007
INFO:root:FL Epoch: 465 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :351
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556432
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509948
INFO:root:FL Epoch: 465 Norm Difference for worker 351 is 0.855108
INFO:root:FL Epoch: 465 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1764
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 1.053378
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626747
INFO:root:FL Epoch: 465 Norm Difference for worker 1764 is 0.977533
INFO:root:FL Epoch: 465 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1030
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451860
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382131
INFO:root:FL Epoch: 465 Norm Difference for worker 1030 is 0.901429
INFO:root:FL Epoch: 465 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :751
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370985
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573035
INFO:root:FL Epoch: 465 Norm Difference for worker 751 is 0.804575
INFO:root:FL Epoch: 465 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1163
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793591
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650486
INFO:root:FL Epoch: 465 Norm Difference for worker 1163 is 0.932521
INFO:root:FL Epoch: 465 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :582
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652351
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480346
INFO:root:FL Epoch: 465 Norm Difference for worker 582 is 0.979255
INFO:root:FL Epoch: 465 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :323
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 323 is 0.952707
INFO:root:FL Epoch: 465 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1265
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828959
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615120
INFO:root:FL Epoch: 465 Norm Difference for worker 1265 is 0.930994
INFO:root:FL Epoch: 465 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :143
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 143 is 0.931688
INFO:root:FL Epoch: 465 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 751
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.5067831979078405 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.22074604903658232                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1824, 1524, 512, 513, 1770, 173, 1460, 639, 1261, 1732]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1824
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600121
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692138
INFO:root:FL Epoch: 466 Norm Difference for worker 1824 is 0.841231
INFO:root:FL Epoch: 466 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1524
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604332
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333125
INFO:root:FL Epoch: 466 Norm Difference for worker 1524 is 0.912005
INFO:root:FL Epoch: 466 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :512
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554317
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252150
INFO:root:FL Epoch: 466 Norm Difference for worker 512 is 0.842648
INFO:root:FL Epoch: 466 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :513
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692455
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455810
INFO:root:FL Epoch: 466 Norm Difference for worker 513 is 0.863457
INFO:root:FL Epoch: 466 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1770
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386648
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408381
INFO:root:FL Epoch: 466 Norm Difference for worker 1770 is 0.709869
INFO:root:FL Epoch: 466 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :173
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.563090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 173 is 0.837942
INFO:root:FL Epoch: 466 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1460
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211566
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489074
INFO:root:FL Epoch: 466 Norm Difference for worker 1460 is 0.736918
INFO:root:FL Epoch: 466 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :639
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579080
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662016
INFO:root:FL Epoch: 466 Norm Difference for worker 639 is 0.701276
INFO:root:FL Epoch: 466 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1261
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578436
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491762
INFO:root:FL Epoch: 466 Norm Difference for worker 1261 is 0.788277
INFO:root:FL Epoch: 466 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1732
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552409
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552379
INFO:root:FL Epoch: 466 Norm Difference for worker 1732 is 0.750929
INFO:root:FL Epoch: 466 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.5105621087200501 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.2141768236955007                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1773, 938, 657, 1319, 1905, 21, 745, 488, 408, 1595]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 467 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1773
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496980
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307249
INFO:root:FL Epoch: 467 Norm Difference for worker 1773 is 0.831374
INFO:root:FL Epoch: 467 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :938
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380949
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420386
INFO:root:FL Epoch: 467 Norm Difference for worker 938 is 0.826127
INFO:root:FL Epoch: 467 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :657
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549760
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499624
INFO:root:FL Epoch: 467 Norm Difference for worker 657 is 0.825406
INFO:root:FL Epoch: 467 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1319
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497426
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518876
INFO:root:FL Epoch: 467 Norm Difference for worker 1319 is 0.87383
INFO:root:FL Epoch: 467 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1905
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250497
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492763
INFO:root:FL Epoch: 467 Norm Difference for worker 1905 is 0.787295
INFO:root:FL Epoch: 467 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :21
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.221868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.177486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 21 is 0.73177
INFO:root:FL Epoch: 467 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :745
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750631
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409447
INFO:root:FL Epoch: 467 Norm Difference for worker 745 is 0.948503
INFO:root:FL Epoch: 467 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :488
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738539
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603206
INFO:root:FL Epoch: 467 Norm Difference for worker 488 is 0.757161
INFO:root:FL Epoch: 467 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :408
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407577
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438677
INFO:root:FL Epoch: 467 Norm Difference for worker 408 is 0.815382
INFO:root:FL Epoch: 467 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1595
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415155
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379040
INFO:root:FL Epoch: 467 Norm Difference for worker 1595 is 0.801166
INFO:root:FL Epoch: 467 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1595
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.507525796399397 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.23461521665255228                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1586, 1317, 626, 1406, 854, 1493, 724, 1905, 1504, 843]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1586
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653011
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372761
INFO:root:FL Epoch: 468 Norm Difference for worker 1586 is 0.748629
INFO:root:FL Epoch: 468 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1317
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601087
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590908
INFO:root:FL Epoch: 468 Norm Difference for worker 1317 is 0.744683
INFO:root:FL Epoch: 468 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :626
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444878
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544542
INFO:root:FL Epoch: 468 Norm Difference for worker 626 is 0.773243
INFO:root:FL Epoch: 468 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1406
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833155
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535533
INFO:root:FL Epoch: 468 Norm Difference for worker 1406 is 0.735773
INFO:root:FL Epoch: 468 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :854
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440136
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360941
INFO:root:FL Epoch: 468 Norm Difference for worker 854 is 0.725132
INFO:root:FL Epoch: 468 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1493
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564717
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532086
INFO:root:FL Epoch: 468 Norm Difference for worker 1493 is 0.798107
INFO:root:FL Epoch: 468 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :724
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601666
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502276
INFO:root:FL Epoch: 468 Norm Difference for worker 724 is 0.721549
INFO:root:FL Epoch: 468 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1905
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415739
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576938
INFO:root:FL Epoch: 468 Norm Difference for worker 1905 is 0.73001
INFO:root:FL Epoch: 468 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1504
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573628
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606762
INFO:root:FL Epoch: 468 Norm Difference for worker 1504 is 0.777316
INFO:root:FL Epoch: 468 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :843
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704936
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551300
INFO:root:FL Epoch: 468 Norm Difference for worker 843 is 0.853667
INFO:root:FL Epoch: 468 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 724
INFO:root:Norm of Aggregated Model: 5154.97509765625
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.5079534606021994 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.2901693930228551                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [554, 1448, 934, 1333, 217, 1698, 1453, 379, 1803, 488]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :554
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851210
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267829
INFO:root:FL Epoch: 469 Norm Difference for worker 554 is 0.688555
INFO:root:FL Epoch: 469 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1448
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604878
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511711
INFO:root:FL Epoch: 469 Norm Difference for worker 1448 is 0.713847
INFO:root:FL Epoch: 469 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :934
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571432
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597707
INFO:root:FL Epoch: 469 Norm Difference for worker 934 is 0.789447
INFO:root:FL Epoch: 469 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1333
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630665
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405033
INFO:root:FL Epoch: 469 Norm Difference for worker 1333 is 0.713223
INFO:root:FL Epoch: 469 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :217
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 217 is 0.727053
INFO:root:FL Epoch: 469 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1698
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279240
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619846
INFO:root:FL Epoch: 469 Norm Difference for worker 1698 is 0.776565
INFO:root:FL Epoch: 469 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1453
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500277
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503728
INFO:root:FL Epoch: 469 Norm Difference for worker 1453 is 0.700297
INFO:root:FL Epoch: 469 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :379
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391055
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595079
INFO:root:FL Epoch: 469 Norm Difference for worker 379 is 0.714312
INFO:root:FL Epoch: 469 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1803
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581725
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494975
INFO:root:FL Epoch: 469 Norm Difference for worker 1803 is 0.720515
INFO:root:FL Epoch: 469 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :488
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583381
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615196
INFO:root:FL Epoch: 469 Norm Difference for worker 488 is 0.714881
INFO:root:FL Epoch: 469 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 554
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.48699679269510154 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.2778980036576589                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [709, 1445, 1569, 618, 1559, 1202, 1010, 484, 1465, 613]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :709
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833156
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525340
INFO:root:FL Epoch: 470 Norm Difference for worker 709 is 0.692822
INFO:root:FL Epoch: 470 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1445
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546401
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718858
INFO:root:FL Epoch: 470 Norm Difference for worker 1445 is 0.680452
INFO:root:FL Epoch: 470 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1569
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563483
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412675
INFO:root:FL Epoch: 470 Norm Difference for worker 1569 is 0.639653
INFO:root:FL Epoch: 470 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :618
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552167
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546708
INFO:root:FL Epoch: 470 Norm Difference for worker 618 is 0.66387
INFO:root:FL Epoch: 470 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1559
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359149
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541311
INFO:root:FL Epoch: 470 Norm Difference for worker 1559 is 0.651981
INFO:root:FL Epoch: 470 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1202
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633526
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452418
INFO:root:FL Epoch: 470 Norm Difference for worker 1202 is 0.658516
INFO:root:FL Epoch: 470 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1010
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558501
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554878
INFO:root:FL Epoch: 470 Norm Difference for worker 1010 is 0.646403
INFO:root:FL Epoch: 470 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :484
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.890389
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366701
INFO:root:FL Epoch: 470 Norm Difference for worker 484 is 0.684408
INFO:root:FL Epoch: 470 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1465
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534687
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539195
INFO:root:FL Epoch: 470 Norm Difference for worker 1465 is 0.630711
INFO:root:FL Epoch: 470 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :613
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638023
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669487
INFO:root:FL Epoch: 470 Norm Difference for worker 613 is 0.675768
INFO:root:FL Epoch: 470 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1569
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.4857323117115918 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.30081761876742047                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 151, 1654, 1080, 91, 1467, 1247, 1165]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275684
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260024
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.24253095438083014 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.19450631588697434 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.144397
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253737
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177051
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.24220928053061166 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.19487477242946624 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.142058
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280855
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167080
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.24261637528737387 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.19562365785241126 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.139241
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :151
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 151 is 0.601061
INFO:root:FL Epoch: 471 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1654
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750300
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440663
INFO:root:FL Epoch: 471 Norm Difference for worker 1654 is 0.666847
INFO:root:FL Epoch: 471 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1080
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451054
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562163
INFO:root:FL Epoch: 471 Norm Difference for worker 1080 is 0.684886
INFO:root:FL Epoch: 471 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :91
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 91 is 0.658873
INFO:root:FL Epoch: 471 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1467
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519316
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497197
INFO:root:FL Epoch: 471 Norm Difference for worker 1467 is 0.688483
INFO:root:FL Epoch: 471 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1247
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597494
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394708
INFO:root:FL Epoch: 471 Norm Difference for worker 1247 is 0.647324
INFO:root:FL Epoch: 471 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1165
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711317
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609822
INFO:root:FL Epoch: 471 Norm Difference for worker 1165 is 0.646699
INFO:root:FL Epoch: 471 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.4849764073596281 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.24261637528737387                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [55, 1275, 894, 1719, 433, 1880, 1000, 1374, 879, 853]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 472 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :55
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515842
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 55 is 0.670938
INFO:root:FL Epoch: 472 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1275
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348976
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347538
INFO:root:FL Epoch: 472 Norm Difference for worker 1275 is 0.639625
INFO:root:FL Epoch: 472 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :894
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682037
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645484
INFO:root:FL Epoch: 472 Norm Difference for worker 894 is 0.710622
INFO:root:FL Epoch: 472 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1719
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403219
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320060
INFO:root:FL Epoch: 472 Norm Difference for worker 1719 is 0.677226
INFO:root:FL Epoch: 472 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :433
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514956
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370196
INFO:root:FL Epoch: 472 Norm Difference for worker 433 is 0.723256
INFO:root:FL Epoch: 472 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1880
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531180
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355287
INFO:root:FL Epoch: 472 Norm Difference for worker 1880 is 0.718671
INFO:root:FL Epoch: 472 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1000
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491379
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492707
INFO:root:FL Epoch: 472 Norm Difference for worker 1000 is 0.754853
INFO:root:FL Epoch: 472 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1374
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341371
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403173
INFO:root:FL Epoch: 472 Norm Difference for worker 1374 is 0.575462
INFO:root:FL Epoch: 472 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :879
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446441
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562042
INFO:root:FL Epoch: 472 Norm Difference for worker 879 is 0.689511
INFO:root:FL Epoch: 472 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :853
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548337
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539237
INFO:root:FL Epoch: 472 Norm Difference for worker 853 is 0.753585
INFO:root:FL Epoch: 472 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1374
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.4853331280105254 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.21606620897849402                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [548, 1156, 785, 1590, 1674, 880, 1577, 662, 1528, 386]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :548
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599944
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359376
INFO:root:FL Epoch: 473 Norm Difference for worker 548 is 0.792693
INFO:root:FL Epoch: 473 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1156
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422531
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422300
INFO:root:FL Epoch: 473 Norm Difference for worker 1156 is 0.7891
INFO:root:FL Epoch: 473 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :785
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493102
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447369
INFO:root:FL Epoch: 473 Norm Difference for worker 785 is 0.836952
INFO:root:FL Epoch: 473 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1590
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307177
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398631
INFO:root:FL Epoch: 473 Norm Difference for worker 1590 is 0.824428
INFO:root:FL Epoch: 473 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1674
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255632
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390332
INFO:root:FL Epoch: 473 Norm Difference for worker 1674 is 0.823268
INFO:root:FL Epoch: 473 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :880
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715830
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306418
INFO:root:FL Epoch: 473 Norm Difference for worker 880 is 0.801995
INFO:root:FL Epoch: 473 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1577
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701251
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362616
INFO:root:FL Epoch: 473 Norm Difference for worker 1577 is 0.801387
INFO:root:FL Epoch: 473 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :662
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433627
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258091
INFO:root:FL Epoch: 473 Norm Difference for worker 662 is 0.743695
INFO:root:FL Epoch: 473 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1528
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700629
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449832
INFO:root:FL Epoch: 473 Norm Difference for worker 1528 is 0.710861
INFO:root:FL Epoch: 473 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :386
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380943
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366366
INFO:root:FL Epoch: 473 Norm Difference for worker 386 is 0.756562
INFO:root:FL Epoch: 473 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1528
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.4912165192996754 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.31274272004763287                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1866, 1598, 830, 460, 382, 1338, 838, 193, 457, 1938]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1866
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524312
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423415
INFO:root:FL Epoch: 474 Norm Difference for worker 1866 is 0.833648
INFO:root:FL Epoch: 474 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1598
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484838
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427412
INFO:root:FL Epoch: 474 Norm Difference for worker 1598 is 0.7571
INFO:root:FL Epoch: 474 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :830
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578232
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350275
INFO:root:FL Epoch: 474 Norm Difference for worker 830 is 0.750458
INFO:root:FL Epoch: 474 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :460
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462265
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695447
INFO:root:FL Epoch: 474 Norm Difference for worker 460 is 0.736602
INFO:root:FL Epoch: 474 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :382
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487148
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297580
INFO:root:FL Epoch: 474 Norm Difference for worker 382 is 0.8044
INFO:root:FL Epoch: 474 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1338
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616279
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474960
INFO:root:FL Epoch: 474 Norm Difference for worker 1338 is 0.648052
INFO:root:FL Epoch: 474 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :838
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432714
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390187
INFO:root:FL Epoch: 474 Norm Difference for worker 838 is 0.777789
INFO:root:FL Epoch: 474 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :193
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 193 is 0.773512
INFO:root:FL Epoch: 474 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :457
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476459
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540868
INFO:root:FL Epoch: 474 Norm Difference for worker 457 is 0.736073
INFO:root:FL Epoch: 474 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1938
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462023
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564574
INFO:root:FL Epoch: 474 Norm Difference for worker 1938 is 0.734714
INFO:root:FL Epoch: 474 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.4752804689547595 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.18344337244828543                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1290, 213, 1351, 1815, 282, 152, 1723, 1823, 752, 1239]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 475 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1290
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412634
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521032
INFO:root:FL Epoch: 475 Norm Difference for worker 1290 is 0.80079
INFO:root:FL Epoch: 475 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :213
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 213 is 0.822004
INFO:root:FL Epoch: 475 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1351
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447677
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466082
INFO:root:FL Epoch: 475 Norm Difference for worker 1351 is 0.753489
INFO:root:FL Epoch: 475 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1815
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.911942
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553980
INFO:root:FL Epoch: 475 Norm Difference for worker 1815 is 0.876215
INFO:root:FL Epoch: 475 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :282
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.567884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 282 is 0.83835
INFO:root:FL Epoch: 475 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :152
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 152 is 0.806272
INFO:root:FL Epoch: 475 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1723
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656323
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.795198
INFO:root:FL Epoch: 475 Norm Difference for worker 1723 is 0.868001
INFO:root:FL Epoch: 475 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1823
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817752
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474274
INFO:root:FL Epoch: 475 Norm Difference for worker 1823 is 0.828111
INFO:root:FL Epoch: 475 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :752
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619967
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575176
INFO:root:FL Epoch: 475 Norm Difference for worker 752 is 0.722791
INFO:root:FL Epoch: 475 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1239
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387518
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320517
INFO:root:FL Epoch: 475 Norm Difference for worker 1239 is 0.812963
INFO:root:FL Epoch: 475 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 752
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.4676525540211621 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.2212303231159846                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [1494, 1738, 1857, 453, 1466, 1132, 1586, 1646, 1059, 419]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 476 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :1494
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612840
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469936
INFO:root:FL Epoch: 476 Norm Difference for worker 1494 is 0.729277
INFO:root:FL Epoch: 476 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1738
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365837
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646131
INFO:root:FL Epoch: 476 Norm Difference for worker 1738 is 0.803777
INFO:root:FL Epoch: 476 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1857
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417227
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365437
INFO:root:FL Epoch: 476 Norm Difference for worker 1857 is 0.83148
INFO:root:FL Epoch: 476 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :453
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756160
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494175
INFO:root:FL Epoch: 476 Norm Difference for worker 453 is 0.735755
INFO:root:FL Epoch: 476 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1466
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710515
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567214
INFO:root:FL Epoch: 476 Norm Difference for worker 1466 is 0.80191
INFO:root:FL Epoch: 476 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1132
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448876
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663625
INFO:root:FL Epoch: 476 Norm Difference for worker 1132 is 0.696989
INFO:root:FL Epoch: 476 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1586
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812524
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655460
INFO:root:FL Epoch: 476 Norm Difference for worker 1586 is 0.75281
INFO:root:FL Epoch: 476 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1646
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396457
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422930
INFO:root:FL Epoch: 476 Norm Difference for worker 1646 is 0.70894
INFO:root:FL Epoch: 476 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1059
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581221
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212666
INFO:root:FL Epoch: 476 Norm Difference for worker 1059 is 0.752378
INFO:root:FL Epoch: 476 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :419
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652021
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441647
INFO:root:FL Epoch: 476 Norm Difference for worker 419 is 0.698756
INFO:root:FL Epoch: 476 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 419
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.4678411834380206 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.3114996775984764                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [952, 411, 415, 1448, 552, 1943, 679, 1277, 1416, 35]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 477 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :952
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395240
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368429
INFO:root:FL Epoch: 477 Norm Difference for worker 952 is 0.763223
INFO:root:FL Epoch: 477 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :411
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345803
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373448
INFO:root:FL Epoch: 477 Norm Difference for worker 411 is 0.744697
INFO:root:FL Epoch: 477 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :415
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675279
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375084
INFO:root:FL Epoch: 477 Norm Difference for worker 415 is 0.700287
INFO:root:FL Epoch: 477 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1448
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794006
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485311
INFO:root:FL Epoch: 477 Norm Difference for worker 1448 is 0.726053
INFO:root:FL Epoch: 477 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :552
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609205
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419326
INFO:root:FL Epoch: 477 Norm Difference for worker 552 is 0.723592
INFO:root:FL Epoch: 477 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1943
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452188
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579600
INFO:root:FL Epoch: 477 Norm Difference for worker 1943 is 0.7401
INFO:root:FL Epoch: 477 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :679
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713386
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318683
INFO:root:FL Epoch: 477 Norm Difference for worker 679 is 0.738809
INFO:root:FL Epoch: 477 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1277
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645013
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474908
INFO:root:FL Epoch: 477 Norm Difference for worker 1277 is 0.720382
INFO:root:FL Epoch: 477 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1416
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451905
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406260
INFO:root:FL Epoch: 477 Norm Difference for worker 1416 is 0.767967
INFO:root:FL Epoch: 477 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :35
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486486
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 35 is 0.770219
INFO:root:FL Epoch: 477 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 415
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.45937376776162314 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.27299580971399945                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [1457, 196, 409, 1243, 850, 1688, 1945, 529, 1824, 301]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 478 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :1457
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443777
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375020
INFO:root:FL Epoch: 478 Norm Difference for worker 1457 is 0.738461
INFO:root:FL Epoch: 478 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :196
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 196 is 0.705936
INFO:root:FL Epoch: 478 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :409
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388501
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.849943
INFO:root:FL Epoch: 478 Norm Difference for worker 409 is 0.753583
INFO:root:FL Epoch: 478 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1243
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806868
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377188
INFO:root:FL Epoch: 478 Norm Difference for worker 1243 is 0.774664
INFO:root:FL Epoch: 478 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :850
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533789
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320658
INFO:root:FL Epoch: 478 Norm Difference for worker 850 is 0.761025
INFO:root:FL Epoch: 478 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1688
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526503
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647205
INFO:root:FL Epoch: 478 Norm Difference for worker 1688 is 0.706289
INFO:root:FL Epoch: 478 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1945
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732433
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322189
INFO:root:FL Epoch: 478 Norm Difference for worker 1945 is 0.699553
INFO:root:FL Epoch: 478 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :529
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506136
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338732
INFO:root:FL Epoch: 478 Norm Difference for worker 529 is 0.710268
INFO:root:FL Epoch: 478 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1824
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673943
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526833
INFO:root:FL Epoch: 478 Norm Difference for worker 1824 is 0.784956
INFO:root:FL Epoch: 478 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :301
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640025
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 301 is 0.74613
INFO:root:FL Epoch: 478 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 529
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.46346794945352215 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.30426455040772754                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [1556, 1805, 396, 462, 693, 700, 492, 688, 164, 1734]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :1556
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624654
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508631
INFO:root:FL Epoch: 479 Norm Difference for worker 1556 is 0.717376
INFO:root:FL Epoch: 479 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1805
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436513
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439793
INFO:root:FL Epoch: 479 Norm Difference for worker 1805 is 0.741985
INFO:root:FL Epoch: 479 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :396
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531203
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498780
INFO:root:FL Epoch: 479 Norm Difference for worker 396 is 0.744334
INFO:root:FL Epoch: 479 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :462
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853123
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656099
INFO:root:FL Epoch: 479 Norm Difference for worker 462 is 0.765032
INFO:root:FL Epoch: 479 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :693
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497870
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412671
INFO:root:FL Epoch: 479 Norm Difference for worker 693 is 0.682704
INFO:root:FL Epoch: 479 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :700
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466675
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418572
INFO:root:FL Epoch: 479 Norm Difference for worker 700 is 0.755931
INFO:root:FL Epoch: 479 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :492
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606440
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381239
INFO:root:FL Epoch: 479 Norm Difference for worker 492 is 0.704375
INFO:root:FL Epoch: 479 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :688
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474298
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411839
INFO:root:FL Epoch: 479 Norm Difference for worker 688 is 0.703591
INFO:root:FL Epoch: 479 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :164
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 164 is 0.757314
INFO:root:FL Epoch: 479 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1734
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663630
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667546
INFO:root:FL Epoch: 479 Norm Difference for worker 1734 is 0.727843
INFO:root:FL Epoch: 479 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.4790639772134669 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.3494875008861224                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [616, 1015, 305, 191, 1119, 1854, 1670, 983, 1569, 980]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :616
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484135
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629711
INFO:root:FL Epoch: 480 Norm Difference for worker 616 is 0.653411
INFO:root:FL Epoch: 480 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1015
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404806
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470754
INFO:root:FL Epoch: 480 Norm Difference for worker 1015 is 0.695015
INFO:root:FL Epoch: 480 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :305
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700427
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 305 is 0.701203
INFO:root:FL Epoch: 480 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :191
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514990
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 191 is 0.710849
INFO:root:FL Epoch: 480 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1119
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478342
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632161
INFO:root:FL Epoch: 480 Norm Difference for worker 1119 is 0.675037
INFO:root:FL Epoch: 480 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1854
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282270
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343874
INFO:root:FL Epoch: 480 Norm Difference for worker 1854 is 0.718932
INFO:root:FL Epoch: 480 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1670
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384289
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417161
INFO:root:FL Epoch: 480 Norm Difference for worker 1670 is 0.609636
INFO:root:FL Epoch: 480 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :983
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756096
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567639
INFO:root:FL Epoch: 480 Norm Difference for worker 983 is 0.703949
INFO:root:FL Epoch: 480 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1569
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384503
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546849
INFO:root:FL Epoch: 480 Norm Difference for worker 1569 is 0.651766
INFO:root:FL Epoch: 480 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :980
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530528
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658028
INFO:root:FL Epoch: 480 Norm Difference for worker 980 is 0.676799
INFO:root:FL Epoch: 480 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.48175949296530557 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.3130556767185529                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 561, 481, 321, 674, 79, 14, 483]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.191095
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152755
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.22867952287197113 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.1696574345231056 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.143331
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235474
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212908
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.23100291937589645 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.17058305963873863 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.139299
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366314
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252850
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.23256399730841318 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.17099409997463227 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.139664
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :561
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412543
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413312
INFO:root:FL Epoch: 481 Norm Difference for worker 561 is 0.7482
INFO:root:FL Epoch: 481 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :481
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366800
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424890
INFO:root:FL Epoch: 481 Norm Difference for worker 481 is 0.707837
INFO:root:FL Epoch: 481 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :321
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 321 is 0.725312
INFO:root:FL Epoch: 481 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :674
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493909
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431191
INFO:root:FL Epoch: 481 Norm Difference for worker 674 is 0.680094
INFO:root:FL Epoch: 481 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :79
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 79 is 0.65145
INFO:root:FL Epoch: 481 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :14
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546781
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 14 is 0.696355
INFO:root:FL Epoch: 481 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :483
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361292
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171739
INFO:root:FL Epoch: 481 Norm Difference for worker 483 is 0.591507
INFO:root:FL Epoch: 481 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.48253585748812733 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.23100291937589645                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [949, 863, 340, 58, 1181, 242, 1945, 1451, 1473, 477]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :949
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580380
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584659
INFO:root:FL Epoch: 482 Norm Difference for worker 949 is 0.809311
INFO:root:FL Epoch: 482 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :863
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500208
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573013
INFO:root:FL Epoch: 482 Norm Difference for worker 863 is 0.75547
INFO:root:FL Epoch: 482 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :340
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642417
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674831
INFO:root:FL Epoch: 482 Norm Difference for worker 340 is 0.807372
INFO:root:FL Epoch: 482 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :58
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712490
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552451
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 58 is 0.76537
INFO:root:FL Epoch: 482 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1181
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788347
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566866
INFO:root:FL Epoch: 482 Norm Difference for worker 1181 is 0.743302
INFO:root:FL Epoch: 482 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :242
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 242 is 0.818415
INFO:root:FL Epoch: 482 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1945
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305357
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461765
INFO:root:FL Epoch: 482 Norm Difference for worker 1945 is 0.702509
INFO:root:FL Epoch: 482 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1451
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438568
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567146
INFO:root:FL Epoch: 482 Norm Difference for worker 1451 is 0.748187
INFO:root:FL Epoch: 482 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1473
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380186
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647109
INFO:root:FL Epoch: 482 Norm Difference for worker 1473 is 0.865291
INFO:root:FL Epoch: 482 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :477
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685206
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514983
INFO:root:FL Epoch: 482 Norm Difference for worker 477 is 0.805017
INFO:root:FL Epoch: 482 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1945
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.4776187994900872 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.20797945310672125                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [849, 1204, 1327, 924, 1031, 409, 912, 401, 117, 1136]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 483 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :849
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568946
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665367
INFO:root:FL Epoch: 483 Norm Difference for worker 849 is 0.769121
INFO:root:FL Epoch: 483 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1204
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625145
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272306
INFO:root:FL Epoch: 483 Norm Difference for worker 1204 is 0.7451
INFO:root:FL Epoch: 483 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1327
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578476
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579366
INFO:root:FL Epoch: 483 Norm Difference for worker 1327 is 0.706068
INFO:root:FL Epoch: 483 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :924
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428952
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266355
INFO:root:FL Epoch: 483 Norm Difference for worker 924 is 0.69111
INFO:root:FL Epoch: 483 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1031
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486687
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502087
INFO:root:FL Epoch: 483 Norm Difference for worker 1031 is 0.760996
INFO:root:FL Epoch: 483 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :409
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569893
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380636
INFO:root:FL Epoch: 483 Norm Difference for worker 409 is 0.71863
INFO:root:FL Epoch: 483 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :912
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580613
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557785
INFO:root:FL Epoch: 483 Norm Difference for worker 912 is 0.75273
INFO:root:FL Epoch: 483 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :401
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498221
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479440
INFO:root:FL Epoch: 483 Norm Difference for worker 401 is 0.722476
INFO:root:FL Epoch: 483 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :117
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 117 is 0.717291
INFO:root:FL Epoch: 483 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1136
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555080
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710595
INFO:root:FL Epoch: 483 Norm Difference for worker 1136 is 0.787401
INFO:root:FL Epoch: 483 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 924
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.47284525457550497 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.17388431231180826                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [528, 141, 406, 1149, 639, 932, 865, 1944, 1827, 1174]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 484 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :528
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563043
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560231
INFO:root:FL Epoch: 484 Norm Difference for worker 528 is 0.813482
INFO:root:FL Epoch: 484 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :141
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516395
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 141 is 0.700912
INFO:root:FL Epoch: 484 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :406
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581474
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597331
INFO:root:FL Epoch: 484 Norm Difference for worker 406 is 0.815618
INFO:root:FL Epoch: 484 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1149
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008708
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417903
INFO:root:FL Epoch: 484 Norm Difference for worker 1149 is 0.847571
INFO:root:FL Epoch: 484 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :639
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346682
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392196
INFO:root:FL Epoch: 484 Norm Difference for worker 639 is 0.608993
INFO:root:FL Epoch: 484 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :932
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385800
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654204
INFO:root:FL Epoch: 484 Norm Difference for worker 932 is 0.838145
INFO:root:FL Epoch: 484 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :865
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557223
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568220
INFO:root:FL Epoch: 484 Norm Difference for worker 865 is 0.828835
INFO:root:FL Epoch: 484 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1944
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437930
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429136
INFO:root:FL Epoch: 484 Norm Difference for worker 1944 is 0.729485
INFO:root:FL Epoch: 484 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1827
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242187
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493620
INFO:root:FL Epoch: 484 Norm Difference for worker 1827 is 0.65643
INFO:root:FL Epoch: 484 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1174
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782216
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588328
INFO:root:FL Epoch: 484 Norm Difference for worker 1174 is 0.808659
INFO:root:FL Epoch: 484 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.48435062257682576 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.1974524768690268                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [496, 203, 42, 22, 915, 382, 62, 1040, 29, 779]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 485 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :496
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582257
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763272
INFO:root:FL Epoch: 485 Norm Difference for worker 496 is 0.836037
INFO:root:FL Epoch: 485 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :203
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 203 is 0.885172
INFO:root:FL Epoch: 485 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :42
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444990
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 42 is 0.694487
INFO:root:FL Epoch: 485 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :22
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 22 is 0.866707
INFO:root:FL Epoch: 485 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :915
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548309
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402484
INFO:root:FL Epoch: 485 Norm Difference for worker 915 is 0.850926
INFO:root:FL Epoch: 485 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :382
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581556
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440940
INFO:root:FL Epoch: 485 Norm Difference for worker 382 is 0.871213
INFO:root:FL Epoch: 485 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :62
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 62 is 0.866549
INFO:root:FL Epoch: 485 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1040
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588022
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349635
INFO:root:FL Epoch: 485 Norm Difference for worker 1040 is 0.847643
INFO:root:FL Epoch: 485 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :29
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 1.055907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 29 is 0.888755
INFO:root:FL Epoch: 485 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :779
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463464
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334355
INFO:root:FL Epoch: 485 Norm Difference for worker 779 is 0.829551
INFO:root:FL Epoch: 485 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.4852025999742396 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.22454936802387238                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1637, 577, 971, 1234, 1712, 1120, 733, 1188, 1270, 393]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1637
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394431
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540125
INFO:root:FL Epoch: 486 Norm Difference for worker 1637 is 0.796703
INFO:root:FL Epoch: 486 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :577
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338469
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460649
INFO:root:FL Epoch: 486 Norm Difference for worker 577 is 0.796584
INFO:root:FL Epoch: 486 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :971
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568128
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377054
INFO:root:FL Epoch: 486 Norm Difference for worker 971 is 0.897097
INFO:root:FL Epoch: 486 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1234
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583048
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699158
INFO:root:FL Epoch: 486 Norm Difference for worker 1234 is 0.874261
INFO:root:FL Epoch: 486 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1712
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548104
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693800
INFO:root:FL Epoch: 486 Norm Difference for worker 1712 is 0.875536
INFO:root:FL Epoch: 486 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1120
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815128
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631495
INFO:root:FL Epoch: 486 Norm Difference for worker 1120 is 0.919412
INFO:root:FL Epoch: 486 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :733
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.929609
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598783
INFO:root:FL Epoch: 486 Norm Difference for worker 733 is 0.895159
INFO:root:FL Epoch: 486 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1188
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447593
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526532
INFO:root:FL Epoch: 486 Norm Difference for worker 1188 is 0.900333
INFO:root:FL Epoch: 486 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1270
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410252
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211484
INFO:root:FL Epoch: 486 Norm Difference for worker 1270 is 0.772168
INFO:root:FL Epoch: 486 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :393
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806601
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482483
INFO:root:FL Epoch: 486 Norm Difference for worker 393 is 0.869534
INFO:root:FL Epoch: 486 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.9755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.47945324112387266 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.23586776852607727                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1318, 1307, 1255, 86, 1583, 73, 1774, 1361, 1191, 72]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1318
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325163
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.784556
INFO:root:FL Epoch: 487 Norm Difference for worker 1318 is 0.846733
INFO:root:FL Epoch: 487 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1307
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898179
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530831
INFO:root:FL Epoch: 487 Norm Difference for worker 1307 is 0.793721
INFO:root:FL Epoch: 487 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1255
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413888
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660256
INFO:root:FL Epoch: 487 Norm Difference for worker 1255 is 0.843176
INFO:root:FL Epoch: 487 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :86
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.236350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.170593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 86 is 0.645395
INFO:root:FL Epoch: 487 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1583
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612892
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536337
INFO:root:FL Epoch: 487 Norm Difference for worker 1583 is 0.825615
INFO:root:FL Epoch: 487 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :73
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 1.054896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 73 is 0.862979
INFO:root:FL Epoch: 487 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1774
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280400
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311399
INFO:root:FL Epoch: 487 Norm Difference for worker 1774 is 0.70597
INFO:root:FL Epoch: 487 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1361
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787551
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507352
INFO:root:FL Epoch: 487 Norm Difference for worker 1361 is 0.821533
INFO:root:FL Epoch: 487 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1191
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515589
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424768
INFO:root:FL Epoch: 487 Norm Difference for worker 1191 is 0.757135
INFO:root:FL Epoch: 487 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :72
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.366740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 72 is 0.757846
INFO:root:FL Epoch: 487 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.5001421667197171 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.2734863410393397                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [1497, 860, 1140, 427, 1056, 1259, 134, 1401, 937, 1377]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 488 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :1497
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428693
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593683
INFO:root:FL Epoch: 488 Norm Difference for worker 1497 is 0.852697
INFO:root:FL Epoch: 488 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :860
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851977
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384431
INFO:root:FL Epoch: 488 Norm Difference for worker 860 is 0.955554
INFO:root:FL Epoch: 488 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1140
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744273
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478241
INFO:root:FL Epoch: 488 Norm Difference for worker 1140 is 0.876958
INFO:root:FL Epoch: 488 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :427
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681220
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735945
INFO:root:FL Epoch: 488 Norm Difference for worker 427 is 0.777225
INFO:root:FL Epoch: 488 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1056
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349762
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344334
INFO:root:FL Epoch: 488 Norm Difference for worker 1056 is 0.857938
INFO:root:FL Epoch: 488 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1259
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374929
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449042
INFO:root:FL Epoch: 488 Norm Difference for worker 1259 is 0.864906
INFO:root:FL Epoch: 488 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :134
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 134 is 0.778958
INFO:root:FL Epoch: 488 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1401
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568649
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329749
INFO:root:FL Epoch: 488 Norm Difference for worker 1401 is 0.774085
INFO:root:FL Epoch: 488 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :937
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355923
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361343
INFO:root:FL Epoch: 488 Norm Difference for worker 937 is 0.835932
INFO:root:FL Epoch: 488 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1377
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591930
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557353
INFO:root:FL Epoch: 488 Norm Difference for worker 1377 is 0.897923
INFO:root:FL Epoch: 488 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 427
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.4823468152214499 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.2477488269408544                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [858, 1611, 442, 1751, 1626, 1430, 557, 6, 1406, 1934]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :858
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444265
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359802
INFO:root:FL Epoch: 489 Norm Difference for worker 858 is 0.794922
INFO:root:FL Epoch: 489 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1611
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573942
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365603
INFO:root:FL Epoch: 489 Norm Difference for worker 1611 is 0.801258
INFO:root:FL Epoch: 489 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :442
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856482
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472538
INFO:root:FL Epoch: 489 Norm Difference for worker 442 is 0.820876
INFO:root:FL Epoch: 489 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1751
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446810
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351640
INFO:root:FL Epoch: 489 Norm Difference for worker 1751 is 0.828603
INFO:root:FL Epoch: 489 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1626
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378488
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400903
INFO:root:FL Epoch: 489 Norm Difference for worker 1626 is 0.771262
INFO:root:FL Epoch: 489 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1430
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418818
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329281
INFO:root:FL Epoch: 489 Norm Difference for worker 1430 is 0.811595
INFO:root:FL Epoch: 489 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :557
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555870
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473118
INFO:root:FL Epoch: 489 Norm Difference for worker 557 is 0.797304
INFO:root:FL Epoch: 489 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :6
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539944
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 6 is 0.781756
INFO:root:FL Epoch: 489 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1406
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.901579
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422013
INFO:root:FL Epoch: 489 Norm Difference for worker 1406 is 0.859621
INFO:root:FL Epoch: 489 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1934
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577168
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708347
INFO:root:FL Epoch: 489 Norm Difference for worker 1934 is 0.868007
INFO:root:FL Epoch: 489 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1626
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.4702128785498002 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.1767172527809938                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [406, 1256, 1544, 894, 738, 923, 1701, 1105, 182, 95]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 490 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :406
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465397
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640831
INFO:root:FL Epoch: 490 Norm Difference for worker 406 is 0.87383
INFO:root:FL Epoch: 490 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1256
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517033
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385589
INFO:root:FL Epoch: 490 Norm Difference for worker 1256 is 0.758522
INFO:root:FL Epoch: 490 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1544
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584343
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526925
INFO:root:FL Epoch: 490 Norm Difference for worker 1544 is 0.869711
INFO:root:FL Epoch: 490 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :894
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727954
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573019
INFO:root:FL Epoch: 490 Norm Difference for worker 894 is 0.789838
INFO:root:FL Epoch: 490 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :738
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382651
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505327
INFO:root:FL Epoch: 490 Norm Difference for worker 738 is 0.792062
INFO:root:FL Epoch: 490 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :923
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838305
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415736
INFO:root:FL Epoch: 490 Norm Difference for worker 923 is 0.751056
INFO:root:FL Epoch: 490 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1701
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546356
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513700
INFO:root:FL Epoch: 490 Norm Difference for worker 1701 is 0.828507
INFO:root:FL Epoch: 490 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1105
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322621
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369115
INFO:root:FL Epoch: 490 Norm Difference for worker 1105 is 0.836921
INFO:root:FL Epoch: 490 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :182
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.977238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 182 is 0.862857
INFO:root:FL Epoch: 490 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :95
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 95 is 0.837589
INFO:root:FL Epoch: 490 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 923
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.46542610315715566 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.25219346582889557                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 1088, 523, 382, 1677, 98, 89, 290]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.152368
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157587
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.20900908857584 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.16395189315080644 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.131054
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.122106
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187017
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.20687734335660934 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.16584131643176078 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.1216
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150816
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151160
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.211501511434714 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.1649649113416672 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.124294
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1088
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442503
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349503
INFO:root:FL Epoch: 491 Norm Difference for worker 1088 is 0.635589
INFO:root:FL Epoch: 491 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :523
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883974
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518752
INFO:root:FL Epoch: 491 Norm Difference for worker 523 is 0.749165
INFO:root:FL Epoch: 491 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :382
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496713
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548885
INFO:root:FL Epoch: 491 Norm Difference for worker 382 is 0.778778
INFO:root:FL Epoch: 491 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1677
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446939
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291258
INFO:root:FL Epoch: 491 Norm Difference for worker 1677 is 0.698651
INFO:root:FL Epoch: 491 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :98
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 98 is 0.778099
INFO:root:FL Epoch: 491 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :89
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.800797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 89 is 0.884085
INFO:root:FL Epoch: 491 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :290
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.812771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 290 is 0.789926
INFO:root:FL Epoch: 491 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.46842818488092985 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.20687734335660934                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [331, 1080, 1356, 698, 1944, 796, 259, 384, 392, 19]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 492 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :331
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488150
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 331 is 0.861643
INFO:root:FL Epoch: 492 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1080
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771076
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614872
INFO:root:FL Epoch: 492 Norm Difference for worker 1080 is 0.922689
INFO:root:FL Epoch: 492 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1356
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944207
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.794108
INFO:root:FL Epoch: 492 Norm Difference for worker 1356 is 0.897659
INFO:root:FL Epoch: 492 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :698
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720847
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578109
INFO:root:FL Epoch: 492 Norm Difference for worker 698 is 0.93379
INFO:root:FL Epoch: 492 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1944
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481757
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337227
INFO:root:FL Epoch: 492 Norm Difference for worker 1944 is 0.720532
INFO:root:FL Epoch: 492 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :796
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873926
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633624
INFO:root:FL Epoch: 492 Norm Difference for worker 796 is 0.837944
INFO:root:FL Epoch: 492 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :259
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 259 is 0.805093
INFO:root:FL Epoch: 492 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :384
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638749
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434380
INFO:root:FL Epoch: 492 Norm Difference for worker 384 is 0.79354
INFO:root:FL Epoch: 492 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :392
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484674
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300528
INFO:root:FL Epoch: 492 Norm Difference for worker 392 is 0.791347
INFO:root:FL Epoch: 492 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :19
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 19 is 0.840057
INFO:root:FL Epoch: 492 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1944
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.4707150283981772 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.20744246120254198                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [1392, 707, 927, 1825, 923, 1449, 169, 1319, 496, 681]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :1392
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537622
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293796
INFO:root:FL Epoch: 493 Norm Difference for worker 1392 is 0.709913
INFO:root:FL Epoch: 493 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :707
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488676
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223336
INFO:root:FL Epoch: 493 Norm Difference for worker 707 is 0.746201
INFO:root:FL Epoch: 493 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :927
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548523
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281077
INFO:root:FL Epoch: 493 Norm Difference for worker 927 is 0.704104
INFO:root:FL Epoch: 493 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1825
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557461
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363186
INFO:root:FL Epoch: 493 Norm Difference for worker 1825 is 0.762959
INFO:root:FL Epoch: 493 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :923
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577056
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360255
INFO:root:FL Epoch: 493 Norm Difference for worker 923 is 0.613295
INFO:root:FL Epoch: 493 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1449
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833014
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348334
INFO:root:FL Epoch: 493 Norm Difference for worker 1449 is 0.794782
INFO:root:FL Epoch: 493 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :169
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 169 is 0.846125
INFO:root:FL Epoch: 493 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1319
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339911
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536409
INFO:root:FL Epoch: 493 Norm Difference for worker 1319 is 0.769918
INFO:root:FL Epoch: 493 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :496
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695115
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320577
INFO:root:FL Epoch: 493 Norm Difference for worker 496 is 0.800075
INFO:root:FL Epoch: 493 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :681
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761471
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649131
INFO:root:FL Epoch: 493 Norm Difference for worker 681 is 0.797028
INFO:root:FL Epoch: 493 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 923
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.4814216056290795 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.2696934938430786                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [999, 311, 1767, 1021, 1187, 1460, 822, 1804, 711, 228]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 494 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :999
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364996
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393309
INFO:root:FL Epoch: 494 Norm Difference for worker 999 is 0.845004
INFO:root:FL Epoch: 494 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :311
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378235
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 311 is 0.898477
INFO:root:FL Epoch: 494 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1767
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391624
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308934
INFO:root:FL Epoch: 494 Norm Difference for worker 1767 is 0.757906
INFO:root:FL Epoch: 494 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1021
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459052
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369723
INFO:root:FL Epoch: 494 Norm Difference for worker 1021 is 0.647834
INFO:root:FL Epoch: 494 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1187
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441980
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620466
INFO:root:FL Epoch: 494 Norm Difference for worker 1187 is 0.83153
INFO:root:FL Epoch: 494 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1460
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353833
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298170
INFO:root:FL Epoch: 494 Norm Difference for worker 1460 is 0.812062
INFO:root:FL Epoch: 494 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :822
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750255
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373424
INFO:root:FL Epoch: 494 Norm Difference for worker 822 is 0.847076
INFO:root:FL Epoch: 494 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1804
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484085
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386981
INFO:root:FL Epoch: 494 Norm Difference for worker 1804 is 0.869805
INFO:root:FL Epoch: 494 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :711
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527142
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338124
INFO:root:FL Epoch: 494 Norm Difference for worker 711 is 0.922411
INFO:root:FL Epoch: 494 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :228
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 228 is 0.889106
INFO:root:FL Epoch: 494 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1021
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.47742429901571837 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.2841702351967494                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [780, 63, 1298, 1777, 1947, 227, 1603, 1502, 1894, 1344]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 495 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :780
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520513
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338907
INFO:root:FL Epoch: 495 Norm Difference for worker 780 is 0.849373
INFO:root:FL Epoch: 495 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :63
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 63 is 1.058502
INFO:root:FL Epoch: 495 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1298
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667907
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463597
INFO:root:FL Epoch: 495 Norm Difference for worker 1298 is 0.888897
INFO:root:FL Epoch: 495 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1777
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549276
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659703
INFO:root:FL Epoch: 495 Norm Difference for worker 1777 is 0.933955
INFO:root:FL Epoch: 495 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1947
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331353
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581670
INFO:root:FL Epoch: 495 Norm Difference for worker 1947 is 0.867828
INFO:root:FL Epoch: 495 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :227
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468063
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 227 is 0.777201
INFO:root:FL Epoch: 495 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1603
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753978
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268114
INFO:root:FL Epoch: 495 Norm Difference for worker 1603 is 0.757321
INFO:root:FL Epoch: 495 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1502
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451572
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346552
INFO:root:FL Epoch: 495 Norm Difference for worker 1502 is 0.769294
INFO:root:FL Epoch: 495 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1894
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.949254
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294606
INFO:root:FL Epoch: 495 Norm Difference for worker 1894 is 0.942351
INFO:root:FL Epoch: 495 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1344
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349971
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466868
INFO:root:FL Epoch: 495 Norm Difference for worker 1344 is 0.838401
INFO:root:FL Epoch: 495 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 227
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.4995129511636846 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.43073495974143344                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [83, 593, 676, 1241, 405, 1473, 912, 335, 726, 15]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 496 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :83
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.978297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 83 is 0.813341
INFO:root:FL Epoch: 496 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :593
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568310
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440398
INFO:root:FL Epoch: 496 Norm Difference for worker 593 is 0.816578
INFO:root:FL Epoch: 496 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :676
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557215
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746875
INFO:root:FL Epoch: 496 Norm Difference for worker 676 is 0.893032
INFO:root:FL Epoch: 496 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1241
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386792
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447346
INFO:root:FL Epoch: 496 Norm Difference for worker 1241 is 0.776277
INFO:root:FL Epoch: 496 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :405
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332848
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251494
INFO:root:FL Epoch: 496 Norm Difference for worker 405 is 0.70401
INFO:root:FL Epoch: 496 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1473
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679972
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459696
INFO:root:FL Epoch: 496 Norm Difference for worker 1473 is 0.874626
INFO:root:FL Epoch: 496 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :912
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835754
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562804
INFO:root:FL Epoch: 496 Norm Difference for worker 912 is 0.768743
INFO:root:FL Epoch: 496 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :335
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.237255
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 335 is 0.892121
INFO:root:FL Epoch: 496 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :726
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550162
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334348
INFO:root:FL Epoch: 496 Norm Difference for worker 726 is 0.791946
INFO:root:FL Epoch: 496 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :15
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 15 is 0.782699
INFO:root:FL Epoch: 496 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 405
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.46328263423022104 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.2996131628751755                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [733, 220, 907, 1530, 605, 307, 873, 1496, 391, 607]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 497 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :733
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573609
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377316
INFO:root:FL Epoch: 497 Norm Difference for worker 733 is 0.81244
INFO:root:FL Epoch: 497 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :220
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 220 is 0.764624
INFO:root:FL Epoch: 497 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :907
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649480
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205731
INFO:root:FL Epoch: 497 Norm Difference for worker 907 is 0.812829
INFO:root:FL Epoch: 497 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1530
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315207
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655925
INFO:root:FL Epoch: 497 Norm Difference for worker 1530 is 0.871689
INFO:root:FL Epoch: 497 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :605
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307677
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514315
INFO:root:FL Epoch: 497 Norm Difference for worker 605 is 0.869704
INFO:root:FL Epoch: 497 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :307
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 307 is 0.840247
INFO:root:FL Epoch: 497 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :873
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680143
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426187
INFO:root:FL Epoch: 497 Norm Difference for worker 873 is 0.864191
INFO:root:FL Epoch: 497 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1496
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353598
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276148
INFO:root:FL Epoch: 497 Norm Difference for worker 1496 is 0.729437
INFO:root:FL Epoch: 497 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :391
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 1.042066
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725499
INFO:root:FL Epoch: 497 Norm Difference for worker 391 is 0.847824
INFO:root:FL Epoch: 497 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :607
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562941
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599735
INFO:root:FL Epoch: 497 Norm Difference for worker 607 is 0.778608
INFO:root:FL Epoch: 497 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.4622640294187209 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.30176685005426407                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [1400, 441, 67, 585, 632, 280, 890, 1637, 897, 1319]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :1400
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647821
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461255
INFO:root:FL Epoch: 498 Norm Difference for worker 1400 is 0.706114
INFO:root:FL Epoch: 498 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :441
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399199
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436962
INFO:root:FL Epoch: 498 Norm Difference for worker 441 is 0.720319
INFO:root:FL Epoch: 498 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :67
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.303383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 67 is 0.709027
INFO:root:FL Epoch: 498 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :585
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353124
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343541
INFO:root:FL Epoch: 498 Norm Difference for worker 585 is 0.687138
INFO:root:FL Epoch: 498 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :632
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455420
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357238
INFO:root:FL Epoch: 498 Norm Difference for worker 632 is 0.643419
INFO:root:FL Epoch: 498 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :280
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666041
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445733
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 280 is 0.685378
INFO:root:FL Epoch: 498 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :890
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517063
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470565
INFO:root:FL Epoch: 498 Norm Difference for worker 890 is 0.757612
INFO:root:FL Epoch: 498 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1637
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294656
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213733
INFO:root:FL Epoch: 498 Norm Difference for worker 1637 is 0.560569
INFO:root:FL Epoch: 498 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :897
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510644
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452713
INFO:root:FL Epoch: 498 Norm Difference for worker 897 is 0.71651
INFO:root:FL Epoch: 498 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1319
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747025
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472191
INFO:root:FL Epoch: 498 Norm Difference for worker 1319 is 0.674448
INFO:root:FL Epoch: 498 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.46944350530119505 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.2575964778661728                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1014, 1779, 1466, 1440, 1234, 808, 479, 1215, 188, 1752]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1014
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364331
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762790
INFO:root:FL Epoch: 499 Norm Difference for worker 1014 is 0.815313
INFO:root:FL Epoch: 499 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1779
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667646
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360837
INFO:root:FL Epoch: 499 Norm Difference for worker 1779 is 0.852919
INFO:root:FL Epoch: 499 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1466
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360314
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347808
INFO:root:FL Epoch: 499 Norm Difference for worker 1466 is 0.823223
INFO:root:FL Epoch: 499 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1440
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724141
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555776
INFO:root:FL Epoch: 499 Norm Difference for worker 1440 is 0.78822
INFO:root:FL Epoch: 499 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1234
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.986664
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707288
INFO:root:FL Epoch: 499 Norm Difference for worker 1234 is 0.884822
INFO:root:FL Epoch: 499 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :808
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506917
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514055
INFO:root:FL Epoch: 499 Norm Difference for worker 808 is 0.864241
INFO:root:FL Epoch: 499 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :479
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631271
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585597
INFO:root:FL Epoch: 499 Norm Difference for worker 479 is 0.919813
INFO:root:FL Epoch: 499 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1215
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736797
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742390
INFO:root:FL Epoch: 499 Norm Difference for worker 1215 is 0.892366
INFO:root:FL Epoch: 499 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :188
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 188 is 0.819314
INFO:root:FL Epoch: 499 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1752
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421294
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337007
INFO:root:FL Epoch: 499 Norm Difference for worker 1752 is 0.786311
INFO:root:FL Epoch: 499 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1440
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.47282345855937286 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.32821690787871677                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [465, 1676, 1137, 1286, 1292, 469, 679, 551, 1025, 1649]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :465
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534334
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596935
INFO:root:FL Epoch: 500 Norm Difference for worker 465 is 0.719261
INFO:root:FL Epoch: 500 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1676
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649346
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462915
INFO:root:FL Epoch: 500 Norm Difference for worker 1676 is 0.774738
INFO:root:FL Epoch: 500 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1137
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364636
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427664
INFO:root:FL Epoch: 500 Norm Difference for worker 1137 is 0.797114
INFO:root:FL Epoch: 500 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1286
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369029
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647685
INFO:root:FL Epoch: 500 Norm Difference for worker 1286 is 0.837444
INFO:root:FL Epoch: 500 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1292
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431753
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409158
INFO:root:FL Epoch: 500 Norm Difference for worker 1292 is 0.769141
INFO:root:FL Epoch: 500 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :469
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482458
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450544
INFO:root:FL Epoch: 500 Norm Difference for worker 469 is 0.740482
INFO:root:FL Epoch: 500 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :679
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339274
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457940
INFO:root:FL Epoch: 500 Norm Difference for worker 679 is 0.76167
INFO:root:FL Epoch: 500 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :551
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576002
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426884
INFO:root:FL Epoch: 500 Norm Difference for worker 551 is 0.709896
INFO:root:FL Epoch: 500 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1025
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470253
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393766
INFO:root:FL Epoch: 500 Norm Difference for worker 1025 is 0.766112
INFO:root:FL Epoch: 500 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1649
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820909
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577477
INFO:root:FL Epoch: 500 Norm Difference for worker 1649 is 0.771586
INFO:root:FL Epoch: 500 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.97607421875
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.47716959259089303 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.3698825240135193                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/edge-case/common-krum/stats.csv ******
