INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [595, 500, 859, 383, 1838, 1939, 1125, 353, 1260, 1834]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :595
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688655
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678628
INFO:root:FL Epoch: 1 Norm Difference for worker 595 is 0.309219
INFO:root:FL Epoch: 1 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :500
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687979
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695450
INFO:root:FL Epoch: 1 Norm Difference for worker 500 is 0.312871
INFO:root:FL Epoch: 1 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :859
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688206
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692797
INFO:root:FL Epoch: 1 Norm Difference for worker 859 is 0.339252
INFO:root:FL Epoch: 1 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :383
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695146
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691239
INFO:root:FL Epoch: 1 Norm Difference for worker 383 is 0.294267
INFO:root:FL Epoch: 1 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1838
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693395
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685373
INFO:root:FL Epoch: 1 Norm Difference for worker 1838 is 0.288625
INFO:root:FL Epoch: 1 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1939
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689367
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690727
INFO:root:FL Epoch: 1 Norm Difference for worker 1939 is 0.282308
INFO:root:FL Epoch: 1 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1125
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693816
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691197
INFO:root:FL Epoch: 1 Norm Difference for worker 1125 is 0.309659
INFO:root:FL Epoch: 1 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :353
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698617
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688889
INFO:root:FL Epoch: 1 Norm Difference for worker 353 is 0.281798
INFO:root:FL Epoch: 1 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1260
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694889
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697892
INFO:root:FL Epoch: 1 Norm Difference for worker 1260 is 0.342221
INFO:root:FL Epoch: 1 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1834
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689608
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693329
INFO:root:FL Epoch: 1 Norm Difference for worker 1834 is 0.292841
INFO:root:FL Epoch: 1 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 0 6 8 5 3 7], which are global users: [1838, 595, 1125, 1260, 1939, 383, 353]
INFO:root:Aggregating After Defense
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6895469812785878 and Test Accuracy:59.705882352941174 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.686738520860672                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1016
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688348
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670409
INFO:root:FL Epoch: 2 Norm Difference for worker 1016 is 0.39299
INFO:root:FL Epoch: 2 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :543
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697003
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675301
INFO:root:FL Epoch: 2 Norm Difference for worker 543 is 0.344555
INFO:root:FL Epoch: 2 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1103
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696136
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691961
INFO:root:FL Epoch: 2 Norm Difference for worker 1103 is 0.297794
INFO:root:FL Epoch: 2 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1820
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695242
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688489
INFO:root:FL Epoch: 2 Norm Difference for worker 1820 is 0.303601
INFO:root:FL Epoch: 2 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :768
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693480
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668366
INFO:root:FL Epoch: 2 Norm Difference for worker 768 is 0.35756
INFO:root:FL Epoch: 2 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1316
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683815
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693966
INFO:root:FL Epoch: 2 Norm Difference for worker 1316 is 0.279206
INFO:root:FL Epoch: 2 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699455
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701965
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.356791
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :276
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 276 is 0.326934
INFO:root:FL Epoch: 2 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :207
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 207 is 0.295509
INFO:root:FL Epoch: 2 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :159
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688841
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 159 is 0.30844
INFO:root:FL Epoch: 2 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 201 201]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 6 4 2], which are global users: [1316, 159, 207, 1820, 1598, 768, 1103]
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6884256145533394 and Test Accuracy:53.23529411764706 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.6537288328011831                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 3 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :263
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706713
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 263 is 0.33002
INFO:root:FL Epoch: 3 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1554
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694919
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671538
INFO:root:FL Epoch: 3 Norm Difference for worker 1554 is 0.45214
INFO:root:FL Epoch: 3 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1266
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698722
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696385
INFO:root:FL Epoch: 3 Norm Difference for worker 1266 is 0.280485
INFO:root:FL Epoch: 3 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :982
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694231
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684177
INFO:root:FL Epoch: 3 Norm Difference for worker 982 is 0.32145
INFO:root:FL Epoch: 3 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704348
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664061
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.335511
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :475
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705439
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686072
INFO:root:FL Epoch: 3 Norm Difference for worker 475 is 0.328663
INFO:root:FL Epoch: 3 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1357
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682705
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667400
INFO:root:FL Epoch: 3 Norm Difference for worker 1357 is 0.311076
INFO:root:FL Epoch: 3 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :684
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691225
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683668
INFO:root:FL Epoch: 3 Norm Difference for worker 684 is 0.326596
INFO:root:FL Epoch: 3 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1506
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675128
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698585
INFO:root:FL Epoch: 3 Norm Difference for worker 1506 is 0.341257
INFO:root:FL Epoch: 3 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1238
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697211
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681441
INFO:root:FL Epoch: 3 Norm Difference for worker 1238 is 0.325412
INFO:root:FL Epoch: 3 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [9 4 7 5 8 2 6], which are global users: [1238, 1278, 684, 475, 1506, 1266, 1357]
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6839692452374626 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.7107692956924438                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :979
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692280
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712957
INFO:root:FL Epoch: 4 Norm Difference for worker 979 is 0.371856
INFO:root:FL Epoch: 4 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :915
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694146
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686441
INFO:root:FL Epoch: 4 Norm Difference for worker 915 is 0.486818
INFO:root:FL Epoch: 4 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1324
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715360
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707416
INFO:root:FL Epoch: 4 Norm Difference for worker 1324 is 0.358762
INFO:root:FL Epoch: 4 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1034
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675665
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676619
INFO:root:FL Epoch: 4 Norm Difference for worker 1034 is 0.40419
INFO:root:FL Epoch: 4 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :360
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674514
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680897
INFO:root:FL Epoch: 4 Norm Difference for worker 360 is 0.411958
INFO:root:FL Epoch: 4 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1751
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685812
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682387
INFO:root:FL Epoch: 4 Norm Difference for worker 1751 is 0.324054
INFO:root:FL Epoch: 4 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1025
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684551
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680959
INFO:root:FL Epoch: 4 Norm Difference for worker 1025 is 0.332047
INFO:root:FL Epoch: 4 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :153
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712902
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 153 is 0.401083
INFO:root:FL Epoch: 4 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1482
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678789
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684122
INFO:root:FL Epoch: 4 Norm Difference for worker 1482 is 0.35217
INFO:root:FL Epoch: 4 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :274
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664740
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 274 is 0.326351
INFO:root:FL Epoch: 4 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 6 0 8], which are global users: [1751, 360, 1324, 1034, 1025, 979, 1482]
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.683368493528927 and Test Accuracy:54.705882352941174 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.6428716977437338                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 5 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :786
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672470
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683413
INFO:root:FL Epoch: 5 Norm Difference for worker 786 is 0.353945
INFO:root:FL Epoch: 5 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :115
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.651253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 115 is 0.393025
INFO:root:FL Epoch: 5 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :329
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 329 is 0.376814
INFO:root:FL Epoch: 5 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :440
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658753
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683437
INFO:root:FL Epoch: 5 Norm Difference for worker 440 is 0.343838
INFO:root:FL Epoch: 5 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1220
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678428
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685304
INFO:root:FL Epoch: 5 Norm Difference for worker 1220 is 0.360805
INFO:root:FL Epoch: 5 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :622
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668090
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673093
INFO:root:FL Epoch: 5 Norm Difference for worker 622 is 0.487085
INFO:root:FL Epoch: 5 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1865
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691603
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687462
INFO:root:FL Epoch: 5 Norm Difference for worker 1865 is 0.404099
INFO:root:FL Epoch: 5 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1868
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742279
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681237
INFO:root:FL Epoch: 5 Norm Difference for worker 1868 is 0.434571
INFO:root:FL Epoch: 5 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1776
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649164
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642645
INFO:root:FL Epoch: 5 Norm Difference for worker 1776 is 0.374146
INFO:root:FL Epoch: 5 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1316
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699290
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661547
INFO:root:FL Epoch: 5 Norm Difference for worker 1316 is 0.353224
INFO:root:FL Epoch: 5 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [9 4 6 2 8 3 0], which are global users: [1316, 1220, 1865, 329, 1776, 440, 786]
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6790420658448163 and Test Accuracy:58.23529411764706 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.67232213417689                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 6 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :1197
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653336
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627981
INFO:root:FL Epoch: 6 Norm Difference for worker 1197 is 0.56382
INFO:root:FL Epoch: 6 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1507
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665449
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687148
INFO:root:FL Epoch: 6 Norm Difference for worker 1507 is 0.506012
INFO:root:FL Epoch: 6 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1435
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674356
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681630
INFO:root:FL Epoch: 6 Norm Difference for worker 1435 is 0.413458
INFO:root:FL Epoch: 6 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1040
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664525
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686194
INFO:root:FL Epoch: 6 Norm Difference for worker 1040 is 0.406642
INFO:root:FL Epoch: 6 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1420
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681076
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629146
INFO:root:FL Epoch: 6 Norm Difference for worker 1420 is 0.585612
INFO:root:FL Epoch: 6 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :361
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716955
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663242
INFO:root:FL Epoch: 6 Norm Difference for worker 361 is 0.413963
INFO:root:FL Epoch: 6 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1002
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654795
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654863
INFO:root:FL Epoch: 6 Norm Difference for worker 1002 is 0.483712
INFO:root:FL Epoch: 6 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :327
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654631
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689136
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 327 is 0.410913
INFO:root:FL Epoch: 6 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :674
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681334
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674995
INFO:root:FL Epoch: 6 Norm Difference for worker 674 is 0.516534
INFO:root:FL Epoch: 6 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1021
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663237
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674062
INFO:root:FL Epoch: 6 Norm Difference for worker 1021 is 0.468647
INFO:root:FL Epoch: 6 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 8 2 9 7 5 1], which are global users: [1002, 674, 1435, 1021, 327, 361, 1507]
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6751870793454787 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7826323807239532                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 7 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :1809
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684711
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714789
INFO:root:FL Epoch: 7 Norm Difference for worker 1809 is 0.442195
INFO:root:FL Epoch: 7 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :835
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681400
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685933
INFO:root:FL Epoch: 7 Norm Difference for worker 835 is 0.478761
INFO:root:FL Epoch: 7 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :972
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701687
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640049
INFO:root:FL Epoch: 7 Norm Difference for worker 972 is 0.498499
INFO:root:FL Epoch: 7 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1512
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756392
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660799
INFO:root:FL Epoch: 7 Norm Difference for worker 1512 is 0.481645
INFO:root:FL Epoch: 7 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1161
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659033
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664169
INFO:root:FL Epoch: 7 Norm Difference for worker 1161 is 0.456118
INFO:root:FL Epoch: 7 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1280
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680278
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643658
INFO:root:FL Epoch: 7 Norm Difference for worker 1280 is 0.517964
INFO:root:FL Epoch: 7 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1341
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665059
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629551
INFO:root:FL Epoch: 7 Norm Difference for worker 1341 is 0.576347
INFO:root:FL Epoch: 7 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :243
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 243 is 0.477395
INFO:root:FL Epoch: 7 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1257
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742246
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662361
INFO:root:FL Epoch: 7 Norm Difference for worker 1257 is 0.493165
INFO:root:FL Epoch: 7 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :863
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605988
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658250
INFO:root:FL Epoch: 7 Norm Difference for worker 863 is 0.494055
INFO:root:FL Epoch: 7 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 9 8 0 7 4 2], which are global users: [835, 863, 1257, 1809, 243, 1161, 972]
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6705224969807793 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.711906373500824                             and Backdoor Test Accuracy:55.0 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1434
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654496
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682967
INFO:root:FL Epoch: 8 Norm Difference for worker 1434 is 0.526045
INFO:root:FL Epoch: 8 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :721
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680641
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708601
INFO:root:FL Epoch: 8 Norm Difference for worker 721 is 0.505186
INFO:root:FL Epoch: 8 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :363
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688089
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661494
INFO:root:FL Epoch: 8 Norm Difference for worker 363 is 0.612083
INFO:root:FL Epoch: 8 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :467
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671592
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661109
INFO:root:FL Epoch: 8 Norm Difference for worker 467 is 0.539825
INFO:root:FL Epoch: 8 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1443
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703861
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632186
INFO:root:FL Epoch: 8 Norm Difference for worker 1443 is 0.555334
INFO:root:FL Epoch: 8 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1573
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683875
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670019
INFO:root:FL Epoch: 8 Norm Difference for worker 1573 is 0.56539
INFO:root:FL Epoch: 8 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.503176
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :475
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599842
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685112
INFO:root:FL Epoch: 8 Norm Difference for worker 475 is 0.511746
INFO:root:FL Epoch: 8 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1216
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649728
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695527
INFO:root:FL Epoch: 8 Norm Difference for worker 1216 is 0.512983
INFO:root:FL Epoch: 8 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :521
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653372
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707912
INFO:root:FL Epoch: 8 Norm Difference for worker 521 is 0.507221
INFO:root:FL Epoch: 8 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 7 3 1 0 8], which are global users: [269, 521, 475, 467, 721, 1434, 1216]
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.668672551127041 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7265673776467642                             and Backdoor Test Accuracy:43.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1154
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660032
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643850
INFO:root:FL Epoch: 9 Norm Difference for worker 1154 is 0.512907
INFO:root:FL Epoch: 9 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :257
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656623
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 257 is 0.547937
INFO:root:FL Epoch: 9 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1894
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674381
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701300
INFO:root:FL Epoch: 9 Norm Difference for worker 1894 is 0.604663
INFO:root:FL Epoch: 9 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :729
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671659
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630984
INFO:root:FL Epoch: 9 Norm Difference for worker 729 is 0.550978
INFO:root:FL Epoch: 9 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1361
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657464
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654662
INFO:root:FL Epoch: 9 Norm Difference for worker 1361 is 0.578413
INFO:root:FL Epoch: 9 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :634
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688584
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723527
INFO:root:FL Epoch: 9 Norm Difference for worker 634 is 0.58165
INFO:root:FL Epoch: 9 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668308
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652331
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.57678
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :657
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619603
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656058
INFO:root:FL Epoch: 9 Norm Difference for worker 657 is 0.589343
INFO:root:FL Epoch: 9 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :28
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.713031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 28 is 0.555315
INFO:root:FL Epoch: 9 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :344
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663636
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652880
INFO:root:FL Epoch: 9 Norm Difference for worker 344 is 0.504647
INFO:root:FL Epoch: 9 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 201]
INFO:root:The chosen ones are users: [0 9 7 4 1 3 8], which are global users: [1154, 344, 657, 1361, 257, 729, 28]
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6664742091122795 and Test Accuracy:61.76470588235294 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.8048456311225891                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :322
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 322 is 0.634195
INFO:root:FL Epoch: 10 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1069
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781486
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737440
INFO:root:FL Epoch: 10 Norm Difference for worker 1069 is 0.649743
INFO:root:FL Epoch: 10 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644296
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657253
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.603947
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :716
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657943
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652217
INFO:root:FL Epoch: 10 Norm Difference for worker 716 is 0.618145
INFO:root:FL Epoch: 10 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1613
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645244
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666837
INFO:root:FL Epoch: 10 Norm Difference for worker 1613 is 0.652151
INFO:root:FL Epoch: 10 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1184
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658791
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714571
INFO:root:FL Epoch: 10 Norm Difference for worker 1184 is 0.566133
INFO:root:FL Epoch: 10 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1191
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649112
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678675
INFO:root:FL Epoch: 10 Norm Difference for worker 1191 is 0.699509
INFO:root:FL Epoch: 10 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :27
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 27 is 0.615252
INFO:root:FL Epoch: 10 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1904
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679337
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645957
INFO:root:FL Epoch: 10 Norm Difference for worker 1904 is 0.717993
INFO:root:FL Epoch: 10 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :291
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688443
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 291 is 0.616414
INFO:root:FL Epoch: 10 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [201 201 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 9], which are global users: [27, 322, 1454, 716, 1069, 1184, 291]
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6645095944404602 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.8311072885990143                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [1409, 1122, 467, 247, 1802, 1801, 1139, 1528, 498, 594]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :1409
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666151
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643259
INFO:root:FL Epoch: 11 Norm Difference for worker 1409 is 0.655587
INFO:root:FL Epoch: 11 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1122
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679414
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578033
INFO:root:FL Epoch: 11 Norm Difference for worker 1122 is 0.746822
INFO:root:FL Epoch: 11 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :467
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655819
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596456
INFO:root:FL Epoch: 11 Norm Difference for worker 467 is 0.678104
INFO:root:FL Epoch: 11 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :247
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 247 is 0.734395
INFO:root:FL Epoch: 11 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1802
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689171
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633217
INFO:root:FL Epoch: 11 Norm Difference for worker 1802 is 0.6862
INFO:root:FL Epoch: 11 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1801
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677647
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565690
INFO:root:FL Epoch: 11 Norm Difference for worker 1801 is 0.697643
INFO:root:FL Epoch: 11 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1139
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720047
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641857
INFO:root:FL Epoch: 11 Norm Difference for worker 1139 is 0.682894
INFO:root:FL Epoch: 11 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1528
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708067
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570095
INFO:root:FL Epoch: 11 Norm Difference for worker 1528 is 0.773377
INFO:root:FL Epoch: 11 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :498
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616165
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628031
INFO:root:FL Epoch: 11 Norm Difference for worker 498 is 0.68196
INFO:root:FL Epoch: 11 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :594
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629531
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645464
INFO:root:FL Epoch: 11 Norm Difference for worker 594 is 0.686602
INFO:root:FL Epoch: 11 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 6 4 2 1], which are global users: [1801, 1409, 498, 1139, 1802, 467, 1122]
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6579453594544354 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.8405344486236572                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1405
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641269
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618782
INFO:root:FL Epoch: 12 Norm Difference for worker 1405 is 0.821074
INFO:root:FL Epoch: 12 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1244
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631745
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639324
INFO:root:FL Epoch: 12 Norm Difference for worker 1244 is 0.842732
INFO:root:FL Epoch: 12 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :380
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686814
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678580
INFO:root:FL Epoch: 12 Norm Difference for worker 380 is 0.765569
INFO:root:FL Epoch: 12 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :125
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 125 is 0.81711
INFO:root:FL Epoch: 12 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :802
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608799
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592167
INFO:root:FL Epoch: 12 Norm Difference for worker 802 is 0.80604
INFO:root:FL Epoch: 12 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :840
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662633
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622887
INFO:root:FL Epoch: 12 Norm Difference for worker 840 is 0.838633
INFO:root:FL Epoch: 12 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1334
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657341
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531610
INFO:root:FL Epoch: 12 Norm Difference for worker 1334 is 0.862973
INFO:root:FL Epoch: 12 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648831
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625240
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.810994
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :689
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612556
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641284
INFO:root:FL Epoch: 12 Norm Difference for worker 689 is 0.774899
INFO:root:FL Epoch: 12 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1036
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674286
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691734
INFO:root:FL Epoch: 12 Norm Difference for worker 1036 is 0.812541
INFO:root:FL Epoch: 12 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [8 9 2 3 4 5 0], which are global users: [689, 1036, 380, 125, 802, 840, 1405]
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6562777757644653 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.9130103091398875                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1930
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611690
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512132
INFO:root:FL Epoch: 13 Norm Difference for worker 1930 is 0.991252
INFO:root:FL Epoch: 13 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1474
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607975
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546290
INFO:root:FL Epoch: 13 Norm Difference for worker 1474 is 0.902075
INFO:root:FL Epoch: 13 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :442
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698997
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732741
INFO:root:FL Epoch: 13 Norm Difference for worker 442 is 0.846919
INFO:root:FL Epoch: 13 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :232
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.718417
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 232 is 0.951822
INFO:root:FL Epoch: 13 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :116
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611720
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 116 is 0.932269
INFO:root:FL Epoch: 13 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :202
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 202 is 0.881135
INFO:root:FL Epoch: 13 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1081
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703929
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607307
INFO:root:FL Epoch: 13 Norm Difference for worker 1081 is 0.953916
INFO:root:FL Epoch: 13 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :606
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631245
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544729
INFO:root:FL Epoch: 13 Norm Difference for worker 606 is 0.924961
INFO:root:FL Epoch: 13 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1303
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639390
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657654
INFO:root:FL Epoch: 13 Norm Difference for worker 1303 is 0.940671
INFO:root:FL Epoch: 13 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :945
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686182
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611961
INFO:root:FL Epoch: 13 Norm Difference for worker 945 is 0.953857
INFO:root:FL Epoch: 13 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 201 200 200 200 200]
INFO:root:Num selected data points: [201 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 1 9 7], which are global users: [202, 116, 442, 232, 1474, 945, 606]
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6535765178063336 and Test Accuracy:59.705882352941174 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:1.0020424127578735                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1163
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600196
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578599
INFO:root:FL Epoch: 14 Norm Difference for worker 1163 is 1.034023
INFO:root:FL Epoch: 14 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1460
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609163
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639474
INFO:root:FL Epoch: 14 Norm Difference for worker 1460 is 1.023481
INFO:root:FL Epoch: 14 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :409
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581544
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599716
INFO:root:FL Epoch: 14 Norm Difference for worker 409 is 1.128849
INFO:root:FL Epoch: 14 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1123
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577644
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677147
INFO:root:FL Epoch: 14 Norm Difference for worker 1123 is 1.039404
INFO:root:FL Epoch: 14 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :604
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638718
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508303
INFO:root:FL Epoch: 14 Norm Difference for worker 604 is 1.114606
INFO:root:FL Epoch: 14 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :200
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 200 is 0.997786
INFO:root:FL Epoch: 14 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :551
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606658
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543039
INFO:root:FL Epoch: 14 Norm Difference for worker 551 is 1.001131
INFO:root:FL Epoch: 14 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1222
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684450
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531741
INFO:root:FL Epoch: 14 Norm Difference for worker 1222 is 1.062637
INFO:root:FL Epoch: 14 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1589
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616987
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577231
INFO:root:FL Epoch: 14 Norm Difference for worker 1589 is 1.010046
INFO:root:FL Epoch: 14 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :746
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632271
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598046
INFO:root:FL Epoch: 14 Norm Difference for worker 746 is 0.983235
INFO:root:FL Epoch: 14 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 6 0 3 1], which are global users: [200, 746, 1589, 551, 1163, 1123, 1460]
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6441614259691799 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:1.1224995056788127                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 15 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :1506
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573428
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548672
INFO:root:FL Epoch: 15 Norm Difference for worker 1506 is 1.187171
INFO:root:FL Epoch: 15 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :196
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 196 is 1.213333
INFO:root:FL Epoch: 15 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1478
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585160
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584219
INFO:root:FL Epoch: 15 Norm Difference for worker 1478 is 1.149689
INFO:root:FL Epoch: 15 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613895
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455553
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 1.222508
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1923
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645869
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642758
INFO:root:FL Epoch: 15 Norm Difference for worker 1923 is 1.156174
INFO:root:FL Epoch: 15 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :91
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.651895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 91 is 1.153884
INFO:root:FL Epoch: 15 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :242
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 242 is 1.119175
INFO:root:FL Epoch: 15 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1709
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566808
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649219
INFO:root:FL Epoch: 15 Norm Difference for worker 1709 is 1.171362
INFO:root:FL Epoch: 15 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1297
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746208
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679824
INFO:root:FL Epoch: 15 Norm Difference for worker 1297 is 1.170692
INFO:root:FL Epoch: 15 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1000
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587437
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603228
INFO:root:FL Epoch: 15 Norm Difference for worker 1000 is 1.198465
INFO:root:FL Epoch: 15 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 201 201 200 200]
INFO:root:The chosen ones are users: [5 0 2 6 1 4 3], which are global users: [91, 1506, 1478, 242, 196, 1923, 1595]
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6393359478782205 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:1.1966280738512676                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :639
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617692
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457907
INFO:root:FL Epoch: 16 Norm Difference for worker 639 is 1.313741
INFO:root:FL Epoch: 16 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :327
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 327 is 1.358638
INFO:root:FL Epoch: 16 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :503
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642801
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636791
INFO:root:FL Epoch: 16 Norm Difference for worker 503 is 1.321715
INFO:root:FL Epoch: 16 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1110
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614364
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564210
INFO:root:FL Epoch: 16 Norm Difference for worker 1110 is 1.303324
INFO:root:FL Epoch: 16 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :839
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599614
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536818
INFO:root:FL Epoch: 16 Norm Difference for worker 839 is 1.334644
INFO:root:FL Epoch: 16 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :472
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709810
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472026
INFO:root:FL Epoch: 16 Norm Difference for worker 472 is 1.344992
INFO:root:FL Epoch: 16 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :274
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 274 is 1.319341
INFO:root:FL Epoch: 16 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :481
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500741
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609537
INFO:root:FL Epoch: 16 Norm Difference for worker 481 is 1.353515
INFO:root:FL Epoch: 16 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :805
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669229
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663945
INFO:root:FL Epoch: 16 Norm Difference for worker 805 is 1.32248
INFO:root:FL Epoch: 16 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1606
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600800
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649587
INFO:root:FL Epoch: 16 Norm Difference for worker 1606 is 1.313914
INFO:root:FL Epoch: 16 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 9 6 4 5 0 2], which are global users: [1110, 1606, 274, 839, 472, 639, 503]
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6214197979253882 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.2638175288836162                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :116
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 116 is 1.455232
INFO:root:FL Epoch: 17 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1658
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531688
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560708
INFO:root:FL Epoch: 17 Norm Difference for worker 1658 is 1.458047
INFO:root:FL Epoch: 17 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :988
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576911
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393664
INFO:root:FL Epoch: 17 Norm Difference for worker 988 is 1.471129
INFO:root:FL Epoch: 17 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1655
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617884
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511599
INFO:root:FL Epoch: 17 Norm Difference for worker 1655 is 1.470739
INFO:root:FL Epoch: 17 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :62
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552273
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 62 is 1.425362
INFO:root:FL Epoch: 17 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :870
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609593
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650890
INFO:root:FL Epoch: 17 Norm Difference for worker 870 is 1.460402
INFO:root:FL Epoch: 17 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :955
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655433
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492173
INFO:root:FL Epoch: 17 Norm Difference for worker 955 is 1.476894
INFO:root:FL Epoch: 17 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :304
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612497
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 304 is 1.420409
INFO:root:FL Epoch: 17 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1427
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658014
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623720
INFO:root:FL Epoch: 17 Norm Difference for worker 1427 is 1.401842
INFO:root:FL Epoch: 17 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :652
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536199
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575550
INFO:root:FL Epoch: 17 Norm Difference for worker 652 is 1.439339
INFO:root:FL Epoch: 17 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 201 201 200 200]
INFO:root:The chosen ones are users: [8 9 0 7 4 5 1], which are global users: [1427, 652, 116, 304, 62, 870, 1658]
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6250992557581734 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:1.173357327779134                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1037
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669945
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594264
INFO:root:FL Epoch: 18 Norm Difference for worker 1037 is 1.464291
INFO:root:FL Epoch: 18 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1375
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714871
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447068
INFO:root:FL Epoch: 18 Norm Difference for worker 1375 is 1.466506
INFO:root:FL Epoch: 18 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :637
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620817
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425927
INFO:root:FL Epoch: 18 Norm Difference for worker 637 is 1.565195
INFO:root:FL Epoch: 18 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :293
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682125
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 293 is 1.468364
INFO:root:FL Epoch: 18 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1435
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703093
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593465
INFO:root:FL Epoch: 18 Norm Difference for worker 1435 is 1.5196
INFO:root:FL Epoch: 18 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1294
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715458
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500003
INFO:root:FL Epoch: 18 Norm Difference for worker 1294 is 1.458573
INFO:root:FL Epoch: 18 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :712
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808576
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508198
INFO:root:FL Epoch: 18 Norm Difference for worker 712 is 1.585177
INFO:root:FL Epoch: 18 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :440
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571707
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643588
INFO:root:FL Epoch: 18 Norm Difference for worker 440 is 1.384477
INFO:root:FL Epoch: 18 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1768
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622015
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571270
INFO:root:FL Epoch: 18 Norm Difference for worker 1768 is 1.416303
INFO:root:FL Epoch: 18 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1805
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581770
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612162
INFO:root:FL Epoch: 18 Norm Difference for worker 1805 is 1.497788
INFO:root:FL Epoch: 18 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 8 3 1 5 4], which are global users: [440, 1037, 1768, 293, 1375, 1294, 1435]
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.61539485875298 and Test Accuracy:65.0 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.2871030966440837                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 19 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :772
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758433
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348324
INFO:root:FL Epoch: 19 Norm Difference for worker 772 is 1.469122
INFO:root:FL Epoch: 19 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :212
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 212 is 1.510287
INFO:root:FL Epoch: 19 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :407
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505744
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541065
INFO:root:FL Epoch: 19 Norm Difference for worker 407 is 1.457292
INFO:root:FL Epoch: 19 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :782
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643892
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638312
INFO:root:FL Epoch: 19 Norm Difference for worker 782 is 1.593702
INFO:root:FL Epoch: 19 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1093
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613467
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538956
INFO:root:FL Epoch: 19 Norm Difference for worker 1093 is 1.504568
INFO:root:FL Epoch: 19 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1764
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718987
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518462
INFO:root:FL Epoch: 19 Norm Difference for worker 1764 is 1.607264
INFO:root:FL Epoch: 19 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633494
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 1.533046
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :351
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646755
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460305
INFO:root:FL Epoch: 19 Norm Difference for worker 351 is 1.46668
INFO:root:FL Epoch: 19 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1391
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743495
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573205
INFO:root:FL Epoch: 19 Norm Difference for worker 1391 is 1.53864
INFO:root:FL Epoch: 19 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :334
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 334 is 1.581887
INFO:root:FL Epoch: 19 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 4 2 8 1 7 0], which are global users: [38, 1093, 407, 1391, 212, 351, 772]
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6271787163089303 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.391416331132253                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :697
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638983
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480286
INFO:root:FL Epoch: 20 Norm Difference for worker 697 is 1.653996
INFO:root:FL Epoch: 20 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1059
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630127
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545807
INFO:root:FL Epoch: 20 Norm Difference for worker 1059 is 1.542111
INFO:root:FL Epoch: 20 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :940
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723119
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476619
INFO:root:FL Epoch: 20 Norm Difference for worker 940 is 1.585531
INFO:root:FL Epoch: 20 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1796
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578672
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646372
INFO:root:FL Epoch: 20 Norm Difference for worker 1796 is 1.598523
INFO:root:FL Epoch: 20 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1162
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550530
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541957
INFO:root:FL Epoch: 20 Norm Difference for worker 1162 is 1.63446
INFO:root:FL Epoch: 20 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1765
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643768
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682768
INFO:root:FL Epoch: 20 Norm Difference for worker 1765 is 1.527742
INFO:root:FL Epoch: 20 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :469
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629745
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489564
INFO:root:FL Epoch: 20 Norm Difference for worker 469 is 1.554952
INFO:root:FL Epoch: 20 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1470
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532938
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435959
INFO:root:FL Epoch: 20 Norm Difference for worker 1470 is 1.492897
INFO:root:FL Epoch: 20 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :442
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742886
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554449
INFO:root:FL Epoch: 20 Norm Difference for worker 442 is 1.53249
INFO:root:FL Epoch: 20 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1373
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688144
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433541
INFO:root:FL Epoch: 20 Norm Difference for worker 1373 is 1.559657
INFO:root:FL Epoch: 20 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 8 1 5 6], which are global users: [1470, 1373, 940, 442, 1059, 1765, 469]
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6159423011190751 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.1843889355659485                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [188, 485, 797, 1233, 876, 159, 811, 1592, 1089, 1895]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :188
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533922
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 188 is 1.512651
INFO:root:FL Epoch: 21 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :485
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698717
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502048
INFO:root:FL Epoch: 21 Norm Difference for worker 485 is 1.628909
INFO:root:FL Epoch: 21 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :797
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686687
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586567
INFO:root:FL Epoch: 21 Norm Difference for worker 797 is 1.566518
INFO:root:FL Epoch: 21 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1233
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673765
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503588
INFO:root:FL Epoch: 21 Norm Difference for worker 1233 is 1.64329
INFO:root:FL Epoch: 21 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :876
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655466
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599528
INFO:root:FL Epoch: 21 Norm Difference for worker 876 is 1.566228
INFO:root:FL Epoch: 21 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :159
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.768048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 159 is 1.504997
INFO:root:FL Epoch: 21 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :811
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811297
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481406
INFO:root:FL Epoch: 21 Norm Difference for worker 811 is 1.539719
INFO:root:FL Epoch: 21 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1592
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671937
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541504
INFO:root:FL Epoch: 21 Norm Difference for worker 1592 is 1.573727
INFO:root:FL Epoch: 21 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1089
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649880
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520090
INFO:root:FL Epoch: 21 Norm Difference for worker 1089 is 1.513142
INFO:root:FL Epoch: 21 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1895
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858720
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576978
INFO:root:FL Epoch: 21 Norm Difference for worker 1895 is 1.599052
INFO:root:FL Epoch: 21 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [8 0 4 5 6 9 7], which are global users: [1089, 188, 876, 159, 811, 1895, 1592]
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6114242146996891 and Test Accuracy:65.0 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:1.1514854828516643                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 22 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :1716
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570050
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482839
INFO:root:FL Epoch: 22 Norm Difference for worker 1716 is 1.403495
INFO:root:FL Epoch: 22 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :910
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547043
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555279
INFO:root:FL Epoch: 22 Norm Difference for worker 910 is 1.508312
INFO:root:FL Epoch: 22 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1098
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490931
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351634
INFO:root:FL Epoch: 22 Norm Difference for worker 1098 is 1.518823
INFO:root:FL Epoch: 22 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1721
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486141
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592090
INFO:root:FL Epoch: 22 Norm Difference for worker 1721 is 1.484503
INFO:root:FL Epoch: 22 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :576
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515721
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490995
INFO:root:FL Epoch: 22 Norm Difference for worker 576 is 1.399029
INFO:root:FL Epoch: 22 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :104
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.829584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 104 is 1.412739
INFO:root:FL Epoch: 22 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1834
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622271
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577298
INFO:root:FL Epoch: 22 Norm Difference for worker 1834 is 1.494127
INFO:root:FL Epoch: 22 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1178
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658949
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430304
INFO:root:FL Epoch: 22 Norm Difference for worker 1178 is 1.473685
INFO:root:FL Epoch: 22 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :810
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638482
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448673
INFO:root:FL Epoch: 22 Norm Difference for worker 810 is 1.475675
INFO:root:FL Epoch: 22 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1047
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567327
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507110
INFO:root:FL Epoch: 22 Norm Difference for worker 1047 is 1.477126
INFO:root:FL Epoch: 22 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [4 0 8 5 1 9 3], which are global users: [576, 1716, 810, 104, 910, 1047, 1721]
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6277626595076393 and Test Accuracy:65.0 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:1.3269863526026409                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1150
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553274
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456204
INFO:root:FL Epoch: 23 Norm Difference for worker 1150 is 1.503638
INFO:root:FL Epoch: 23 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :703
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591915
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567824
INFO:root:FL Epoch: 23 Norm Difference for worker 703 is 1.563969
INFO:root:FL Epoch: 23 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1942
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537069
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651376
INFO:root:FL Epoch: 23 Norm Difference for worker 1942 is 1.646277
INFO:root:FL Epoch: 23 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :362
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632575
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640742
INFO:root:FL Epoch: 23 Norm Difference for worker 362 is 1.650472
INFO:root:FL Epoch: 23 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1475
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583854
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466745
INFO:root:FL Epoch: 23 Norm Difference for worker 1475 is 1.594478
INFO:root:FL Epoch: 23 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :742
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520429
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456174
INFO:root:FL Epoch: 23 Norm Difference for worker 742 is 1.621102
INFO:root:FL Epoch: 23 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648492
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575467
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 1.500214
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :355
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570907
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562615
INFO:root:FL Epoch: 23 Norm Difference for worker 355 is 1.640838
INFO:root:FL Epoch: 23 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :747
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569866
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428876
INFO:root:FL Epoch: 23 Norm Difference for worker 747 is 1.623798
INFO:root:FL Epoch: 23 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :802
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643052
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614693
INFO:root:FL Epoch: 23 Norm Difference for worker 802 is 1.66804
INFO:root:FL Epoch: 23 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 6 3 4 8 9], which are global users: [703, 1150, 1557, 362, 1475, 747, 802]
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.635267427738975 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:1.4681305885314941                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498573
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424694
INFO:root:FL Epoch: 24 Norm Difference for worker 858 is 1.604501
INFO:root:FL Epoch: 24 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :699
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592106
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494051
INFO:root:FL Epoch: 24 Norm Difference for worker 699 is 1.681041
INFO:root:FL Epoch: 24 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :206
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579911
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 206 is 1.535231
INFO:root:FL Epoch: 24 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1820
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627895
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555830
INFO:root:FL Epoch: 24 Norm Difference for worker 1820 is 1.67495
INFO:root:FL Epoch: 24 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1414
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635141
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513165
INFO:root:FL Epoch: 24 Norm Difference for worker 1414 is 1.632857
INFO:root:FL Epoch: 24 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :474
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636981
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569567
INFO:root:FL Epoch: 24 Norm Difference for worker 474 is 1.617912
INFO:root:FL Epoch: 24 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :7
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.743526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 7 is 1.563318
INFO:root:FL Epoch: 24 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1914
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585918
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626720
INFO:root:FL Epoch: 24 Norm Difference for worker 1914 is 1.584497
INFO:root:FL Epoch: 24 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :865
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729661
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412393
INFO:root:FL Epoch: 24 Norm Difference for worker 865 is 1.62297
INFO:root:FL Epoch: 24 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :249
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561763
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 249 is 1.538437
INFO:root:FL Epoch: 24 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [201 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 8 4 7 5], which are global users: [7, 249, 206, 865, 1414, 1914, 474]
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6251149791128495 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:1.436653772989909                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1399
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614749
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431388
INFO:root:FL Epoch: 25 Norm Difference for worker 1399 is 1.626671
INFO:root:FL Epoch: 25 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :693
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496207
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524782
INFO:root:FL Epoch: 25 Norm Difference for worker 693 is 1.649545
INFO:root:FL Epoch: 25 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1217
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584736
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479333
INFO:root:FL Epoch: 25 Norm Difference for worker 1217 is 1.707998
INFO:root:FL Epoch: 25 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :70
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 70 is 1.553035
INFO:root:FL Epoch: 25 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :496
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734427
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526723
INFO:root:FL Epoch: 25 Norm Difference for worker 496 is 1.597756
INFO:root:FL Epoch: 25 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :407
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658455
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311707
INFO:root:FL Epoch: 25 Norm Difference for worker 407 is 1.538435
INFO:root:FL Epoch: 25 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :317
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391887
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 317 is 1.620949
INFO:root:FL Epoch: 25 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :98
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 98 is 1.656501
INFO:root:FL Epoch: 25 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1286
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670311
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465098
INFO:root:FL Epoch: 25 Norm Difference for worker 1286 is 1.60552
INFO:root:FL Epoch: 25 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1251
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569082
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387373
INFO:root:FL Epoch: 25 Norm Difference for worker 1251 is 1.751996
INFO:root:FL Epoch: 25 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 201 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 201 200]
INFO:root:The chosen ones are users: [5 4 8 3 0 7 1], which are global users: [407, 496, 1286, 70, 1399, 98, 693]
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6325086320147795 and Test Accuracy:64.11764705882354 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.6975998481114705                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 26 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :1748
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663834
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405879
INFO:root:FL Epoch: 26 Norm Difference for worker 1748 is 1.648379
INFO:root:FL Epoch: 26 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1403
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702673
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427140
INFO:root:FL Epoch: 26 Norm Difference for worker 1403 is 1.655
INFO:root:FL Epoch: 26 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1456
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720723
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466551
INFO:root:FL Epoch: 26 Norm Difference for worker 1456 is 1.689879
INFO:root:FL Epoch: 26 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1021
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551076
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396886
INFO:root:FL Epoch: 26 Norm Difference for worker 1021 is 1.543565
INFO:root:FL Epoch: 26 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1824
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496808
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702661
INFO:root:FL Epoch: 26 Norm Difference for worker 1824 is 1.76379
INFO:root:FL Epoch: 26 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :311
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 311 is 1.611123
INFO:root:FL Epoch: 26 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :906
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538399
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490083
INFO:root:FL Epoch: 26 Norm Difference for worker 906 is 1.675391
INFO:root:FL Epoch: 26 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1618
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732541
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616491
INFO:root:FL Epoch: 26 Norm Difference for worker 1618 is 1.591546
INFO:root:FL Epoch: 26 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :900
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647050
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533465
INFO:root:FL Epoch: 26 Norm Difference for worker 900 is 1.839991
INFO:root:FL Epoch: 26 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1277
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583048
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582673
INFO:root:FL Epoch: 26 Norm Difference for worker 1277 is 1.654501
INFO:root:FL Epoch: 26 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 9 7 3 1 5 0], which are global users: [906, 1277, 1618, 1021, 1403, 311, 1748]
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6034515482537887 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:1.4860622485478718                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 27 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1930
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599566
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322186
INFO:root:FL Epoch: 27 Norm Difference for worker 1930 is 1.703463
INFO:root:FL Epoch: 27 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1641
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672757
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556731
INFO:root:FL Epoch: 27 Norm Difference for worker 1641 is 1.710788
INFO:root:FL Epoch: 27 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :786
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659687
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524459
INFO:root:FL Epoch: 27 Norm Difference for worker 786 is 1.715269
INFO:root:FL Epoch: 27 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1944
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725610
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384940
INFO:root:FL Epoch: 27 Norm Difference for worker 1944 is 1.605356
INFO:root:FL Epoch: 27 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :949
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611896
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675367
INFO:root:FL Epoch: 27 Norm Difference for worker 949 is 1.765592
INFO:root:FL Epoch: 27 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424566
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 1.609928
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1024
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719800
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439094
INFO:root:FL Epoch: 27 Norm Difference for worker 1024 is 1.661009
INFO:root:FL Epoch: 27 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :860
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796317
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476335
INFO:root:FL Epoch: 27 Norm Difference for worker 860 is 1.793124
INFO:root:FL Epoch: 27 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :79
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 79 is 1.680558
INFO:root:FL Epoch: 27 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1497
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546747
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520753
INFO:root:FL Epoch: 27 Norm Difference for worker 1497 is 1.67532
INFO:root:FL Epoch: 27 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [6 9 2 3 8 5 0], which are global users: [1024, 1497, 786, 1944, 79, 161, 1930]
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6151768863201141 and Test Accuracy:65.0 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:1.0326649745305378                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :533
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579689
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642863
INFO:root:FL Epoch: 28 Norm Difference for worker 533 is 1.624067
INFO:root:FL Epoch: 28 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1370
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600750
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454166
INFO:root:FL Epoch: 28 Norm Difference for worker 1370 is 1.622189
INFO:root:FL Epoch: 28 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1778
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445006
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415154
INFO:root:FL Epoch: 28 Norm Difference for worker 1778 is 1.592369
INFO:root:FL Epoch: 28 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :376
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531712
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462336
INFO:root:FL Epoch: 28 Norm Difference for worker 376 is 1.601021
INFO:root:FL Epoch: 28 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1688
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645695
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527232
INFO:root:FL Epoch: 28 Norm Difference for worker 1688 is 1.554291
INFO:root:FL Epoch: 28 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1791
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751791
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480092
INFO:root:FL Epoch: 28 Norm Difference for worker 1791 is 1.554145
INFO:root:FL Epoch: 28 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :744
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527617
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517456
INFO:root:FL Epoch: 28 Norm Difference for worker 744 is 1.605486
INFO:root:FL Epoch: 28 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :605
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685440
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551737
INFO:root:FL Epoch: 28 Norm Difference for worker 605 is 1.751315
INFO:root:FL Epoch: 28 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1458
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669367
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579820
INFO:root:FL Epoch: 28 Norm Difference for worker 1458 is 1.610641
INFO:root:FL Epoch: 28 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :452
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828007
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532497
INFO:root:FL Epoch: 28 Norm Difference for worker 452 is 1.616019
INFO:root:FL Epoch: 28 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 5 2 8 1 6], which are global users: [1688, 452, 1791, 1778, 1458, 1370, 744]
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6157308185801786 and Test Accuracy:64.11764705882354 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.317353884379069                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :173
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 173 is 1.693669
INFO:root:FL Epoch: 29 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1917
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634351
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493606
INFO:root:FL Epoch: 29 Norm Difference for worker 1917 is 1.602248
INFO:root:FL Epoch: 29 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1341
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608113
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433608
INFO:root:FL Epoch: 29 Norm Difference for worker 1341 is 1.555331
INFO:root:FL Epoch: 29 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :789
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677464
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505986
INFO:root:FL Epoch: 29 Norm Difference for worker 789 is 1.704417
INFO:root:FL Epoch: 29 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :961
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665870
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452530
INFO:root:FL Epoch: 29 Norm Difference for worker 961 is 1.643585
INFO:root:FL Epoch: 29 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1601
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599186
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392317
INFO:root:FL Epoch: 29 Norm Difference for worker 1601 is 1.696422
INFO:root:FL Epoch: 29 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1755
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641573
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443614
INFO:root:FL Epoch: 29 Norm Difference for worker 1755 is 1.651361
INFO:root:FL Epoch: 29 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1597
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516222
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499457
INFO:root:FL Epoch: 29 Norm Difference for worker 1597 is 1.717054
INFO:root:FL Epoch: 29 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1906
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562155
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535224
INFO:root:FL Epoch: 29 Norm Difference for worker 1906 is 1.712662
INFO:root:FL Epoch: 29 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :545
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591326
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450232
INFO:root:FL Epoch: 29 Norm Difference for worker 545 is 1.559608
INFO:root:FL Epoch: 29 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 2 4 7 6 3], which are global users: [1917, 545, 1341, 961, 1597, 1755, 789]
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6281337983467999 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:1.65887447198232                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :97
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.563779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 97 is 1.779082
INFO:root:FL Epoch: 30 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585538
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525008
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 1.757251
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1598
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433913
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391917
INFO:root:FL Epoch: 30 Norm Difference for worker 1598 is 1.758725
INFO:root:FL Epoch: 30 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1172
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677490
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545116
INFO:root:FL Epoch: 30 Norm Difference for worker 1172 is 1.786452
INFO:root:FL Epoch: 30 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :189
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 189 is 1.711572
INFO:root:FL Epoch: 30 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1585
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841008
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378357
INFO:root:FL Epoch: 30 Norm Difference for worker 1585 is 1.822262
INFO:root:FL Epoch: 30 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1215
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686666
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431281
INFO:root:FL Epoch: 30 Norm Difference for worker 1215 is 1.728682
INFO:root:FL Epoch: 30 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :439
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556534
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409185
INFO:root:FL Epoch: 30 Norm Difference for worker 439 is 1.742338
INFO:root:FL Epoch: 30 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :573
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486819
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454472
INFO:root:FL Epoch: 30 Norm Difference for worker 573 is 1.860471
INFO:root:FL Epoch: 30 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1311
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457892
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343586
INFO:root:FL Epoch: 30 Norm Difference for worker 1311 is 1.885642
INFO:root:FL Epoch: 30 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 4 2 7 1 0 5], which are global users: [1215, 189, 1598, 439, 1517, 97, 1585]
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6044346234377693 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:1.7408643960952759                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [1693, 599, 1613, 1374, 698, 1310, 1539, 786, 1330, 1413]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 31 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :1693
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597989
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524212
INFO:root:FL Epoch: 31 Norm Difference for worker 1693 is 1.744035
INFO:root:FL Epoch: 31 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :599
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646817
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319352
INFO:root:FL Epoch: 31 Norm Difference for worker 599 is 1.730454
INFO:root:FL Epoch: 31 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1613
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700627
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430475
INFO:root:FL Epoch: 31 Norm Difference for worker 1613 is 1.803707
INFO:root:FL Epoch: 31 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1374
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499046
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497062
INFO:root:FL Epoch: 31 Norm Difference for worker 1374 is 1.722552
INFO:root:FL Epoch: 31 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :698
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632990
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341219
INFO:root:FL Epoch: 31 Norm Difference for worker 698 is 1.748794
INFO:root:FL Epoch: 31 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1310
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524978
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399780
INFO:root:FL Epoch: 31 Norm Difference for worker 1310 is 1.818518
INFO:root:FL Epoch: 31 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1539
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491268
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423319
INFO:root:FL Epoch: 31 Norm Difference for worker 1539 is 1.728928
INFO:root:FL Epoch: 31 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :786
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575646
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382839
INFO:root:FL Epoch: 31 Norm Difference for worker 786 is 1.782231
INFO:root:FL Epoch: 31 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1330
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510930
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487132
INFO:root:FL Epoch: 31 Norm Difference for worker 1330 is 1.888925
INFO:root:FL Epoch: 31 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1413
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591031
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420895
INFO:root:FL Epoch: 31 Norm Difference for worker 1413 is 1.817523
INFO:root:FL Epoch: 31 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 7 3 4 1 9], which are global users: [1539, 1693, 786, 1374, 698, 599, 1413]
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.5823744009522831 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:1.4876182277997334                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :1528
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601217
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344723
INFO:root:FL Epoch: 32 Norm Difference for worker 1528 is 1.698054
INFO:root:FL Epoch: 32 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :546
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586324
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377871
INFO:root:FL Epoch: 32 Norm Difference for worker 546 is 1.750583
INFO:root:FL Epoch: 32 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1315
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498675
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444480
INFO:root:FL Epoch: 32 Norm Difference for worker 1315 is 1.797421
INFO:root:FL Epoch: 32 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 1.691334
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :504
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539106
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415618
INFO:root:FL Epoch: 32 Norm Difference for worker 504 is 1.773963
INFO:root:FL Epoch: 32 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :250
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 250 is 1.718852
INFO:root:FL Epoch: 32 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :655
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595227
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373200
INFO:root:FL Epoch: 32 Norm Difference for worker 655 is 1.721358
INFO:root:FL Epoch: 32 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1640
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637908
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514896
INFO:root:FL Epoch: 32 Norm Difference for worker 1640 is 1.806126
INFO:root:FL Epoch: 32 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1386
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596060
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424490
INFO:root:FL Epoch: 32 Norm Difference for worker 1386 is 1.710128
INFO:root:FL Epoch: 32 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :46
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392655
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 46 is 1.759243
INFO:root:FL Epoch: 32 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 201]
INFO:root:Num selected data points: [201 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [3 0 1 9 8 6 5], which are global users: [41, 1528, 546, 46, 1386, 655, 250]
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.5865843155804802 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.9557518362998962                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1149
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435962
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517275
INFO:root:FL Epoch: 33 Norm Difference for worker 1149 is 1.9825
INFO:root:FL Epoch: 33 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :529
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488235
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396546
INFO:root:FL Epoch: 33 Norm Difference for worker 529 is 1.925957
INFO:root:FL Epoch: 33 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :986
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739957
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427027
INFO:root:FL Epoch: 33 Norm Difference for worker 986 is 2.043303
INFO:root:FL Epoch: 33 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :911
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575930
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597244
INFO:root:FL Epoch: 33 Norm Difference for worker 911 is 2.024429
INFO:root:FL Epoch: 33 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :260
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 260 is 1.934701
INFO:root:FL Epoch: 33 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :855
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424338
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478988
INFO:root:FL Epoch: 33 Norm Difference for worker 855 is 1.991805
INFO:root:FL Epoch: 33 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :478
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508029
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391910
INFO:root:FL Epoch: 33 Norm Difference for worker 478 is 1.94054
INFO:root:FL Epoch: 33 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1001
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487646
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383649
INFO:root:FL Epoch: 33 Norm Difference for worker 1001 is 1.785337
INFO:root:FL Epoch: 33 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :407
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574318
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333887
INFO:root:FL Epoch: 33 Norm Difference for worker 407 is 1.762448
INFO:root:FL Epoch: 33 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1886
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695906
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429778
INFO:root:FL Epoch: 33 Norm Difference for worker 1886 is 2.041011
INFO:root:FL Epoch: 33 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 8 7 1 4 5], which are global users: [478, 1149, 407, 1001, 529, 260, 855]
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.5732295250191408 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:1.8650631308555603                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1640
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598726
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519498
INFO:root:FL Epoch: 34 Norm Difference for worker 1640 is 1.70783
INFO:root:FL Epoch: 34 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :942
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585321
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441168
INFO:root:FL Epoch: 34 Norm Difference for worker 942 is 1.699024
INFO:root:FL Epoch: 34 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :389
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633637
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468050
INFO:root:FL Epoch: 34 Norm Difference for worker 389 is 1.719033
INFO:root:FL Epoch: 34 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :907
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530885
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364773
INFO:root:FL Epoch: 34 Norm Difference for worker 907 is 1.738972
INFO:root:FL Epoch: 34 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1081
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587968
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430491
INFO:root:FL Epoch: 34 Norm Difference for worker 1081 is 1.730962
INFO:root:FL Epoch: 34 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1797
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615747
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456485
INFO:root:FL Epoch: 34 Norm Difference for worker 1797 is 1.75482
INFO:root:FL Epoch: 34 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1890
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760818
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448953
INFO:root:FL Epoch: 34 Norm Difference for worker 1890 is 1.743592
INFO:root:FL Epoch: 34 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :922
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850558
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476427
INFO:root:FL Epoch: 34 Norm Difference for worker 922 is 1.797095
INFO:root:FL Epoch: 34 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1593
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697194
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527022
INFO:root:FL Epoch: 34 Norm Difference for worker 1593 is 1.676571
INFO:root:FL Epoch: 34 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1411
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583849
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576633
INFO:root:FL Epoch: 34 Norm Difference for worker 1411 is 1.688925
INFO:root:FL Epoch: 34 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [3 0 8 9 2 6 1], which are global users: [907, 1640, 1593, 1411, 389, 1890, 942]
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.5812409677926231 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.718079686164856                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1678
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800497
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556568
INFO:root:FL Epoch: 35 Norm Difference for worker 1678 is 1.651481
INFO:root:FL Epoch: 35 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1654
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541395
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561619
INFO:root:FL Epoch: 35 Norm Difference for worker 1654 is 1.817811
INFO:root:FL Epoch: 35 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1413
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430535
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478323
INFO:root:FL Epoch: 35 Norm Difference for worker 1413 is 1.747735
INFO:root:FL Epoch: 35 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :547
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579522
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464803
INFO:root:FL Epoch: 35 Norm Difference for worker 547 is 1.783569
INFO:root:FL Epoch: 35 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1443
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749646
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386083
INFO:root:FL Epoch: 35 Norm Difference for worker 1443 is 1.767562
INFO:root:FL Epoch: 35 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :144
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.796419
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538245
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 144 is 1.77289
INFO:root:FL Epoch: 35 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :892
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671049
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269735
INFO:root:FL Epoch: 35 Norm Difference for worker 892 is 1.721681
INFO:root:FL Epoch: 35 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :191
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611859
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 191 is 1.85508
INFO:root:FL Epoch: 35 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :340
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738661
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403327
INFO:root:FL Epoch: 35 Norm Difference for worker 340 is 1.774598
INFO:root:FL Epoch: 35 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1558
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582522
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498980
INFO:root:FL Epoch: 35 Norm Difference for worker 1558 is 1.795141
INFO:root:FL Epoch: 35 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 6 4 2 9 8], which are global users: [144, 1678, 892, 1443, 1413, 1558, 340]
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.5690941915792578 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.4413881103197734                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1323
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741011
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487181
INFO:root:FL Epoch: 36 Norm Difference for worker 1323 is 1.835484
INFO:root:FL Epoch: 36 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1216
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687812
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374631
INFO:root:FL Epoch: 36 Norm Difference for worker 1216 is 1.753854
INFO:root:FL Epoch: 36 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513725
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444294
INFO:root:FL Epoch: 36 Norm Difference for worker 1937 is 1.83531
INFO:root:FL Epoch: 36 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :432
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641105
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439406
INFO:root:FL Epoch: 36 Norm Difference for worker 432 is 1.646136
INFO:root:FL Epoch: 36 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1511
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585971
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623435
INFO:root:FL Epoch: 36 Norm Difference for worker 1511 is 1.901824
INFO:root:FL Epoch: 36 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :669
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697038
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471539
INFO:root:FL Epoch: 36 Norm Difference for worker 669 is 1.862681
INFO:root:FL Epoch: 36 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1891
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797593
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525089
INFO:root:FL Epoch: 36 Norm Difference for worker 1891 is 1.694074
INFO:root:FL Epoch: 36 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1824
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480974
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632551
INFO:root:FL Epoch: 36 Norm Difference for worker 1824 is 1.923909
INFO:root:FL Epoch: 36 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :228
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 228 is 1.776362
INFO:root:FL Epoch: 36 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :447
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732041
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491790
INFO:root:FL Epoch: 36 Norm Difference for worker 447 is 1.844279
INFO:root:FL Epoch: 36 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 6], which are global users: [228, 447, 1937, 432, 1216, 669, 1891]
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.5665064594324898 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.6186015009880066                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 37 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :400
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684574
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490397
INFO:root:FL Epoch: 37 Norm Difference for worker 400 is 1.798388
INFO:root:FL Epoch: 37 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :3
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438452
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 3 is 1.897918
INFO:root:FL Epoch: 37 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1265
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709672
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386244
INFO:root:FL Epoch: 37 Norm Difference for worker 1265 is 1.883584
INFO:root:FL Epoch: 37 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :532
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509154
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563341
INFO:root:FL Epoch: 37 Norm Difference for worker 532 is 1.88132
INFO:root:FL Epoch: 37 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1836
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634758
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424925
INFO:root:FL Epoch: 37 Norm Difference for worker 1836 is 1.762248
INFO:root:FL Epoch: 37 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :270
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 270 is 1.789029
INFO:root:FL Epoch: 37 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1792
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602883
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422405
INFO:root:FL Epoch: 37 Norm Difference for worker 1792 is 1.660478
INFO:root:FL Epoch: 37 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1318
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551683
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411168
INFO:root:FL Epoch: 37 Norm Difference for worker 1318 is 1.761178
INFO:root:FL Epoch: 37 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :159
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545105
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492082
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 159 is 1.758342
INFO:root:FL Epoch: 37 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :894
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594548
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391443
INFO:root:FL Epoch: 37 Norm Difference for worker 894 is 1.839826
INFO:root:FL Epoch: 37 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [6 4 2 8 7 0 5], which are global users: [1792, 1836, 1265, 159, 1318, 400, 270]
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.5481999218463898 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.8025890191396077                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 38 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :91
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 91 is 1.859078
INFO:root:FL Epoch: 38 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :406
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519783
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692673
INFO:root:FL Epoch: 38 Norm Difference for worker 406 is 1.921161
INFO:root:FL Epoch: 38 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1341
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406233
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409495
INFO:root:FL Epoch: 38 Norm Difference for worker 1341 is 1.758644
INFO:root:FL Epoch: 38 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1142
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738183
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317819
INFO:root:FL Epoch: 38 Norm Difference for worker 1142 is 1.879086
INFO:root:FL Epoch: 38 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :961
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545711
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483133
INFO:root:FL Epoch: 38 Norm Difference for worker 961 is 1.829179
INFO:root:FL Epoch: 38 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1634
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645271
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507622
INFO:root:FL Epoch: 38 Norm Difference for worker 1634 is 1.961344
INFO:root:FL Epoch: 38 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :278
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 278 is 1.914695
INFO:root:FL Epoch: 38 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1725
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611239
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462551
INFO:root:FL Epoch: 38 Norm Difference for worker 1725 is 1.955818
INFO:root:FL Epoch: 38 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1426
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813005
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366098
INFO:root:FL Epoch: 38 Norm Difference for worker 1426 is 1.973319
INFO:root:FL Epoch: 38 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :171
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 171 is 1.893113
INFO:root:FL Epoch: 38 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 201 200 201]
INFO:root:The chosen ones are users: [3 0 2 4 6 1 9], which are global users: [1142, 91, 1341, 961, 278, 406, 171]
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.5697113082689398 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:1.5466623902320862                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :793
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754481
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434382
INFO:root:FL Epoch: 39 Norm Difference for worker 793 is 1.755336
INFO:root:FL Epoch: 39 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1430
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569617
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349405
INFO:root:FL Epoch: 39 Norm Difference for worker 1430 is 1.789677
INFO:root:FL Epoch: 39 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1259
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685021
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538647
INFO:root:FL Epoch: 39 Norm Difference for worker 1259 is 1.788887
INFO:root:FL Epoch: 39 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :83
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 83 is 1.804418
INFO:root:FL Epoch: 39 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :963
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766694
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473180
INFO:root:FL Epoch: 39 Norm Difference for worker 963 is 1.864262
INFO:root:FL Epoch: 39 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :727
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657320
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510017
INFO:root:FL Epoch: 39 Norm Difference for worker 727 is 1.793771
INFO:root:FL Epoch: 39 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1798
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719236
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446061
INFO:root:FL Epoch: 39 Norm Difference for worker 1798 is 1.805735
INFO:root:FL Epoch: 39 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1045
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441410
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512636
INFO:root:FL Epoch: 39 Norm Difference for worker 1045 is 1.739362
INFO:root:FL Epoch: 39 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :795
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590394
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519326
INFO:root:FL Epoch: 39 Norm Difference for worker 795 is 1.753055
INFO:root:FL Epoch: 39 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579359
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589027
INFO:root:FL Epoch: 39 Norm Difference for worker 1544 is 1.812354
INFO:root:FL Epoch: 39 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 9 5 1], which are global users: [1045, 793, 1259, 795, 1544, 727, 1430]
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.5799151869381175 and Test Accuracy:70.0 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:1.7514610091845195                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :1876
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725608
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377502
INFO:root:FL Epoch: 40 Norm Difference for worker 1876 is 1.986767
INFO:root:FL Epoch: 40 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1511
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744808
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417950
INFO:root:FL Epoch: 40 Norm Difference for worker 1511 is 1.919403
INFO:root:FL Epoch: 40 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1817
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579861
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268432
INFO:root:FL Epoch: 40 Norm Difference for worker 1817 is 1.904855
INFO:root:FL Epoch: 40 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :696
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649680
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549704
INFO:root:FL Epoch: 40 Norm Difference for worker 696 is 1.867794
INFO:root:FL Epoch: 40 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :514
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686652
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383286
INFO:root:FL Epoch: 40 Norm Difference for worker 514 is 1.772856
INFO:root:FL Epoch: 40 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :724
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641281
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556963
INFO:root:FL Epoch: 40 Norm Difference for worker 724 is 1.898867
INFO:root:FL Epoch: 40 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :71
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643214
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 71 is 1.724579
INFO:root:FL Epoch: 40 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1627
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464786
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520470
INFO:root:FL Epoch: 40 Norm Difference for worker 1627 is 1.867485
INFO:root:FL Epoch: 40 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1036
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494023
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297602
INFO:root:FL Epoch: 40 Norm Difference for worker 1036 is 1.860517
INFO:root:FL Epoch: 40 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1139
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589435
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499229
INFO:root:FL Epoch: 40 Norm Difference for worker 1139 is 1.854111
INFO:root:FL Epoch: 40 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 8 4 3 7], which are global users: [71, 1139, 1817, 1036, 514, 696, 1627]
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.5667922479264876 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.385683834552765                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [431, 1920, 659, 855, 1679, 48, 359, 1794, 466, 1659]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :431
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581780
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420253
INFO:root:FL Epoch: 41 Norm Difference for worker 431 is 1.822687
INFO:root:FL Epoch: 41 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1920
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569862
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461937
INFO:root:FL Epoch: 41 Norm Difference for worker 1920 is 1.859574
INFO:root:FL Epoch: 41 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670063
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538664
INFO:root:FL Epoch: 41 Norm Difference for worker 659 is 1.934166
INFO:root:FL Epoch: 41 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :855
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695879
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503255
INFO:root:FL Epoch: 41 Norm Difference for worker 855 is 1.833594
INFO:root:FL Epoch: 41 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1679
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692448
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397952
INFO:root:FL Epoch: 41 Norm Difference for worker 1679 is 1.972922
INFO:root:FL Epoch: 41 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :48
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 48 is 1.839975
INFO:root:FL Epoch: 41 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :359
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409164
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452459
INFO:root:FL Epoch: 41 Norm Difference for worker 359 is 1.846568
INFO:root:FL Epoch: 41 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1794
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491340
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422912
INFO:root:FL Epoch: 41 Norm Difference for worker 1794 is 1.99977
INFO:root:FL Epoch: 41 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :466
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456406
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453735
INFO:root:FL Epoch: 41 Norm Difference for worker 466 is 1.820787
INFO:root:FL Epoch: 41 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781583
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370593
INFO:root:FL Epoch: 41 Norm Difference for worker 1659 is 1.903038
INFO:root:FL Epoch: 41 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 6 9 1], which are global users: [48, 431, 466, 855, 359, 1659, 1920]
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.5563995224588058 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:1.1378409266471863                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1016
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475884
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335393
INFO:root:FL Epoch: 42 Norm Difference for worker 1016 is 1.93289
INFO:root:FL Epoch: 42 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :758
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537337
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582454
INFO:root:FL Epoch: 42 Norm Difference for worker 758 is 1.764891
INFO:root:FL Epoch: 42 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1919
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493492
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640401
INFO:root:FL Epoch: 42 Norm Difference for worker 1919 is 1.944287
INFO:root:FL Epoch: 42 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1693
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573000
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395397
INFO:root:FL Epoch: 42 Norm Difference for worker 1693 is 1.776108
INFO:root:FL Epoch: 42 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1465
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639096
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385278
INFO:root:FL Epoch: 42 Norm Difference for worker 1465 is 1.826676
INFO:root:FL Epoch: 42 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :882
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737801
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445657
INFO:root:FL Epoch: 42 Norm Difference for worker 882 is 1.853111
INFO:root:FL Epoch: 42 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :176
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 176 is 1.882344
INFO:root:FL Epoch: 42 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1854
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509433
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445868
INFO:root:FL Epoch: 42 Norm Difference for worker 1854 is 1.97786
INFO:root:FL Epoch: 42 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :107
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 107 is 1.909526
INFO:root:FL Epoch: 42 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :77
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636663
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417550
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 77 is 1.869827
INFO:root:FL Epoch: 42 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 201 201]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [1 4 5 3 9 8 2], which are global users: [758, 1465, 882, 1693, 77, 107, 1919]
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.5636777562253615 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:1.0599919160207112                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 43 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :301
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 301 is 1.885747
INFO:root:FL Epoch: 43 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :961
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630865
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297775
INFO:root:FL Epoch: 43 Norm Difference for worker 961 is 1.791861
INFO:root:FL Epoch: 43 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1081
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743973
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538399
INFO:root:FL Epoch: 43 Norm Difference for worker 1081 is 1.895785
INFO:root:FL Epoch: 43 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :165
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611407
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 165 is 1.842475
INFO:root:FL Epoch: 43 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1765
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488488
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556085
INFO:root:FL Epoch: 43 Norm Difference for worker 1765 is 1.686224
INFO:root:FL Epoch: 43 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.873096
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 1.876988
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :21
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.755224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 21 is 1.772458
INFO:root:FL Epoch: 43 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :425
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606419
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505482
INFO:root:FL Epoch: 43 Norm Difference for worker 425 is 1.848771
INFO:root:FL Epoch: 43 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1827
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698419
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456513
INFO:root:FL Epoch: 43 Norm Difference for worker 1827 is 1.85295
INFO:root:FL Epoch: 43 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1721
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361332
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347581
INFO:root:FL Epoch: 43 Norm Difference for worker 1721 is 1.794327
INFO:root:FL Epoch: 43 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 201 201]
INFO:root:The chosen ones are users: [6 4 9 1 8 5 3], which are global users: [21, 1765, 1721, 961, 1827, 96, 165]
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.5329473491977242 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:1.2427561084429424                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :617
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315195
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330774
INFO:root:FL Epoch: 44 Norm Difference for worker 617 is 1.894094
INFO:root:FL Epoch: 44 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :842
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535511
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518101
INFO:root:FL Epoch: 44 Norm Difference for worker 842 is 1.891015
INFO:root:FL Epoch: 44 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :851
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550273
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246548
INFO:root:FL Epoch: 44 Norm Difference for worker 851 is 1.691345
INFO:root:FL Epoch: 44 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :604
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424662
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255614
INFO:root:FL Epoch: 44 Norm Difference for worker 604 is 1.968675
INFO:root:FL Epoch: 44 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1478
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468334
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251914
INFO:root:FL Epoch: 44 Norm Difference for worker 1478 is 1.78008
INFO:root:FL Epoch: 44 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1239
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633799
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468856
INFO:root:FL Epoch: 44 Norm Difference for worker 1239 is 1.988508
INFO:root:FL Epoch: 44 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1744
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770345
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512788
INFO:root:FL Epoch: 44 Norm Difference for worker 1744 is 1.967212
INFO:root:FL Epoch: 44 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1946
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708133
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543053
INFO:root:FL Epoch: 44 Norm Difference for worker 1946 is 1.909481
INFO:root:FL Epoch: 44 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1499
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548910
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365756
INFO:root:FL Epoch: 44 Norm Difference for worker 1499 is 1.917341
INFO:root:FL Epoch: 44 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1072
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468548
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433528
INFO:root:FL Epoch: 44 Norm Difference for worker 1072 is 1.845028
INFO:root:FL Epoch: 44 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [2 4 9 7 0 8 1], which are global users: [851, 1478, 1072, 1946, 617, 1499, 842]
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.5539452591363121 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:1.4990806976954143                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :284
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 284 is 2.025703
INFO:root:FL Epoch: 45 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :629
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527289
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396039
INFO:root:FL Epoch: 45 Norm Difference for worker 629 is 1.8661
INFO:root:FL Epoch: 45 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1483
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526348
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266745
INFO:root:FL Epoch: 45 Norm Difference for worker 1483 is 1.870337
INFO:root:FL Epoch: 45 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :496
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937404
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300980
INFO:root:FL Epoch: 45 Norm Difference for worker 496 is 1.904089
INFO:root:FL Epoch: 45 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1902
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377239
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373744
INFO:root:FL Epoch: 45 Norm Difference for worker 1902 is 1.915133
INFO:root:FL Epoch: 45 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :261
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.680175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 261 is 2.062206
INFO:root:FL Epoch: 45 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1691
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843418
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394391
INFO:root:FL Epoch: 45 Norm Difference for worker 1691 is 1.983698
INFO:root:FL Epoch: 45 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :309
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 309 is 1.914341
INFO:root:FL Epoch: 45 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :195
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 195 is 1.941949
INFO:root:FL Epoch: 45 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :346
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478226
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376457
INFO:root:FL Epoch: 45 Norm Difference for worker 346 is 1.961842
INFO:root:FL Epoch: 45 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 201 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 8 6], which are global users: [309, 1902, 1483, 496, 629, 195, 1691]
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.5537464022636414 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:1.5194035172462463                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1012
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656718
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518767
INFO:root:FL Epoch: 46 Norm Difference for worker 1012 is 1.840641
INFO:root:FL Epoch: 46 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1287
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464948
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415527
INFO:root:FL Epoch: 46 Norm Difference for worker 1287 is 1.985835
INFO:root:FL Epoch: 46 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1772
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615075
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547834
INFO:root:FL Epoch: 46 Norm Difference for worker 1772 is 1.996662
INFO:root:FL Epoch: 46 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :973
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641310
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428873
INFO:root:FL Epoch: 46 Norm Difference for worker 973 is 1.967273
INFO:root:FL Epoch: 46 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :355
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778721
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553060
INFO:root:FL Epoch: 46 Norm Difference for worker 355 is 2.039991
INFO:root:FL Epoch: 46 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :15
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414863
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 15 is 1.88814
INFO:root:FL Epoch: 46 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1335
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525174
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482344
INFO:root:FL Epoch: 46 Norm Difference for worker 1335 is 1.882526
INFO:root:FL Epoch: 46 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :859
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461441
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413621
INFO:root:FL Epoch: 46 Norm Difference for worker 859 is 1.979122
INFO:root:FL Epoch: 46 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1060
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403179
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614929
INFO:root:FL Epoch: 46 Norm Difference for worker 1060 is 2.102784
INFO:root:FL Epoch: 46 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1175
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755195
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426504
INFO:root:FL Epoch: 46 Norm Difference for worker 1175 is 1.956581
INFO:root:FL Epoch: 46 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 6 9 7 1 3], which are global users: [15, 1012, 1335, 1175, 859, 1287, 973]
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.5639576719087713 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:1.362117886543274                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1026
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610354
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277768
INFO:root:FL Epoch: 47 Norm Difference for worker 1026 is 1.904504
INFO:root:FL Epoch: 47 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1386
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477921
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255241
INFO:root:FL Epoch: 47 Norm Difference for worker 1386 is 1.771011
INFO:root:FL Epoch: 47 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :370
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630757
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348301
INFO:root:FL Epoch: 47 Norm Difference for worker 370 is 1.885275
INFO:root:FL Epoch: 47 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1316
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555718
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548550
INFO:root:FL Epoch: 47 Norm Difference for worker 1316 is 1.872235
INFO:root:FL Epoch: 47 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1423
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678572
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361172
INFO:root:FL Epoch: 47 Norm Difference for worker 1423 is 1.836733
INFO:root:FL Epoch: 47 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1323
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494045
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420426
INFO:root:FL Epoch: 47 Norm Difference for worker 1323 is 1.999624
INFO:root:FL Epoch: 47 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1440
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587811
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448171
INFO:root:FL Epoch: 47 Norm Difference for worker 1440 is 1.883993
INFO:root:FL Epoch: 47 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :374
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582879
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628082
INFO:root:FL Epoch: 47 Norm Difference for worker 374 is 1.911324
INFO:root:FL Epoch: 47 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :641
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539727
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403918
INFO:root:FL Epoch: 47 Norm Difference for worker 641 is 1.863937
INFO:root:FL Epoch: 47 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :685
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532053
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458947
INFO:root:FL Epoch: 47 Norm Difference for worker 685 is 1.861435
INFO:root:FL Epoch: 47 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 4 0 3 9 8 2], which are global users: [1386, 1423, 1026, 1316, 685, 641, 370]
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.5633441437693203 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:1.74487300713857                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :742
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521603
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327297
INFO:root:FL Epoch: 48 Norm Difference for worker 742 is 1.990628
INFO:root:FL Epoch: 48 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :885
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710470
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314153
INFO:root:FL Epoch: 48 Norm Difference for worker 885 is 2.017126
INFO:root:FL Epoch: 48 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :169
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469319
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 169 is 2.023592
INFO:root:FL Epoch: 48 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622929
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345429
INFO:root:FL Epoch: 48 Norm Difference for worker 1527 is 1.801482
INFO:root:FL Epoch: 48 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :884
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407356
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319031
INFO:root:FL Epoch: 48 Norm Difference for worker 884 is 2.050277
INFO:root:FL Epoch: 48 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1072
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487118
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351226
INFO:root:FL Epoch: 48 Norm Difference for worker 1072 is 1.870894
INFO:root:FL Epoch: 48 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :458
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487094
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539005
INFO:root:FL Epoch: 48 Norm Difference for worker 458 is 1.906674
INFO:root:FL Epoch: 48 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1623
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592418
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409076
INFO:root:FL Epoch: 48 Norm Difference for worker 1623 is 1.951733
INFO:root:FL Epoch: 48 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1318
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553467
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371486
INFO:root:FL Epoch: 48 Norm Difference for worker 1318 is 1.941639
INFO:root:FL Epoch: 48 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1808
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476840
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352169
INFO:root:FL Epoch: 48 Norm Difference for worker 1808 is 2.05992
INFO:root:FL Epoch: 48 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 3 6 8 7 0 1], which are global users: [1072, 1527, 458, 1318, 1623, 742, 885]
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.5703636162421283 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.7943484783172607                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :1089
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646990
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295198
INFO:root:FL Epoch: 49 Norm Difference for worker 1089 is 1.957292
INFO:root:FL Epoch: 49 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1220
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492096
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507394
INFO:root:FL Epoch: 49 Norm Difference for worker 1220 is 2.059792
INFO:root:FL Epoch: 49 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :832
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540546
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507721
INFO:root:FL Epoch: 49 Norm Difference for worker 832 is 2.120249
INFO:root:FL Epoch: 49 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :348
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590092
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638346
INFO:root:FL Epoch: 49 Norm Difference for worker 348 is 2.025024
INFO:root:FL Epoch: 49 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1483
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597974
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345325
INFO:root:FL Epoch: 49 Norm Difference for worker 1483 is 1.919863
INFO:root:FL Epoch: 49 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1709
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398962
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294002
INFO:root:FL Epoch: 49 Norm Difference for worker 1709 is 2.162828
INFO:root:FL Epoch: 49 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :170
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 170 is 2.047144
INFO:root:FL Epoch: 49 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676292
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361861
INFO:root:FL Epoch: 49 Norm Difference for worker 862 is 2.134202
INFO:root:FL Epoch: 49 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1619
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633754
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419991
INFO:root:FL Epoch: 49 Norm Difference for worker 1619 is 2.05727
INFO:root:FL Epoch: 49 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :52
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.836459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 52 is 2.141648
INFO:root:FL Epoch: 49 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [4 0 8 2 1 3 6], which are global users: [1483, 1089, 1619, 832, 1220, 348, 170]
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.5816817792022929 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:1.427634835243225                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :1159
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862507
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364769
INFO:root:FL Epoch: 50 Norm Difference for worker 1159 is 1.896679
INFO:root:FL Epoch: 50 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :973
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584139
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358605
INFO:root:FL Epoch: 50 Norm Difference for worker 973 is 1.868358
INFO:root:FL Epoch: 50 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :918
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514473
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455210
INFO:root:FL Epoch: 50 Norm Difference for worker 918 is 2.007001
INFO:root:FL Epoch: 50 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :978
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744687
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293769
INFO:root:FL Epoch: 50 Norm Difference for worker 978 is 1.930714
INFO:root:FL Epoch: 50 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1454
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512801
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458275
INFO:root:FL Epoch: 50 Norm Difference for worker 1454 is 1.824342
INFO:root:FL Epoch: 50 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1102
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596026
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336063
INFO:root:FL Epoch: 50 Norm Difference for worker 1102 is 2.047174
INFO:root:FL Epoch: 50 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :762
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653042
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510194
INFO:root:FL Epoch: 50 Norm Difference for worker 762 is 1.914644
INFO:root:FL Epoch: 50 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :302
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 302 is 1.8853
INFO:root:FL Epoch: 50 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1871
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435921
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369915
INFO:root:FL Epoch: 50 Norm Difference for worker 1871 is 2.049123
INFO:root:FL Epoch: 50 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :580
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590797
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348236
INFO:root:FL Epoch: 50 Norm Difference for worker 580 is 1.902508
INFO:root:FL Epoch: 50 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 7 0 1 2 3], which are global users: [1454, 580, 302, 1159, 973, 918, 978]
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.569307977662367 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.86186550060908                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [1942, 848, 888, 1807, 655, 164, 302, 119, 1277, 1553]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :1942
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518904
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441393
INFO:root:FL Epoch: 51 Norm Difference for worker 1942 is 2.024438
INFO:root:FL Epoch: 51 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :848
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815053
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445450
INFO:root:FL Epoch: 51 Norm Difference for worker 848 is 2.070941
INFO:root:FL Epoch: 51 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :888
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754060
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478762
INFO:root:FL Epoch: 51 Norm Difference for worker 888 is 2.022132
INFO:root:FL Epoch: 51 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1807
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831406
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353650
INFO:root:FL Epoch: 51 Norm Difference for worker 1807 is 1.92887
INFO:root:FL Epoch: 51 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :655
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619046
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381825
INFO:root:FL Epoch: 51 Norm Difference for worker 655 is 1.871719
INFO:root:FL Epoch: 51 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :164
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607825
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 164 is 1.995703
INFO:root:FL Epoch: 51 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :302
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 302 is 1.831802
INFO:root:FL Epoch: 51 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :119
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 119 is 2.028881
INFO:root:FL Epoch: 51 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1277
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746447
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273702
INFO:root:FL Epoch: 51 Norm Difference for worker 1277 is 1.987577
INFO:root:FL Epoch: 51 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1553
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753118
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335444
INFO:root:FL Epoch: 51 Norm Difference for worker 1553 is 2.009796
INFO:root:FL Epoch: 51 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 201 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [3 4 6 9 8 2 5], which are global users: [1807, 655, 302, 1553, 1277, 888, 164]
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.5591048387920156 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:1.6011842091878254                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :410
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466051
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305626
INFO:root:FL Epoch: 52 Norm Difference for worker 410 is 2.018456
INFO:root:FL Epoch: 52 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :710
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672481
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478690
INFO:root:FL Epoch: 52 Norm Difference for worker 710 is 2.030709
INFO:root:FL Epoch: 52 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1013
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474471
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421112
INFO:root:FL Epoch: 52 Norm Difference for worker 1013 is 2.057202
INFO:root:FL Epoch: 52 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :60
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661354
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 60 is 2.059215
INFO:root:FL Epoch: 52 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :109
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682047
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 109 is 2.15733
INFO:root:FL Epoch: 52 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1576
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631544
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319095
INFO:root:FL Epoch: 52 Norm Difference for worker 1576 is 1.986015
INFO:root:FL Epoch: 52 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :931
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786124
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248421
INFO:root:FL Epoch: 52 Norm Difference for worker 931 is 2.143816
INFO:root:FL Epoch: 52 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :407
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737950
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345952
INFO:root:FL Epoch: 52 Norm Difference for worker 407 is 1.860658
INFO:root:FL Epoch: 52 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :697
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655975
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266255
INFO:root:FL Epoch: 52 Norm Difference for worker 697 is 2.085786
INFO:root:FL Epoch: 52 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1217
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435620
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539645
INFO:root:FL Epoch: 52 Norm Difference for worker 1217 is 2.070901
INFO:root:FL Epoch: 52 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 4], which are global users: [407, 410, 1013, 60, 710, 1576, 109]
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.5610495472655577 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:1.7730563084284465                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1299
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584455
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404571
INFO:root:FL Epoch: 53 Norm Difference for worker 1299 is 1.939583
INFO:root:FL Epoch: 53 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :593
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733578
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464907
INFO:root:FL Epoch: 53 Norm Difference for worker 593 is 1.972781
INFO:root:FL Epoch: 53 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1438
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764563
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359701
INFO:root:FL Epoch: 53 Norm Difference for worker 1438 is 1.98612
INFO:root:FL Epoch: 53 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1891
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591305
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445922
INFO:root:FL Epoch: 53 Norm Difference for worker 1891 is 1.883238
INFO:root:FL Epoch: 53 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1705
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468198
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325426
INFO:root:FL Epoch: 53 Norm Difference for worker 1705 is 2.006885
INFO:root:FL Epoch: 53 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1052
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649221
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331814
INFO:root:FL Epoch: 53 Norm Difference for worker 1052 is 1.920761
INFO:root:FL Epoch: 53 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1474
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727946
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320556
INFO:root:FL Epoch: 53 Norm Difference for worker 1474 is 1.942143
INFO:root:FL Epoch: 53 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :550
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721770
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366154
INFO:root:FL Epoch: 53 Norm Difference for worker 550 is 1.948526
INFO:root:FL Epoch: 53 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :475
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553673
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359593
INFO:root:FL Epoch: 53 Norm Difference for worker 475 is 1.902235
INFO:root:FL Epoch: 53 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1925
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571704
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353150
INFO:root:FL Epoch: 53 Norm Difference for worker 1925 is 1.980058
INFO:root:FL Epoch: 53 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 3 6 5 8 7 0], which are global users: [593, 1891, 1474, 1052, 475, 550, 1299]
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.5453104324200574 and Test Accuracy:70.0 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.5835486849149067                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 54 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :1628
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565444
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328689
INFO:root:FL Epoch: 54 Norm Difference for worker 1628 is 1.865378
INFO:root:FL Epoch: 54 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :165
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 165 is 1.970881
INFO:root:FL Epoch: 54 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :671
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514849
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356282
INFO:root:FL Epoch: 54 Norm Difference for worker 671 is 1.900768
INFO:root:FL Epoch: 54 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :216
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465473
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 216 is 1.9135
INFO:root:FL Epoch: 54 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :620
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711429
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300675
INFO:root:FL Epoch: 54 Norm Difference for worker 620 is 1.792157
INFO:root:FL Epoch: 54 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :465
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525150
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370062
INFO:root:FL Epoch: 54 Norm Difference for worker 465 is 1.906917
INFO:root:FL Epoch: 54 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :72
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408033
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 72 is 1.923824
INFO:root:FL Epoch: 54 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :559
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836476
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368578
INFO:root:FL Epoch: 54 Norm Difference for worker 559 is 1.876186
INFO:root:FL Epoch: 54 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :886
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584788
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350639
INFO:root:FL Epoch: 54 Norm Difference for worker 886 is 1.871077
INFO:root:FL Epoch: 54 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1530
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587076
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363919
INFO:root:FL Epoch: 54 Norm Difference for worker 1530 is 1.932903
INFO:root:FL Epoch: 54 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [4 0 7 2 8 5 6], which are global users: [620, 1628, 559, 671, 886, 465, 72]
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.5500168432207668 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:1.8659285704294841                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1536
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664453
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464690
INFO:root:FL Epoch: 55 Norm Difference for worker 1536 is 1.857155
INFO:root:FL Epoch: 55 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1204
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566672
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456092
INFO:root:FL Epoch: 55 Norm Difference for worker 1204 is 2.016142
INFO:root:FL Epoch: 55 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1550
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656758
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396099
INFO:root:FL Epoch: 55 Norm Difference for worker 1550 is 1.985024
INFO:root:FL Epoch: 55 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1139
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466521
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288197
INFO:root:FL Epoch: 55 Norm Difference for worker 1139 is 1.91611
INFO:root:FL Epoch: 55 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :735
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594431
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430848
INFO:root:FL Epoch: 55 Norm Difference for worker 735 is 2.051607
INFO:root:FL Epoch: 55 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1804
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493819
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535761
INFO:root:FL Epoch: 55 Norm Difference for worker 1804 is 1.973649
INFO:root:FL Epoch: 55 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1303
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496337
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483382
INFO:root:FL Epoch: 55 Norm Difference for worker 1303 is 1.941835
INFO:root:FL Epoch: 55 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :856
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 1.016525
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435689
INFO:root:FL Epoch: 55 Norm Difference for worker 856 is 2.142653
INFO:root:FL Epoch: 55 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1587
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465262
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377614
INFO:root:FL Epoch: 55 Norm Difference for worker 1587 is 1.931553
INFO:root:FL Epoch: 55 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :124
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435017
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 124 is 2.060496
INFO:root:FL Epoch: 55 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 6 4 1], which are global users: [1804, 1536, 1587, 1139, 1303, 735, 1204]
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.5391866336850559 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:1.6581118901570637                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 56 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :103
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 103 is 1.869508
INFO:root:FL Epoch: 56 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :47
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 47 is 1.844168
INFO:root:FL Epoch: 56 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1805
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535451
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426070
INFO:root:FL Epoch: 56 Norm Difference for worker 1805 is 1.984828
INFO:root:FL Epoch: 56 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1280
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648172
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407432
INFO:root:FL Epoch: 56 Norm Difference for worker 1280 is 1.921657
INFO:root:FL Epoch: 56 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1599
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570554
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443145
INFO:root:FL Epoch: 56 Norm Difference for worker 1599 is 1.993781
INFO:root:FL Epoch: 56 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1088
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496341
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279692
INFO:root:FL Epoch: 56 Norm Difference for worker 1088 is 1.834262
INFO:root:FL Epoch: 56 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1092
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493014
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441223
INFO:root:FL Epoch: 56 Norm Difference for worker 1092 is 2.062798
INFO:root:FL Epoch: 56 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1468
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815719
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529481
INFO:root:FL Epoch: 56 Norm Difference for worker 1468 is 2.024652
INFO:root:FL Epoch: 56 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :962
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386481
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471284
INFO:root:FL Epoch: 56 Norm Difference for worker 962 is 1.931736
INFO:root:FL Epoch: 56 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1742
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503825
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332780
INFO:root:FL Epoch: 56 Norm Difference for worker 1742 is 1.951228
INFO:root:FL Epoch: 56 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 8 5 9 2 3], which are global users: [47, 103, 962, 1088, 1742, 1805, 1280]
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.5240430604009068 and Test Accuracy:75.0 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.5305313467979431                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :1087
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500127
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488518
INFO:root:FL Epoch: 57 Norm Difference for worker 1087 is 1.925375
INFO:root:FL Epoch: 57 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :51
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.863834
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 51 is 1.927195
INFO:root:FL Epoch: 57 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :352
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606641
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370117
INFO:root:FL Epoch: 57 Norm Difference for worker 352 is 1.989342
INFO:root:FL Epoch: 57 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1760
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.972606
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344061
INFO:root:FL Epoch: 57 Norm Difference for worker 1760 is 2.159891
INFO:root:FL Epoch: 57 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1518
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713568
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260919
INFO:root:FL Epoch: 57 Norm Difference for worker 1518 is 2.006247
INFO:root:FL Epoch: 57 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1886
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573053
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366296
INFO:root:FL Epoch: 57 Norm Difference for worker 1886 is 2.080282
INFO:root:FL Epoch: 57 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1418
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629547
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399745
INFO:root:FL Epoch: 57 Norm Difference for worker 1418 is 1.925068
INFO:root:FL Epoch: 57 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :593
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628009
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348975
INFO:root:FL Epoch: 57 Norm Difference for worker 593 is 1.964558
INFO:root:FL Epoch: 57 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :803
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442688
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323246
INFO:root:FL Epoch: 57 Norm Difference for worker 803 is 1.9481
INFO:root:FL Epoch: 57 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1360
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525620
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430661
INFO:root:FL Epoch: 57 Norm Difference for worker 1360 is 1.936049
INFO:root:FL Epoch: 57 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 6 0 7 2 8], which are global users: [51, 1360, 1418, 1087, 593, 352, 803]
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.5324931845945471 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:1.8898506959279378                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1472
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561595
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427851
INFO:root:FL Epoch: 58 Norm Difference for worker 1472 is 1.988804
INFO:root:FL Epoch: 58 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :142
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 142 is 1.940104
INFO:root:FL Epoch: 58 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :686
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609300
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453923
INFO:root:FL Epoch: 58 Norm Difference for worker 686 is 1.998818
INFO:root:FL Epoch: 58 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1238
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463985
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349317
INFO:root:FL Epoch: 58 Norm Difference for worker 1238 is 1.949354
INFO:root:FL Epoch: 58 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :610
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840160
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383589
INFO:root:FL Epoch: 58 Norm Difference for worker 610 is 1.909377
INFO:root:FL Epoch: 58 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :438
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599421
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423497
INFO:root:FL Epoch: 58 Norm Difference for worker 438 is 1.938069
INFO:root:FL Epoch: 58 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1853
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521416
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296944
INFO:root:FL Epoch: 58 Norm Difference for worker 1853 is 2.03267
INFO:root:FL Epoch: 58 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1371
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647484
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371847
INFO:root:FL Epoch: 58 Norm Difference for worker 1371 is 1.972261
INFO:root:FL Epoch: 58 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :839
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613288
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330161
INFO:root:FL Epoch: 58 Norm Difference for worker 839 is 2.003313
INFO:root:FL Epoch: 58 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1439
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744766
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365194
INFO:root:FL Epoch: 58 Norm Difference for worker 1439 is 2.051589
INFO:root:FL Epoch: 58 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [8 4 2 3 1 5 6], which are global users: [839, 610, 686, 1238, 142, 438, 1853]
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.5429213345050812 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:1.5197368661562602                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1354
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781722
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389431
INFO:root:FL Epoch: 59 Norm Difference for worker 1354 is 2.011862
INFO:root:FL Epoch: 59 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :228
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 228 is 1.84338
INFO:root:FL Epoch: 59 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :462
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757360
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560281
INFO:root:FL Epoch: 59 Norm Difference for worker 462 is 1.984976
INFO:root:FL Epoch: 59 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1636
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498677
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258702
INFO:root:FL Epoch: 59 Norm Difference for worker 1636 is 1.932006
INFO:root:FL Epoch: 59 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1046
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508313
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378258
INFO:root:FL Epoch: 59 Norm Difference for worker 1046 is 1.960163
INFO:root:FL Epoch: 59 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1188
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403923
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666074
INFO:root:FL Epoch: 59 Norm Difference for worker 1188 is 2.068783
INFO:root:FL Epoch: 59 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1882
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618384
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313499
INFO:root:FL Epoch: 59 Norm Difference for worker 1882 is 2.000139
INFO:root:FL Epoch: 59 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1003
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632193
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442093
INFO:root:FL Epoch: 59 Norm Difference for worker 1003 is 1.935582
INFO:root:FL Epoch: 59 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1658
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434512
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507272
INFO:root:FL Epoch: 59 Norm Difference for worker 1658 is 1.839606
INFO:root:FL Epoch: 59 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1075
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546142
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480250
INFO:root:FL Epoch: 59 Norm Difference for worker 1075 is 1.939455
INFO:root:FL Epoch: 59 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 8 7 4 3 0], which are global users: [228, 1075, 1658, 1003, 1046, 1636, 1354]
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.5394054511014152 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.793663760026296                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :160
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.321671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400386
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 160 is 2.217054
INFO:root:FL Epoch: 60 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1460
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410099
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319007
INFO:root:FL Epoch: 60 Norm Difference for worker 1460 is 1.981965
INFO:root:FL Epoch: 60 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1369
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545982
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325509
INFO:root:FL Epoch: 60 Norm Difference for worker 1369 is 2.085845
INFO:root:FL Epoch: 60 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1465
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748920
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457620
INFO:root:FL Epoch: 60 Norm Difference for worker 1465 is 2.05188
INFO:root:FL Epoch: 60 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :920
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442221
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356536
INFO:root:FL Epoch: 60 Norm Difference for worker 920 is 2.08929
INFO:root:FL Epoch: 60 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :167
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 167 is 2.140661
INFO:root:FL Epoch: 60 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :434
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486103
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272034
INFO:root:FL Epoch: 60 Norm Difference for worker 434 is 2.00976
INFO:root:FL Epoch: 60 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :908
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678071
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292072
INFO:root:FL Epoch: 60 Norm Difference for worker 908 is 1.978396
INFO:root:FL Epoch: 60 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1014
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.976958
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295742
INFO:root:FL Epoch: 60 Norm Difference for worker 1014 is 1.957913
INFO:root:FL Epoch: 60 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1614
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384388
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376393
INFO:root:FL Epoch: 60 Norm Difference for worker 1614 is 2.293184
INFO:root:FL Epoch: 60 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 7 8 6 3 4 2], which are global users: [1460, 908, 1014, 434, 1465, 920, 1369]
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.5232636087081012 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:1.4727326432863872                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [1377, 126, 1194, 362, 1279, 1826, 1404, 1802, 128, 1290]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 61 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :1377
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565795
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358274
INFO:root:FL Epoch: 61 Norm Difference for worker 1377 is 1.923922
INFO:root:FL Epoch: 61 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :126
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 126 is 1.87107
INFO:root:FL Epoch: 61 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1194
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670547
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336419
INFO:root:FL Epoch: 61 Norm Difference for worker 1194 is 1.958832
INFO:root:FL Epoch: 61 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :362
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597281
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377075
INFO:root:FL Epoch: 61 Norm Difference for worker 362 is 1.948688
INFO:root:FL Epoch: 61 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1279
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703330
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351174
INFO:root:FL Epoch: 61 Norm Difference for worker 1279 is 1.833585
INFO:root:FL Epoch: 61 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1826
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281862
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489173
INFO:root:FL Epoch: 61 Norm Difference for worker 1826 is 1.853698
INFO:root:FL Epoch: 61 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1404
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386035
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379168
INFO:root:FL Epoch: 61 Norm Difference for worker 1404 is 1.767245
INFO:root:FL Epoch: 61 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1802
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504560
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280228
INFO:root:FL Epoch: 61 Norm Difference for worker 1802 is 1.857068
INFO:root:FL Epoch: 61 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :128
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 128 is 1.939586
INFO:root:FL Epoch: 61 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1290
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483727
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594521
INFO:root:FL Epoch: 61 Norm Difference for worker 1290 is 2.088705
INFO:root:FL Epoch: 61 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 4 7 3 1 5 0], which are global users: [1404, 1279, 1802, 362, 126, 1826, 1377]
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.5387471160467934 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.8686490853627522                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :228
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 228 is 1.799761
INFO:root:FL Epoch: 62 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :380
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677463
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356719
INFO:root:FL Epoch: 62 Norm Difference for worker 380 is 2.035899
INFO:root:FL Epoch: 62 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1593
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388596
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269231
INFO:root:FL Epoch: 62 Norm Difference for worker 1593 is 1.858078
INFO:root:FL Epoch: 62 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1340
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485196
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380661
INFO:root:FL Epoch: 62 Norm Difference for worker 1340 is 2.04321
INFO:root:FL Epoch: 62 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :838
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477890
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390094
INFO:root:FL Epoch: 62 Norm Difference for worker 838 is 2.027332
INFO:root:FL Epoch: 62 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :117
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649461
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 117 is 1.931213
INFO:root:FL Epoch: 62 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :48
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 48 is 2.00554
INFO:root:FL Epoch: 62 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :793
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677572
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539347
INFO:root:FL Epoch: 62 Norm Difference for worker 793 is 2.027578
INFO:root:FL Epoch: 62 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1118
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690258
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433611
INFO:root:FL Epoch: 62 Norm Difference for worker 1118 is 1.964251
INFO:root:FL Epoch: 62 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1657
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644554
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411440
INFO:root:FL Epoch: 62 Norm Difference for worker 1657 is 2.107444
INFO:root:FL Epoch: 62 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 8 1 5 4], which are global users: [48, 228, 1593, 1118, 380, 117, 838]
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.5602681566687191 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.768293023109436                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1234
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452016
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280145
INFO:root:FL Epoch: 63 Norm Difference for worker 1234 is 2.068808
INFO:root:FL Epoch: 63 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :729
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392696
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211100
INFO:root:FL Epoch: 63 Norm Difference for worker 729 is 2.017742
INFO:root:FL Epoch: 63 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :469
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508820
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178761
INFO:root:FL Epoch: 63 Norm Difference for worker 469 is 2.018203
INFO:root:FL Epoch: 63 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :846
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665458
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382354
INFO:root:FL Epoch: 63 Norm Difference for worker 846 is 2.111513
INFO:root:FL Epoch: 63 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1600
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801508
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323702
INFO:root:FL Epoch: 63 Norm Difference for worker 1600 is 2.08844
INFO:root:FL Epoch: 63 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :157
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505667
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 157 is 2.062383
INFO:root:FL Epoch: 63 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1182
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449633
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362544
INFO:root:FL Epoch: 63 Norm Difference for worker 1182 is 1.984699
INFO:root:FL Epoch: 63 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1061
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749372
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368522
INFO:root:FL Epoch: 63 Norm Difference for worker 1061 is 1.988999
INFO:root:FL Epoch: 63 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1408
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466588
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433157
INFO:root:FL Epoch: 63 Norm Difference for worker 1408 is 2.076848
INFO:root:FL Epoch: 63 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :650
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620722
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551545
INFO:root:FL Epoch: 63 Norm Difference for worker 650 is 2.198176
INFO:root:FL Epoch: 63 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 5 6], which are global users: [1061, 1600, 469, 846, 729, 157, 1182]
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.5408762798589819 and Test Accuracy:75.0 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.7932702700297039                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :207
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 207 is 2.071354
INFO:root:FL Epoch: 64 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :542
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623710
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399729
INFO:root:FL Epoch: 64 Norm Difference for worker 542 is 1.96783
INFO:root:FL Epoch: 64 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1793
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655777
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353534
INFO:root:FL Epoch: 64 Norm Difference for worker 1793 is 2.033116
INFO:root:FL Epoch: 64 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1161
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748790
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395844
INFO:root:FL Epoch: 64 Norm Difference for worker 1161 is 2.06456
INFO:root:FL Epoch: 64 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1832
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735578
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517407
INFO:root:FL Epoch: 64 Norm Difference for worker 1832 is 2.028972
INFO:root:FL Epoch: 64 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1180
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516471
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397914
INFO:root:FL Epoch: 64 Norm Difference for worker 1180 is 1.965784
INFO:root:FL Epoch: 64 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1370
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552175
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358014
INFO:root:FL Epoch: 64 Norm Difference for worker 1370 is 1.99102
INFO:root:FL Epoch: 64 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :679
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490983
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316524
INFO:root:FL Epoch: 64 Norm Difference for worker 679 is 1.885981
INFO:root:FL Epoch: 64 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1235
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307479
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328881
INFO:root:FL Epoch: 64 Norm Difference for worker 1235 is 1.999637
INFO:root:FL Epoch: 64 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :562
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728464
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383791
INFO:root:FL Epoch: 64 Norm Difference for worker 562 is 2.017551
INFO:root:FL Epoch: 64 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 8 3 1 5 6], which are global users: [679, 562, 1235, 1161, 542, 1180, 1370]
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5353292279383716 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:1.7718091209729512                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 65 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :7
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564490
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 7 is 2.033812
INFO:root:FL Epoch: 65 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :806
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703256
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457980
INFO:root:FL Epoch: 65 Norm Difference for worker 806 is 2.130974
INFO:root:FL Epoch: 65 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :172
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 172 is 1.899217
INFO:root:FL Epoch: 65 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :751
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571220
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280323
INFO:root:FL Epoch: 65 Norm Difference for worker 751 is 1.829553
INFO:root:FL Epoch: 65 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :922
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543600
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316240
INFO:root:FL Epoch: 65 Norm Difference for worker 922 is 1.980494
INFO:root:FL Epoch: 65 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1606
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621276
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310343
INFO:root:FL Epoch: 65 Norm Difference for worker 1606 is 1.946901
INFO:root:FL Epoch: 65 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :904
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367160
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316585
INFO:root:FL Epoch: 65 Norm Difference for worker 904 is 1.842698
INFO:root:FL Epoch: 65 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1023
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609670
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405528
INFO:root:FL Epoch: 65 Norm Difference for worker 1023 is 1.906659
INFO:root:FL Epoch: 65 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :451
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467261
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471153
INFO:root:FL Epoch: 65 Norm Difference for worker 451 is 2.076118
INFO:root:FL Epoch: 65 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :871
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504983
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415098
INFO:root:FL Epoch: 65 Norm Difference for worker 871 is 1.92552
INFO:root:FL Epoch: 65 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 3 7 5 4], which are global users: [904, 871, 172, 751, 1023, 1606, 922]
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.5250092569519492 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.5077875057856243                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1824
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692387
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345715
INFO:root:FL Epoch: 66 Norm Difference for worker 1824 is 2.163507
INFO:root:FL Epoch: 66 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :776
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561747
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457487
INFO:root:FL Epoch: 66 Norm Difference for worker 776 is 1.931144
INFO:root:FL Epoch: 66 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :679
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522981
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324626
INFO:root:FL Epoch: 66 Norm Difference for worker 679 is 1.918178
INFO:root:FL Epoch: 66 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1263
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666183
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294701
INFO:root:FL Epoch: 66 Norm Difference for worker 1263 is 1.939463
INFO:root:FL Epoch: 66 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1658
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662962
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328481
INFO:root:FL Epoch: 66 Norm Difference for worker 1658 is 1.892363
INFO:root:FL Epoch: 66 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :161
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 161 is 1.91713
INFO:root:FL Epoch: 66 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :623
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493263
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378859
INFO:root:FL Epoch: 66 Norm Difference for worker 623 is 2.094801
INFO:root:FL Epoch: 66 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1308
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728995
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491449
INFO:root:FL Epoch: 66 Norm Difference for worker 1308 is 2.05946
INFO:root:FL Epoch: 66 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :248
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 248 is 2.004419
INFO:root:FL Epoch: 66 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :692
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476105
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386906
INFO:root:FL Epoch: 66 Norm Difference for worker 692 is 2.073218
INFO:root:FL Epoch: 66 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [8 4 2 3 1 5 9], which are global users: [248, 1658, 679, 1263, 776, 161, 692]
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.5133397772031671 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:1.8831016222635906                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :1855
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606090
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340154
INFO:root:FL Epoch: 67 Norm Difference for worker 1855 is 1.976511
INFO:root:FL Epoch: 67 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :447
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613423
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430727
INFO:root:FL Epoch: 67 Norm Difference for worker 447 is 2.019595
INFO:root:FL Epoch: 67 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :860
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684075
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346473
INFO:root:FL Epoch: 67 Norm Difference for worker 860 is 2.189155
INFO:root:FL Epoch: 67 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459736
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445527
INFO:root:FL Epoch: 67 Norm Difference for worker 1575 is 2.045267
INFO:root:FL Epoch: 67 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :818
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561992
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334785
INFO:root:FL Epoch: 67 Norm Difference for worker 818 is 2.066006
INFO:root:FL Epoch: 67 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1745
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505494
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272759
INFO:root:FL Epoch: 67 Norm Difference for worker 1745 is 1.922576
INFO:root:FL Epoch: 67 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :201
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354210
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 201 is 1.998862
INFO:root:FL Epoch: 67 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :82
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 82 is 1.948057
INFO:root:FL Epoch: 67 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :907
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453350
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327612
INFO:root:FL Epoch: 67 Norm Difference for worker 907 is 2.021659
INFO:root:FL Epoch: 67 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1068
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624051
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278140
INFO:root:FL Epoch: 67 Norm Difference for worker 1068 is 1.936502
INFO:root:FL Epoch: 67 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 7 0 1 6 8], which are global users: [1745, 1068, 82, 1855, 447, 201, 907]
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5281109950121712 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.6035786469777424                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1385
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352041
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588897
INFO:root:FL Epoch: 68 Norm Difference for worker 1385 is 1.993565
INFO:root:FL Epoch: 68 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1108
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908993
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433393
INFO:root:FL Epoch: 68 Norm Difference for worker 1108 is 2.014184
INFO:root:FL Epoch: 68 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1575
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660082
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257043
INFO:root:FL Epoch: 68 Norm Difference for worker 1575 is 2.002516
INFO:root:FL Epoch: 68 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :567
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474843
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241364
INFO:root:FL Epoch: 68 Norm Difference for worker 567 is 1.898306
INFO:root:FL Epoch: 68 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1334
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532471
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273489
INFO:root:FL Epoch: 68 Norm Difference for worker 1334 is 2.039174
INFO:root:FL Epoch: 68 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :186
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 186 is 2.020019
INFO:root:FL Epoch: 68 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :589
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679073
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500346
INFO:root:FL Epoch: 68 Norm Difference for worker 589 is 2.084006
INFO:root:FL Epoch: 68 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :861
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851301
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373543
INFO:root:FL Epoch: 68 Norm Difference for worker 861 is 2.137274
INFO:root:FL Epoch: 68 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :249
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 249 is 1.962864
INFO:root:FL Epoch: 68 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :363
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684647
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380571
INFO:root:FL Epoch: 68 Norm Difference for worker 363 is 2.119175
INFO:root:FL Epoch: 68 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 8 3 1 0 2], which are global users: [186, 1334, 249, 567, 1108, 1385, 1575]
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5223435268682592 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.6463840007781982                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :1792
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396993
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251227
INFO:root:FL Epoch: 69 Norm Difference for worker 1792 is 1.878535
INFO:root:FL Epoch: 69 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1931
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499986
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337623
INFO:root:FL Epoch: 69 Norm Difference for worker 1931 is 2.056852
INFO:root:FL Epoch: 69 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1446
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548634
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413886
INFO:root:FL Epoch: 69 Norm Difference for worker 1446 is 1.946901
INFO:root:FL Epoch: 69 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1658
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365076
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259034
INFO:root:FL Epoch: 69 Norm Difference for worker 1658 is 1.778989
INFO:root:FL Epoch: 69 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1501
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515909
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346415
INFO:root:FL Epoch: 69 Norm Difference for worker 1501 is 2.06584
INFO:root:FL Epoch: 69 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :633
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472590
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226415
INFO:root:FL Epoch: 69 Norm Difference for worker 633 is 1.985642
INFO:root:FL Epoch: 69 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :191
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 191 is 2.078609
INFO:root:FL Epoch: 69 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :365
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498366
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404753
INFO:root:FL Epoch: 69 Norm Difference for worker 365 is 2.018721
INFO:root:FL Epoch: 69 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :539
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772648
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365343
INFO:root:FL Epoch: 69 Norm Difference for worker 539 is 2.094747
INFO:root:FL Epoch: 69 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1151
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657016
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418330
INFO:root:FL Epoch: 69 Norm Difference for worker 1151 is 1.965857
INFO:root:FL Epoch: 69 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 3 9 7 4], which are global users: [633, 1792, 1446, 1658, 1151, 365, 1501]
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5095965932397282 and Test Accuracy:75.0 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.9664697845776875                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1947
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528426
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230482
INFO:root:FL Epoch: 70 Norm Difference for worker 1947 is 1.983191
INFO:root:FL Epoch: 70 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :708
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597564
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314446
INFO:root:FL Epoch: 70 Norm Difference for worker 708 is 1.919141
INFO:root:FL Epoch: 70 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1032
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562864
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315313
INFO:root:FL Epoch: 70 Norm Difference for worker 1032 is 1.985387
INFO:root:FL Epoch: 70 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1835
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813378
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378665
INFO:root:FL Epoch: 70 Norm Difference for worker 1835 is 2.155602
INFO:root:FL Epoch: 70 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1097
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562116
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456997
INFO:root:FL Epoch: 70 Norm Difference for worker 1097 is 2.102887
INFO:root:FL Epoch: 70 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1636
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585759
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423443
INFO:root:FL Epoch: 70 Norm Difference for worker 1636 is 2.084489
INFO:root:FL Epoch: 70 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :104
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 104 is 2.063045
INFO:root:FL Epoch: 70 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1018
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499308
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400132
INFO:root:FL Epoch: 70 Norm Difference for worker 1018 is 2.00217
INFO:root:FL Epoch: 70 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :783
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701383
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632371
INFO:root:FL Epoch: 70 Norm Difference for worker 783 is 2.116007
INFO:root:FL Epoch: 70 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1165
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488071
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404851
INFO:root:FL Epoch: 70 Norm Difference for worker 1165 is 2.077706
INFO:root:FL Epoch: 70 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 5 9], which are global users: [104, 1947, 1032, 1018, 708, 1636, 1165]
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.5090243027490728 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.813841998577118                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [62, 1637, 492, 467, 439, 1788, 1531, 1101, 1372, 1289]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :62
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 62 is 2.000541
INFO:root:FL Epoch: 71 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1637
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749032
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333494
INFO:root:FL Epoch: 71 Norm Difference for worker 1637 is 2.026508
INFO:root:FL Epoch: 71 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :492
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502481
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265048
INFO:root:FL Epoch: 71 Norm Difference for worker 492 is 1.893798
INFO:root:FL Epoch: 71 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :467
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362769
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377751
INFO:root:FL Epoch: 71 Norm Difference for worker 467 is 1.894669
INFO:root:FL Epoch: 71 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :439
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519498
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379885
INFO:root:FL Epoch: 71 Norm Difference for worker 439 is 2.084617
INFO:root:FL Epoch: 71 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1788
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691512
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445020
INFO:root:FL Epoch: 71 Norm Difference for worker 1788 is 2.019064
INFO:root:FL Epoch: 71 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1531
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504629
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503552
INFO:root:FL Epoch: 71 Norm Difference for worker 1531 is 2.092763
INFO:root:FL Epoch: 71 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1101
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333840
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419398
INFO:root:FL Epoch: 71 Norm Difference for worker 1101 is 2.08032
INFO:root:FL Epoch: 71 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1372
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446066
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378651
INFO:root:FL Epoch: 71 Norm Difference for worker 1372 is 1.98854
INFO:root:FL Epoch: 71 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1289
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491108
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414435
INFO:root:FL Epoch: 71 Norm Difference for worker 1289 is 1.91295
INFO:root:FL Epoch: 71 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 0], which are global users: [1372, 1289, 492, 467, 1637, 1788, 62]
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.5689743564409369 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.8516426086425781                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1808
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380655
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283265
INFO:root:FL Epoch: 72 Norm Difference for worker 1808 is 2.082569
INFO:root:FL Epoch: 72 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :988
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560807
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216218
INFO:root:FL Epoch: 72 Norm Difference for worker 988 is 1.884332
INFO:root:FL Epoch: 72 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1871
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619425
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240838
INFO:root:FL Epoch: 72 Norm Difference for worker 1871 is 2.114904
INFO:root:FL Epoch: 72 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :246
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408612
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 246 is 2.033509
INFO:root:FL Epoch: 72 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :578
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519815
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232203
INFO:root:FL Epoch: 72 Norm Difference for worker 578 is 1.961499
INFO:root:FL Epoch: 72 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1167
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481004
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336604
INFO:root:FL Epoch: 72 Norm Difference for worker 1167 is 2.001945
INFO:root:FL Epoch: 72 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1905
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629900
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286163
INFO:root:FL Epoch: 72 Norm Difference for worker 1905 is 1.958636
INFO:root:FL Epoch: 72 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :161
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488112
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 161 is 1.876557
INFO:root:FL Epoch: 72 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :115
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 115 is 1.958072
INFO:root:FL Epoch: 72 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :918
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562030
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446954
INFO:root:FL Epoch: 72 Norm Difference for worker 918 is 2.135488
INFO:root:FL Epoch: 72 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 201 201 200]
INFO:root:Num selected data points: [201 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [7 4 8 3 1 5 6], which are global users: [161, 578, 115, 246, 988, 1167, 1905]
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5114406031720778 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:1.7167562047640483                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 73 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1190
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668521
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228492
INFO:root:FL Epoch: 73 Norm Difference for worker 1190 is 1.936482
INFO:root:FL Epoch: 73 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :534
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673025
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416293
INFO:root:FL Epoch: 73 Norm Difference for worker 534 is 2.144607
INFO:root:FL Epoch: 73 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1482
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586283
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292427
INFO:root:FL Epoch: 73 Norm Difference for worker 1482 is 1.980823
INFO:root:FL Epoch: 73 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :854
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791433
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250715
INFO:root:FL Epoch: 73 Norm Difference for worker 854 is 1.957408
INFO:root:FL Epoch: 73 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1711
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680374
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246298
INFO:root:FL Epoch: 73 Norm Difference for worker 1711 is 2.127371
INFO:root:FL Epoch: 73 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :834
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555739
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517189
INFO:root:FL Epoch: 73 Norm Difference for worker 834 is 2.30164
INFO:root:FL Epoch: 73 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :816
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569838
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332692
INFO:root:FL Epoch: 73 Norm Difference for worker 816 is 2.077758
INFO:root:FL Epoch: 73 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1421
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308710
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299764
INFO:root:FL Epoch: 73 Norm Difference for worker 1421 is 1.880993
INFO:root:FL Epoch: 73 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1353
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377884
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378889
INFO:root:FL Epoch: 73 Norm Difference for worker 1353 is 2.004143
INFO:root:FL Epoch: 73 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :991
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907213
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386295
INFO:root:FL Epoch: 73 Norm Difference for worker 991 is 2.197156
INFO:root:FL Epoch: 73 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 6], which are global users: [1421, 1190, 1482, 854, 534, 1353, 816]
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.5325669032685897 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:1.7346280813217163                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :906
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280603
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392031
INFO:root:FL Epoch: 74 Norm Difference for worker 906 is 2.163158
INFO:root:FL Epoch: 74 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :572
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647684
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366239
INFO:root:FL Epoch: 74 Norm Difference for worker 572 is 2.044096
INFO:root:FL Epoch: 74 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1804
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690822
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477387
INFO:root:FL Epoch: 74 Norm Difference for worker 1804 is 2.02367
INFO:root:FL Epoch: 74 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :98
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.221970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 98 is 2.0854
INFO:root:FL Epoch: 74 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1645
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603682
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293261
INFO:root:FL Epoch: 74 Norm Difference for worker 1645 is 2.078493
INFO:root:FL Epoch: 74 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :583
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528112
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388271
INFO:root:FL Epoch: 74 Norm Difference for worker 583 is 2.087261
INFO:root:FL Epoch: 74 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :100
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.197176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 100 is 2.085837
INFO:root:FL Epoch: 74 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1709
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531637
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415248
INFO:root:FL Epoch: 74 Norm Difference for worker 1709 is 2.05769
INFO:root:FL Epoch: 74 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :278
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 278 is 2.200734
INFO:root:FL Epoch: 74 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :942
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711302
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420405
INFO:root:FL Epoch: 74 Norm Difference for worker 942 is 1.957936
INFO:root:FL Epoch: 74 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 7 1 4 0], which are global users: [583, 942, 1804, 1709, 572, 1645, 906]
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.543921279556611 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.9384893576304119                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :978
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534692
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287735
INFO:root:FL Epoch: 75 Norm Difference for worker 978 is 1.971566
INFO:root:FL Epoch: 75 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :410
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549639
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271880
INFO:root:FL Epoch: 75 Norm Difference for worker 410 is 1.91166
INFO:root:FL Epoch: 75 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :848
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382857
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532814
INFO:root:FL Epoch: 75 Norm Difference for worker 848 is 2.043979
INFO:root:FL Epoch: 75 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1023
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363903
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406690
INFO:root:FL Epoch: 75 Norm Difference for worker 1023 is 1.905224
INFO:root:FL Epoch: 75 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :197
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542744
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 197 is 2.052696
INFO:root:FL Epoch: 75 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1535
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503468
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257689
INFO:root:FL Epoch: 75 Norm Difference for worker 1535 is 1.966035
INFO:root:FL Epoch: 75 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :786
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590538
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445312
INFO:root:FL Epoch: 75 Norm Difference for worker 786 is 2.116464
INFO:root:FL Epoch: 75 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1486
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758278
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464455
INFO:root:FL Epoch: 75 Norm Difference for worker 1486 is 2.085413
INFO:root:FL Epoch: 75 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1128
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612572
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244647
INFO:root:FL Epoch: 75 Norm Difference for worker 1128 is 1.951542
INFO:root:FL Epoch: 75 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1761
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442382
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429539
INFO:root:FL Epoch: 75 Norm Difference for worker 1761 is 2.011056
INFO:root:FL Epoch: 75 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 1 9 2], which are global users: [1535, 978, 1128, 1023, 410, 1761, 848]
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.48956480271676006 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:2.027579148610433                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 76 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1548
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 1.011653
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503548
INFO:root:FL Epoch: 76 Norm Difference for worker 1548 is 2.139332
INFO:root:FL Epoch: 76 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1417
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653317
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392769
INFO:root:FL Epoch: 76 Norm Difference for worker 1417 is 1.945683
INFO:root:FL Epoch: 76 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :840
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527632
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521754
INFO:root:FL Epoch: 76 Norm Difference for worker 840 is 2.033478
INFO:root:FL Epoch: 76 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :570
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776610
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502371
INFO:root:FL Epoch: 76 Norm Difference for worker 570 is 1.914115
INFO:root:FL Epoch: 76 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1300
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551147
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298169
INFO:root:FL Epoch: 76 Norm Difference for worker 1300 is 2.099613
INFO:root:FL Epoch: 76 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1440
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751785
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196918
INFO:root:FL Epoch: 76 Norm Difference for worker 1440 is 1.942605
INFO:root:FL Epoch: 76 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :716
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741920
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212266
INFO:root:FL Epoch: 76 Norm Difference for worker 716 is 1.88924
INFO:root:FL Epoch: 76 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1434
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654797
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359489
INFO:root:FL Epoch: 76 Norm Difference for worker 1434 is 1.913432
INFO:root:FL Epoch: 76 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1090
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465971
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281653
INFO:root:FL Epoch: 76 Norm Difference for worker 1090 is 1.950844
INFO:root:FL Epoch: 76 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :170
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 170 is 2.026003
INFO:root:FL Epoch: 76 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 3 6 7 8 1 2], which are global users: [1440, 570, 716, 1434, 1090, 1417, 840]
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5036557912826538 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.6055552959442139                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :975
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587937
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288470
INFO:root:FL Epoch: 77 Norm Difference for worker 975 is 2.176645
INFO:root:FL Epoch: 77 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :926
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473339
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354225
INFO:root:FL Epoch: 77 Norm Difference for worker 926 is 1.947262
INFO:root:FL Epoch: 77 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462475
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278459
INFO:root:FL Epoch: 77 Norm Difference for worker 1128 is 1.877686
INFO:root:FL Epoch: 77 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 303 is 2.019054
INFO:root:FL Epoch: 77 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1274
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538882
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266792
INFO:root:FL Epoch: 77 Norm Difference for worker 1274 is 2.022953
INFO:root:FL Epoch: 77 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :483
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488723
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304957
INFO:root:FL Epoch: 77 Norm Difference for worker 483 is 2.115802
INFO:root:FL Epoch: 77 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :944
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673549
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468897
INFO:root:FL Epoch: 77 Norm Difference for worker 944 is 2.082632
INFO:root:FL Epoch: 77 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :904
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632388
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363283
INFO:root:FL Epoch: 77 Norm Difference for worker 904 is 1.786357
INFO:root:FL Epoch: 77 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :394
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609015
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337209
INFO:root:FL Epoch: 77 Norm Difference for worker 394 is 2.196441
INFO:root:FL Epoch: 77 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1282
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543076
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491499
INFO:root:FL Epoch: 77 Norm Difference for worker 1282 is 2.150159
INFO:root:FL Epoch: 77 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 5 6], which are global users: [904, 1274, 1128, 303, 926, 483, 944]
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5314044145976796 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.836804707845052                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :1205
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523615
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189500
INFO:root:FL Epoch: 78 Norm Difference for worker 1205 is 1.99219
INFO:root:FL Epoch: 78 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :886
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586256
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340708
INFO:root:FL Epoch: 78 Norm Difference for worker 886 is 2.018675
INFO:root:FL Epoch: 78 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :835
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678653
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304621
INFO:root:FL Epoch: 78 Norm Difference for worker 835 is 1.97583
INFO:root:FL Epoch: 78 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1830
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527730
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273799
INFO:root:FL Epoch: 78 Norm Difference for worker 1830 is 1.906132
INFO:root:FL Epoch: 78 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :482
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339292
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373198
INFO:root:FL Epoch: 78 Norm Difference for worker 482 is 2.018369
INFO:root:FL Epoch: 78 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1179
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534620
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391910
INFO:root:FL Epoch: 78 Norm Difference for worker 1179 is 1.951209
INFO:root:FL Epoch: 78 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1312
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590941
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409176
INFO:root:FL Epoch: 78 Norm Difference for worker 1312 is 1.945923
INFO:root:FL Epoch: 78 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1592
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507352
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491936
INFO:root:FL Epoch: 78 Norm Difference for worker 1592 is 2.138961
INFO:root:FL Epoch: 78 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :45
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653535
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 45 is 2.100605
INFO:root:FL Epoch: 78 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1934
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547080
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416366
INFO:root:FL Epoch: 78 Norm Difference for worker 1934 is 2.075936
INFO:root:FL Epoch: 78 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 3 6 4 1], which are global users: [1179, 1205, 835, 1830, 1312, 482, 886]
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.5037865428363576 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.854357620080312                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1712
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730155
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261856
INFO:root:FL Epoch: 79 Norm Difference for worker 1712 is 2.049446
INFO:root:FL Epoch: 79 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :194
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321867
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 194 is 1.999352
INFO:root:FL Epoch: 79 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :814
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474435
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316134
INFO:root:FL Epoch: 79 Norm Difference for worker 814 is 2.009876
INFO:root:FL Epoch: 79 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :277
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374020
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 277 is 1.980145
INFO:root:FL Epoch: 79 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1810
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288229
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286135
INFO:root:FL Epoch: 79 Norm Difference for worker 1810 is 1.932901
INFO:root:FL Epoch: 79 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :235
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 235 is 1.971914
INFO:root:FL Epoch: 79 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :487
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467461
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334406
INFO:root:FL Epoch: 79 Norm Difference for worker 487 is 1.966882
INFO:root:FL Epoch: 79 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1274
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596742
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266673
INFO:root:FL Epoch: 79 Norm Difference for worker 1274 is 1.925704
INFO:root:FL Epoch: 79 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :998
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382806
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372114
INFO:root:FL Epoch: 79 Norm Difference for worker 998 is 2.094144
INFO:root:FL Epoch: 79 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1460
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403091
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267257
INFO:root:FL Epoch: 79 Norm Difference for worker 1460 is 1.923928
INFO:root:FL Epoch: 79 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 201 200]
INFO:root:The chosen ones are users: [9 4 6 5 7 3 2], which are global users: [1460, 1810, 487, 235, 1274, 277, 814]
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.4976656717412612 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.869316836198171                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 80 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :951
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810172
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324259
INFO:root:FL Epoch: 80 Norm Difference for worker 951 is 2.036577
INFO:root:FL Epoch: 80 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :196
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.167692
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 196 is 1.980404
INFO:root:FL Epoch: 80 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :695
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582704
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284628
INFO:root:FL Epoch: 80 Norm Difference for worker 695 is 1.921641
INFO:root:FL Epoch: 80 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1847
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790392
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416615
INFO:root:FL Epoch: 80 Norm Difference for worker 1847 is 1.951937
INFO:root:FL Epoch: 80 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1670
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604995
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225241
INFO:root:FL Epoch: 80 Norm Difference for worker 1670 is 1.880115
INFO:root:FL Epoch: 80 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1872
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431617
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277881
INFO:root:FL Epoch: 80 Norm Difference for worker 1872 is 2.046379
INFO:root:FL Epoch: 80 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731693
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361469
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.939119
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :564
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440868
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423368
INFO:root:FL Epoch: 80 Norm Difference for worker 564 is 2.006567
INFO:root:FL Epoch: 80 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :683
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412558
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212213
INFO:root:FL Epoch: 80 Norm Difference for worker 683 is 1.950428
INFO:root:FL Epoch: 80 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :33
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 33 is 2.073442
INFO:root:FL Epoch: 80 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 3 2 4 7 1 5], which are global users: [1335, 1847, 695, 1670, 564, 196, 1872]
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5038805866942686 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:1.9277024666468303                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1552, 722, 895, 1912, 1905, 370, 1295, 616, 579, 1867]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1552
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527942
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473902
INFO:root:FL Epoch: 81 Norm Difference for worker 1552 is 2.070076
INFO:root:FL Epoch: 81 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :722
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548263
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437772
INFO:root:FL Epoch: 81 Norm Difference for worker 722 is 2.033952
INFO:root:FL Epoch: 81 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :895
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512699
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346340
INFO:root:FL Epoch: 81 Norm Difference for worker 895 is 1.996005
INFO:root:FL Epoch: 81 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1912
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498369
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359418
INFO:root:FL Epoch: 81 Norm Difference for worker 1912 is 2.011939
INFO:root:FL Epoch: 81 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1905
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487267
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310119
INFO:root:FL Epoch: 81 Norm Difference for worker 1905 is 1.867548
INFO:root:FL Epoch: 81 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :370
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686420
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192974
INFO:root:FL Epoch: 81 Norm Difference for worker 370 is 1.853896
INFO:root:FL Epoch: 81 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1295
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515837
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344412
INFO:root:FL Epoch: 81 Norm Difference for worker 1295 is 1.976245
INFO:root:FL Epoch: 81 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :616
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610351
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361838
INFO:root:FL Epoch: 81 Norm Difference for worker 616 is 2.070805
INFO:root:FL Epoch: 81 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :579
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821906
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335583
INFO:root:FL Epoch: 81 Norm Difference for worker 579 is 2.074146
INFO:root:FL Epoch: 81 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1867
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764951
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390603
INFO:root:FL Epoch: 81 Norm Difference for worker 1867 is 2.003613
INFO:root:FL Epoch: 81 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 6 1 9 3], which are global users: [370, 1905, 895, 1295, 722, 1867, 1912]
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5189229758346782 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.889554738998413                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1016
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580625
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425872
INFO:root:FL Epoch: 82 Norm Difference for worker 1016 is 2.130781
INFO:root:FL Epoch: 82 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1907
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382176
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593888
INFO:root:FL Epoch: 82 Norm Difference for worker 1907 is 2.058468
INFO:root:FL Epoch: 82 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :171
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611735
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 171 is 2.030492
INFO:root:FL Epoch: 82 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :180
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 180 is 2.002256
INFO:root:FL Epoch: 82 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1447
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463920
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178453
INFO:root:FL Epoch: 82 Norm Difference for worker 1447 is 2.032868
INFO:root:FL Epoch: 82 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :316
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 316 is 2.001324
INFO:root:FL Epoch: 82 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1107
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504471
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357062
INFO:root:FL Epoch: 82 Norm Difference for worker 1107 is 1.925836
INFO:root:FL Epoch: 82 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :451
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562074
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557334
INFO:root:FL Epoch: 82 Norm Difference for worker 451 is 2.145022
INFO:root:FL Epoch: 82 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1246
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630113
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418128
INFO:root:FL Epoch: 82 Norm Difference for worker 1246 is 2.055431
INFO:root:FL Epoch: 82 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :792
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719513
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211687
INFO:root:FL Epoch: 82 Norm Difference for worker 792 is 1.950194
INFO:root:FL Epoch: 82 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [5 9 8 3 6 4 2], which are global users: [316, 792, 1246, 180, 1107, 1447, 171]
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.5346586581538705 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.9315985441207886                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1537
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534524
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615229
INFO:root:FL Epoch: 83 Norm Difference for worker 1537 is 2.19973
INFO:root:FL Epoch: 83 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :890
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571616
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358418
INFO:root:FL Epoch: 83 Norm Difference for worker 890 is 2.045092
INFO:root:FL Epoch: 83 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1098
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270534
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355471
INFO:root:FL Epoch: 83 Norm Difference for worker 1098 is 1.962998
INFO:root:FL Epoch: 83 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :872
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501377
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285880
INFO:root:FL Epoch: 83 Norm Difference for worker 872 is 2.092401
INFO:root:FL Epoch: 83 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1229
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810161
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298128
INFO:root:FL Epoch: 83 Norm Difference for worker 1229 is 2.00036
INFO:root:FL Epoch: 83 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :169
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727894
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338410
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 169 is 1.986033
INFO:root:FL Epoch: 83 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1490
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508973
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297919
INFO:root:FL Epoch: 83 Norm Difference for worker 1490 is 1.941704
INFO:root:FL Epoch: 83 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :659
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500011
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371645
INFO:root:FL Epoch: 83 Norm Difference for worker 659 is 2.122106
INFO:root:FL Epoch: 83 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :81
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 81 is 2.142933
INFO:root:FL Epoch: 83 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :873
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468499
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395008
INFO:root:FL Epoch: 83 Norm Difference for worker 873 is 1.986717
INFO:root:FL Epoch: 83 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 6 4 3 1], which are global users: [169, 873, 1098, 1490, 1229, 872, 890]
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.5225993359790129 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.9522331357002258                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1878
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601125
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319586
INFO:root:FL Epoch: 84 Norm Difference for worker 1878 is 2.050609
INFO:root:FL Epoch: 84 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1224
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546609
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334049
INFO:root:FL Epoch: 84 Norm Difference for worker 1224 is 2.044121
INFO:root:FL Epoch: 84 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :132
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 132 is 1.99477
INFO:root:FL Epoch: 84 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :198
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 198 is 2.007315
INFO:root:FL Epoch: 84 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :140
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 140 is 2.098824
INFO:root:FL Epoch: 84 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :649
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867617
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294954
INFO:root:FL Epoch: 84 Norm Difference for worker 649 is 2.043882
INFO:root:FL Epoch: 84 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :436
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778647
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344338
INFO:root:FL Epoch: 84 Norm Difference for worker 436 is 2.040951
INFO:root:FL Epoch: 84 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :86
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 86 is 1.878301
INFO:root:FL Epoch: 84 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1238
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562446
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286286
INFO:root:FL Epoch: 84 Norm Difference for worker 1238 is 2.004546
INFO:root:FL Epoch: 84 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1616
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660591
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368793
INFO:root:FL Epoch: 84 Norm Difference for worker 1616 is 1.999129
INFO:root:FL Epoch: 84 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 201 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 201 200 201 201]
INFO:root:The chosen ones are users: [6 9 2 3 1 7 4], which are global users: [436, 1616, 132, 198, 1224, 86, 140]
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5339719530414132 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:2.0450120170911155                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :376
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754822
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335975
INFO:root:FL Epoch: 85 Norm Difference for worker 376 is 1.969836
INFO:root:FL Epoch: 85 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :587
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500502
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471922
INFO:root:FL Epoch: 85 Norm Difference for worker 587 is 1.959911
INFO:root:FL Epoch: 85 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1674
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531309
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490608
INFO:root:FL Epoch: 85 Norm Difference for worker 1674 is 1.854674
INFO:root:FL Epoch: 85 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1650
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517437
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430845
INFO:root:FL Epoch: 85 Norm Difference for worker 1650 is 2.004314
INFO:root:FL Epoch: 85 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1395
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461912
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470036
INFO:root:FL Epoch: 85 Norm Difference for worker 1395 is 1.896158
INFO:root:FL Epoch: 85 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :747
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446274
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308519
INFO:root:FL Epoch: 85 Norm Difference for worker 747 is 1.873149
INFO:root:FL Epoch: 85 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :841
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489960
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388346
INFO:root:FL Epoch: 85 Norm Difference for worker 841 is 1.864
INFO:root:FL Epoch: 85 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1713
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417088
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542817
INFO:root:FL Epoch: 85 Norm Difference for worker 1713 is 1.904477
INFO:root:FL Epoch: 85 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :586
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685238
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316747
INFO:root:FL Epoch: 85 Norm Difference for worker 586 is 1.950204
INFO:root:FL Epoch: 85 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :76
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 76 is 1.969903
INFO:root:FL Epoch: 85 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 8 1 5 6], which are global users: [1713, 1395, 1674, 586, 587, 747, 841]
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5292882761534523 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:2.1675389806429544                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1588
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560988
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308086
INFO:root:FL Epoch: 86 Norm Difference for worker 1588 is 1.788858
INFO:root:FL Epoch: 86 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :653
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746871
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367929
INFO:root:FL Epoch: 86 Norm Difference for worker 653 is 1.85239
INFO:root:FL Epoch: 86 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1926
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579466
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318801
INFO:root:FL Epoch: 86 Norm Difference for worker 1926 is 1.941609
INFO:root:FL Epoch: 86 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1027
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559304
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159544
INFO:root:FL Epoch: 86 Norm Difference for worker 1027 is 1.835343
INFO:root:FL Epoch: 86 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :529
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662724
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242013
INFO:root:FL Epoch: 86 Norm Difference for worker 529 is 1.811751
INFO:root:FL Epoch: 86 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1929
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374177
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238084
INFO:root:FL Epoch: 86 Norm Difference for worker 1929 is 1.856188
INFO:root:FL Epoch: 86 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :184
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484960
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.170469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 184 is 1.819091
INFO:root:FL Epoch: 86 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1709
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582839
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299755
INFO:root:FL Epoch: 86 Norm Difference for worker 1709 is 1.902757
INFO:root:FL Epoch: 86 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :74
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 74 is 1.975155
INFO:root:FL Epoch: 86 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1001
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633193
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305077
INFO:root:FL Epoch: 86 Norm Difference for worker 1001 is 1.917295
INFO:root:FL Epoch: 86 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [3 4 0 1 6 5 9], which are global users: [1027, 529, 1588, 653, 184, 1929, 1001]
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5467661443878623 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:2.214654008547465                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1919
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748408
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385997
INFO:root:FL Epoch: 87 Norm Difference for worker 1919 is 2.016341
INFO:root:FL Epoch: 87 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :211
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 211 is 2.055035
INFO:root:FL Epoch: 87 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :692
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432860
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283474
INFO:root:FL Epoch: 87 Norm Difference for worker 692 is 1.9756
INFO:root:FL Epoch: 87 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :756
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512127
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342317
INFO:root:FL Epoch: 87 Norm Difference for worker 756 is 2.134724
INFO:root:FL Epoch: 87 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :452
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420529
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285391
INFO:root:FL Epoch: 87 Norm Difference for worker 452 is 1.910959
INFO:root:FL Epoch: 87 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1940
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597347
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368496
INFO:root:FL Epoch: 87 Norm Difference for worker 1940 is 1.933474
INFO:root:FL Epoch: 87 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1274
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629652
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470643
INFO:root:FL Epoch: 87 Norm Difference for worker 1274 is 1.841199
INFO:root:FL Epoch: 87 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :505
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452285
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357393
INFO:root:FL Epoch: 87 Norm Difference for worker 505 is 2.104712
INFO:root:FL Epoch: 87 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1090
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438368
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301419
INFO:root:FL Epoch: 87 Norm Difference for worker 1090 is 2.035717
INFO:root:FL Epoch: 87 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :674
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663038
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318334
INFO:root:FL Epoch: 87 Norm Difference for worker 674 is 1.895302
INFO:root:FL Epoch: 87 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 6 9 8 2 0], which are global users: [1940, 452, 1274, 674, 1090, 692, 1919]
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5172628357129938 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.9983694553375244                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :754
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673750
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246826
INFO:root:FL Epoch: 88 Norm Difference for worker 754 is 2.056318
INFO:root:FL Epoch: 88 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1867
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533114
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370474
INFO:root:FL Epoch: 88 Norm Difference for worker 1867 is 1.954158
INFO:root:FL Epoch: 88 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1196
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788483
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393733
INFO:root:FL Epoch: 88 Norm Difference for worker 1196 is 2.048361
INFO:root:FL Epoch: 88 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1355
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512678
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365105
INFO:root:FL Epoch: 88 Norm Difference for worker 1355 is 2.16878
INFO:root:FL Epoch: 88 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1912
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377200
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426201
INFO:root:FL Epoch: 88 Norm Difference for worker 1912 is 2.015341
INFO:root:FL Epoch: 88 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1919
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600092
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216689
INFO:root:FL Epoch: 88 Norm Difference for worker 1919 is 1.866607
INFO:root:FL Epoch: 88 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1518
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434023
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309598
INFO:root:FL Epoch: 88 Norm Difference for worker 1518 is 2.031813
INFO:root:FL Epoch: 88 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :818
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489625
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297207
INFO:root:FL Epoch: 88 Norm Difference for worker 818 is 2.054483
INFO:root:FL Epoch: 88 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1600
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498483
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239586
INFO:root:FL Epoch: 88 Norm Difference for worker 1600 is 2.129944
INFO:root:FL Epoch: 88 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1594
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711703
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499498
INFO:root:FL Epoch: 88 Norm Difference for worker 1594 is 2.018698
INFO:root:FL Epoch: 88 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 5 4 7 6 2], which are global users: [1867, 1594, 1919, 1912, 818, 1518, 1196]
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5170090391355402 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.9644141991933186                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 89 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1856
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514145
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378453
INFO:root:FL Epoch: 89 Norm Difference for worker 1856 is 2.024535
INFO:root:FL Epoch: 89 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :476
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831177
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385081
INFO:root:FL Epoch: 89 Norm Difference for worker 476 is 1.972104
INFO:root:FL Epoch: 89 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :191
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.310500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 191 is 2.13354
INFO:root:FL Epoch: 89 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :401
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725106
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394915
INFO:root:FL Epoch: 89 Norm Difference for worker 401 is 2.08714
INFO:root:FL Epoch: 89 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :350
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699470
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646849
INFO:root:FL Epoch: 89 Norm Difference for worker 350 is 2.126587
INFO:root:FL Epoch: 89 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :34
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 34 is 2.086998
INFO:root:FL Epoch: 89 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :742
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554669
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297682
INFO:root:FL Epoch: 89 Norm Difference for worker 742 is 1.953761
INFO:root:FL Epoch: 89 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1521
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542780
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209995
INFO:root:FL Epoch: 89 Norm Difference for worker 1521 is 2.006524
INFO:root:FL Epoch: 89 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1275
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389585
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259724
INFO:root:FL Epoch: 89 Norm Difference for worker 1275 is 1.901515
INFO:root:FL Epoch: 89 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :107
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.211441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 107 is 2.092731
INFO:root:FL Epoch: 89 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [1 8 6 7 0 3 5], which are global users: [476, 1275, 742, 1521, 1856, 401, 34]
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.5235404915669385 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.9428348938624065                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1193
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535353
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279218
INFO:root:FL Epoch: 90 Norm Difference for worker 1193 is 2.119109
INFO:root:FL Epoch: 90 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :930
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640241
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263900
INFO:root:FL Epoch: 90 Norm Difference for worker 930 is 2.024475
INFO:root:FL Epoch: 90 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1680
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578199
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616457
INFO:root:FL Epoch: 90 Norm Difference for worker 1680 is 2.164171
INFO:root:FL Epoch: 90 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1543
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817588
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317396
INFO:root:FL Epoch: 90 Norm Difference for worker 1543 is 2.062403
INFO:root:FL Epoch: 90 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :25
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592938
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 25 is 1.955046
INFO:root:FL Epoch: 90 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1115
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453670
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342793
INFO:root:FL Epoch: 90 Norm Difference for worker 1115 is 2.022955
INFO:root:FL Epoch: 90 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1856
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296105
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175701
INFO:root:FL Epoch: 90 Norm Difference for worker 1856 is 1.776413
INFO:root:FL Epoch: 90 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :687
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584138
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320879
INFO:root:FL Epoch: 90 Norm Difference for worker 687 is 2.131296
INFO:root:FL Epoch: 90 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :24
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.319115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 24 is 2.078088
INFO:root:FL Epoch: 90 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :850
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403200
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357796
INFO:root:FL Epoch: 90 Norm Difference for worker 850 is 2.250823
INFO:root:FL Epoch: 90 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 5 0], which are global users: [1856, 25, 24, 1543, 930, 1115, 1193]
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5311872696175295 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.9996171991030376                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [623, 1591, 1404, 853, 1441, 944, 1326, 1243, 1153, 1122]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 91 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :623
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592600
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425189
INFO:root:FL Epoch: 91 Norm Difference for worker 623 is 2.082502
INFO:root:FL Epoch: 91 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1591
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565221
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420970
INFO:root:FL Epoch: 91 Norm Difference for worker 1591 is 2.154045
INFO:root:FL Epoch: 91 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1404
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422826
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327465
INFO:root:FL Epoch: 91 Norm Difference for worker 1404 is 1.960915
INFO:root:FL Epoch: 91 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :853
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548367
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273866
INFO:root:FL Epoch: 91 Norm Difference for worker 853 is 2.176664
INFO:root:FL Epoch: 91 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1441
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777960
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228474
INFO:root:FL Epoch: 91 Norm Difference for worker 1441 is 2.026123
INFO:root:FL Epoch: 91 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :944
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584839
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274937
INFO:root:FL Epoch: 91 Norm Difference for worker 944 is 2.062695
INFO:root:FL Epoch: 91 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1326
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642288
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322284
INFO:root:FL Epoch: 91 Norm Difference for worker 1326 is 2.115428
INFO:root:FL Epoch: 91 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1243
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714526
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462467
INFO:root:FL Epoch: 91 Norm Difference for worker 1243 is 2.259139
INFO:root:FL Epoch: 91 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1153
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388475
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255572
INFO:root:FL Epoch: 91 Norm Difference for worker 1153 is 2.084452
INFO:root:FL Epoch: 91 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1122
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727928
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418075
INFO:root:FL Epoch: 91 Norm Difference for worker 1122 is 2.106891
INFO:root:FL Epoch: 91 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 8 0 6 9], which are global users: [944, 1441, 1404, 1153, 623, 1326, 1122]
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.5313962136997896 and Test Accuracy:75.0 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:2.2728688716888428                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :845
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487966
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366071
INFO:root:FL Epoch: 92 Norm Difference for worker 845 is 1.921335
INFO:root:FL Epoch: 92 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1139
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497610
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290451
INFO:root:FL Epoch: 92 Norm Difference for worker 1139 is 1.886175
INFO:root:FL Epoch: 92 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :844
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567675
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348269
INFO:root:FL Epoch: 92 Norm Difference for worker 844 is 1.803219
INFO:root:FL Epoch: 92 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :540
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477022
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521394
INFO:root:FL Epoch: 92 Norm Difference for worker 540 is 2.145089
INFO:root:FL Epoch: 92 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :872
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848954
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330621
INFO:root:FL Epoch: 92 Norm Difference for worker 872 is 1.907153
INFO:root:FL Epoch: 92 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1177
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496843
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387532
INFO:root:FL Epoch: 92 Norm Difference for worker 1177 is 1.894825
INFO:root:FL Epoch: 92 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1685
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644308
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246740
INFO:root:FL Epoch: 92 Norm Difference for worker 1685 is 1.919046
INFO:root:FL Epoch: 92 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 175 is 1.891691
INFO:root:FL Epoch: 92 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :376
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823048
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431683
INFO:root:FL Epoch: 92 Norm Difference for worker 376 is 2.120087
INFO:root:FL Epoch: 92 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1367
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717650
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196890
INFO:root:FL Epoch: 92 Norm Difference for worker 1367 is 2.0621
INFO:root:FL Epoch: 92 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [1 4 2 7 0 6 5], which are global users: [1139, 872, 844, 175, 845, 1685, 1177]
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.49796247657607584 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:2.068008840084076                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 93 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :48
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 48 is 1.88107
INFO:root:FL Epoch: 93 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :872
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444057
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300165
INFO:root:FL Epoch: 93 Norm Difference for worker 872 is 1.692783
INFO:root:FL Epoch: 93 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1196
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772779
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375290
INFO:root:FL Epoch: 93 Norm Difference for worker 1196 is 1.974442
INFO:root:FL Epoch: 93 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1390
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554080
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294674
INFO:root:FL Epoch: 93 Norm Difference for worker 1390 is 1.87009
INFO:root:FL Epoch: 93 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1195
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586888
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241322
INFO:root:FL Epoch: 93 Norm Difference for worker 1195 is 2.040055
INFO:root:FL Epoch: 93 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :341
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550143
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248909
INFO:root:FL Epoch: 93 Norm Difference for worker 341 is 2.102009
INFO:root:FL Epoch: 93 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :279
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 279 is 1.910291
INFO:root:FL Epoch: 93 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :241
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 241 is 2.138324
INFO:root:FL Epoch: 93 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1160
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774864
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403397
INFO:root:FL Epoch: 93 Norm Difference for worker 1160 is 2.019511
INFO:root:FL Epoch: 93 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1421
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261862
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315498
INFO:root:FL Epoch: 93 Norm Difference for worker 1421 is 1.847004
INFO:root:FL Epoch: 93 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [1 9 0 3 6 2 8], which are global users: [872, 1421, 48, 1390, 279, 1196, 1160]
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.48586126811364116 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:2.189130743344625                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1770
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403082
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249337
INFO:root:FL Epoch: 94 Norm Difference for worker 1770 is 2.139026
INFO:root:FL Epoch: 94 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :149
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257806
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 149 is 2.006948
INFO:root:FL Epoch: 94 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1939
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543976
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298570
INFO:root:FL Epoch: 94 Norm Difference for worker 1939 is 2.225306
INFO:root:FL Epoch: 94 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1250
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478229
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425442
INFO:root:FL Epoch: 94 Norm Difference for worker 1250 is 2.136951
INFO:root:FL Epoch: 94 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :809
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535874
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301327
INFO:root:FL Epoch: 94 Norm Difference for worker 809 is 2.146632
INFO:root:FL Epoch: 94 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :301
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 301 is 2.109901
INFO:root:FL Epoch: 94 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :636
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626593
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328006
INFO:root:FL Epoch: 94 Norm Difference for worker 636 is 2.176486
INFO:root:FL Epoch: 94 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1925
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502799
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281783
INFO:root:FL Epoch: 94 Norm Difference for worker 1925 is 2.140523
INFO:root:FL Epoch: 94 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :125
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418137
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 125 is 1.958703
INFO:root:FL Epoch: 94 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1537
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870405
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480712
INFO:root:FL Epoch: 94 Norm Difference for worker 1537 is 2.318033
INFO:root:FL Epoch: 94 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [201 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 1 4 7], which are global users: [301, 1770, 125, 1250, 149, 809, 1925]
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.513706715667949 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.95646337668101                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :1495
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493834
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340577
INFO:root:FL Epoch: 95 Norm Difference for worker 1495 is 1.890183
INFO:root:FL Epoch: 95 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1264
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581321
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359661
INFO:root:FL Epoch: 95 Norm Difference for worker 1264 is 1.869955
INFO:root:FL Epoch: 95 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :469
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404212
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336177
INFO:root:FL Epoch: 95 Norm Difference for worker 469 is 1.777565
INFO:root:FL Epoch: 95 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1275
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361082
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224640
INFO:root:FL Epoch: 95 Norm Difference for worker 1275 is 1.708136
INFO:root:FL Epoch: 95 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :734
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484617
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365143
INFO:root:FL Epoch: 95 Norm Difference for worker 734 is 1.916548
INFO:root:FL Epoch: 95 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1533
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763749
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332675
INFO:root:FL Epoch: 95 Norm Difference for worker 1533 is 1.875679
INFO:root:FL Epoch: 95 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1555
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387210
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311216
INFO:root:FL Epoch: 95 Norm Difference for worker 1555 is 1.923864
INFO:root:FL Epoch: 95 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :94
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 94 is 1.812998
INFO:root:FL Epoch: 95 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :311
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 311 is 1.893718
INFO:root:FL Epoch: 95 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :243
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 243 is 1.910326
INFO:root:FL Epoch: 95 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 201 201]
INFO:root:Num selected data points: [201 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 8 5 4], which are global users: [94, 243, 469, 1275, 311, 1533, 734]
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.5362281536354738 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.9356545408566792                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746255
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351262
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 1.974913
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1172
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677458
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473424
INFO:root:FL Epoch: 96 Norm Difference for worker 1172 is 2.137477
INFO:root:FL Epoch: 96 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :440
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295105
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389591
INFO:root:FL Epoch: 96 Norm Difference for worker 440 is 1.86032
INFO:root:FL Epoch: 96 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :207
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 1.081646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 207 is 1.969164
INFO:root:FL Epoch: 96 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :205
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564611
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 205 is 1.902372
INFO:root:FL Epoch: 96 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :542
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444904
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190305
INFO:root:FL Epoch: 96 Norm Difference for worker 542 is 1.808522
INFO:root:FL Epoch: 96 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1428
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385919
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269510
INFO:root:FL Epoch: 96 Norm Difference for worker 1428 is 2.121557
INFO:root:FL Epoch: 96 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1348
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748960
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272817
INFO:root:FL Epoch: 96 Norm Difference for worker 1348 is 1.834996
INFO:root:FL Epoch: 96 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1135
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600470
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438216
INFO:root:FL Epoch: 96 Norm Difference for worker 1135 is 1.931616
INFO:root:FL Epoch: 96 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :308
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 308 is 1.917842
INFO:root:FL Epoch: 96 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 2 8 7 4 0], which are global users: [542, 308, 440, 1135, 1348, 205, 1199]
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.49598712956204133 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.8402313391367595                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 97 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :848
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468082
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348559
INFO:root:FL Epoch: 97 Norm Difference for worker 848 is 1.985884
INFO:root:FL Epoch: 97 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :769
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398501
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416820
INFO:root:FL Epoch: 97 Norm Difference for worker 769 is 2.049862
INFO:root:FL Epoch: 97 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :627
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483683
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420095
INFO:root:FL Epoch: 97 Norm Difference for worker 627 is 1.896459
INFO:root:FL Epoch: 97 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :413
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438537
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308414
INFO:root:FL Epoch: 97 Norm Difference for worker 413 is 1.984911
INFO:root:FL Epoch: 97 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1061
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567152
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475198
INFO:root:FL Epoch: 97 Norm Difference for worker 1061 is 1.854574
INFO:root:FL Epoch: 97 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1302
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724645
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329592
INFO:root:FL Epoch: 97 Norm Difference for worker 1302 is 1.931238
INFO:root:FL Epoch: 97 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1445
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864907
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388199
INFO:root:FL Epoch: 97 Norm Difference for worker 1445 is 2.038966
INFO:root:FL Epoch: 97 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :973
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510248
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410527
INFO:root:FL Epoch: 97 Norm Difference for worker 973 is 1.962237
INFO:root:FL Epoch: 97 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :110
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531510
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 110 is 1.940551
INFO:root:FL Epoch: 97 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :15
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560909
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 15 is 1.846747
INFO:root:FL Epoch: 97 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [2 4 9 7 3 5 8], which are global users: [627, 1061, 15, 973, 413, 1302, 110]
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5222405265359318 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:2.0121388832728067                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 98 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :633
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484517
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399826
INFO:root:FL Epoch: 98 Norm Difference for worker 633 is 1.858771
INFO:root:FL Epoch: 98 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :77
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308039
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 77 is 1.900497
INFO:root:FL Epoch: 98 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1548
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563508
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233377
INFO:root:FL Epoch: 98 Norm Difference for worker 1548 is 1.954572
INFO:root:FL Epoch: 98 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :734
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846030
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330279
INFO:root:FL Epoch: 98 Norm Difference for worker 734 is 1.823012
INFO:root:FL Epoch: 98 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1609
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500572
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388952
INFO:root:FL Epoch: 98 Norm Difference for worker 1609 is 2.084023
INFO:root:FL Epoch: 98 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1375
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509934
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412693
INFO:root:FL Epoch: 98 Norm Difference for worker 1375 is 1.939419
INFO:root:FL Epoch: 98 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1209
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489252
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277617
INFO:root:FL Epoch: 98 Norm Difference for worker 1209 is 1.947726
INFO:root:FL Epoch: 98 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1751
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514139
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265963
INFO:root:FL Epoch: 98 Norm Difference for worker 1751 is 1.964075
INFO:root:FL Epoch: 98 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1773
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530024
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501856
INFO:root:FL Epoch: 98 Norm Difference for worker 1773 is 2.089611
INFO:root:FL Epoch: 98 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1238
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516464
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291176
INFO:root:FL Epoch: 98 Norm Difference for worker 1238 is 1.990219
INFO:root:FL Epoch: 98 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 6 3 9 7 5], which are global users: [77, 633, 1209, 734, 1238, 1751, 1375]
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.49441423661568584 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.8165485858917236                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 99 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1854
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446555
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342588
INFO:root:FL Epoch: 99 Norm Difference for worker 1854 is 2.071959
INFO:root:FL Epoch: 99 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1767
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406941
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366219
INFO:root:FL Epoch: 99 Norm Difference for worker 1767 is 1.904081
INFO:root:FL Epoch: 99 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1325
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.891670
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462658
INFO:root:FL Epoch: 99 Norm Difference for worker 1325 is 1.98455
INFO:root:FL Epoch: 99 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :857
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662975
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355595
INFO:root:FL Epoch: 99 Norm Difference for worker 857 is 2.090676
INFO:root:FL Epoch: 99 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :918
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508875
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299221
INFO:root:FL Epoch: 99 Norm Difference for worker 918 is 1.957898
INFO:root:FL Epoch: 99 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :86
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 86 is 1.74709
INFO:root:FL Epoch: 99 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :420
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565791
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279937
INFO:root:FL Epoch: 99 Norm Difference for worker 420 is 2.026078
INFO:root:FL Epoch: 99 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :564
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395382
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328793
INFO:root:FL Epoch: 99 Norm Difference for worker 564 is 1.870972
INFO:root:FL Epoch: 99 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :958
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903245
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563550
INFO:root:FL Epoch: 99 Norm Difference for worker 958 is 1.997743
INFO:root:FL Epoch: 99 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :800
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527909
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311931
INFO:root:FL Epoch: 99 Norm Difference for worker 800 is 2.002923
INFO:root:FL Epoch: 99 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 7 1 9 8], which are global users: [86, 918, 1325, 564, 1767, 800, 958]
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.5355821602484759 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.9264216820398967                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1823
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442338
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453317
INFO:root:FL Epoch: 100 Norm Difference for worker 1823 is 2.05959
INFO:root:FL Epoch: 100 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1049
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443258
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507565
INFO:root:FL Epoch: 100 Norm Difference for worker 1049 is 1.882123
INFO:root:FL Epoch: 100 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1864
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514044
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253969
INFO:root:FL Epoch: 100 Norm Difference for worker 1864 is 2.019232
INFO:root:FL Epoch: 100 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1066
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482857
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332580
INFO:root:FL Epoch: 100 Norm Difference for worker 1066 is 1.972378
INFO:root:FL Epoch: 100 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1740
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695679
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362972
INFO:root:FL Epoch: 100 Norm Difference for worker 1740 is 1.876351
INFO:root:FL Epoch: 100 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1716
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527976
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437287
INFO:root:FL Epoch: 100 Norm Difference for worker 1716 is 2.014699
INFO:root:FL Epoch: 100 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :840
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454616
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290755
INFO:root:FL Epoch: 100 Norm Difference for worker 840 is 1.764778
INFO:root:FL Epoch: 100 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :11
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 11 is 1.784947
INFO:root:FL Epoch: 100 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1887
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398398
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346089
INFO:root:FL Epoch: 100 Norm Difference for worker 1887 is 1.911038
INFO:root:FL Epoch: 100 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :845
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409130
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354149
INFO:root:FL Epoch: 100 Norm Difference for worker 845 is 1.888487
INFO:root:FL Epoch: 100 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 7 4 1 3], which are global users: [840, 845, 1887, 11, 1740, 1049, 1066]
INFO:root:Aggregating After Defense
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5204386939020718 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:2.1693228681882224                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.990970
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337527
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.2609234154224396 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.30104555040597913 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.909164
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722417
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494124
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.2461579367518425 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.3054028958082199 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 0.919284
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.868584
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356498
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.2328936979174614 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.31397999823093414 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 0.906243
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401215
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314019
INFO:root:FL Epoch: 101 Norm Difference for worker 1526 is 1.982637
INFO:root:FL Epoch: 101 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1322
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639432
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410384
INFO:root:FL Epoch: 101 Norm Difference for worker 1322 is 1.9935
INFO:root:FL Epoch: 101 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :862
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593202
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314803
INFO:root:FL Epoch: 101 Norm Difference for worker 862 is 2.106495
INFO:root:FL Epoch: 101 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :701
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330461
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359430
INFO:root:FL Epoch: 101 Norm Difference for worker 701 is 1.984528
INFO:root:FL Epoch: 101 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1726
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485691
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273717
INFO:root:FL Epoch: 101 Norm Difference for worker 1726 is 2.070565
INFO:root:FL Epoch: 101 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293032
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425182
INFO:root:FL Epoch: 101 Norm Difference for worker 526 is 2.048116
INFO:root:FL Epoch: 101 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1267
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616351
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453933
INFO:root:FL Epoch: 101 Norm Difference for worker 1267 is 2.018109
INFO:root:FL Epoch: 101 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 9 4], which are global users: [701, 0, 2, 1526, 1, 1267, 1322]
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.5324431938283584 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.7565441926320394                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1911
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295970
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440355
INFO:root:FL Epoch: 102 Norm Difference for worker 1911 is 2.015324
INFO:root:FL Epoch: 102 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :427
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577338
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479342
INFO:root:FL Epoch: 102 Norm Difference for worker 427 is 1.925477
INFO:root:FL Epoch: 102 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1354
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537828
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305991
INFO:root:FL Epoch: 102 Norm Difference for worker 1354 is 1.783592
INFO:root:FL Epoch: 102 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :10
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 10 is 2.011999
INFO:root:FL Epoch: 102 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1326
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497527
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421389
INFO:root:FL Epoch: 102 Norm Difference for worker 1326 is 1.875554
INFO:root:FL Epoch: 102 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1947
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645783
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244094
INFO:root:FL Epoch: 102 Norm Difference for worker 1947 is 1.859794
INFO:root:FL Epoch: 102 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1506
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631970
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223191
INFO:root:FL Epoch: 102 Norm Difference for worker 1506 is 1.777387
INFO:root:FL Epoch: 102 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1248
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504828
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252360
INFO:root:FL Epoch: 102 Norm Difference for worker 1248 is 1.875311
INFO:root:FL Epoch: 102 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :887
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379942
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299219
INFO:root:FL Epoch: 102 Norm Difference for worker 887 is 1.906321
INFO:root:FL Epoch: 102 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1077
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434118
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310539
INFO:root:FL Epoch: 102 Norm Difference for worker 1077 is 1.844786
INFO:root:FL Epoch: 102 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 8 7 5 4], which are global users: [1506, 1077, 1354, 887, 1248, 1947, 1326]
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5207012909300187 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:1.0965089797973633                             and Backdoor Test Accuracy:38.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1424
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648629
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328193
INFO:root:FL Epoch: 103 Norm Difference for worker 1424 is 1.916547
INFO:root:FL Epoch: 103 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :869
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644352
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201664
INFO:root:FL Epoch: 103 Norm Difference for worker 869 is 1.873961
INFO:root:FL Epoch: 103 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1947
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535177
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238966
INFO:root:FL Epoch: 103 Norm Difference for worker 1947 is 1.678946
INFO:root:FL Epoch: 103 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1218
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592073
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360022
INFO:root:FL Epoch: 103 Norm Difference for worker 1218 is 1.971255
INFO:root:FL Epoch: 103 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :731
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657367
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491336
INFO:root:FL Epoch: 103 Norm Difference for worker 731 is 1.92864
INFO:root:FL Epoch: 103 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :391
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685549
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322943
INFO:root:FL Epoch: 103 Norm Difference for worker 391 is 2.066258
INFO:root:FL Epoch: 103 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1873
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480702
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247358
INFO:root:FL Epoch: 103 Norm Difference for worker 1873 is 1.931906
INFO:root:FL Epoch: 103 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :163
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 163 is 2.024131
INFO:root:FL Epoch: 103 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1175
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325266
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345754
INFO:root:FL Epoch: 103 Norm Difference for worker 1175 is 1.961617
INFO:root:FL Epoch: 103 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1457
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643525
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258504
INFO:root:FL Epoch: 103 Norm Difference for worker 1457 is 1.971072
INFO:root:FL Epoch: 103 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 6 4 8 9], which are global users: [869, 1424, 1947, 1873, 731, 1175, 1457]
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.5057334409040564 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:1.3855368693669636                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :612
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683465
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456270
INFO:root:FL Epoch: 104 Norm Difference for worker 612 is 2.203655
INFO:root:FL Epoch: 104 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1157
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577478
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259219
INFO:root:FL Epoch: 104 Norm Difference for worker 1157 is 2.152085
INFO:root:FL Epoch: 104 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1471
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617050
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205573
INFO:root:FL Epoch: 104 Norm Difference for worker 1471 is 2.161422
INFO:root:FL Epoch: 104 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :128
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 128 is 2.189939
INFO:root:FL Epoch: 104 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :66
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 66 is 2.130776
INFO:root:FL Epoch: 104 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :879
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551321
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225269
INFO:root:FL Epoch: 104 Norm Difference for worker 879 is 2.105685
INFO:root:FL Epoch: 104 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1042
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558452
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260885
INFO:root:FL Epoch: 104 Norm Difference for worker 1042 is 2.011967
INFO:root:FL Epoch: 104 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1632
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477446
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240816
INFO:root:FL Epoch: 104 Norm Difference for worker 1632 is 2.031614
INFO:root:FL Epoch: 104 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :150
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 150 is 2.097599
INFO:root:FL Epoch: 104 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1712
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703619
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414143
INFO:root:FL Epoch: 104 Norm Difference for worker 1712 is 2.096415
INFO:root:FL Epoch: 104 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 4 7 1 5], which are global users: [1042, 1712, 150, 66, 1632, 1157, 879]
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5161925414029289 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:1.0446639756361644                             and Backdoor Test Accuracy:36.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1124
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393841
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365504
INFO:root:FL Epoch: 105 Norm Difference for worker 1124 is 1.911005
INFO:root:FL Epoch: 105 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :766
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511057
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440468
INFO:root:FL Epoch: 105 Norm Difference for worker 766 is 1.805077
INFO:root:FL Epoch: 105 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :284
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 284 is 1.918944
INFO:root:FL Epoch: 105 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1589
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813024
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441055
INFO:root:FL Epoch: 105 Norm Difference for worker 1589 is 1.978499
INFO:root:FL Epoch: 105 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1409
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384562
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324429
INFO:root:FL Epoch: 105 Norm Difference for worker 1409 is 1.868421
INFO:root:FL Epoch: 105 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1883
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688208
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425749
INFO:root:FL Epoch: 105 Norm Difference for worker 1883 is 1.783947
INFO:root:FL Epoch: 105 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :833
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492272
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349302
INFO:root:FL Epoch: 105 Norm Difference for worker 833 is 1.872038
INFO:root:FL Epoch: 105 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1441
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404743
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362431
INFO:root:FL Epoch: 105 Norm Difference for worker 1441 is 1.821004
INFO:root:FL Epoch: 105 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :847
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568478
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254468
INFO:root:FL Epoch: 105 Norm Difference for worker 847 is 1.855519
INFO:root:FL Epoch: 105 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1423
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247204
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396330
INFO:root:FL Epoch: 105 Norm Difference for worker 1423 is 1.665351
INFO:root:FL Epoch: 105 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 5 4 8 7 6], which are global users: [766, 1423, 1883, 1409, 847, 1441, 833]
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5150095785365385 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:1.4798188010851543                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :534
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686869
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385412
INFO:root:FL Epoch: 106 Norm Difference for worker 534 is 2.030192
INFO:root:FL Epoch: 106 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :186
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 186 is 1.809728
INFO:root:FL Epoch: 106 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :452
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521503
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278191
INFO:root:FL Epoch: 106 Norm Difference for worker 452 is 1.764785
INFO:root:FL Epoch: 106 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :985
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425944
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280423
INFO:root:FL Epoch: 106 Norm Difference for worker 985 is 1.95004
INFO:root:FL Epoch: 106 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1302
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632263
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334464
INFO:root:FL Epoch: 106 Norm Difference for worker 1302 is 1.903733
INFO:root:FL Epoch: 106 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1826
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484095
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436519
INFO:root:FL Epoch: 106 Norm Difference for worker 1826 is 1.833815
INFO:root:FL Epoch: 106 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :274
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 274 is 1.881695
INFO:root:FL Epoch: 106 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1833
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396497
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371050
INFO:root:FL Epoch: 106 Norm Difference for worker 1833 is 1.887333
INFO:root:FL Epoch: 106 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :626
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414613
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305934
INFO:root:FL Epoch: 106 Norm Difference for worker 626 is 1.831464
INFO:root:FL Epoch: 106 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694082
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265231
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.914871
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 201]
INFO:root:The chosen ones are users: [7 4 2 8 1 5 6], which are global users: [1833, 1302, 452, 626, 186, 1826, 274]
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5081368807484122 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.3984498778978984                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1731
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679388
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212229
INFO:root:FL Epoch: 107 Norm Difference for worker 1731 is 2.002901
INFO:root:FL Epoch: 107 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1909
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729048
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293450
INFO:root:FL Epoch: 107 Norm Difference for worker 1909 is 2.042745
INFO:root:FL Epoch: 107 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1927
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579981
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191265
INFO:root:FL Epoch: 107 Norm Difference for worker 1927 is 1.942943
INFO:root:FL Epoch: 107 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1664
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579352
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227817
INFO:root:FL Epoch: 107 Norm Difference for worker 1664 is 1.894138
INFO:root:FL Epoch: 107 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :392
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579270
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317874
INFO:root:FL Epoch: 107 Norm Difference for worker 392 is 1.914268
INFO:root:FL Epoch: 107 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :575
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753121
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381003
INFO:root:FL Epoch: 107 Norm Difference for worker 575 is 2.142667
INFO:root:FL Epoch: 107 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1365
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391433
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294375
INFO:root:FL Epoch: 107 Norm Difference for worker 1365 is 1.970389
INFO:root:FL Epoch: 107 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :308
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.253809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 308 is 1.835252
INFO:root:FL Epoch: 107 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1329
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438832
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285262
INFO:root:FL Epoch: 107 Norm Difference for worker 1329 is 1.962813
INFO:root:FL Epoch: 107 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :142
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 142 is 1.972547
INFO:root:FL Epoch: 107 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [200 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [3 4 7 9 2 6 0], which are global users: [1664, 392, 308, 142, 1927, 1365, 1731]
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.5085617654463824 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.5812302827835083                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 108 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :65
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 65 is 2.01747
INFO:root:FL Epoch: 108 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :163
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369343
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 163 is 2.002113
INFO:root:FL Epoch: 108 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :504
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620388
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269705
INFO:root:FL Epoch: 108 Norm Difference for worker 504 is 1.965249
INFO:root:FL Epoch: 108 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :120
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 120 is 1.965153
INFO:root:FL Epoch: 108 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1859
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637031
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448615
INFO:root:FL Epoch: 108 Norm Difference for worker 1859 is 2.034734
INFO:root:FL Epoch: 108 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1651
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720321
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522223
INFO:root:FL Epoch: 108 Norm Difference for worker 1651 is 1.862723
INFO:root:FL Epoch: 108 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1272
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370186
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629311
INFO:root:FL Epoch: 108 Norm Difference for worker 1272 is 1.985715
INFO:root:FL Epoch: 108 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :595
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734010
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213130
INFO:root:FL Epoch: 108 Norm Difference for worker 595 is 1.9551
INFO:root:FL Epoch: 108 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :487
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243753
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574519
INFO:root:FL Epoch: 108 Norm Difference for worker 487 is 1.823398
INFO:root:FL Epoch: 108 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1181
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386245
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271885
INFO:root:FL Epoch: 108 Norm Difference for worker 1181 is 1.813468
INFO:root:FL Epoch: 108 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 8 5 6], which are global users: [595, 1181, 504, 120, 487, 1651, 1272]
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.4634014140157139 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:1.3275251587231953                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :659
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422911
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298059
INFO:root:FL Epoch: 109 Norm Difference for worker 659 is 2.029999
INFO:root:FL Epoch: 109 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1630
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551634
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470893
INFO:root:FL Epoch: 109 Norm Difference for worker 1630 is 2.035017
INFO:root:FL Epoch: 109 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :147
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 147 is 1.939659
INFO:root:FL Epoch: 109 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1704
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602197
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249873
INFO:root:FL Epoch: 109 Norm Difference for worker 1704 is 1.882481
INFO:root:FL Epoch: 109 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1338
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555104
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462803
INFO:root:FL Epoch: 109 Norm Difference for worker 1338 is 1.837567
INFO:root:FL Epoch: 109 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :376
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779814
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329683
INFO:root:FL Epoch: 109 Norm Difference for worker 376 is 1.970419
INFO:root:FL Epoch: 109 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :790
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526415
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353987
INFO:root:FL Epoch: 109 Norm Difference for worker 790 is 1.913533
INFO:root:FL Epoch: 109 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1004
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737634
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362633
INFO:root:FL Epoch: 109 Norm Difference for worker 1004 is 2.010458
INFO:root:FL Epoch: 109 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1131
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629611
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580603
INFO:root:FL Epoch: 109 Norm Difference for worker 1131 is 1.99344
INFO:root:FL Epoch: 109 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :172
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601063
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 172 is 1.888743
INFO:root:FL Epoch: 109 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [3 4 9 6 2 7 5], which are global users: [1704, 1338, 172, 790, 147, 1004, 376]
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.46761642308796153 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.1410648028055828                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :191
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343828
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 191 is 1.902994
INFO:root:FL Epoch: 110 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :844
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258611
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231561
INFO:root:FL Epoch: 110 Norm Difference for worker 844 is 1.737063
INFO:root:FL Epoch: 110 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1062
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612367
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484421
INFO:root:FL Epoch: 110 Norm Difference for worker 1062 is 2.032364
INFO:root:FL Epoch: 110 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1182
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353908
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575005
INFO:root:FL Epoch: 110 Norm Difference for worker 1182 is 1.841027
INFO:root:FL Epoch: 110 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1038
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689996
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517933
INFO:root:FL Epoch: 110 Norm Difference for worker 1038 is 1.823365
INFO:root:FL Epoch: 110 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :791
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279106
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262356
INFO:root:FL Epoch: 110 Norm Difference for worker 791 is 1.885797
INFO:root:FL Epoch: 110 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1015
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392200
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420945
INFO:root:FL Epoch: 110 Norm Difference for worker 1015 is 1.89253
INFO:root:FL Epoch: 110 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :160
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 160 is 1.96171
INFO:root:FL Epoch: 110 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :803
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.929723
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290174
INFO:root:FL Epoch: 110 Norm Difference for worker 803 is 1.818356
INFO:root:FL Epoch: 110 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :902
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540872
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258008
INFO:root:FL Epoch: 110 Norm Difference for worker 902 is 1.816774
INFO:root:FL Epoch: 110 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 4 8 3 6 5], which are global users: [844, 902, 1038, 803, 1182, 1015, 791]
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.48930199531947866 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.4055967132250469                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.970758
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520903
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.2435727541645368 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.29119694977998734 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.710708
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671265
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597605
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.22066187237699827 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.2904159024357796 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 0.749136
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493228
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250608
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.22242997959256172 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.29587451815605165 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 0.739118
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :212
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363609
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 212 is 1.784884
INFO:root:FL Epoch: 111 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :603
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713931
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323082
INFO:root:FL Epoch: 111 Norm Difference for worker 603 is 1.908988
INFO:root:FL Epoch: 111 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1485
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346655
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292054
INFO:root:FL Epoch: 111 Norm Difference for worker 1485 is 1.871775
INFO:root:FL Epoch: 111 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1334
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410601
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529477
INFO:root:FL Epoch: 111 Norm Difference for worker 1334 is 1.865015
INFO:root:FL Epoch: 111 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :260
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.982071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272990
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 260 is 1.85546
INFO:root:FL Epoch: 111 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1352
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503490
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226058
INFO:root:FL Epoch: 111 Norm Difference for worker 1352 is 1.969278
INFO:root:FL Epoch: 111 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1619
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480397
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174060
INFO:root:FL Epoch: 111 Norm Difference for worker 1619 is 1.863463
INFO:root:FL Epoch: 111 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 6], which are global users: [260, 0, 2, 212, 1, 1485, 1334]
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.4868144094944 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.4510427862405777                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 112 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :254
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 254 is 1.871904
INFO:root:FL Epoch: 112 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :253
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.364076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 253 is 1.840357
INFO:root:FL Epoch: 112 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :267
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 267 is 1.843002
INFO:root:FL Epoch: 112 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1281
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647831
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193785
INFO:root:FL Epoch: 112 Norm Difference for worker 1281 is 1.859728
INFO:root:FL Epoch: 112 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :552
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540866
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425997
INFO:root:FL Epoch: 112 Norm Difference for worker 552 is 1.913654
INFO:root:FL Epoch: 112 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1889
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515789
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356768
INFO:root:FL Epoch: 112 Norm Difference for worker 1889 is 1.963525
INFO:root:FL Epoch: 112 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1555
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558114
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331475
INFO:root:FL Epoch: 112 Norm Difference for worker 1555 is 1.854258
INFO:root:FL Epoch: 112 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1475
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594410
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361672
INFO:root:FL Epoch: 112 Norm Difference for worker 1475 is 1.89084
INFO:root:FL Epoch: 112 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :334
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458676
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 334 is 1.884858
INFO:root:FL Epoch: 112 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :202
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 202 is 1.913562
INFO:root:FL Epoch: 112 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 201 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 201 201 200 201 201 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 6], which are global users: [1475, 254, 267, 1281, 253, 334, 1555]
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.480507748968461 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.7400777637958527                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 113 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :173
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 173 is 1.887874
INFO:root:FL Epoch: 113 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1677
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584019
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374368
INFO:root:FL Epoch: 113 Norm Difference for worker 1677 is 1.937748
INFO:root:FL Epoch: 113 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1063
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440656
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352658
INFO:root:FL Epoch: 113 Norm Difference for worker 1063 is 2.043713
INFO:root:FL Epoch: 113 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :828
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548513
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214230
INFO:root:FL Epoch: 113 Norm Difference for worker 828 is 2.080554
INFO:root:FL Epoch: 113 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1243
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671634
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418848
INFO:root:FL Epoch: 113 Norm Difference for worker 1243 is 2.179022
INFO:root:FL Epoch: 113 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1645
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771066
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261057
INFO:root:FL Epoch: 113 Norm Difference for worker 1645 is 1.858174
INFO:root:FL Epoch: 113 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :701
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663576
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257674
INFO:root:FL Epoch: 113 Norm Difference for worker 701 is 1.945998
INFO:root:FL Epoch: 113 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :511
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443673
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204215
INFO:root:FL Epoch: 113 Norm Difference for worker 511 is 1.953408
INFO:root:FL Epoch: 113 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1769
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784892
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385492
INFO:root:FL Epoch: 113 Norm Difference for worker 1769 is 1.889019
INFO:root:FL Epoch: 113 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :539
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668100
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273529
INFO:root:FL Epoch: 113 Norm Difference for worker 539 is 2.007527
INFO:root:FL Epoch: 113 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [1 7 6 5 8 0 2], which are global users: [1677, 511, 701, 1645, 1769, 173, 1063]
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.48102959990501404 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.8689245084921519                             and Backdoor Test Accuracy:50.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1682
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323002
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353209
INFO:root:FL Epoch: 114 Norm Difference for worker 1682 is 1.910938
INFO:root:FL Epoch: 114 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :817
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725088
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270188
INFO:root:FL Epoch: 114 Norm Difference for worker 817 is 1.917396
INFO:root:FL Epoch: 114 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :747
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602698
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261294
INFO:root:FL Epoch: 114 Norm Difference for worker 747 is 1.826086
INFO:root:FL Epoch: 114 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1065
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556263
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436255
INFO:root:FL Epoch: 114 Norm Difference for worker 1065 is 1.8799
INFO:root:FL Epoch: 114 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :615
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323959
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208496
INFO:root:FL Epoch: 114 Norm Difference for worker 615 is 1.915347
INFO:root:FL Epoch: 114 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :439
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313391
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358330
INFO:root:FL Epoch: 114 Norm Difference for worker 439 is 1.83344
INFO:root:FL Epoch: 114 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :501
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424103
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332732
INFO:root:FL Epoch: 114 Norm Difference for worker 501 is 1.875176
INFO:root:FL Epoch: 114 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1941
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605046
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480529
INFO:root:FL Epoch: 114 Norm Difference for worker 1941 is 1.881798
INFO:root:FL Epoch: 114 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :729
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368508
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426768
INFO:root:FL Epoch: 114 Norm Difference for worker 729 is 1.903433
INFO:root:FL Epoch: 114 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1621
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522035
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384256
INFO:root:FL Epoch: 114 Norm Difference for worker 1621 is 1.881114
INFO:root:FL Epoch: 114 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 8 0 6 7], which are global users: [439, 1621, 747, 729, 1682, 501, 1941]
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.4620817145880531 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.964245448509852                             and Backdoor Test Accuracy:47.5 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1247
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562968
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419306
INFO:root:FL Epoch: 115 Norm Difference for worker 1247 is 1.923895
INFO:root:FL Epoch: 115 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1891
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547291
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250253
INFO:root:FL Epoch: 115 Norm Difference for worker 1891 is 1.802898
INFO:root:FL Epoch: 115 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1092
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560963
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309898
INFO:root:FL Epoch: 115 Norm Difference for worker 1092 is 1.896721
INFO:root:FL Epoch: 115 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1160
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615184
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402054
INFO:root:FL Epoch: 115 Norm Difference for worker 1160 is 1.976186
INFO:root:FL Epoch: 115 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1542
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373313
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333216
INFO:root:FL Epoch: 115 Norm Difference for worker 1542 is 1.908961
INFO:root:FL Epoch: 115 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599498
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359596
INFO:root:FL Epoch: 115 Norm Difference for worker 1248 is 1.835257
INFO:root:FL Epoch: 115 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1758
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760788
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297310
INFO:root:FL Epoch: 115 Norm Difference for worker 1758 is 1.823179
INFO:root:FL Epoch: 115 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :206
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.223737
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 206 is 1.618008
INFO:root:FL Epoch: 115 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :881
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504314
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328670
INFO:root:FL Epoch: 115 Norm Difference for worker 881 is 1.67118
INFO:root:FL Epoch: 115 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1311
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499041
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502595
INFO:root:FL Epoch: 115 Norm Difference for worker 1311 is 1.841689
INFO:root:FL Epoch: 115 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 7 1 5 0], which are global users: [1758, 1311, 881, 206, 1891, 1248, 1247]
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.47041625836316275 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:0.9548917313416799                             and Backdoor Test Accuracy:45.0 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :670
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803220
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300833
INFO:root:FL Epoch: 116 Norm Difference for worker 670 is 1.810688
INFO:root:FL Epoch: 116 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :77
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302404
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 77 is 1.715531
INFO:root:FL Epoch: 116 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :14
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 14 is 1.823799
INFO:root:FL Epoch: 116 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :831
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484252
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374562
INFO:root:FL Epoch: 116 Norm Difference for worker 831 is 1.767816
INFO:root:FL Epoch: 116 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :557
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493028
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320525
INFO:root:FL Epoch: 116 Norm Difference for worker 557 is 1.860645
INFO:root:FL Epoch: 116 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1196
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532961
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385628
INFO:root:FL Epoch: 116 Norm Difference for worker 1196 is 1.919783
INFO:root:FL Epoch: 116 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1519
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898497
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317874
INFO:root:FL Epoch: 116 Norm Difference for worker 1519 is 1.846095
INFO:root:FL Epoch: 116 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :237
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 237 is 1.878242
INFO:root:FL Epoch: 116 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1512
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656987
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249262
INFO:root:FL Epoch: 116 Norm Difference for worker 1512 is 1.85511
INFO:root:FL Epoch: 116 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :592
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349843
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364073
INFO:root:FL Epoch: 116 Norm Difference for worker 592 is 1.833629
INFO:root:FL Epoch: 116 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [3 0 1 9 2 6 4], which are global users: [831, 670, 77, 592, 14, 1519, 557]
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.4889078455812791 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.8551907042662302                             and Backdoor Test Accuracy:50.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 117 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :300
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380730
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 300 is 1.944378
INFO:root:FL Epoch: 117 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :251
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 251 is 1.895355
INFO:root:FL Epoch: 117 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :562
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575596
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233585
INFO:root:FL Epoch: 117 Norm Difference for worker 562 is 1.8004
INFO:root:FL Epoch: 117 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1356
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796038
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380013
INFO:root:FL Epoch: 117 Norm Difference for worker 1356 is 2.081647
INFO:root:FL Epoch: 117 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :204
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 204 is 1.97747
INFO:root:FL Epoch: 117 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :809
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851412
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347671
INFO:root:FL Epoch: 117 Norm Difference for worker 809 is 1.79384
INFO:root:FL Epoch: 117 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :968
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647680
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391940
INFO:root:FL Epoch: 117 Norm Difference for worker 968 is 1.832729
INFO:root:FL Epoch: 117 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1645
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459221
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243786
INFO:root:FL Epoch: 117 Norm Difference for worker 1645 is 1.818261
INFO:root:FL Epoch: 117 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1482
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651696
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313715
INFO:root:FL Epoch: 117 Norm Difference for worker 1482 is 1.853943
INFO:root:FL Epoch: 117 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :844
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421611
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213090
INFO:root:FL Epoch: 117 Norm Difference for worker 844 is 1.676572
INFO:root:FL Epoch: 117 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 9 2 8 1 5 6], which are global users: [1645, 844, 562, 1482, 251, 809, 968]
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.48497741537935596 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.8701064685980479                             and Backdoor Test Accuracy:53.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 118 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :191
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 191 is 2.005791
INFO:root:FL Epoch: 118 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1890
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577172
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327267
INFO:root:FL Epoch: 118 Norm Difference for worker 1890 is 1.898099
INFO:root:FL Epoch: 118 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :999
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498684
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320908
INFO:root:FL Epoch: 118 Norm Difference for worker 999 is 1.911387
INFO:root:FL Epoch: 118 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1404
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348965
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262112
INFO:root:FL Epoch: 118 Norm Difference for worker 1404 is 1.753302
INFO:root:FL Epoch: 118 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :725
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450178
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351721
INFO:root:FL Epoch: 118 Norm Difference for worker 725 is 1.863864
INFO:root:FL Epoch: 118 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1853
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380889
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358527
INFO:root:FL Epoch: 118 Norm Difference for worker 1853 is 2.040863
INFO:root:FL Epoch: 118 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1315
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561495
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441765
INFO:root:FL Epoch: 118 Norm Difference for worker 1315 is 1.955211
INFO:root:FL Epoch: 118 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1082
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562443
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404031
INFO:root:FL Epoch: 118 Norm Difference for worker 1082 is 1.792294
INFO:root:FL Epoch: 118 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :862
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802198
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327141
INFO:root:FL Epoch: 118 Norm Difference for worker 862 is 1.940676
INFO:root:FL Epoch: 118 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :84
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.836787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 84 is 1.849198
INFO:root:FL Epoch: 118 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [3 9 7 4 1 6 2], which are global users: [1404, 84, 1082, 725, 1890, 1315, 999]
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.48522449766888337 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:0.9689492583274841                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :917
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521026
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373219
INFO:root:FL Epoch: 119 Norm Difference for worker 917 is 2.007642
INFO:root:FL Epoch: 119 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :474
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416330
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386380
INFO:root:FL Epoch: 119 Norm Difference for worker 474 is 1.970732
INFO:root:FL Epoch: 119 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618256
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387882
INFO:root:FL Epoch: 119 Norm Difference for worker 748 is 2.029246
INFO:root:FL Epoch: 119 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1071
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730431
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266418
INFO:root:FL Epoch: 119 Norm Difference for worker 1071 is 1.88203
INFO:root:FL Epoch: 119 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :436
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587785
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468230
INFO:root:FL Epoch: 119 Norm Difference for worker 436 is 1.86191
INFO:root:FL Epoch: 119 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1413
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447094
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206885
INFO:root:FL Epoch: 119 Norm Difference for worker 1413 is 1.77668
INFO:root:FL Epoch: 119 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :141
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.308600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240170
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 141 is 1.763006
INFO:root:FL Epoch: 119 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :439
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574135
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352621
INFO:root:FL Epoch: 119 Norm Difference for worker 439 is 1.815227
INFO:root:FL Epoch: 119 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :281
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 281 is 1.820665
INFO:root:FL Epoch: 119 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1415
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525547
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384175
INFO:root:FL Epoch: 119 Norm Difference for worker 1415 is 2.106082
INFO:root:FL Epoch: 119 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [7 4 8 3 1 5 6], which are global users: [439, 436, 281, 1071, 474, 1413, 141]
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.48180682869518504 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:0.8152495721975962                             and Backdoor Test Accuracy:55.0 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :672
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551325
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468905
INFO:root:FL Epoch: 120 Norm Difference for worker 672 is 1.955648
INFO:root:FL Epoch: 120 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1130
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677956
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484162
INFO:root:FL Epoch: 120 Norm Difference for worker 1130 is 2.009037
INFO:root:FL Epoch: 120 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :89
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394278
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 89 is 1.92585
INFO:root:FL Epoch: 120 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :766
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455974
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261995
INFO:root:FL Epoch: 120 Norm Difference for worker 766 is 1.767541
INFO:root:FL Epoch: 120 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :604
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795129
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207247
INFO:root:FL Epoch: 120 Norm Difference for worker 604 is 1.913039
INFO:root:FL Epoch: 120 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1934
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428036
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300381
INFO:root:FL Epoch: 120 Norm Difference for worker 1934 is 2.033301
INFO:root:FL Epoch: 120 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1085
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334293
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401511
INFO:root:FL Epoch: 120 Norm Difference for worker 1085 is 1.981977
INFO:root:FL Epoch: 120 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1785
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491118
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229178
INFO:root:FL Epoch: 120 Norm Difference for worker 1785 is 1.97019
INFO:root:FL Epoch: 120 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :799
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290051
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262874
INFO:root:FL Epoch: 120 Norm Difference for worker 799 is 1.944624
INFO:root:FL Epoch: 120 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :394
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568636
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361506
INFO:root:FL Epoch: 120 Norm Difference for worker 394 is 1.918815
INFO:root:FL Epoch: 120 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 9 2 0 6 4 8], which are global users: [766, 394, 89, 672, 1085, 604, 799]
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.48220771200516643 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:0.8302866816520691                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762870
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301537
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.2285534106194973 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.2588458687067032 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.611161
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576275
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290564
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.2129429429769516 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.2606265485286713 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 0.598395
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612643
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261766
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.17764235163728395 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.2621114656329155 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 0.615057
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1516
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418740
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369612
INFO:root:FL Epoch: 121 Norm Difference for worker 1516 is 1.915685
INFO:root:FL Epoch: 121 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1691
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623993
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394755
INFO:root:FL Epoch: 121 Norm Difference for worker 1691 is 1.906651
INFO:root:FL Epoch: 121 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1534
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445074
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189947
INFO:root:FL Epoch: 121 Norm Difference for worker 1534 is 1.829276
INFO:root:FL Epoch: 121 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1245
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478775
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363423
INFO:root:FL Epoch: 121 Norm Difference for worker 1245 is 1.914413
INFO:root:FL Epoch: 121 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1693
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554834
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208787
INFO:root:FL Epoch: 121 Norm Difference for worker 1693 is 1.771621
INFO:root:FL Epoch: 121 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :520
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523639
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500020
INFO:root:FL Epoch: 121 Norm Difference for worker 520 is 1.833532
INFO:root:FL Epoch: 121 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680455
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278780
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 1.842455
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 9], which are global users: [1693, 0, 2, 520, 1, 1534, 996]
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.47453438359148364 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.45371004442373913                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 122 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :847
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487452
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301939
INFO:root:FL Epoch: 122 Norm Difference for worker 847 is 1.84303
INFO:root:FL Epoch: 122 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :302
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 302 is 1.817603
INFO:root:FL Epoch: 122 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1156
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519045
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301993
INFO:root:FL Epoch: 122 Norm Difference for worker 1156 is 1.883095
INFO:root:FL Epoch: 122 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1187
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538614
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187472
INFO:root:FL Epoch: 122 Norm Difference for worker 1187 is 1.871756
INFO:root:FL Epoch: 122 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :252
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 252 is 1.926949
INFO:root:FL Epoch: 122 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :460
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365393
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296941
INFO:root:FL Epoch: 122 Norm Difference for worker 460 is 2.009122
INFO:root:FL Epoch: 122 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1246
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430311
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695201
INFO:root:FL Epoch: 122 Norm Difference for worker 1246 is 1.966599
INFO:root:FL Epoch: 122 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :151
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 151 is 1.862214
INFO:root:FL Epoch: 122 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :556
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695793
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403775
INFO:root:FL Epoch: 122 Norm Difference for worker 556 is 1.928547
INFO:root:FL Epoch: 122 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1367
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389731
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286077
INFO:root:FL Epoch: 122 Norm Difference for worker 1367 is 2.006993
INFO:root:FL Epoch: 122 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 6], which are global users: [151, 847, 1156, 1187, 302, 556, 1246]
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.48992592271636515 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.7492029170195261                             and Backdoor Test Accuracy:55.0 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :900
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609174
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353921
INFO:root:FL Epoch: 123 Norm Difference for worker 900 is 1.882256
INFO:root:FL Epoch: 123 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :614
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803189
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361114
INFO:root:FL Epoch: 123 Norm Difference for worker 614 is 1.875943
INFO:root:FL Epoch: 123 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1916
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520294
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249453
INFO:root:FL Epoch: 123 Norm Difference for worker 1916 is 1.862545
INFO:root:FL Epoch: 123 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1149
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373748
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434554
INFO:root:FL Epoch: 123 Norm Difference for worker 1149 is 1.887993
INFO:root:FL Epoch: 123 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1225
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759869
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359073
INFO:root:FL Epoch: 123 Norm Difference for worker 1225 is 1.857828
INFO:root:FL Epoch: 123 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :315
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581436
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436002
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 315 is 1.753952
INFO:root:FL Epoch: 123 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :66
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 66 is 1.816505
INFO:root:FL Epoch: 123 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :959
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744985
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385299
INFO:root:FL Epoch: 123 Norm Difference for worker 959 is 1.987203
INFO:root:FL Epoch: 123 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :938
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626583
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269241
INFO:root:FL Epoch: 123 Norm Difference for worker 938 is 1.892155
INFO:root:FL Epoch: 123 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1349
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470954
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355621
INFO:root:FL Epoch: 123 Norm Difference for worker 1349 is 1.868509
INFO:root:FL Epoch: 123 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 6 4 3 0 2], which are global users: [315, 1349, 66, 1225, 1149, 900, 1916]
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5037933430250954 and Test Accuracy:75.0 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.7740798195203146                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :1329
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879648
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321703
INFO:root:FL Epoch: 124 Norm Difference for worker 1329 is 1.907238
INFO:root:FL Epoch: 124 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1737
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390447
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334957
INFO:root:FL Epoch: 124 Norm Difference for worker 1737 is 1.828637
INFO:root:FL Epoch: 124 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :570
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368197
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258884
INFO:root:FL Epoch: 124 Norm Difference for worker 570 is 1.7059
INFO:root:FL Epoch: 124 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1802
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586106
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349976
INFO:root:FL Epoch: 124 Norm Difference for worker 1802 is 1.89322
INFO:root:FL Epoch: 124 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1438
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808846
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425080
INFO:root:FL Epoch: 124 Norm Difference for worker 1438 is 1.823336
INFO:root:FL Epoch: 124 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :725
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354833
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225378
INFO:root:FL Epoch: 124 Norm Difference for worker 725 is 1.793472
INFO:root:FL Epoch: 124 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :394
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424877
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341793
INFO:root:FL Epoch: 124 Norm Difference for worker 394 is 1.861802
INFO:root:FL Epoch: 124 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :456
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541264
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202635
INFO:root:FL Epoch: 124 Norm Difference for worker 456 is 1.898414
INFO:root:FL Epoch: 124 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1801
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529314
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184474
INFO:root:FL Epoch: 124 Norm Difference for worker 1801 is 1.937221
INFO:root:FL Epoch: 124 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1221
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594190
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364454
INFO:root:FL Epoch: 124 Norm Difference for worker 1221 is 1.93123
INFO:root:FL Epoch: 124 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 6 1 0 9], which are global users: [725, 1438, 570, 394, 1737, 1329, 1221]
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.4737318596419166 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.6205629756053289                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :371
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368042
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251914
INFO:root:FL Epoch: 125 Norm Difference for worker 371 is 1.913053
INFO:root:FL Epoch: 125 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :455
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781531
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446513
INFO:root:FL Epoch: 125 Norm Difference for worker 455 is 2.069165
INFO:root:FL Epoch: 125 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :747
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421960
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306016
INFO:root:FL Epoch: 125 Norm Difference for worker 747 is 1.755051
INFO:root:FL Epoch: 125 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :106
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.845653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 106 is 1.939695
INFO:root:FL Epoch: 125 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1722
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273966
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159303
INFO:root:FL Epoch: 125 Norm Difference for worker 1722 is 1.864389
INFO:root:FL Epoch: 125 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :631
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505732
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285868
INFO:root:FL Epoch: 125 Norm Difference for worker 631 is 1.917851
INFO:root:FL Epoch: 125 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :374
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758340
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290114
INFO:root:FL Epoch: 125 Norm Difference for worker 374 is 1.758764
INFO:root:FL Epoch: 125 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1617
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537408
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397959
INFO:root:FL Epoch: 125 Norm Difference for worker 1617 is 1.862098
INFO:root:FL Epoch: 125 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :513
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944291
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435435
INFO:root:FL Epoch: 125 Norm Difference for worker 513 is 1.994856
INFO:root:FL Epoch: 125 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1270
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468202
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164448
INFO:root:FL Epoch: 125 Norm Difference for worker 1270 is 1.80767
INFO:root:FL Epoch: 125 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 9 2 4 7 0 3], which are global users: [374, 1270, 747, 1722, 1617, 371, 106]
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.4854612964041093 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.6323502510786057                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 126 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1262
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502765
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274412
INFO:root:FL Epoch: 126 Norm Difference for worker 1262 is 2.02926
INFO:root:FL Epoch: 126 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :808
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388367
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257293
INFO:root:FL Epoch: 126 Norm Difference for worker 808 is 1.860858
INFO:root:FL Epoch: 126 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :93
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 93 is 1.840613
INFO:root:FL Epoch: 126 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1323
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794994
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240484
INFO:root:FL Epoch: 126 Norm Difference for worker 1323 is 1.993464
INFO:root:FL Epoch: 126 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1090
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566224
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216614
INFO:root:FL Epoch: 126 Norm Difference for worker 1090 is 1.724693
INFO:root:FL Epoch: 126 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :844
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237067
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262574
INFO:root:FL Epoch: 126 Norm Difference for worker 844 is 1.660243
INFO:root:FL Epoch: 126 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :915
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509106
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316130
INFO:root:FL Epoch: 126 Norm Difference for worker 915 is 1.939798
INFO:root:FL Epoch: 126 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :433
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490838
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364713
INFO:root:FL Epoch: 126 Norm Difference for worker 433 is 1.801161
INFO:root:FL Epoch: 126 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :605
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737224
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320660
INFO:root:FL Epoch: 126 Norm Difference for worker 605 is 1.849646
INFO:root:FL Epoch: 126 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :416
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670353
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258198
INFO:root:FL Epoch: 126 Norm Difference for worker 416 is 1.840452
INFO:root:FL Epoch: 126 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [5 4 8 7 1 9 2], which are global users: [844, 1090, 605, 433, 808, 416, 93]
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.4625732521800434 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.6138022243976593                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :857
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503367
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310266
INFO:root:FL Epoch: 127 Norm Difference for worker 857 is 2.14238
INFO:root:FL Epoch: 127 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1514
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568382
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331007
INFO:root:FL Epoch: 127 Norm Difference for worker 1514 is 1.951731
INFO:root:FL Epoch: 127 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :267
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512993
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.183589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 267 is 1.844295
INFO:root:FL Epoch: 127 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1586
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.927662
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410592
INFO:root:FL Epoch: 127 Norm Difference for worker 1586 is 1.900321
INFO:root:FL Epoch: 127 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :889
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556207
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259547
INFO:root:FL Epoch: 127 Norm Difference for worker 889 is 2.025415
INFO:root:FL Epoch: 127 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1059
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665786
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203447
INFO:root:FL Epoch: 127 Norm Difference for worker 1059 is 1.784862
INFO:root:FL Epoch: 127 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1388
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433471
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327998
INFO:root:FL Epoch: 127 Norm Difference for worker 1388 is 1.901518
INFO:root:FL Epoch: 127 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1617
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379092
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356981
INFO:root:FL Epoch: 127 Norm Difference for worker 1617 is 1.904373
INFO:root:FL Epoch: 127 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1454
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339222
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204255
INFO:root:FL Epoch: 127 Norm Difference for worker 1454 is 1.832664
INFO:root:FL Epoch: 127 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1616
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435241
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464353
INFO:root:FL Epoch: 127 Norm Difference for worker 1616 is 1.91893
INFO:root:FL Epoch: 127 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 8 2 9 6 3 1], which are global users: [1059, 1454, 267, 1616, 1388, 1586, 1514]
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.4589180657092263 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.9146776596705118                             and Backdoor Test Accuracy:49.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 128 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :310
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 310 is 2.244402
INFO:root:FL Epoch: 128 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :104
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382480
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 104 is 1.967383
INFO:root:FL Epoch: 128 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :160
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.835052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 160 is 2.123
INFO:root:FL Epoch: 128 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :498
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346661
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407706
INFO:root:FL Epoch: 128 Norm Difference for worker 498 is 2.014655
INFO:root:FL Epoch: 128 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :577
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626450
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391867
INFO:root:FL Epoch: 128 Norm Difference for worker 577 is 2.003606
INFO:root:FL Epoch: 128 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1023
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380851
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233921
INFO:root:FL Epoch: 128 Norm Difference for worker 1023 is 1.907145
INFO:root:FL Epoch: 128 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :911
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730795
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342379
INFO:root:FL Epoch: 128 Norm Difference for worker 911 is 1.954412
INFO:root:FL Epoch: 128 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :823
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584114
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336025
INFO:root:FL Epoch: 128 Norm Difference for worker 823 is 1.955983
INFO:root:FL Epoch: 128 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1667
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626251
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294626
INFO:root:FL Epoch: 128 Norm Difference for worker 1667 is 2.077195
INFO:root:FL Epoch: 128 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :754
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459649
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364976
INFO:root:FL Epoch: 128 Norm Difference for worker 754 is 1.920141
INFO:root:FL Epoch: 128 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [5 9 7 6 1 4 3], which are global users: [1023, 754, 823, 911, 104, 577, 498]
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.4557497571496403 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.8119787077109019                             and Backdoor Test Accuracy:56.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1492
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467581
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260951
INFO:root:FL Epoch: 129 Norm Difference for worker 1492 is 1.815672
INFO:root:FL Epoch: 129 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :354
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575513
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324392
INFO:root:FL Epoch: 129 Norm Difference for worker 354 is 1.796377
INFO:root:FL Epoch: 129 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :33
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 33 is 1.887242
INFO:root:FL Epoch: 129 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1440
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579577
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277371
INFO:root:FL Epoch: 129 Norm Difference for worker 1440 is 1.855716
INFO:root:FL Epoch: 129 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :773
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476389
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226371
INFO:root:FL Epoch: 129 Norm Difference for worker 773 is 1.785688
INFO:root:FL Epoch: 129 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1028
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.966996
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564811
INFO:root:FL Epoch: 129 Norm Difference for worker 1028 is 1.78829
INFO:root:FL Epoch: 129 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :863
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590735
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441303
INFO:root:FL Epoch: 129 Norm Difference for worker 863 is 1.828022
INFO:root:FL Epoch: 129 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :755
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536788
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382804
INFO:root:FL Epoch: 129 Norm Difference for worker 755 is 1.895356
INFO:root:FL Epoch: 129 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1307
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731542
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441960
INFO:root:FL Epoch: 129 Norm Difference for worker 1307 is 1.795099
INFO:root:FL Epoch: 129 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1724
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640017
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347659
INFO:root:FL Epoch: 129 Norm Difference for worker 1724 is 1.929463
INFO:root:FL Epoch: 129 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 6 4 1 7], which are global users: [1028, 1492, 1307, 863, 773, 354, 755]
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.46934375166893005 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.9132397671540579                             and Backdoor Test Accuracy:46.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 130 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :324
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.935112
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 324 is 1.746285
INFO:root:FL Epoch: 130 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :145
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 145 is 1.742378
INFO:root:FL Epoch: 130 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :544
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615987
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359396
INFO:root:FL Epoch: 130 Norm Difference for worker 544 is 1.823985
INFO:root:FL Epoch: 130 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :970
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419121
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282472
INFO:root:FL Epoch: 130 Norm Difference for worker 970 is 1.896836
INFO:root:FL Epoch: 130 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1423
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485020
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274053
INFO:root:FL Epoch: 130 Norm Difference for worker 1423 is 1.715575
INFO:root:FL Epoch: 130 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1402
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338106
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280700
INFO:root:FL Epoch: 130 Norm Difference for worker 1402 is 1.801382
INFO:root:FL Epoch: 130 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :689
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393355
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516972
INFO:root:FL Epoch: 130 Norm Difference for worker 689 is 1.85685
INFO:root:FL Epoch: 130 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1486
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505700
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402194
INFO:root:FL Epoch: 130 Norm Difference for worker 1486 is 1.870073
INFO:root:FL Epoch: 130 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :765
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425667
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193686
INFO:root:FL Epoch: 130 Norm Difference for worker 765 is 1.876631
INFO:root:FL Epoch: 130 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :11
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.398297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 11 is 1.754296
INFO:root:FL Epoch: 130 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [201 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [1 4 0 2 5 9 8], which are global users: [145, 1423, 324, 544, 1402, 11, 765]
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.4610208413180183 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.6715524146954218                             and Backdoor Test Accuracy:65.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397651
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509900
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.18882823114593825 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.24373771697282792 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.524701
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479253
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331857
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.2181506392856439 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.24537346810102462 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 0.495238
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380727
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374174
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.2100508933266004 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.24635612964630127 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 0.499626
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1513
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440465
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211456
INFO:root:FL Epoch: 131 Norm Difference for worker 1513 is 1.777577
INFO:root:FL Epoch: 131 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1131
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788844
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481986
INFO:root:FL Epoch: 131 Norm Difference for worker 1131 is 1.930795
INFO:root:FL Epoch: 131 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :516
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467867
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357908
INFO:root:FL Epoch: 131 Norm Difference for worker 516 is 1.914224
INFO:root:FL Epoch: 131 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :950
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523490
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311485
INFO:root:FL Epoch: 131 Norm Difference for worker 950 is 1.832276
INFO:root:FL Epoch: 131 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :910
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451685
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456641
INFO:root:FL Epoch: 131 Norm Difference for worker 910 is 1.829702
INFO:root:FL Epoch: 131 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :386
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303385
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197842
INFO:root:FL Epoch: 131 Norm Difference for worker 386 is 1.763234
INFO:root:FL Epoch: 131 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :240
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 240 is 1.867801
INFO:root:FL Epoch: 131 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 6], which are global users: [910, 0, 2, 1513, 1, 386, 950]
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.4564930849215564 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.4753040025631587                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 132 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :1511
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665723
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361754
INFO:root:FL Epoch: 132 Norm Difference for worker 1511 is 1.943884
INFO:root:FL Epoch: 132 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1912
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428634
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214156
INFO:root:FL Epoch: 132 Norm Difference for worker 1912 is 1.6837
INFO:root:FL Epoch: 132 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :355
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741696
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270827
INFO:root:FL Epoch: 132 Norm Difference for worker 355 is 1.902727
INFO:root:FL Epoch: 132 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :961
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653911
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347070
INFO:root:FL Epoch: 132 Norm Difference for worker 961 is 1.938673
INFO:root:FL Epoch: 132 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :352
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662864
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212622
INFO:root:FL Epoch: 132 Norm Difference for worker 352 is 1.901707
INFO:root:FL Epoch: 132 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :366
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332351
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351497
INFO:root:FL Epoch: 132 Norm Difference for worker 366 is 1.894641
INFO:root:FL Epoch: 132 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :136
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.168463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 136 is 1.79711
INFO:root:FL Epoch: 132 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :335
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632377
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 335 is 1.82104
INFO:root:FL Epoch: 132 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1156
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759633
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292497
INFO:root:FL Epoch: 132 Norm Difference for worker 1156 is 1.693289
INFO:root:FL Epoch: 132 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1522
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590889
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403181
INFO:root:FL Epoch: 132 Norm Difference for worker 1522 is 1.755695
INFO:root:FL Epoch: 132 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 7 1 5 4], which are global users: [136, 1522, 1156, 335, 1912, 366, 352]
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.4524000988287084 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.5164826661348343                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1447
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435248
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276923
INFO:root:FL Epoch: 133 Norm Difference for worker 1447 is 1.889467
INFO:root:FL Epoch: 133 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1313
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697395
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251000
INFO:root:FL Epoch: 133 Norm Difference for worker 1313 is 1.864971
INFO:root:FL Epoch: 133 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1892
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404071
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329183
INFO:root:FL Epoch: 133 Norm Difference for worker 1892 is 1.857805
INFO:root:FL Epoch: 133 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742002
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302367
INFO:root:FL Epoch: 133 Norm Difference for worker 700 is 1.892856
INFO:root:FL Epoch: 133 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1180
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443894
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405185
INFO:root:FL Epoch: 133 Norm Difference for worker 1180 is 1.838719
INFO:root:FL Epoch: 133 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :208
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 208 is 1.842374
INFO:root:FL Epoch: 133 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1366
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817328
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185243
INFO:root:FL Epoch: 133 Norm Difference for worker 1366 is 1.755857
INFO:root:FL Epoch: 133 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1174
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662067
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369070
INFO:root:FL Epoch: 133 Norm Difference for worker 1174 is 1.951394
INFO:root:FL Epoch: 133 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :968
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366956
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519646
INFO:root:FL Epoch: 133 Norm Difference for worker 968 is 1.902058
INFO:root:FL Epoch: 133 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585612
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236406
INFO:root:FL Epoch: 133 Norm Difference for worker 869 is 1.893314
INFO:root:FL Epoch: 133 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [8 4 2 3 1 5 6], which are global users: [968, 1180, 1892, 700, 1313, 208, 1366]
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.4218513614991132 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.5688830018043518                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1137
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510895
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383346
INFO:root:FL Epoch: 134 Norm Difference for worker 1137 is 2.020502
INFO:root:FL Epoch: 134 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1389
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692432
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222449
INFO:root:FL Epoch: 134 Norm Difference for worker 1389 is 1.842152
INFO:root:FL Epoch: 134 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :158
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 158 is 1.950127
INFO:root:FL Epoch: 134 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :892
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425119
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273035
INFO:root:FL Epoch: 134 Norm Difference for worker 892 is 1.835913
INFO:root:FL Epoch: 134 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :314
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 314 is 1.862107
INFO:root:FL Epoch: 134 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :737
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753411
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466440
INFO:root:FL Epoch: 134 Norm Difference for worker 737 is 1.915296
INFO:root:FL Epoch: 134 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1206
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799869
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274765
INFO:root:FL Epoch: 134 Norm Difference for worker 1206 is 1.849032
INFO:root:FL Epoch: 134 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :362
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618914
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285427
INFO:root:FL Epoch: 134 Norm Difference for worker 362 is 1.863976
INFO:root:FL Epoch: 134 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1354
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314570
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351490
INFO:root:FL Epoch: 134 Norm Difference for worker 1354 is 1.838727
INFO:root:FL Epoch: 134 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :650
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797157
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250282
INFO:root:FL Epoch: 134 Norm Difference for worker 650 is 1.916379
INFO:root:FL Epoch: 134 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 5 9], which are global users: [1206, 314, 1354, 892, 1389, 737, 650]
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.45084715590757485 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.6035199662049612                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1702
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553442
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359030
INFO:root:FL Epoch: 135 Norm Difference for worker 1702 is 1.84478
INFO:root:FL Epoch: 135 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :19
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.788685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 19 is 1.788877
INFO:root:FL Epoch: 135 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :779
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511169
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364398
INFO:root:FL Epoch: 135 Norm Difference for worker 779 is 1.749328
INFO:root:FL Epoch: 135 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1874
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404059
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245397
INFO:root:FL Epoch: 135 Norm Difference for worker 1874 is 1.77873
INFO:root:FL Epoch: 135 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :153
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688279
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 153 is 1.761803
INFO:root:FL Epoch: 135 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :751
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558745
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208306
INFO:root:FL Epoch: 135 Norm Difference for worker 751 is 1.771544
INFO:root:FL Epoch: 135 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1409
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543889
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246797
INFO:root:FL Epoch: 135 Norm Difference for worker 1409 is 1.724471
INFO:root:FL Epoch: 135 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1891
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624584
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331088
INFO:root:FL Epoch: 135 Norm Difference for worker 1891 is 1.742966
INFO:root:FL Epoch: 135 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1327
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490592
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375318
INFO:root:FL Epoch: 135 Norm Difference for worker 1327 is 1.694587
INFO:root:FL Epoch: 135 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :312
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532663
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 312 is 1.862768
INFO:root:FL Epoch: 135 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [5 8 6 3 2 7 4], which are global users: [751, 1327, 1409, 1874, 779, 1891, 153]
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.43845531695029316 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.7201826969782511                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :950
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526471
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213662
INFO:root:FL Epoch: 136 Norm Difference for worker 950 is 1.713743
INFO:root:FL Epoch: 136 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1614
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538826
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424125
INFO:root:FL Epoch: 136 Norm Difference for worker 1614 is 1.967047
INFO:root:FL Epoch: 136 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1069
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 1.006810
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335646
INFO:root:FL Epoch: 136 Norm Difference for worker 1069 is 1.910638
INFO:root:FL Epoch: 136 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1082
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450770
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392197
INFO:root:FL Epoch: 136 Norm Difference for worker 1082 is 1.664849
INFO:root:FL Epoch: 136 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :755
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607005
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232978
INFO:root:FL Epoch: 136 Norm Difference for worker 755 is 1.803528
INFO:root:FL Epoch: 136 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :211
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 211 is 1.921936
INFO:root:FL Epoch: 136 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :626
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546981
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238476
INFO:root:FL Epoch: 136 Norm Difference for worker 626 is 1.58665
INFO:root:FL Epoch: 136 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1801
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396652
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491920
INFO:root:FL Epoch: 136 Norm Difference for worker 1801 is 1.881393
INFO:root:FL Epoch: 136 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :592
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299019
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221444
INFO:root:FL Epoch: 136 Norm Difference for worker 592 is 1.789762
INFO:root:FL Epoch: 136 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :113
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 113 is 1.743311
INFO:root:FL Epoch: 136 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [3 0 6 9 7 4 8], which are global users: [1082, 950, 626, 113, 1801, 755, 592]
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.4362747458850636 and Test Accuracy:81.76470588235294 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.8879002730051676                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :935
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663059
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288725
INFO:root:FL Epoch: 137 Norm Difference for worker 935 is 1.9
INFO:root:FL Epoch: 137 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1785
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443230
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317145
INFO:root:FL Epoch: 137 Norm Difference for worker 1785 is 1.960393
INFO:root:FL Epoch: 137 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :769
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393163
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271753
INFO:root:FL Epoch: 137 Norm Difference for worker 769 is 2.080156
INFO:root:FL Epoch: 137 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :514
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272190
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243746
INFO:root:FL Epoch: 137 Norm Difference for worker 514 is 1.815015
INFO:root:FL Epoch: 137 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :59
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434336
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433342
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 59 is 1.963114
INFO:root:FL Epoch: 137 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1601
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614591
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205220
INFO:root:FL Epoch: 137 Norm Difference for worker 1601 is 1.82855
INFO:root:FL Epoch: 137 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1554
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713496
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215451
INFO:root:FL Epoch: 137 Norm Difference for worker 1554 is 1.887173
INFO:root:FL Epoch: 137 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1492
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584144
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323942
INFO:root:FL Epoch: 137 Norm Difference for worker 1492 is 1.851436
INFO:root:FL Epoch: 137 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :393
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573368
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386238
INFO:root:FL Epoch: 137 Norm Difference for worker 393 is 2.047124
INFO:root:FL Epoch: 137 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1921
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708874
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340851
INFO:root:FL Epoch: 137 Norm Difference for worker 1921 is 2.007767
INFO:root:FL Epoch: 137 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 0 7 3 1 5 4], which are global users: [1554, 935, 1492, 514, 1785, 1601, 59]
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.433825704981299 and Test Accuracy:81.17647058823529 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.8011246422926585                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :589
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459896
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550479
INFO:root:FL Epoch: 138 Norm Difference for worker 589 is 1.887317
INFO:root:FL Epoch: 138 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1143
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531938
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466788
INFO:root:FL Epoch: 138 Norm Difference for worker 1143 is 1.89988
INFO:root:FL Epoch: 138 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1020
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522794
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425442
INFO:root:FL Epoch: 138 Norm Difference for worker 1020 is 1.84931
INFO:root:FL Epoch: 138 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1022
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366571
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289825
INFO:root:FL Epoch: 138 Norm Difference for worker 1022 is 1.71908
INFO:root:FL Epoch: 138 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :730
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380615
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207335
INFO:root:FL Epoch: 138 Norm Difference for worker 730 is 1.819207
INFO:root:FL Epoch: 138 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :346
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562026
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325382
INFO:root:FL Epoch: 138 Norm Difference for worker 346 is 1.796239
INFO:root:FL Epoch: 138 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 1.858877
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :139
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 139 is 1.776614
INFO:root:FL Epoch: 138 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1469
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633010
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316354
INFO:root:FL Epoch: 138 Norm Difference for worker 1469 is 1.891878
INFO:root:FL Epoch: 138 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1364
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768720
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248258
INFO:root:FL Epoch: 138 Norm Difference for worker 1364 is 1.85254
INFO:root:FL Epoch: 138 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 4 2 3 1 5 6], which are global users: [139, 730, 1020, 1022, 1143, 346, 92]
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.4333923827199375 and Test Accuracy:80.0 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:1.048421820004781                             and Backdoor Test Accuracy:38.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 139 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :545
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732203
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293201
INFO:root:FL Epoch: 139 Norm Difference for worker 545 is 1.876543
INFO:root:FL Epoch: 139 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :55
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385280
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 55 is 1.751691
INFO:root:FL Epoch: 139 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :702
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652270
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467403
INFO:root:FL Epoch: 139 Norm Difference for worker 702 is 1.824163
INFO:root:FL Epoch: 139 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1861
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522400
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359271
INFO:root:FL Epoch: 139 Norm Difference for worker 1861 is 1.874129
INFO:root:FL Epoch: 139 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1745
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555444
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371250
INFO:root:FL Epoch: 139 Norm Difference for worker 1745 is 1.833718
INFO:root:FL Epoch: 139 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :524
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527211
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354386
INFO:root:FL Epoch: 139 Norm Difference for worker 524 is 1.817269
INFO:root:FL Epoch: 139 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :900
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576937
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273751
INFO:root:FL Epoch: 139 Norm Difference for worker 900 is 1.719532
INFO:root:FL Epoch: 139 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :492
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445707
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429143
INFO:root:FL Epoch: 139 Norm Difference for worker 492 is 1.847648
INFO:root:FL Epoch: 139 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1013
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713284
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363956
INFO:root:FL Epoch: 139 Norm Difference for worker 1013 is 1.915717
INFO:root:FL Epoch: 139 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1556
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577258
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302431
INFO:root:FL Epoch: 139 Norm Difference for worker 1556 is 1.70716
INFO:root:FL Epoch: 139 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 6 4 7 3 5], which are global users: [55, 1556, 900, 1745, 492, 1861, 524]
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.479740032378365 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.8783337573210398                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :1834
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917547
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214576
INFO:root:FL Epoch: 140 Norm Difference for worker 1834 is 1.936857
INFO:root:FL Epoch: 140 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :946
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519724
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302873
INFO:root:FL Epoch: 140 Norm Difference for worker 946 is 1.874441
INFO:root:FL Epoch: 140 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :646
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620650
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488607
INFO:root:FL Epoch: 140 Norm Difference for worker 646 is 1.860445
INFO:root:FL Epoch: 140 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1428
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699953
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340533
INFO:root:FL Epoch: 140 Norm Difference for worker 1428 is 1.931076
INFO:root:FL Epoch: 140 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :50
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 50 is 1.912985
INFO:root:FL Epoch: 140 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1198
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612675
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460516
INFO:root:FL Epoch: 140 Norm Difference for worker 1198 is 1.917056
INFO:root:FL Epoch: 140 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1355
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583790
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323369
INFO:root:FL Epoch: 140 Norm Difference for worker 1355 is 1.895991
INFO:root:FL Epoch: 140 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :222
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414665
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 222 is 1.774163
INFO:root:FL Epoch: 140 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1642
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761790
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247456
INFO:root:FL Epoch: 140 Norm Difference for worker 1642 is 1.899704
INFO:root:FL Epoch: 140 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1223
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650468
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406515
INFO:root:FL Epoch: 140 Norm Difference for worker 1223 is 2.059431
INFO:root:FL Epoch: 140 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 8 3 1 5 6], which are global users: [222, 50, 1642, 1428, 946, 1198, 1355]
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.4874674485010259 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.8124254445234934                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340819
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275703
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.15746654073397318 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.24226468354463576 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.548268
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381169
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589174
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.13453903421759605 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.24870292395353316 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 0.567582
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503958
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349951
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.17041289433836937 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.24090488255023956 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 0.545181
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1878
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541978
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268564
INFO:root:FL Epoch: 141 Norm Difference for worker 1878 is 1.962316
INFO:root:FL Epoch: 141 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :962
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525115
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227577
INFO:root:FL Epoch: 141 Norm Difference for worker 962 is 1.81649
INFO:root:FL Epoch: 141 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430555
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262064
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.781292
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :976
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625421
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407696
INFO:root:FL Epoch: 141 Norm Difference for worker 976 is 1.828308
INFO:root:FL Epoch: 141 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :769
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787916
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351593
INFO:root:FL Epoch: 141 Norm Difference for worker 769 is 1.809594
INFO:root:FL Epoch: 141 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :465
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431100
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340098
INFO:root:FL Epoch: 141 Norm Difference for worker 465 is 1.760251
INFO:root:FL Epoch: 141 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1750
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782495
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560309
INFO:root:FL Epoch: 141 Norm Difference for worker 1750 is 1.920021
INFO:root:FL Epoch: 141 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 8 1 5 4], which are global users: [976, 0, 2, 465, 1, 549, 962]
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.4841494770611034 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.438858300447464                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1841
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652036
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389737
INFO:root:FL Epoch: 142 Norm Difference for worker 1841 is 1.874571
INFO:root:FL Epoch: 142 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1522
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423936
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312637
INFO:root:FL Epoch: 142 Norm Difference for worker 1522 is 1.738696
INFO:root:FL Epoch: 142 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :23
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 23 is 1.969284
INFO:root:FL Epoch: 142 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1157
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532285
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259450
INFO:root:FL Epoch: 142 Norm Difference for worker 1157 is 1.843561
INFO:root:FL Epoch: 142 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :56
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 56 is 1.815306
INFO:root:FL Epoch: 142 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1269
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478383
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392322
INFO:root:FL Epoch: 142 Norm Difference for worker 1269 is 1.817173
INFO:root:FL Epoch: 142 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :442
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478960
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474365
INFO:root:FL Epoch: 142 Norm Difference for worker 442 is 1.831891
INFO:root:FL Epoch: 142 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :577
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552051
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249343
INFO:root:FL Epoch: 142 Norm Difference for worker 577 is 1.907729
INFO:root:FL Epoch: 142 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :219
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688310
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 219 is 1.921558
INFO:root:FL Epoch: 142 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1614
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500951
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309403
INFO:root:FL Epoch: 142 Norm Difference for worker 1614 is 2.023487
INFO:root:FL Epoch: 142 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 5 0], which are global users: [442, 56, 219, 1157, 1522, 1269, 1841]
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.5045009132693795 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.5175884713729223                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1520
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489547
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306716
INFO:root:FL Epoch: 143 Norm Difference for worker 1520 is 1.800512
INFO:root:FL Epoch: 143 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1151
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586854
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287004
INFO:root:FL Epoch: 143 Norm Difference for worker 1151 is 1.753998
INFO:root:FL Epoch: 143 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :182
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 182 is 1.825109
INFO:root:FL Epoch: 143 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :755
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498658
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188416
INFO:root:FL Epoch: 143 Norm Difference for worker 755 is 1.733825
INFO:root:FL Epoch: 143 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :86
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.327984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 86 is 1.735961
INFO:root:FL Epoch: 143 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1828
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476222
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370534
INFO:root:FL Epoch: 143 Norm Difference for worker 1828 is 1.843767
INFO:root:FL Epoch: 143 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1417
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510207
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333350
INFO:root:FL Epoch: 143 Norm Difference for worker 1417 is 1.731579
INFO:root:FL Epoch: 143 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :504
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728545
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220477
INFO:root:FL Epoch: 143 Norm Difference for worker 504 is 1.780456
INFO:root:FL Epoch: 143 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :250
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 250 is 1.737864
INFO:root:FL Epoch: 143 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :634
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769843
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336677
INFO:root:FL Epoch: 143 Norm Difference for worker 634 is 1.648906
INFO:root:FL Epoch: 143 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [3 4 1 9 8 6 0], which are global users: [755, 86, 1151, 634, 250, 1417, 1520]
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.46633462520206675 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.6142442325750986                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1753
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838948
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354314
INFO:root:FL Epoch: 144 Norm Difference for worker 1753 is 1.806065
INFO:root:FL Epoch: 144 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1838
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560289
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337822
INFO:root:FL Epoch: 144 Norm Difference for worker 1838 is 1.822649
INFO:root:FL Epoch: 144 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :71
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349227
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 71 is 1.765988
INFO:root:FL Epoch: 144 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :711
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767689
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262474
INFO:root:FL Epoch: 144 Norm Difference for worker 711 is 1.827837
INFO:root:FL Epoch: 144 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :960
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572653
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334560
INFO:root:FL Epoch: 144 Norm Difference for worker 960 is 1.876095
INFO:root:FL Epoch: 144 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :665
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822683
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340255
INFO:root:FL Epoch: 144 Norm Difference for worker 665 is 1.787941
INFO:root:FL Epoch: 144 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1500
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820365
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256921
INFO:root:FL Epoch: 144 Norm Difference for worker 1500 is 1.84877
INFO:root:FL Epoch: 144 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1467
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.948045
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307951
INFO:root:FL Epoch: 144 Norm Difference for worker 1467 is 1.785395
INFO:root:FL Epoch: 144 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :800
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471248
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352438
INFO:root:FL Epoch: 144 Norm Difference for worker 800 is 1.792609
INFO:root:FL Epoch: 144 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :787
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486140
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293236
INFO:root:FL Epoch: 144 Norm Difference for worker 787 is 1.831451
INFO:root:FL Epoch: 144 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 9], which are global users: [1467, 1753, 71, 800, 1838, 665, 787]
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.49243418609394746 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.6842378377914429                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :380
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219617
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311726
INFO:root:FL Epoch: 145 Norm Difference for worker 380 is 1.750343
INFO:root:FL Epoch: 145 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :95
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404449
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 95 is 1.84887
INFO:root:FL Epoch: 145 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :818
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.234055
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203361
INFO:root:FL Epoch: 145 Norm Difference for worker 818 is 1.682568
INFO:root:FL Epoch: 145 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1766
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670686
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427361
INFO:root:FL Epoch: 145 Norm Difference for worker 1766 is 1.868828
INFO:root:FL Epoch: 145 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1585
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322922
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202178
INFO:root:FL Epoch: 145 Norm Difference for worker 1585 is 1.750543
INFO:root:FL Epoch: 145 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1927
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671675
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379627
INFO:root:FL Epoch: 145 Norm Difference for worker 1927 is 1.758379
INFO:root:FL Epoch: 145 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1721
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287677
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663527
INFO:root:FL Epoch: 145 Norm Difference for worker 1721 is 1.728809
INFO:root:FL Epoch: 145 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662182
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339250
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 1.8225
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1393
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495666
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256746
INFO:root:FL Epoch: 145 Norm Difference for worker 1393 is 1.812199
INFO:root:FL Epoch: 145 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1170
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386694
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297832
INFO:root:FL Epoch: 145 Norm Difference for worker 1170 is 1.753046
INFO:root:FL Epoch: 145 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 0 2 6 4 1 9], which are global users: [1927, 380, 818, 1721, 1585, 95, 1170]
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.4624268658020917 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.6018660118182501                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :968
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467485
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275847
INFO:root:FL Epoch: 146 Norm Difference for worker 968 is 1.697123
INFO:root:FL Epoch: 146 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :715
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854322
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444105
INFO:root:FL Epoch: 146 Norm Difference for worker 715 is 1.95557
INFO:root:FL Epoch: 146 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :798
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428488
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263632
INFO:root:FL Epoch: 146 Norm Difference for worker 798 is 1.730522
INFO:root:FL Epoch: 146 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1158
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545433
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357514
INFO:root:FL Epoch: 146 Norm Difference for worker 1158 is 1.860685
INFO:root:FL Epoch: 146 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1312
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560597
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232950
INFO:root:FL Epoch: 146 Norm Difference for worker 1312 is 1.78324
INFO:root:FL Epoch: 146 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :656
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329385
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354301
INFO:root:FL Epoch: 146 Norm Difference for worker 656 is 1.899321
INFO:root:FL Epoch: 146 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :911
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534865
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333018
INFO:root:FL Epoch: 146 Norm Difference for worker 911 is 1.776175
INFO:root:FL Epoch: 146 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :391
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650543
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384235
INFO:root:FL Epoch: 146 Norm Difference for worker 391 is 1.960663
INFO:root:FL Epoch: 146 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 1.742623
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :800
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378346
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153893
INFO:root:FL Epoch: 146 Norm Difference for worker 800 is 1.770255
INFO:root:FL Epoch: 146 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 0 2 9 6 4 3], which are global users: [42, 968, 798, 800, 911, 1312, 1158]
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.4945535642259261 and Test Accuracy:75.0 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.7172861099243164                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1230
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782653
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205091
INFO:root:FL Epoch: 147 Norm Difference for worker 1230 is 1.797644
INFO:root:FL Epoch: 147 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1810
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467727
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268010
INFO:root:FL Epoch: 147 Norm Difference for worker 1810 is 1.681772
INFO:root:FL Epoch: 147 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :202
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 202 is 1.881231
INFO:root:FL Epoch: 147 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :692
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666425
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392067
INFO:root:FL Epoch: 147 Norm Difference for worker 692 is 1.864543
INFO:root:FL Epoch: 147 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1869
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402278
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466280
INFO:root:FL Epoch: 147 Norm Difference for worker 1869 is 1.900712
INFO:root:FL Epoch: 147 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1931
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477432
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353079
INFO:root:FL Epoch: 147 Norm Difference for worker 1931 is 1.940596
INFO:root:FL Epoch: 147 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1058
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592910
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342445
INFO:root:FL Epoch: 147 Norm Difference for worker 1058 is 1.973553
INFO:root:FL Epoch: 147 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :783
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627283
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384763
INFO:root:FL Epoch: 147 Norm Difference for worker 783 is 1.869102
INFO:root:FL Epoch: 147 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :536
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503989
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376302
INFO:root:FL Epoch: 147 Norm Difference for worker 536 is 1.85156
INFO:root:FL Epoch: 147 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :950
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555704
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164703
INFO:root:FL Epoch: 147 Norm Difference for worker 950 is 1.761143
INFO:root:FL Epoch: 147 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 0 7 3 8 4], which are global users: [1810, 950, 1230, 783, 692, 536, 1869]
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.45849423198138967 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.5930294841527939                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :376
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382851
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316460
INFO:root:FL Epoch: 148 Norm Difference for worker 376 is 1.86098
INFO:root:FL Epoch: 148 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :932
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466748
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331664
INFO:root:FL Epoch: 148 Norm Difference for worker 932 is 1.885412
INFO:root:FL Epoch: 148 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :206
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.172303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 206 is 1.586017
INFO:root:FL Epoch: 148 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :532
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753333
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289343
INFO:root:FL Epoch: 148 Norm Difference for worker 532 is 2.011349
INFO:root:FL Epoch: 148 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1088
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357234
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264248
INFO:root:FL Epoch: 148 Norm Difference for worker 1088 is 1.749079
INFO:root:FL Epoch: 148 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :339
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601768
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 339 is 1.848672
INFO:root:FL Epoch: 148 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1682
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350696
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220987
INFO:root:FL Epoch: 148 Norm Difference for worker 1682 is 1.678827
INFO:root:FL Epoch: 148 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :436
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707731
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297156
INFO:root:FL Epoch: 148 Norm Difference for worker 436 is 1.777288
INFO:root:FL Epoch: 148 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1295
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483260
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298641
INFO:root:FL Epoch: 148 Norm Difference for worker 1295 is 1.760519
INFO:root:FL Epoch: 148 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1789
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501208
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360903
INFO:root:FL Epoch: 148 Norm Difference for worker 1789 is 1.762638
INFO:root:FL Epoch: 148 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [6 9 2 7 4 8 5], which are global users: [1682, 1789, 206, 436, 1088, 1295, 339]
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.46578553143669577 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.6435889403025309                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :648
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472110
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220949
INFO:root:FL Epoch: 149 Norm Difference for worker 648 is 1.894679
INFO:root:FL Epoch: 149 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1268
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731391
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492462
INFO:root:FL Epoch: 149 Norm Difference for worker 1268 is 1.788245
INFO:root:FL Epoch: 149 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :337
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 337 is 1.897474
INFO:root:FL Epoch: 149 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1086
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558807
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430911
INFO:root:FL Epoch: 149 Norm Difference for worker 1086 is 1.798067
INFO:root:FL Epoch: 149 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1112
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617778
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326637
INFO:root:FL Epoch: 149 Norm Difference for worker 1112 is 1.970125
INFO:root:FL Epoch: 149 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :725
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622909
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198694
INFO:root:FL Epoch: 149 Norm Difference for worker 725 is 1.761848
INFO:root:FL Epoch: 149 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :610
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.899773
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358463
INFO:root:FL Epoch: 149 Norm Difference for worker 610 is 1.807236
INFO:root:FL Epoch: 149 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1600
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377191
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342122
INFO:root:FL Epoch: 149 Norm Difference for worker 1600 is 2.09437
INFO:root:FL Epoch: 149 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :335
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.318334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.190191
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 335 is 1.790059
INFO:root:FL Epoch: 149 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :996
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323402
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331281
INFO:root:FL Epoch: 149 Norm Difference for worker 996 is 1.859082
INFO:root:FL Epoch: 149 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 6], which are global users: [335, 996, 337, 1086, 1268, 725, 610]
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.4690735769622466 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.7502771615982056                             and Backdoor Test Accuracy:60.0 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :969
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575203
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275824
INFO:root:FL Epoch: 150 Norm Difference for worker 969 is 1.770935
INFO:root:FL Epoch: 150 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :73
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 73 is 1.989137
INFO:root:FL Epoch: 150 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1089
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719779
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311894
INFO:root:FL Epoch: 150 Norm Difference for worker 1089 is 1.792206
INFO:root:FL Epoch: 150 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1428
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711976
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350615
INFO:root:FL Epoch: 150 Norm Difference for worker 1428 is 2.06082
INFO:root:FL Epoch: 150 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :306
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 306 is 1.928747
INFO:root:FL Epoch: 150 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :424
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532369
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316616
INFO:root:FL Epoch: 150 Norm Difference for worker 424 is 1.76764
INFO:root:FL Epoch: 150 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1357
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453527
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426838
INFO:root:FL Epoch: 150 Norm Difference for worker 1357 is 2.011447
INFO:root:FL Epoch: 150 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :441
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 1.025657
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392709
INFO:root:FL Epoch: 150 Norm Difference for worker 441 is 2.027763
INFO:root:FL Epoch: 150 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :62
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 62 is 1.727386
INFO:root:FL Epoch: 150 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :459
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446557
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166726
INFO:root:FL Epoch: 150 Norm Difference for worker 459 is 1.803608
INFO:root:FL Epoch: 150 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [5 0 2 8 9 3 4], which are global users: [424, 969, 1089, 62, 459, 1428, 306]
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.46880490814938264 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.6975185871124268                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335593
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378959
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.1398117939631144 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.21460792422294617 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.540023
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713634
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202364
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.171564731746912 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.20626796036958694 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 0.521335
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383413
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303143
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.1464735952516397 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.20961815640330314 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 0.530488
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :954
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365429
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457922
INFO:root:FL Epoch: 151 Norm Difference for worker 954 is 1.854257
INFO:root:FL Epoch: 151 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1013
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761420
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410421
INFO:root:FL Epoch: 151 Norm Difference for worker 1013 is 1.847926
INFO:root:FL Epoch: 151 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :183
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475285
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306800
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 183 is 1.893237
INFO:root:FL Epoch: 151 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :593
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577346
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469311
INFO:root:FL Epoch: 151 Norm Difference for worker 593 is 1.926339
INFO:root:FL Epoch: 151 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1646
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664912
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394782
INFO:root:FL Epoch: 151 Norm Difference for worker 1646 is 1.912419
INFO:root:FL Epoch: 151 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :153
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 153 is 1.715897
INFO:root:FL Epoch: 151 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :653
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898448
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482294
INFO:root:FL Epoch: 151 Norm Difference for worker 653 is 1.943115
INFO:root:FL Epoch: 151 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [1 0 2 8 4 3 5], which are global users: [1, 0, 2, 153, 1013, 954, 183]
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.46036692577249866 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.31362442423899967                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1082
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461346
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215605
INFO:root:FL Epoch: 152 Norm Difference for worker 1082 is 1.577965
INFO:root:FL Epoch: 152 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :949
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307793
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428138
INFO:root:FL Epoch: 152 Norm Difference for worker 949 is 1.903522
INFO:root:FL Epoch: 152 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1688
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480119
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283705
INFO:root:FL Epoch: 152 Norm Difference for worker 1688 is 1.849501
INFO:root:FL Epoch: 152 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :734
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284555
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398086
INFO:root:FL Epoch: 152 Norm Difference for worker 734 is 1.674377
INFO:root:FL Epoch: 152 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :277
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.221166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 277 is 1.77263
INFO:root:FL Epoch: 152 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :966
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405072
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486768
INFO:root:FL Epoch: 152 Norm Difference for worker 966 is 1.91391
INFO:root:FL Epoch: 152 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :748
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439469
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350168
INFO:root:FL Epoch: 152 Norm Difference for worker 748 is 1.928413
INFO:root:FL Epoch: 152 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :886
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459611
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397393
INFO:root:FL Epoch: 152 Norm Difference for worker 886 is 1.70708
INFO:root:FL Epoch: 152 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :918
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483205
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340317
INFO:root:FL Epoch: 152 Norm Difference for worker 918 is 1.828202
INFO:root:FL Epoch: 152 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :418
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585254
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237198
INFO:root:FL Epoch: 152 Norm Difference for worker 418 is 1.766772
INFO:root:FL Epoch: 152 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [3 0 7 4 2 9 8], which are global users: [734, 1082, 886, 277, 1688, 418, 918]
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.4688434600830078 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.3992733359336853                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :115
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 115 is 1.730427
INFO:root:FL Epoch: 153 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :899
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688754
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432511
INFO:root:FL Epoch: 153 Norm Difference for worker 899 is 1.825544
INFO:root:FL Epoch: 153 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1476
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719447
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211238
INFO:root:FL Epoch: 153 Norm Difference for worker 1476 is 1.799599
INFO:root:FL Epoch: 153 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :185
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.155499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 185 is 1.714587
INFO:root:FL Epoch: 153 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :482
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431528
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225608
INFO:root:FL Epoch: 153 Norm Difference for worker 482 is 1.851012
INFO:root:FL Epoch: 153 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1640
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303090
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616085
INFO:root:FL Epoch: 153 Norm Difference for worker 1640 is 1.758242
INFO:root:FL Epoch: 153 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1042
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494806
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362303
INFO:root:FL Epoch: 153 Norm Difference for worker 1042 is 1.753305
INFO:root:FL Epoch: 153 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :354
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584946
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308256
INFO:root:FL Epoch: 153 Norm Difference for worker 354 is 1.812508
INFO:root:FL Epoch: 153 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :626
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430474
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140201
INFO:root:FL Epoch: 153 Norm Difference for worker 626 is 1.588956
INFO:root:FL Epoch: 153 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :922
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484408
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267671
INFO:root:FL Epoch: 153 Norm Difference for worker 922 is 1.832128
INFO:root:FL Epoch: 153 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 8 5 6], which are global users: [354, 115, 1476, 185, 626, 1640, 1042]
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.472913500140695 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.5096285889546076                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :1534
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315616
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291036
INFO:root:FL Epoch: 154 Norm Difference for worker 1534 is 1.844344
INFO:root:FL Epoch: 154 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1285
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500176
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171859
INFO:root:FL Epoch: 154 Norm Difference for worker 1285 is 1.839241
INFO:root:FL Epoch: 154 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :791
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485648
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239513
INFO:root:FL Epoch: 154 Norm Difference for worker 791 is 1.830116
INFO:root:FL Epoch: 154 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :829
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862290
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384129
INFO:root:FL Epoch: 154 Norm Difference for worker 829 is 1.975366
INFO:root:FL Epoch: 154 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1852
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754227
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400870
INFO:root:FL Epoch: 154 Norm Difference for worker 1852 is 1.767769
INFO:root:FL Epoch: 154 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1002
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500239
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195679
INFO:root:FL Epoch: 154 Norm Difference for worker 1002 is 1.805251
INFO:root:FL Epoch: 154 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :160
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 160 is 2.004527
INFO:root:FL Epoch: 154 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1586
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699999
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504883
INFO:root:FL Epoch: 154 Norm Difference for worker 1586 is 2.042732
INFO:root:FL Epoch: 154 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1575
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486530
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294349
INFO:root:FL Epoch: 154 Norm Difference for worker 1575 is 1.887414
INFO:root:FL Epoch: 154 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :545
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458608
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431562
INFO:root:FL Epoch: 154 Norm Difference for worker 545 is 1.863164
INFO:root:FL Epoch: 154 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 0 5 2 8 1 9], which are global users: [1852, 1534, 1002, 791, 1575, 1285, 545]
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.4507083138998817 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.5351437379916509                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 155 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1219
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772231
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324801
INFO:root:FL Epoch: 155 Norm Difference for worker 1219 is 1.925274
INFO:root:FL Epoch: 155 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :334
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240622
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 334 is 1.725749
INFO:root:FL Epoch: 155 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :82
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508939
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 82 is 1.805378
INFO:root:FL Epoch: 155 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :426
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464923
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286590
INFO:root:FL Epoch: 155 Norm Difference for worker 426 is 1.771677
INFO:root:FL Epoch: 155 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :457
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427580
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203581
INFO:root:FL Epoch: 155 Norm Difference for worker 457 is 1.908201
INFO:root:FL Epoch: 155 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :687
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261286
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404947
INFO:root:FL Epoch: 155 Norm Difference for worker 687 is 1.880438
INFO:root:FL Epoch: 155 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :836
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394699
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320125
INFO:root:FL Epoch: 155 Norm Difference for worker 836 is 1.868813
INFO:root:FL Epoch: 155 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1157
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689813
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462319
INFO:root:FL Epoch: 155 Norm Difference for worker 1157 is 1.85677
INFO:root:FL Epoch: 155 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :845
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607364
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375676
INFO:root:FL Epoch: 155 Norm Difference for worker 845 is 1.788037
INFO:root:FL Epoch: 155 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :422
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356407
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204001
INFO:root:FL Epoch: 155 Norm Difference for worker 422 is 1.888954
INFO:root:FL Epoch: 155 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [1 3 8 2 7 4 5], which are global users: [334, 426, 845, 82, 1157, 457, 687]
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.465907517601462 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.5644852767388026                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :1330
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337521
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281902
INFO:root:FL Epoch: 156 Norm Difference for worker 1330 is 1.853128
INFO:root:FL Epoch: 156 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1035
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720842
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438592
INFO:root:FL Epoch: 156 Norm Difference for worker 1035 is 1.927008
INFO:root:FL Epoch: 156 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :774
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591070
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302556
INFO:root:FL Epoch: 156 Norm Difference for worker 774 is 1.77063
INFO:root:FL Epoch: 156 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1736
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412761
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405370
INFO:root:FL Epoch: 156 Norm Difference for worker 1736 is 1.970099
INFO:root:FL Epoch: 156 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1439
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733789
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360496
INFO:root:FL Epoch: 156 Norm Difference for worker 1439 is 1.908676
INFO:root:FL Epoch: 156 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :824
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577612
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398950
INFO:root:FL Epoch: 156 Norm Difference for worker 824 is 1.847035
INFO:root:FL Epoch: 156 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :957
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630084
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442353
INFO:root:FL Epoch: 156 Norm Difference for worker 957 is 1.846329
INFO:root:FL Epoch: 156 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :80
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443371
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 80 is 1.707924
INFO:root:FL Epoch: 156 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :952
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607591
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344747
INFO:root:FL Epoch: 156 Norm Difference for worker 952 is 1.918218
INFO:root:FL Epoch: 156 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :703
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666730
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243995
INFO:root:FL Epoch: 156 Norm Difference for worker 703 is 1.851539
INFO:root:FL Epoch: 156 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 7 0 4 1], which are global users: [824, 703, 774, 80, 1330, 1439, 1035]
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.46791456026189465 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.5330340713262558                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :1090
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803783
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283728
INFO:root:FL Epoch: 157 Norm Difference for worker 1090 is 1.653454
INFO:root:FL Epoch: 157 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1884
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621273
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275017
INFO:root:FL Epoch: 157 Norm Difference for worker 1884 is 1.761072
INFO:root:FL Epoch: 157 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1139
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614313
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243102
INFO:root:FL Epoch: 157 Norm Difference for worker 1139 is 1.62311
INFO:root:FL Epoch: 157 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :349
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709972
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304704
INFO:root:FL Epoch: 157 Norm Difference for worker 349 is 1.721431
INFO:root:FL Epoch: 157 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :877
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433076
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231986
INFO:root:FL Epoch: 157 Norm Difference for worker 877 is 1.706843
INFO:root:FL Epoch: 157 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :538
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481745
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351658
INFO:root:FL Epoch: 157 Norm Difference for worker 538 is 1.782474
INFO:root:FL Epoch: 157 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :147
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 147 is 1.7527
INFO:root:FL Epoch: 157 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1085
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537986
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323531
INFO:root:FL Epoch: 157 Norm Difference for worker 1085 is 1.724875
INFO:root:FL Epoch: 157 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1142
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613544
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286957
INFO:root:FL Epoch: 157 Norm Difference for worker 1142 is 1.703352
INFO:root:FL Epoch: 157 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :98
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490407
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 98 is 1.811331
INFO:root:FL Epoch: 157 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 8 4 5], which are global users: [1085, 1090, 1139, 349, 1142, 877, 538]
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.45533591859480915 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.4291004290183385                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 158 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :527
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417236
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293181
INFO:root:FL Epoch: 158 Norm Difference for worker 527 is 1.895757
INFO:root:FL Epoch: 158 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :126
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 126 is 1.752073
INFO:root:FL Epoch: 158 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1253
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352679
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328524
INFO:root:FL Epoch: 158 Norm Difference for worker 1253 is 1.91944
INFO:root:FL Epoch: 158 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :917
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850525
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286032
INFO:root:FL Epoch: 158 Norm Difference for worker 917 is 1.936775
INFO:root:FL Epoch: 158 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1316
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702435
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247825
INFO:root:FL Epoch: 158 Norm Difference for worker 1316 is 1.86673
INFO:root:FL Epoch: 158 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526220
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343423
INFO:root:FL Epoch: 158 Norm Difference for worker 1311 is 1.77513
INFO:root:FL Epoch: 158 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 311 is 1.864934
INFO:root:FL Epoch: 158 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :779
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680557
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287095
INFO:root:FL Epoch: 158 Norm Difference for worker 779 is 1.899034
INFO:root:FL Epoch: 158 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1872
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539835
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282790
INFO:root:FL Epoch: 158 Norm Difference for worker 1872 is 1.822774
INFO:root:FL Epoch: 158 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :900
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360009
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409217
INFO:root:FL Epoch: 158 Norm Difference for worker 900 is 1.726919
INFO:root:FL Epoch: 158 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [1 9 8 5 0 4 6], which are global users: [126, 900, 1872, 1311, 527, 1316, 311]
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.4458896903430714 and Test Accuracy:80.88235294117646 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.3992054959138234                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :757
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 1.048650
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275843
INFO:root:FL Epoch: 159 Norm Difference for worker 757 is 1.814738
INFO:root:FL Epoch: 159 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1832
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430439
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327790
INFO:root:FL Epoch: 159 Norm Difference for worker 1832 is 1.944561
INFO:root:FL Epoch: 159 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :439
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568700
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244960
INFO:root:FL Epoch: 159 Norm Difference for worker 439 is 1.791702
INFO:root:FL Epoch: 159 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :689
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347862
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337410
INFO:root:FL Epoch: 159 Norm Difference for worker 689 is 1.86465
INFO:root:FL Epoch: 159 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :232
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545452
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 232 is 1.845226
INFO:root:FL Epoch: 159 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1446
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375484
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227479
INFO:root:FL Epoch: 159 Norm Difference for worker 1446 is 1.7351
INFO:root:FL Epoch: 159 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1516
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471364
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173629
INFO:root:FL Epoch: 159 Norm Difference for worker 1516 is 1.785297
INFO:root:FL Epoch: 159 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :603
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296639
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319413
INFO:root:FL Epoch: 159 Norm Difference for worker 603 is 1.910523
INFO:root:FL Epoch: 159 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1899
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640493
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267804
INFO:root:FL Epoch: 159 Norm Difference for worker 1899 is 1.745352
INFO:root:FL Epoch: 159 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1913
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420596
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402696
INFO:root:FL Epoch: 159 Norm Difference for worker 1913 is 1.867671
INFO:root:FL Epoch: 159 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 8 6 0 9], which are global users: [1446, 232, 439, 1899, 1516, 757, 1913]
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.47639966011047363 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.5966244488954544                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 160 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :492
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392494
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140489
INFO:root:FL Epoch: 160 Norm Difference for worker 492 is 1.594306
INFO:root:FL Epoch: 160 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :665
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521673
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319810
INFO:root:FL Epoch: 160 Norm Difference for worker 665 is 1.754649
INFO:root:FL Epoch: 160 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1803
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405976
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259766
INFO:root:FL Epoch: 160 Norm Difference for worker 1803 is 1.868441
INFO:root:FL Epoch: 160 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1792
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367329
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276877
INFO:root:FL Epoch: 160 Norm Difference for worker 1792 is 1.689646
INFO:root:FL Epoch: 160 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1299
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.926412
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349070
INFO:root:FL Epoch: 160 Norm Difference for worker 1299 is 1.818944
INFO:root:FL Epoch: 160 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :384
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701202
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291915
INFO:root:FL Epoch: 160 Norm Difference for worker 384 is 1.679889
INFO:root:FL Epoch: 160 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1039
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707702
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472157
INFO:root:FL Epoch: 160 Norm Difference for worker 1039 is 1.877485
INFO:root:FL Epoch: 160 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :603
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495126
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406660
INFO:root:FL Epoch: 160 Norm Difference for worker 603 is 1.762011
INFO:root:FL Epoch: 160 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :159
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274261
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 159 is 1.788173
INFO:root:FL Epoch: 160 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :209
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467832
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 209 is 1.800995
INFO:root:FL Epoch: 160 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [7 0 8 3 1 5 9], which are global users: [603, 492, 159, 1792, 665, 384, 209]
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.46212141829378467 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.5703745583693186                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344051
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448842
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.174753670891126 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.2290234312415123 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.447742
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.168656
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257904
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.17412922531366348 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.22508256435394286 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 0.452853
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266152
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402779
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.1767193116247654 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.2171156719326973 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 0.481702
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :906
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396931
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203656
INFO:root:FL Epoch: 161 Norm Difference for worker 906 is 1.652292
INFO:root:FL Epoch: 161 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1144
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677303
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289158
INFO:root:FL Epoch: 161 Norm Difference for worker 1144 is 1.710934
INFO:root:FL Epoch: 161 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1064
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292741
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371882
INFO:root:FL Epoch: 161 Norm Difference for worker 1064 is 1.714298
INFO:root:FL Epoch: 161 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :596
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508622
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318631
INFO:root:FL Epoch: 161 Norm Difference for worker 596 is 1.816428
INFO:root:FL Epoch: 161 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1021
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289269
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373155
INFO:root:FL Epoch: 161 Norm Difference for worker 1021 is 1.670852
INFO:root:FL Epoch: 161 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :234
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 234 is 1.78511
INFO:root:FL Epoch: 161 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1844
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547172
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263263
INFO:root:FL Epoch: 161 Norm Difference for worker 1844 is 1.710666
INFO:root:FL Epoch: 161 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 9 5], which are global users: [1021, 0, 2, 906, 1, 1844, 1064]
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.43698564697714415 and Test Accuracy:80.0 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.36382895211378735                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496386
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211638
INFO:root:FL Epoch: 162 Norm Difference for worker 941 is 1.728418
INFO:root:FL Epoch: 162 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1390
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483268
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226978
INFO:root:FL Epoch: 162 Norm Difference for worker 1390 is 1.819895
INFO:root:FL Epoch: 162 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628883
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293899
INFO:root:FL Epoch: 162 Norm Difference for worker 1941 is 1.759981
INFO:root:FL Epoch: 162 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :884
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 1.052796
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523606
INFO:root:FL Epoch: 162 Norm Difference for worker 884 is 1.939429
INFO:root:FL Epoch: 162 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :44
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 44 is 1.818067
INFO:root:FL Epoch: 162 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1585
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494274
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363703
INFO:root:FL Epoch: 162 Norm Difference for worker 1585 is 1.895206
INFO:root:FL Epoch: 162 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1081
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650633
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258966
INFO:root:FL Epoch: 162 Norm Difference for worker 1081 is 1.992281
INFO:root:FL Epoch: 162 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1024
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364730
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385013
INFO:root:FL Epoch: 162 Norm Difference for worker 1024 is 1.934407
INFO:root:FL Epoch: 162 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1886
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485300
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252250
INFO:root:FL Epoch: 162 Norm Difference for worker 1886 is 1.807844
INFO:root:FL Epoch: 162 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1439
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405822
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220852
INFO:root:FL Epoch: 162 Norm Difference for worker 1439 is 1.837556
INFO:root:FL Epoch: 162 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 0 2 8 4 5 9], which are global users: [1390, 941, 1941, 1886, 44, 1585, 1439]
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.43019818032489104 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.3966543525457382                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1559
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616949
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489753
INFO:root:FL Epoch: 163 Norm Difference for worker 1559 is 1.785749
INFO:root:FL Epoch: 163 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1487
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408027
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370326
INFO:root:FL Epoch: 163 Norm Difference for worker 1487 is 1.901268
INFO:root:FL Epoch: 163 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :359
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786656
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236076
INFO:root:FL Epoch: 163 Norm Difference for worker 359 is 1.673732
INFO:root:FL Epoch: 163 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1586
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554395
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470599
INFO:root:FL Epoch: 163 Norm Difference for worker 1586 is 1.829306
INFO:root:FL Epoch: 163 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1338
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519202
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589859
INFO:root:FL Epoch: 163 Norm Difference for worker 1338 is 1.801138
INFO:root:FL Epoch: 163 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1840
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674865
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317877
INFO:root:FL Epoch: 163 Norm Difference for worker 1840 is 1.903195
INFO:root:FL Epoch: 163 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :901
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367980
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280855
INFO:root:FL Epoch: 163 Norm Difference for worker 901 is 1.687264
INFO:root:FL Epoch: 163 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :711
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569920
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358051
INFO:root:FL Epoch: 163 Norm Difference for worker 711 is 1.802154
INFO:root:FL Epoch: 163 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1413
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452923
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315662
INFO:root:FL Epoch: 163 Norm Difference for worker 1413 is 1.767742
INFO:root:FL Epoch: 163 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :431
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515551
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314450
INFO:root:FL Epoch: 163 Norm Difference for worker 431 is 1.755858
INFO:root:FL Epoch: 163 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 8 0 4 7], which are global users: [901, 431, 359, 1413, 1559, 1338, 711]
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.43222711191457863 and Test Accuracy:81.47058823529412 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.4034489889939626                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 164 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1316
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297876
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196282
INFO:root:FL Epoch: 164 Norm Difference for worker 1316 is 1.638196
INFO:root:FL Epoch: 164 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :898
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509809
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317751
INFO:root:FL Epoch: 164 Norm Difference for worker 898 is 1.717621
INFO:root:FL Epoch: 164 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :465
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669054
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215253
INFO:root:FL Epoch: 164 Norm Difference for worker 465 is 1.79695
INFO:root:FL Epoch: 164 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :599
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557611
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287557
INFO:root:FL Epoch: 164 Norm Difference for worker 599 is 1.762133
INFO:root:FL Epoch: 164 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1822
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496922
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233905
INFO:root:FL Epoch: 164 Norm Difference for worker 1822 is 1.757375
INFO:root:FL Epoch: 164 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1634
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469190
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420265
INFO:root:FL Epoch: 164 Norm Difference for worker 1634 is 1.83216
INFO:root:FL Epoch: 164 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1455
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688971
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304400
INFO:root:FL Epoch: 164 Norm Difference for worker 1455 is 1.713813
INFO:root:FL Epoch: 164 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :250
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 250 is 1.72791
INFO:root:FL Epoch: 164 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :791
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475161
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211481
INFO:root:FL Epoch: 164 Norm Difference for worker 791 is 1.655749
INFO:root:FL Epoch: 164 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1388
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572278
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249118
INFO:root:FL Epoch: 164 Norm Difference for worker 1388 is 1.779909
INFO:root:FL Epoch: 164 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 7 1 9 3], which are global users: [1455, 1316, 791, 250, 898, 1388, 599]
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.43957216774716096 and Test Accuracy:80.0 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.47288085023562115                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 165 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :1295
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554997
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207531
INFO:root:FL Epoch: 165 Norm Difference for worker 1295 is 1.667036
INFO:root:FL Epoch: 165 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1294
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421699
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223446
INFO:root:FL Epoch: 165 Norm Difference for worker 1294 is 1.838302
INFO:root:FL Epoch: 165 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1754
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829089
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657283
INFO:root:FL Epoch: 165 Norm Difference for worker 1754 is 1.726077
INFO:root:FL Epoch: 165 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :782
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701950
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268584
INFO:root:FL Epoch: 165 Norm Difference for worker 782 is 2.023188
INFO:root:FL Epoch: 165 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :108
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.301379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 108 is 1.762139
INFO:root:FL Epoch: 165 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1018
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453143
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580263
INFO:root:FL Epoch: 165 Norm Difference for worker 1018 is 1.786153
INFO:root:FL Epoch: 165 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :832
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528985
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226625
INFO:root:FL Epoch: 165 Norm Difference for worker 832 is 1.884265
INFO:root:FL Epoch: 165 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :133
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 133 is 1.857662
INFO:root:FL Epoch: 165 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :12
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 12 is 1.863138
INFO:root:FL Epoch: 165 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :34
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.895129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 34 is 1.713128
INFO:root:FL Epoch: 165 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 201 201 201]
INFO:root:Num selected data points: [200 201 200 200 201 201 201]
INFO:root:The chosen ones are users: [0 9 5 2 7 4 8], which are global users: [1295, 34, 1018, 1754, 133, 108, 12]
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.4548611255253063 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.41966767609119415                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 166 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :319
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.296161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 319 is 1.69351
INFO:root:FL Epoch: 166 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :958
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334204
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239147
INFO:root:FL Epoch: 166 Norm Difference for worker 958 is 1.846885
INFO:root:FL Epoch: 166 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1164
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480637
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389972
INFO:root:FL Epoch: 166 Norm Difference for worker 1164 is 1.86431
INFO:root:FL Epoch: 166 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :515
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494559
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277718
INFO:root:FL Epoch: 166 Norm Difference for worker 515 is 1.807465
INFO:root:FL Epoch: 166 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :688
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486678
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399932
INFO:root:FL Epoch: 166 Norm Difference for worker 688 is 1.739562
INFO:root:FL Epoch: 166 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1693
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618940
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283753
INFO:root:FL Epoch: 166 Norm Difference for worker 1693 is 1.697697
INFO:root:FL Epoch: 166 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1070
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826920
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500717
INFO:root:FL Epoch: 166 Norm Difference for worker 1070 is 1.844221
INFO:root:FL Epoch: 166 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1237
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464315
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452641
INFO:root:FL Epoch: 166 Norm Difference for worker 1237 is 1.719868
INFO:root:FL Epoch: 166 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1365
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485901
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192626
INFO:root:FL Epoch: 166 Norm Difference for worker 1365 is 1.750107
INFO:root:FL Epoch: 166 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :936
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457225
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469234
INFO:root:FL Epoch: 166 Norm Difference for worker 936 is 1.752136
INFO:root:FL Epoch: 166 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 9 7 4 3], which are global users: [1693, 319, 1365, 936, 1237, 688, 515]
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.43931417780763965 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.42006051540374756                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :106
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587771
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 106 is 1.710841
INFO:root:FL Epoch: 167 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345308
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202329
INFO:root:FL Epoch: 167 Norm Difference for worker 755 is 1.72439
INFO:root:FL Epoch: 167 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :81
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346973
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 81 is 1.813956
INFO:root:FL Epoch: 167 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1241
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801074
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395848
INFO:root:FL Epoch: 167 Norm Difference for worker 1241 is 1.691561
INFO:root:FL Epoch: 167 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :665
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441902
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253375
INFO:root:FL Epoch: 167 Norm Difference for worker 665 is 1.58814
INFO:root:FL Epoch: 167 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1244
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566697
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281186
INFO:root:FL Epoch: 167 Norm Difference for worker 1244 is 1.777156
INFO:root:FL Epoch: 167 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466114
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311660
INFO:root:FL Epoch: 167 Norm Difference for worker 1755 is 1.655605
INFO:root:FL Epoch: 167 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1189
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494125
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303632
INFO:root:FL Epoch: 167 Norm Difference for worker 1189 is 1.797719
INFO:root:FL Epoch: 167 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :785
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783640
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275374
INFO:root:FL Epoch: 167 Norm Difference for worker 785 is 1.777344
INFO:root:FL Epoch: 167 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1463
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571037
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376897
INFO:root:FL Epoch: 167 Norm Difference for worker 1463 is 1.880192
INFO:root:FL Epoch: 167 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 4 6 3 0 8 5], which are global users: [755, 665, 1755, 1241, 106, 785, 1244]
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.4267399100696339 and Test Accuracy:80.0 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.4743315825859706                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1872
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340613
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327171
INFO:root:FL Epoch: 168 Norm Difference for worker 1872 is 1.787555
INFO:root:FL Epoch: 168 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1711
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454437
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432578
INFO:root:FL Epoch: 168 Norm Difference for worker 1711 is 1.883493
INFO:root:FL Epoch: 168 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :18
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445017
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 18 is 1.800714
INFO:root:FL Epoch: 168 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :202
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 202 is 1.802733
INFO:root:FL Epoch: 168 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360767
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 1.865792
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1782
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587011
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329039
INFO:root:FL Epoch: 168 Norm Difference for worker 1782 is 1.810644
INFO:root:FL Epoch: 168 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1869
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416430
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180762
INFO:root:FL Epoch: 168 Norm Difference for worker 1869 is 1.755612
INFO:root:FL Epoch: 168 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1830
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354764
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319727
INFO:root:FL Epoch: 168 Norm Difference for worker 1830 is 1.776732
INFO:root:FL Epoch: 168 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1197
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477573
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472151
INFO:root:FL Epoch: 168 Norm Difference for worker 1197 is 1.989822
INFO:root:FL Epoch: 168 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1476
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601106
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186553
INFO:root:FL Epoch: 168 Norm Difference for worker 1476 is 1.778817
INFO:root:FL Epoch: 168 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 7 9 5], which are global users: [1869, 1872, 18, 202, 1830, 1476, 1782]
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.43392253447981444 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.5627053330341975                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 169 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :945
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665073
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180873
INFO:root:FL Epoch: 169 Norm Difference for worker 945 is 1.646049
INFO:root:FL Epoch: 169 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :273
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 273 is 1.760853
INFO:root:FL Epoch: 169 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1442
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650803
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232811
INFO:root:FL Epoch: 169 Norm Difference for worker 1442 is 1.817356
INFO:root:FL Epoch: 169 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :952
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371727
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242307
INFO:root:FL Epoch: 169 Norm Difference for worker 952 is 1.912735
INFO:root:FL Epoch: 169 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1360
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323299
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331552
INFO:root:FL Epoch: 169 Norm Difference for worker 1360 is 1.879791
INFO:root:FL Epoch: 169 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :854
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590694
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251646
INFO:root:FL Epoch: 169 Norm Difference for worker 854 is 1.749068
INFO:root:FL Epoch: 169 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :821
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672713
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214301
INFO:root:FL Epoch: 169 Norm Difference for worker 821 is 1.838754
INFO:root:FL Epoch: 169 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1782
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303482
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184210
INFO:root:FL Epoch: 169 Norm Difference for worker 1782 is 1.566907
INFO:root:FL Epoch: 169 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :807
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679568
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510887
INFO:root:FL Epoch: 169 Norm Difference for worker 807 is 1.929568
INFO:root:FL Epoch: 169 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :24
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 24 is 1.811486
INFO:root:FL Epoch: 169 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 0 7 5 9 4 2], which are global users: [273, 945, 1782, 854, 24, 1360, 1442]
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.4309387189500472 and Test Accuracy:80.0 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.4728025371829669                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :603
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388852
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286999
INFO:root:FL Epoch: 170 Norm Difference for worker 603 is 1.864128
INFO:root:FL Epoch: 170 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :40
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312136
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 40 is 1.886431
INFO:root:FL Epoch: 170 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1838
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841197
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420911
INFO:root:FL Epoch: 170 Norm Difference for worker 1838 is 1.904926
INFO:root:FL Epoch: 170 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :467
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576269
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270289
INFO:root:FL Epoch: 170 Norm Difference for worker 467 is 1.715673
INFO:root:FL Epoch: 170 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :350
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390117
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455093
INFO:root:FL Epoch: 170 Norm Difference for worker 350 is 1.968795
INFO:root:FL Epoch: 170 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :263
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503340
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265794
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 263 is 2.001475
INFO:root:FL Epoch: 170 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1301
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486817
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230510
INFO:root:FL Epoch: 170 Norm Difference for worker 1301 is 2.14396
INFO:root:FL Epoch: 170 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :833
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590916
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310887
INFO:root:FL Epoch: 170 Norm Difference for worker 833 is 1.806206
INFO:root:FL Epoch: 170 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :465
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546311
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343449
INFO:root:FL Epoch: 170 Norm Difference for worker 465 is 1.900932
INFO:root:FL Epoch: 170 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :863
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510901
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453870
INFO:root:FL Epoch: 170 Norm Difference for worker 863 is 1.895039
INFO:root:FL Epoch: 170 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 7 3 9 8 2], which are global users: [40, 603, 833, 467, 863, 465, 1838]
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.4419487662175122 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.48313242197036743                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403516
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286532
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.1502958138783773 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.19234424382448195 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.45693
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352765
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274040
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.154632447908322 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.19562110528349877 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 0.457418
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308931
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376997
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.1614991140862306 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.19484120160341262 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 0.449448
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :694
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512532
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245128
INFO:root:FL Epoch: 171 Norm Difference for worker 694 is 1.67958
INFO:root:FL Epoch: 171 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1305
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465146
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294371
INFO:root:FL Epoch: 171 Norm Difference for worker 1305 is 1.828566
INFO:root:FL Epoch: 171 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1063
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889935
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316078
INFO:root:FL Epoch: 171 Norm Difference for worker 1063 is 1.836521
INFO:root:FL Epoch: 171 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1767
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521118
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372888
INFO:root:FL Epoch: 171 Norm Difference for worker 1767 is 1.724954
INFO:root:FL Epoch: 171 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :318
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.775755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 318 is 1.740734
INFO:root:FL Epoch: 171 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :760
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547877
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286750
INFO:root:FL Epoch: 171 Norm Difference for worker 760 is 1.870084
INFO:root:FL Epoch: 171 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1876
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572682
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203789
INFO:root:FL Epoch: 171 Norm Difference for worker 1876 is 1.936157
INFO:root:FL Epoch: 171 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 6], which are global users: [318, 0, 2, 694, 1, 1063, 1767]
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.44937167974079356 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.3089250475168228                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1003
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755261
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175224
INFO:root:FL Epoch: 172 Norm Difference for worker 1003 is 1.619584
INFO:root:FL Epoch: 172 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :375
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 1.161539
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245826
INFO:root:FL Epoch: 172 Norm Difference for worker 375 is 1.731068
INFO:root:FL Epoch: 172 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :966
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660372
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370298
INFO:root:FL Epoch: 172 Norm Difference for worker 966 is 1.802252
INFO:root:FL Epoch: 172 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :334
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506700
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 334 is 1.577705
INFO:root:FL Epoch: 172 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :312
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 312 is 1.763973
INFO:root:FL Epoch: 172 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1747
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594082
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255669
INFO:root:FL Epoch: 172 Norm Difference for worker 1747 is 1.906794
INFO:root:FL Epoch: 172 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1294
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614354
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298799
INFO:root:FL Epoch: 172 Norm Difference for worker 1294 is 1.81373
INFO:root:FL Epoch: 172 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :737
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450842
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351999
INFO:root:FL Epoch: 172 Norm Difference for worker 737 is 1.874182
INFO:root:FL Epoch: 172 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1064
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425919
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315615
INFO:root:FL Epoch: 172 Norm Difference for worker 1064 is 1.675324
INFO:root:FL Epoch: 172 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1392
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406850
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197833
INFO:root:FL Epoch: 172 Norm Difference for worker 1392 is 1.635853
INFO:root:FL Epoch: 172 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [3 9 0 1 4 8 6], which are global users: [334, 1392, 1003, 375, 312, 1064, 1294]
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.459765728782205 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.37728991359472275                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1721
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617906
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260131
INFO:root:FL Epoch: 173 Norm Difference for worker 1721 is 1.67523
INFO:root:FL Epoch: 173 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1093
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883681
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455668
INFO:root:FL Epoch: 173 Norm Difference for worker 1093 is 1.842583
INFO:root:FL Epoch: 173 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1173
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569823
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326803
INFO:root:FL Epoch: 173 Norm Difference for worker 1173 is 1.890552
INFO:root:FL Epoch: 173 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :968
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604915
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234691
INFO:root:FL Epoch: 173 Norm Difference for worker 968 is 1.760584
INFO:root:FL Epoch: 173 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :270
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 270 is 1.716356
INFO:root:FL Epoch: 173 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :894
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578573
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253507
INFO:root:FL Epoch: 173 Norm Difference for worker 894 is 1.722166
INFO:root:FL Epoch: 173 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :594
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586755
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345929
INFO:root:FL Epoch: 173 Norm Difference for worker 594 is 1.852459
INFO:root:FL Epoch: 173 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1009
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721244
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227258
INFO:root:FL Epoch: 173 Norm Difference for worker 1009 is 1.988616
INFO:root:FL Epoch: 173 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1378
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849967
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254941
INFO:root:FL Epoch: 173 Norm Difference for worker 1378 is 1.84317
INFO:root:FL Epoch: 173 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :906
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219251
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258672
INFO:root:FL Epoch: 173 Norm Difference for worker 906 is 1.681655
INFO:root:FL Epoch: 173 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [9 0 4 5 8 6 3], which are global users: [906, 1721, 270, 894, 1378, 594, 968]
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.47740219095174 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.3075617377956708                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 174 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :1667
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585769
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165001
INFO:root:FL Epoch: 174 Norm Difference for worker 1667 is 1.758094
INFO:root:FL Epoch: 174 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :907
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589375
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173711
INFO:root:FL Epoch: 174 Norm Difference for worker 907 is 1.866392
INFO:root:FL Epoch: 174 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1313
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584078
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218024
INFO:root:FL Epoch: 174 Norm Difference for worker 1313 is 1.767061
INFO:root:FL Epoch: 174 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :522
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622211
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490675
INFO:root:FL Epoch: 174 Norm Difference for worker 522 is 1.738692
INFO:root:FL Epoch: 174 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :913
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725637
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480519
INFO:root:FL Epoch: 174 Norm Difference for worker 913 is 1.957634
INFO:root:FL Epoch: 174 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1260
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293075
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245787
INFO:root:FL Epoch: 174 Norm Difference for worker 1260 is 1.834369
INFO:root:FL Epoch: 174 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1683
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 1.171192
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552573
INFO:root:FL Epoch: 174 Norm Difference for worker 1683 is 2.022895
INFO:root:FL Epoch: 174 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :925
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395993
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169364
INFO:root:FL Epoch: 174 Norm Difference for worker 925 is 1.695014
INFO:root:FL Epoch: 174 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1459
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452339
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342371
INFO:root:FL Epoch: 174 Norm Difference for worker 1459 is 1.977661
INFO:root:FL Epoch: 174 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1264
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322145
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712426
INFO:root:FL Epoch: 174 Norm Difference for worker 1264 is 1.816119
INFO:root:FL Epoch: 174 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 3 7 9 1], which are global users: [1260, 1667, 1313, 522, 925, 1264, 907]
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.4507787648369284 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.34222236027320224                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516589
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367250
INFO:root:FL Epoch: 175 Norm Difference for worker 850 is 1.84516
INFO:root:FL Epoch: 175 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680780
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574612
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 1.878503
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1212
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412718
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302724
INFO:root:FL Epoch: 175 Norm Difference for worker 1212 is 1.796031
INFO:root:FL Epoch: 175 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1570
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430086
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342723
INFO:root:FL Epoch: 175 Norm Difference for worker 1570 is 1.866533
INFO:root:FL Epoch: 175 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :305
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246933
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 305 is 1.692445
INFO:root:FL Epoch: 175 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1197
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633185
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220394
INFO:root:FL Epoch: 175 Norm Difference for worker 1197 is 1.83355
INFO:root:FL Epoch: 175 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1169
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493277
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279062
INFO:root:FL Epoch: 175 Norm Difference for worker 1169 is 1.821784
INFO:root:FL Epoch: 175 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1057
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786918
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688186
INFO:root:FL Epoch: 175 Norm Difference for worker 1057 is 1.896831
INFO:root:FL Epoch: 175 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1584
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626844
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463467
INFO:root:FL Epoch: 175 Norm Difference for worker 1584 is 1.795858
INFO:root:FL Epoch: 175 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1528
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493366
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329980
INFO:root:FL Epoch: 175 Norm Difference for worker 1528 is 1.62388
INFO:root:FL Epoch: 175 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [9 4 2 5 8 6 0], which are global users: [1528, 305, 1212, 1197, 1584, 1169, 850]
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.44622432834961834 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.3447953810294469                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :637
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697660
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305841
INFO:root:FL Epoch: 176 Norm Difference for worker 637 is 1.969866
INFO:root:FL Epoch: 176 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1889
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663848
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199886
INFO:root:FL Epoch: 176 Norm Difference for worker 1889 is 1.751869
INFO:root:FL Epoch: 176 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :528
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649579
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315522
INFO:root:FL Epoch: 176 Norm Difference for worker 528 is 1.868416
INFO:root:FL Epoch: 176 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1101
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743180
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400481
INFO:root:FL Epoch: 176 Norm Difference for worker 1101 is 1.715114
INFO:root:FL Epoch: 176 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1673
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581551
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287514
INFO:root:FL Epoch: 176 Norm Difference for worker 1673 is 1.772524
INFO:root:FL Epoch: 176 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :974
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504698
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344151
INFO:root:FL Epoch: 176 Norm Difference for worker 974 is 1.716977
INFO:root:FL Epoch: 176 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1233
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483069
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293217
INFO:root:FL Epoch: 176 Norm Difference for worker 1233 is 1.872659
INFO:root:FL Epoch: 176 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :787
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415063
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328554
INFO:root:FL Epoch: 176 Norm Difference for worker 787 is 1.769984
INFO:root:FL Epoch: 176 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :977
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493576
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310211
INFO:root:FL Epoch: 176 Norm Difference for worker 977 is 1.769687
INFO:root:FL Epoch: 176 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :516
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552454
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185110
INFO:root:FL Epoch: 176 Norm Difference for worker 516 is 1.738089
INFO:root:FL Epoch: 176 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [787, 516, 528, 1101, 1889, 974, 977]
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.45496289695010467 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.4532424658536911                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :313
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526611
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 313 is 1.64538
INFO:root:FL Epoch: 177 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :908
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761414
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241681
INFO:root:FL Epoch: 177 Norm Difference for worker 908 is 1.754948
INFO:root:FL Epoch: 177 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :557
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692487
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378967
INFO:root:FL Epoch: 177 Norm Difference for worker 557 is 1.669719
INFO:root:FL Epoch: 177 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :881
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249262
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367214
INFO:root:FL Epoch: 177 Norm Difference for worker 881 is 1.612257
INFO:root:FL Epoch: 177 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1256
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424233
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267125
INFO:root:FL Epoch: 177 Norm Difference for worker 1256 is 1.726395
INFO:root:FL Epoch: 177 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :539
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.941576
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353587
INFO:root:FL Epoch: 177 Norm Difference for worker 539 is 1.801054
INFO:root:FL Epoch: 177 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 1.731584
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :220
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.196638
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 220 is 1.566102
INFO:root:FL Epoch: 177 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :342
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379599
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242967
INFO:root:FL Epoch: 177 Norm Difference for worker 342 is 1.818117
INFO:root:FL Epoch: 177 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1936
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410663
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255472
INFO:root:FL Epoch: 177 Norm Difference for worker 1936 is 1.75199
INFO:root:FL Epoch: 177 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 7 4], which are global users: [8, 313, 557, 881, 908, 220, 1256]
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.44820291680448193 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.41826650500297546                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :1855
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523321
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569031
INFO:root:FL Epoch: 178 Norm Difference for worker 1855 is 1.75009
INFO:root:FL Epoch: 178 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :418
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440928
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484081
INFO:root:FL Epoch: 178 Norm Difference for worker 418 is 1.645674
INFO:root:FL Epoch: 178 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1550
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667037
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311787
INFO:root:FL Epoch: 178 Norm Difference for worker 1550 is 1.691988
INFO:root:FL Epoch: 178 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1800
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452790
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331839
INFO:root:FL Epoch: 178 Norm Difference for worker 1800 is 1.679271
INFO:root:FL Epoch: 178 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1189
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674110
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261921
INFO:root:FL Epoch: 178 Norm Difference for worker 1189 is 1.724819
INFO:root:FL Epoch: 178 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :611
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653058
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267367
INFO:root:FL Epoch: 178 Norm Difference for worker 611 is 1.699298
INFO:root:FL Epoch: 178 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :325
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 325 is 1.709938
INFO:root:FL Epoch: 178 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :983
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717133
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472612
INFO:root:FL Epoch: 178 Norm Difference for worker 983 is 1.92406
INFO:root:FL Epoch: 178 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555629
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222884
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.795127
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.828105
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 1.630547
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 3 1 5 0], which are global users: [325, 70, 1550, 1800, 418, 611, 1855]
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.4755402032066794 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.38743596772352856                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1226
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499214
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339074
INFO:root:FL Epoch: 179 Norm Difference for worker 1226 is 1.709792
INFO:root:FL Epoch: 179 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1285
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495438
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171320
INFO:root:FL Epoch: 179 Norm Difference for worker 1285 is 1.716948
INFO:root:FL Epoch: 179 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :972
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776571
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294210
INFO:root:FL Epoch: 179 Norm Difference for worker 972 is 1.875809
INFO:root:FL Epoch: 179 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :393
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445658
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354287
INFO:root:FL Epoch: 179 Norm Difference for worker 393 is 1.851644
INFO:root:FL Epoch: 179 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :977
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270406
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459486
INFO:root:FL Epoch: 179 Norm Difference for worker 977 is 1.716263
INFO:root:FL Epoch: 179 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :59
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210422
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 59 is 1.676426
INFO:root:FL Epoch: 179 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :575
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500279
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352076
INFO:root:FL Epoch: 179 Norm Difference for worker 575 is 1.783909
INFO:root:FL Epoch: 179 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :472
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335378
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313311
INFO:root:FL Epoch: 179 Norm Difference for worker 472 is 1.694682
INFO:root:FL Epoch: 179 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1689
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646899
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381559
INFO:root:FL Epoch: 179 Norm Difference for worker 1689 is 1.882655
INFO:root:FL Epoch: 179 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :565
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359416
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274153
INFO:root:FL Epoch: 179 Norm Difference for worker 565 is 1.698153
INFO:root:FL Epoch: 179 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 7 0 1 6 4], which are global users: [59, 565, 472, 1226, 1285, 575, 977]
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.4587008041494033 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.33224903295437497                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1850
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624851
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469728
INFO:root:FL Epoch: 180 Norm Difference for worker 1850 is 1.833124
INFO:root:FL Epoch: 180 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :989
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545443
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319468
INFO:root:FL Epoch: 180 Norm Difference for worker 989 is 1.758599
INFO:root:FL Epoch: 180 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :611
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309752
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277866
INFO:root:FL Epoch: 180 Norm Difference for worker 611 is 1.62164
INFO:root:FL Epoch: 180 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :637
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619492
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233549
INFO:root:FL Epoch: 180 Norm Difference for worker 637 is 1.939228
INFO:root:FL Epoch: 180 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1690
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788971
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435612
INFO:root:FL Epoch: 180 Norm Difference for worker 1690 is 1.830032
INFO:root:FL Epoch: 180 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1250
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583955
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407760
INFO:root:FL Epoch: 180 Norm Difference for worker 1250 is 1.861695
INFO:root:FL Epoch: 180 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :844
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346413
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325207
INFO:root:FL Epoch: 180 Norm Difference for worker 844 is 1.570371
INFO:root:FL Epoch: 180 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1444
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385477
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315287
INFO:root:FL Epoch: 180 Norm Difference for worker 1444 is 1.780833
INFO:root:FL Epoch: 180 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :120
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 120 is 1.742233
INFO:root:FL Epoch: 180 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :134
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 134 is 1.812177
INFO:root:FL Epoch: 180 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [6 4 2 8 1 7 9], which are global users: [844, 1690, 611, 120, 989, 1444, 134]
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.46073020205778237 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.46209777891635895                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312876
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267682
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.13991363594929376 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.19223759025335313 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.440368
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360496
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260960
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.12690155394375324 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.2005318932235241 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.448584
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392426
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244720
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.15902948131163916 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.1990218624472618 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.407314
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :869
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545055
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341792
INFO:root:FL Epoch: 181 Norm Difference for worker 869 is 1.751823
INFO:root:FL Epoch: 181 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :716
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499921
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173669
INFO:root:FL Epoch: 181 Norm Difference for worker 716 is 1.575273
INFO:root:FL Epoch: 181 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1560
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270327
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257414
INFO:root:FL Epoch: 181 Norm Difference for worker 1560 is 1.725409
INFO:root:FL Epoch: 181 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :623
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764877
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338866
INFO:root:FL Epoch: 181 Norm Difference for worker 623 is 1.767128
INFO:root:FL Epoch: 181 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1018
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684531
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309327
INFO:root:FL Epoch: 181 Norm Difference for worker 1018 is 1.714432
INFO:root:FL Epoch: 181 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :195
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.331536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 195 is 1.785023
INFO:root:FL Epoch: 181 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1034
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688853
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341710
INFO:root:FL Epoch: 181 Norm Difference for worker 1034 is 1.763882
INFO:root:FL Epoch: 181 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 4 7 9 5], which are global users: [1, 0, 2, 716, 1018, 1034, 1560]
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.4407728051438051 and Test Accuracy:81.17647058823529 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.23898832499980927                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1201
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339029
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305608
INFO:root:FL Epoch: 182 Norm Difference for worker 1201 is 1.776423
INFO:root:FL Epoch: 182 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1052
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388734
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462106
INFO:root:FL Epoch: 182 Norm Difference for worker 1052 is 1.879217
INFO:root:FL Epoch: 182 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :959
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515628
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303540
INFO:root:FL Epoch: 182 Norm Difference for worker 959 is 1.867144
INFO:root:FL Epoch: 182 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1624
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621427
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266525
INFO:root:FL Epoch: 182 Norm Difference for worker 1624 is 1.809648
INFO:root:FL Epoch: 182 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :825
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577750
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308845
INFO:root:FL Epoch: 182 Norm Difference for worker 825 is 1.706226
INFO:root:FL Epoch: 182 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1782
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306107
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327241
INFO:root:FL Epoch: 182 Norm Difference for worker 1782 is 1.721395
INFO:root:FL Epoch: 182 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :488
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682094
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192207
INFO:root:FL Epoch: 182 Norm Difference for worker 488 is 1.791359
INFO:root:FL Epoch: 182 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :507
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924770
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303679
INFO:root:FL Epoch: 182 Norm Difference for worker 507 is 1.934225
INFO:root:FL Epoch: 182 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1078
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442367
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260088
INFO:root:FL Epoch: 182 Norm Difference for worker 1078 is 1.84806
INFO:root:FL Epoch: 182 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1849
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480260
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173201
INFO:root:FL Epoch: 182 Norm Difference for worker 1849 is 1.757013
INFO:root:FL Epoch: 182 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 0 9 6 8 3], which are global users: [1782, 825, 1201, 1849, 488, 1078, 1624]
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.4681333022959092 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.24974746257066727                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1215
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811868
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334030
INFO:root:FL Epoch: 183 Norm Difference for worker 1215 is 1.82982
INFO:root:FL Epoch: 183 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1520
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336538
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191894
INFO:root:FL Epoch: 183 Norm Difference for worker 1520 is 1.721569
INFO:root:FL Epoch: 183 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :630
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385110
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369075
INFO:root:FL Epoch: 183 Norm Difference for worker 630 is 2.032942
INFO:root:FL Epoch: 183 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :563
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477016
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284656
INFO:root:FL Epoch: 183 Norm Difference for worker 563 is 1.700164
INFO:root:FL Epoch: 183 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 1.784378
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1104
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569233
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242840
INFO:root:FL Epoch: 183 Norm Difference for worker 1104 is 1.846042
INFO:root:FL Epoch: 183 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1522
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318814
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261258
INFO:root:FL Epoch: 183 Norm Difference for worker 1522 is 1.656368
INFO:root:FL Epoch: 183 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1754
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457640
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198742
INFO:root:FL Epoch: 183 Norm Difference for worker 1754 is 1.720255
INFO:root:FL Epoch: 183 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :48
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209998
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 48 is 1.606339
INFO:root:FL Epoch: 183 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1604
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716977
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258784
INFO:root:FL Epoch: 183 Norm Difference for worker 1604 is 1.880205
INFO:root:FL Epoch: 183 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 7 0], which are global users: [1522, 4, 48, 563, 1520, 1754, 1215]
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.4738285524003646 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.25732218101620674                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1775
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547710
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254123
INFO:root:FL Epoch: 184 Norm Difference for worker 1775 is 1.683674
INFO:root:FL Epoch: 184 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1560
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333211
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219483
INFO:root:FL Epoch: 184 Norm Difference for worker 1560 is 1.643718
INFO:root:FL Epoch: 184 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1234
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569629
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450631
INFO:root:FL Epoch: 184 Norm Difference for worker 1234 is 1.899114
INFO:root:FL Epoch: 184 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1381
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305731
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258720
INFO:root:FL Epoch: 184 Norm Difference for worker 1381 is 1.910748
INFO:root:FL Epoch: 184 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1244
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477293
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382383
INFO:root:FL Epoch: 184 Norm Difference for worker 1244 is 1.882377
INFO:root:FL Epoch: 184 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1478
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613567
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170881
INFO:root:FL Epoch: 184 Norm Difference for worker 1478 is 1.640226
INFO:root:FL Epoch: 184 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1887
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272483
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229163
INFO:root:FL Epoch: 184 Norm Difference for worker 1887 is 1.873623
INFO:root:FL Epoch: 184 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :825
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350257
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318443
INFO:root:FL Epoch: 184 Norm Difference for worker 825 is 1.559297
INFO:root:FL Epoch: 184 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :202
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.266451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.201834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 202 is 1.733829
INFO:root:FL Epoch: 184 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :471
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750580
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323907
INFO:root:FL Epoch: 184 Norm Difference for worker 471 is 1.887769
INFO:root:FL Epoch: 184 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 7 1 5 4], which are global users: [1887, 1775, 202, 825, 1560, 1478, 1244]
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.44357425325057087 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.2897935559352239                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1656
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552762
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185247
INFO:root:FL Epoch: 185 Norm Difference for worker 1656 is 1.76484
INFO:root:FL Epoch: 185 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1518
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397963
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289567
INFO:root:FL Epoch: 185 Norm Difference for worker 1518 is 1.769697
INFO:root:FL Epoch: 185 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1088
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586471
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379080
INFO:root:FL Epoch: 185 Norm Difference for worker 1088 is 1.651955
INFO:root:FL Epoch: 185 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :559
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615991
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336850
INFO:root:FL Epoch: 185 Norm Difference for worker 559 is 1.836103
INFO:root:FL Epoch: 185 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :487
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627868
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294979
INFO:root:FL Epoch: 185 Norm Difference for worker 487 is 1.653832
INFO:root:FL Epoch: 185 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :317
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 317 is 1.834739
INFO:root:FL Epoch: 185 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1080
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642253
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367314
INFO:root:FL Epoch: 185 Norm Difference for worker 1080 is 1.926834
INFO:root:FL Epoch: 185 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.154625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 1.916981
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1146
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498716
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286157
INFO:root:FL Epoch: 185 Norm Difference for worker 1146 is 1.825642
INFO:root:FL Epoch: 185 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513595
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 1.774603
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 200 201]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [2 4 0 8 9 5 1], which are global users: [1088, 487, 1656, 1146, 56, 317, 1518]
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.4638296944253585 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.36735590050617856                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572414
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203095
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.734955
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :785
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423389
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390458
INFO:root:FL Epoch: 186 Norm Difference for worker 785 is 1.839018
INFO:root:FL Epoch: 186 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :663
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794471
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283037
INFO:root:FL Epoch: 186 Norm Difference for worker 663 is 1.750805
INFO:root:FL Epoch: 186 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1530
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775394
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590587
INFO:root:FL Epoch: 186 Norm Difference for worker 1530 is 1.864798
INFO:root:FL Epoch: 186 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :738
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846332
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149880
INFO:root:FL Epoch: 186 Norm Difference for worker 738 is 1.775978
INFO:root:FL Epoch: 186 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :128
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 128 is 1.913571
INFO:root:FL Epoch: 186 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1070
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521148
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299346
INFO:root:FL Epoch: 186 Norm Difference for worker 1070 is 1.814663
INFO:root:FL Epoch: 186 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :823
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586900
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255093
INFO:root:FL Epoch: 186 Norm Difference for worker 823 is 1.757031
INFO:root:FL Epoch: 186 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :385
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637603
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415399
INFO:root:FL Epoch: 186 Norm Difference for worker 385 is 1.83152
INFO:root:FL Epoch: 186 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :503
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438989
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146471
INFO:root:FL Epoch: 186 Norm Difference for worker 503 is 1.735077
INFO:root:FL Epoch: 186 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 9 4 6 1], which are global users: [823, 888, 663, 503, 738, 1070, 785]
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.43184062312631044 and Test Accuracy:80.0 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.40942632655302685                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 187 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :301
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233198
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 301 is 1.690939
INFO:root:FL Epoch: 187 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :277
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.338501
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 277 is 1.825441
INFO:root:FL Epoch: 187 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :269
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533370
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.188554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 269 is 1.775927
INFO:root:FL Epoch: 187 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1198
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544166
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300216
INFO:root:FL Epoch: 187 Norm Difference for worker 1198 is 1.665741
INFO:root:FL Epoch: 187 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :545
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379359
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364633
INFO:root:FL Epoch: 187 Norm Difference for worker 545 is 1.817101
INFO:root:FL Epoch: 187 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1043
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518500
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372041
INFO:root:FL Epoch: 187 Norm Difference for worker 1043 is 1.798631
INFO:root:FL Epoch: 187 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :766
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342401
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273721
INFO:root:FL Epoch: 187 Norm Difference for worker 766 is 1.565502
INFO:root:FL Epoch: 187 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :736
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415325
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292946
INFO:root:FL Epoch: 187 Norm Difference for worker 736 is 1.885291
INFO:root:FL Epoch: 187 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :458
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697659
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310430
INFO:root:FL Epoch: 187 Norm Difference for worker 458 is 1.767299
INFO:root:FL Epoch: 187 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1218
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512841
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176757
INFO:root:FL Epoch: 187 Norm Difference for worker 1218 is 1.783964
INFO:root:FL Epoch: 187 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 8 9 4], which are global users: [766, 301, 269, 1198, 458, 1218, 545]
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.47819684007588553 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.46768951416015625                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 188 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :1848
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537671
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220841
INFO:root:FL Epoch: 188 Norm Difference for worker 1848 is 1.679422
INFO:root:FL Epoch: 188 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :77
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.252279
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.173232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 77 is 1.671084
INFO:root:FL Epoch: 188 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1719
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479887
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259539
INFO:root:FL Epoch: 188 Norm Difference for worker 1719 is 1.718655
INFO:root:FL Epoch: 188 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :49
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.399562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.251388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 49 is 1.962451
INFO:root:FL Epoch: 188 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :382
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560379
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229912
INFO:root:FL Epoch: 188 Norm Difference for worker 382 is 1.884231
INFO:root:FL Epoch: 188 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :721
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494538
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316554
INFO:root:FL Epoch: 188 Norm Difference for worker 721 is 1.970841
INFO:root:FL Epoch: 188 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1690
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668370
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271992
INFO:root:FL Epoch: 188 Norm Difference for worker 1690 is 1.817679
INFO:root:FL Epoch: 188 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1774
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545191
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384616
INFO:root:FL Epoch: 188 Norm Difference for worker 1774 is 1.719033
INFO:root:FL Epoch: 188 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1927
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430570
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351598
INFO:root:FL Epoch: 188 Norm Difference for worker 1927 is 1.752034
INFO:root:FL Epoch: 188 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :433
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420365
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275602
INFO:root:FL Epoch: 188 Norm Difference for worker 433 is 1.754418
INFO:root:FL Epoch: 188 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 9 6], which are global users: [1774, 1848, 1719, 1927, 77, 433, 1690]
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.45037803404471455 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.4512793521086375                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :486
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542782
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265738
INFO:root:FL Epoch: 189 Norm Difference for worker 486 is 1.788471
INFO:root:FL Epoch: 189 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1170
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.866485
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341523
INFO:root:FL Epoch: 189 Norm Difference for worker 1170 is 1.917503
INFO:root:FL Epoch: 189 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1606
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694718
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184205
INFO:root:FL Epoch: 189 Norm Difference for worker 1606 is 1.799849
INFO:root:FL Epoch: 189 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1307
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449768
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346475
INFO:root:FL Epoch: 189 Norm Difference for worker 1307 is 1.83479
INFO:root:FL Epoch: 189 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :901
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283019
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298833
INFO:root:FL Epoch: 189 Norm Difference for worker 901 is 1.642366
INFO:root:FL Epoch: 189 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :556
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616108
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272345
INFO:root:FL Epoch: 189 Norm Difference for worker 556 is 1.715763
INFO:root:FL Epoch: 189 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :740
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460914
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169345
INFO:root:FL Epoch: 189 Norm Difference for worker 740 is 1.806252
INFO:root:FL Epoch: 189 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :927
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622551
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335581
INFO:root:FL Epoch: 189 Norm Difference for worker 927 is 1.576095
INFO:root:FL Epoch: 189 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :270
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341510
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407135
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 270 is 1.790851
INFO:root:FL Epoch: 189 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :488
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379623
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229860
INFO:root:FL Epoch: 189 Norm Difference for worker 488 is 1.637662
INFO:root:FL Epoch: 189 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 4 9 8 6 5 0], which are global users: [927, 901, 488, 270, 740, 556, 486]
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.4593042345607982 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.465846707423528                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :256
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 256 is 1.698418
INFO:root:FL Epoch: 190 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :751
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471810
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464281
INFO:root:FL Epoch: 190 Norm Difference for worker 751 is 1.717404
INFO:root:FL Epoch: 190 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1156
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431150
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251151
INFO:root:FL Epoch: 190 Norm Difference for worker 1156 is 1.644502
INFO:root:FL Epoch: 190 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1330
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425261
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273631
INFO:root:FL Epoch: 190 Norm Difference for worker 1330 is 1.815584
INFO:root:FL Epoch: 190 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :859
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575234
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370054
INFO:root:FL Epoch: 190 Norm Difference for worker 859 is 1.927093
INFO:root:FL Epoch: 190 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :257
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490565
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 257 is 1.882699
INFO:root:FL Epoch: 190 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1432
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586684
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355382
INFO:root:FL Epoch: 190 Norm Difference for worker 1432 is 1.769816
INFO:root:FL Epoch: 190 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458258
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567414
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 1.933882
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1730
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387217
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426997
INFO:root:FL Epoch: 190 Norm Difference for worker 1730 is 1.908278
INFO:root:FL Epoch: 190 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :608
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587777
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242752
INFO:root:FL Epoch: 190 Norm Difference for worker 608 is 1.82816
INFO:root:FL Epoch: 190 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 5 9], which are global users: [1432, 256, 1156, 1330, 751, 257, 608]
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.47358999357504006 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.5319094508886337                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384587
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330695
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.1295426283031702 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.17230041176080704 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.432908
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300007
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379103
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.14654607512056828 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.16627554669976236 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.446053
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323290
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196571
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.1376715681205193 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.16827081218361856 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.435775
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1898
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380809
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416573
INFO:root:FL Epoch: 191 Norm Difference for worker 1898 is 1.801243
INFO:root:FL Epoch: 191 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497186
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228324
INFO:root:FL Epoch: 191 Norm Difference for worker 555 is 1.758686
INFO:root:FL Epoch: 191 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :925
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437495
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340457
INFO:root:FL Epoch: 191 Norm Difference for worker 925 is 1.632345
INFO:root:FL Epoch: 191 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :113
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317821
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 113 is 1.695771
INFO:root:FL Epoch: 191 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1363
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473163
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266704
INFO:root:FL Epoch: 191 Norm Difference for worker 1363 is 1.921244
INFO:root:FL Epoch: 191 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1837
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374744
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175252
INFO:root:FL Epoch: 191 Norm Difference for worker 1837 is 1.775123
INFO:root:FL Epoch: 191 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :781
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551449
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289676
INFO:root:FL Epoch: 191 Norm Difference for worker 781 is 1.776398
INFO:root:FL Epoch: 191 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 8 1 5 4], which are global users: [113, 0, 2, 1837, 1, 925, 555]
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.4395938515663147 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.3286576494574547                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :562
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461013
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242095
INFO:root:FL Epoch: 192 Norm Difference for worker 562 is 1.75892
INFO:root:FL Epoch: 192 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1742
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494183
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247628
INFO:root:FL Epoch: 192 Norm Difference for worker 1742 is 1.87595
INFO:root:FL Epoch: 192 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :947
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740757
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363562
INFO:root:FL Epoch: 192 Norm Difference for worker 947 is 1.79175
INFO:root:FL Epoch: 192 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :406
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447751
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290364
INFO:root:FL Epoch: 192 Norm Difference for worker 406 is 1.889177
INFO:root:FL Epoch: 192 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1259
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633982
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335088
INFO:root:FL Epoch: 192 Norm Difference for worker 1259 is 1.865187
INFO:root:FL Epoch: 192 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :390
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755765
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210719
INFO:root:FL Epoch: 192 Norm Difference for worker 390 is 1.890857
INFO:root:FL Epoch: 192 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1140
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477352
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266174
INFO:root:FL Epoch: 192 Norm Difference for worker 1140 is 1.864194
INFO:root:FL Epoch: 192 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1411
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829858
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431859
INFO:root:FL Epoch: 192 Norm Difference for worker 1411 is 1.934086
INFO:root:FL Epoch: 192 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :66
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 66 is 1.795833
INFO:root:FL Epoch: 192 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :468
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664075
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309727
INFO:root:FL Epoch: 192 Norm Difference for worker 468 is 1.783891
INFO:root:FL Epoch: 192 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 0 2 9 1 4 3], which are global users: [66, 562, 947, 468, 1742, 1259, 406]
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.4434373080730438 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.3503296772638957                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1614
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536407
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421188
INFO:root:FL Epoch: 193 Norm Difference for worker 1614 is 1.972901
INFO:root:FL Epoch: 193 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :504
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232470
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194925
INFO:root:FL Epoch: 193 Norm Difference for worker 504 is 1.746782
INFO:root:FL Epoch: 193 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1022
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416602
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220567
INFO:root:FL Epoch: 193 Norm Difference for worker 1022 is 1.632144
INFO:root:FL Epoch: 193 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :580
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688295
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317407
INFO:root:FL Epoch: 193 Norm Difference for worker 580 is 1.80846
INFO:root:FL Epoch: 193 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1730
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349332
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289231
INFO:root:FL Epoch: 193 Norm Difference for worker 1730 is 1.884927
INFO:root:FL Epoch: 193 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :828
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 1.024730
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271982
INFO:root:FL Epoch: 193 Norm Difference for worker 828 is 1.955571
INFO:root:FL Epoch: 193 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1619
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471508
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414730
INFO:root:FL Epoch: 193 Norm Difference for worker 1619 is 1.879612
INFO:root:FL Epoch: 193 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1205
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439152
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304155
INFO:root:FL Epoch: 193 Norm Difference for worker 1205 is 1.764979
INFO:root:FL Epoch: 193 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :511
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415675
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309201
INFO:root:FL Epoch: 193 Norm Difference for worker 511 is 1.777743
INFO:root:FL Epoch: 193 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1270
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608201
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270480
INFO:root:FL Epoch: 193 Norm Difference for worker 1270 is 1.716881
INFO:root:FL Epoch: 193 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 8 6], which are global users: [1205, 1270, 1022, 580, 504, 511, 1619]
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.4671385884284973 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.3444717253247897                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 135 is 1.847121
INFO:root:FL Epoch: 194 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1532
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489277
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322885
INFO:root:FL Epoch: 194 Norm Difference for worker 1532 is 1.69211
INFO:root:FL Epoch: 194 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1525
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642935
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332695
INFO:root:FL Epoch: 194 Norm Difference for worker 1525 is 1.901057
INFO:root:FL Epoch: 194 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :103
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575719
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210564
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 103 is 1.741609
INFO:root:FL Epoch: 194 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1790
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635288
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164412
INFO:root:FL Epoch: 194 Norm Difference for worker 1790 is 1.706237
INFO:root:FL Epoch: 194 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :752
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432733
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288499
INFO:root:FL Epoch: 194 Norm Difference for worker 752 is 1.722203
INFO:root:FL Epoch: 194 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :784
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674408
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167603
INFO:root:FL Epoch: 194 Norm Difference for worker 784 is 1.786064
INFO:root:FL Epoch: 194 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :630
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721805
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267830
INFO:root:FL Epoch: 194 Norm Difference for worker 630 is 1.863134
INFO:root:FL Epoch: 194 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1283
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410340
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314528
INFO:root:FL Epoch: 194 Norm Difference for worker 1283 is 1.767054
INFO:root:FL Epoch: 194 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1290
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529357
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252714
INFO:root:FL Epoch: 194 Norm Difference for worker 1290 is 1.694537
INFO:root:FL Epoch: 194 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 4 9 8 3 5 6], which are global users: [1532, 1790, 1290, 1283, 103, 752, 784]
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.4637973816955791 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.4361708164215088                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :926
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379975
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341180
INFO:root:FL Epoch: 195 Norm Difference for worker 926 is 1.601042
INFO:root:FL Epoch: 195 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :191
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 191 is 1.786267
INFO:root:FL Epoch: 195 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1426
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345926
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299187
INFO:root:FL Epoch: 195 Norm Difference for worker 1426 is 1.888768
INFO:root:FL Epoch: 195 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :261
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 261 is 1.838723
INFO:root:FL Epoch: 195 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :874
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772368
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410745
INFO:root:FL Epoch: 195 Norm Difference for worker 874 is 1.800697
INFO:root:FL Epoch: 195 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :700
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548662
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154082
INFO:root:FL Epoch: 195 Norm Difference for worker 700 is 1.797496
INFO:root:FL Epoch: 195 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :7
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 7 is 1.772437
INFO:root:FL Epoch: 195 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :301
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 301 is 1.657161
INFO:root:FL Epoch: 195 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :502
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577006
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249480
INFO:root:FL Epoch: 195 Norm Difference for worker 502 is 1.680844
INFO:root:FL Epoch: 195 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1471
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514051
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374313
INFO:root:FL Epoch: 195 Norm Difference for worker 1471 is 1.730032
INFO:root:FL Epoch: 195 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 201 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 0 8 9 5 4 6], which are global users: [301, 926, 502, 1471, 700, 874, 7]
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.4530717029291041 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.3968019386132558                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :437
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534281
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227080
INFO:root:FL Epoch: 196 Norm Difference for worker 437 is 1.616595
INFO:root:FL Epoch: 196 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 1.813756
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1524
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798194
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345212
INFO:root:FL Epoch: 196 Norm Difference for worker 1524 is 1.752545
INFO:root:FL Epoch: 196 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :130
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 130 is 1.713606
INFO:root:FL Epoch: 196 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :478
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761249
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248514
INFO:root:FL Epoch: 196 Norm Difference for worker 478 is 1.792795
INFO:root:FL Epoch: 196 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :911
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338544
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315232
INFO:root:FL Epoch: 196 Norm Difference for worker 911 is 1.689388
INFO:root:FL Epoch: 196 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1227
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458993
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144176
INFO:root:FL Epoch: 196 Norm Difference for worker 1227 is 1.69412
INFO:root:FL Epoch: 196 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1529
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543448
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381322
INFO:root:FL Epoch: 196 Norm Difference for worker 1529 is 1.786662
INFO:root:FL Epoch: 196 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1567
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482105
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239920
INFO:root:FL Epoch: 196 Norm Difference for worker 1567 is 1.781447
INFO:root:FL Epoch: 196 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :633
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561183
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267730
INFO:root:FL Epoch: 196 Norm Difference for worker 633 is 1.664732
INFO:root:FL Epoch: 196 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [0 9 3 5 6 2 7], which are global users: [437, 633, 130, 911, 1227, 1524, 1529]
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.45171788685462055 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.4805811146895091                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1836
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536280
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350927
INFO:root:FL Epoch: 197 Norm Difference for worker 1836 is 1.650659
INFO:root:FL Epoch: 197 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1738
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513458
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288261
INFO:root:FL Epoch: 197 Norm Difference for worker 1738 is 1.734449
INFO:root:FL Epoch: 197 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :552
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490336
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425104
INFO:root:FL Epoch: 197 Norm Difference for worker 552 is 1.809621
INFO:root:FL Epoch: 197 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 1.5651
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1244
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510216
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308603
INFO:root:FL Epoch: 197 Norm Difference for worker 1244 is 1.612015
INFO:root:FL Epoch: 197 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :932
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319315
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340274
INFO:root:FL Epoch: 197 Norm Difference for worker 932 is 1.699434
INFO:root:FL Epoch: 197 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1049
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331470
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420186
INFO:root:FL Epoch: 197 Norm Difference for worker 1049 is 1.673731
INFO:root:FL Epoch: 197 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1589
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807252
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360163
INFO:root:FL Epoch: 197 Norm Difference for worker 1589 is 1.822241
INFO:root:FL Epoch: 197 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :208
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 1.067691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 208 is 1.665148
INFO:root:FL Epoch: 197 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :677
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470747
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284087
INFO:root:FL Epoch: 197 Norm Difference for worker 677 is 1.7651
INFO:root:FL Epoch: 197 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [3 4 6 0 8 1 5], which are global users: [80, 1244, 1049, 1836, 208, 1738, 932]
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.4513082258841571 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.5004192690054575                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :1491
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536222
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342146
INFO:root:FL Epoch: 198 Norm Difference for worker 1491 is 1.646858
INFO:root:FL Epoch: 198 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1790
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470661
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299666
INFO:root:FL Epoch: 198 Norm Difference for worker 1790 is 1.569247
INFO:root:FL Epoch: 198 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1639
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609623
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321172
INFO:root:FL Epoch: 198 Norm Difference for worker 1639 is 1.759586
INFO:root:FL Epoch: 198 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1719
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389123
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219519
INFO:root:FL Epoch: 198 Norm Difference for worker 1719 is 1.558359
INFO:root:FL Epoch: 198 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :448
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630565
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351533
INFO:root:FL Epoch: 198 Norm Difference for worker 448 is 1.74167
INFO:root:FL Epoch: 198 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1768
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701053
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317946
INFO:root:FL Epoch: 198 Norm Difference for worker 1768 is 1.775952
INFO:root:FL Epoch: 198 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1077
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583115
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351764
INFO:root:FL Epoch: 198 Norm Difference for worker 1077 is 1.601435
INFO:root:FL Epoch: 198 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1215
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515294
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272116
INFO:root:FL Epoch: 198 Norm Difference for worker 1215 is 1.673746
INFO:root:FL Epoch: 198 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1640
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548900
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265292
INFO:root:FL Epoch: 198 Norm Difference for worker 1640 is 1.582695
INFO:root:FL Epoch: 198 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1128
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271330
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255407
INFO:root:FL Epoch: 198 Norm Difference for worker 1128 is 1.654687
INFO:root:FL Epoch: 198 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 3 1 0 7], which are global users: [1077, 1128, 1640, 1719, 1790, 1491, 1215]
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.46189509244526133 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.46736570447683334                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :180
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.160144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 180 is 1.661253
INFO:root:FL Epoch: 199 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1879
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529719
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336477
INFO:root:FL Epoch: 199 Norm Difference for worker 1879 is 1.825863
INFO:root:FL Epoch: 199 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1185
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346663
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349799
INFO:root:FL Epoch: 199 Norm Difference for worker 1185 is 1.916476
INFO:root:FL Epoch: 199 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :280
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.157825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 280 is 1.814644
INFO:root:FL Epoch: 199 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1055
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395204
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357823
INFO:root:FL Epoch: 199 Norm Difference for worker 1055 is 1.762651
INFO:root:FL Epoch: 199 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1690
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355226
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210056
INFO:root:FL Epoch: 199 Norm Difference for worker 1690 is 1.717283
INFO:root:FL Epoch: 199 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :722
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457446
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242930
INFO:root:FL Epoch: 199 Norm Difference for worker 722 is 1.746097
INFO:root:FL Epoch: 199 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :933
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575106
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183526
INFO:root:FL Epoch: 199 Norm Difference for worker 933 is 1.845395
INFO:root:FL Epoch: 199 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1874
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303785
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210290
INFO:root:FL Epoch: 199 Norm Difference for worker 1874 is 1.806104
INFO:root:FL Epoch: 199 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1457
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660698
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431297
INFO:root:FL Epoch: 199 Norm Difference for worker 1457 is 1.811663
INFO:root:FL Epoch: 199 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 201]
INFO:root:The chosen ones are users: [5 0 6 4 8 7 3], which are global users: [1690, 180, 722, 1055, 1874, 933, 280]
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.4463142191662508 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.49896741410096485                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :487
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367189
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267108
INFO:root:FL Epoch: 200 Norm Difference for worker 487 is 1.56975
INFO:root:FL Epoch: 200 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :707
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659440
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534400
INFO:root:FL Epoch: 200 Norm Difference for worker 707 is 1.811534
INFO:root:FL Epoch: 200 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :38
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548916
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.211978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 38 is 1.798729
INFO:root:FL Epoch: 200 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :996
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576459
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206009
INFO:root:FL Epoch: 200 Norm Difference for worker 996 is 1.681574
INFO:root:FL Epoch: 200 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1140
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715722
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451228
INFO:root:FL Epoch: 200 Norm Difference for worker 1140 is 1.78809
INFO:root:FL Epoch: 200 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1706
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534031
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313873
INFO:root:FL Epoch: 200 Norm Difference for worker 1706 is 1.849702
INFO:root:FL Epoch: 200 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :765
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660014
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226225
INFO:root:FL Epoch: 200 Norm Difference for worker 765 is 1.783037
INFO:root:FL Epoch: 200 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1194
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842557
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383353
INFO:root:FL Epoch: 200 Norm Difference for worker 1194 is 1.924292
INFO:root:FL Epoch: 200 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1234
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531168
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220038
INFO:root:FL Epoch: 200 Norm Difference for worker 1234 is 1.869439
INFO:root:FL Epoch: 200 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1892
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428253
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351712
INFO:root:FL Epoch: 200 Norm Difference for worker 1892 is 1.77545
INFO:root:FL Epoch: 200 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 4 1 9], which are global users: [765, 487, 38, 996, 1140, 707, 1892]
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.44215889538035674 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.42706871529420215                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402843
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183278
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.14610393469532332 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.16110450848937036 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.374416
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.177998
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181120
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.1407818707327048 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.16026095449924468 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.372811
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336807
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321309
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.12653599306941032 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.1567118652164936 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.386661
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1449
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 1.285417
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485586
INFO:root:FL Epoch: 201 Norm Difference for worker 1449 is 1.866988
INFO:root:FL Epoch: 201 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1835
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695151
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603741
INFO:root:FL Epoch: 201 Norm Difference for worker 1835 is 1.817202
INFO:root:FL Epoch: 201 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1755
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337470
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171856
INFO:root:FL Epoch: 201 Norm Difference for worker 1755 is 1.901314
INFO:root:FL Epoch: 201 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :22
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 22 is 1.747584
INFO:root:FL Epoch: 201 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1640
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697637
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177513
INFO:root:FL Epoch: 201 Norm Difference for worker 1640 is 1.538794
INFO:root:FL Epoch: 201 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :544
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391440
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326207
INFO:root:FL Epoch: 201 Norm Difference for worker 544 is 1.789353
INFO:root:FL Epoch: 201 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :122
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 122 is 1.757375
INFO:root:FL Epoch: 201 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 9 8], which are global users: [22, 0, 2, 1640, 1, 122, 544]
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.43835466574220094 and Test Accuracy:81.47058823529412 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.27015116065740585                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1483
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421761
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298796
INFO:root:FL Epoch: 202 Norm Difference for worker 1483 is 1.585791
INFO:root:FL Epoch: 202 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :377
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547161
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268239
INFO:root:FL Epoch: 202 Norm Difference for worker 377 is 1.978421
INFO:root:FL Epoch: 202 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :300
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 300 is 1.720411
INFO:root:FL Epoch: 202 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :982
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357134
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311148
INFO:root:FL Epoch: 202 Norm Difference for worker 982 is 1.793081
INFO:root:FL Epoch: 202 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :93
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 93 is 1.730573
INFO:root:FL Epoch: 202 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1665
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281626
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695690
INFO:root:FL Epoch: 202 Norm Difference for worker 1665 is 1.868337
INFO:root:FL Epoch: 202 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1168
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493818
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304242
INFO:root:FL Epoch: 202 Norm Difference for worker 1168 is 1.635919
INFO:root:FL Epoch: 202 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :351
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723400
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447327
INFO:root:FL Epoch: 202 Norm Difference for worker 351 is 1.743371
INFO:root:FL Epoch: 202 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :124
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 124 is 1.837773
INFO:root:FL Epoch: 202 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1314
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416997
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194492
INFO:root:FL Epoch: 202 Norm Difference for worker 1314 is 1.765633
INFO:root:FL Epoch: 202 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 9 7 4 3], which are global users: [1168, 1483, 300, 1314, 351, 93, 982]
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.45895271616823535 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.32944736381371814                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1790
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562259
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224756
INFO:root:FL Epoch: 203 Norm Difference for worker 1790 is 1.507511
INFO:root:FL Epoch: 203 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1275
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463435
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279637
INFO:root:FL Epoch: 203 Norm Difference for worker 1275 is 1.532917
INFO:root:FL Epoch: 203 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1712
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444284
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161022
INFO:root:FL Epoch: 203 Norm Difference for worker 1712 is 1.684292
INFO:root:FL Epoch: 203 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :594
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471050
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279993
INFO:root:FL Epoch: 203 Norm Difference for worker 594 is 1.738681
INFO:root:FL Epoch: 203 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :256
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 256 is 1.697037
INFO:root:FL Epoch: 203 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1075
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290910
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215121
INFO:root:FL Epoch: 203 Norm Difference for worker 1075 is 1.700463
INFO:root:FL Epoch: 203 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1770
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322609
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242854
INFO:root:FL Epoch: 203 Norm Difference for worker 1770 is 1.636237
INFO:root:FL Epoch: 203 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1543
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494907
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382511
INFO:root:FL Epoch: 203 Norm Difference for worker 1543 is 1.713832
INFO:root:FL Epoch: 203 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :483
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394644
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401787
INFO:root:FL Epoch: 203 Norm Difference for worker 483 is 1.692984
INFO:root:FL Epoch: 203 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :433
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697446
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218149
INFO:root:FL Epoch: 203 Norm Difference for worker 433 is 1.627075
INFO:root:FL Epoch: 203 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 9 2 8 6 7], which are global users: [1275, 1790, 433, 1712, 483, 1770, 1543]
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.45373475025681886 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.3865949635704358                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :643
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327896
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303712
INFO:root:FL Epoch: 204 Norm Difference for worker 643 is 1.745426
INFO:root:FL Epoch: 204 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :796
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713314
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210761
INFO:root:FL Epoch: 204 Norm Difference for worker 796 is 1.668589
INFO:root:FL Epoch: 204 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1743
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547278
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333304
INFO:root:FL Epoch: 204 Norm Difference for worker 1743 is 1.701259
INFO:root:FL Epoch: 204 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1572
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913306
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339014
INFO:root:FL Epoch: 204 Norm Difference for worker 1572 is 1.710408
INFO:root:FL Epoch: 204 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :644
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.868408
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356557
INFO:root:FL Epoch: 204 Norm Difference for worker 644 is 1.707008
INFO:root:FL Epoch: 204 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :893
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300165
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202502
INFO:root:FL Epoch: 204 Norm Difference for worker 893 is 1.636419
INFO:root:FL Epoch: 204 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :307
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 307 is 1.784894
INFO:root:FL Epoch: 204 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1460
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.198609
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224729
INFO:root:FL Epoch: 204 Norm Difference for worker 1460 is 1.517739
INFO:root:FL Epoch: 204 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1890
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592117
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266250
INFO:root:FL Epoch: 204 Norm Difference for worker 1890 is 1.624524
INFO:root:FL Epoch: 204 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :179
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.718187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 179 is 1.705575
INFO:root:FL Epoch: 204 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [1460, 179, 1743, 1572, 796, 893, 1890]
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.46108754066859975 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.3777499472101529                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1646
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794236
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574979
INFO:root:FL Epoch: 205 Norm Difference for worker 1646 is 1.749363
INFO:root:FL Epoch: 205 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299033
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 1.817121
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :498
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229857
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236451
INFO:root:FL Epoch: 205 Norm Difference for worker 498 is 1.720564
INFO:root:FL Epoch: 205 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :132
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437672
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 132 is 1.634499
INFO:root:FL Epoch: 205 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380516
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257330
INFO:root:FL Epoch: 205 Norm Difference for worker 1171 is 1.684818
INFO:root:FL Epoch: 205 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :587
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628331
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266313
INFO:root:FL Epoch: 205 Norm Difference for worker 587 is 1.753768
INFO:root:FL Epoch: 205 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1921
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507166
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281389
INFO:root:FL Epoch: 205 Norm Difference for worker 1921 is 1.702897
INFO:root:FL Epoch: 205 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1482
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241603
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331350
INFO:root:FL Epoch: 205 Norm Difference for worker 1482 is 1.663778
INFO:root:FL Epoch: 205 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :230
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 230 is 1.739718
INFO:root:FL Epoch: 205 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1399
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597268
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187045
INFO:root:FL Epoch: 205 Norm Difference for worker 1399 is 1.7256
INFO:root:FL Epoch: 205 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [3 9 7 4 2 6 8], which are global users: [132, 1399, 1482, 1171, 498, 1921, 230]
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.4607137985089246 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.38982368260622025                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 206 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :118
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.915298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 118 is 1.734648
INFO:root:FL Epoch: 206 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1272
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735661
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289072
INFO:root:FL Epoch: 206 Norm Difference for worker 1272 is 1.804705
INFO:root:FL Epoch: 206 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1114
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528142
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243123
INFO:root:FL Epoch: 206 Norm Difference for worker 1114 is 1.825793
INFO:root:FL Epoch: 206 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :236
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 236 is 1.905597
INFO:root:FL Epoch: 206 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508743
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308484
INFO:root:FL Epoch: 206 Norm Difference for worker 1838 is 1.722925
INFO:root:FL Epoch: 206 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1835
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720303
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186694
INFO:root:FL Epoch: 206 Norm Difference for worker 1835 is 1.66336
INFO:root:FL Epoch: 206 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :460
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383557
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293753
INFO:root:FL Epoch: 206 Norm Difference for worker 460 is 1.727473
INFO:root:FL Epoch: 206 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1482
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436194
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252945
INFO:root:FL Epoch: 206 Norm Difference for worker 1482 is 1.505839
INFO:root:FL Epoch: 206 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :289
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.204582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 289 is 1.615466
INFO:root:FL Epoch: 206 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :329
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 329 is 1.822756
INFO:root:FL Epoch: 206 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [6 4 8 7 1 5 0], which are global users: [460, 1838, 289, 1482, 1272, 1835, 118]
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.4742835339377908 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.4292026211818059                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1442
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613007
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348079
INFO:root:FL Epoch: 207 Norm Difference for worker 1442 is 1.637955
INFO:root:FL Epoch: 207 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1664
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805298
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212447
INFO:root:FL Epoch: 207 Norm Difference for worker 1664 is 1.500343
INFO:root:FL Epoch: 207 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :483
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688200
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366615
INFO:root:FL Epoch: 207 Norm Difference for worker 483 is 1.686708
INFO:root:FL Epoch: 207 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :754
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273432
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455146
INFO:root:FL Epoch: 207 Norm Difference for worker 754 is 1.687743
INFO:root:FL Epoch: 207 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :166
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209329
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 166 is 1.675523
INFO:root:FL Epoch: 207 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1570
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587783
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259245
INFO:root:FL Epoch: 207 Norm Difference for worker 1570 is 1.730434
INFO:root:FL Epoch: 207 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :541
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758449
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365495
INFO:root:FL Epoch: 207 Norm Difference for worker 541 is 1.723242
INFO:root:FL Epoch: 207 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1604
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572659
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282082
INFO:root:FL Epoch: 207 Norm Difference for worker 1604 is 1.758868
INFO:root:FL Epoch: 207 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :800
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487705
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282435
INFO:root:FL Epoch: 207 Norm Difference for worker 800 is 1.679572
INFO:root:FL Epoch: 207 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :277
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 277 is 1.617164
INFO:root:FL Epoch: 207 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [1 0 9 2 4 3 5], which are global users: [1664, 1442, 277, 483, 166, 754, 1570]
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.4702661230283625 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.38090939571460086                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1406
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283307
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243295
INFO:root:FL Epoch: 208 Norm Difference for worker 1406 is 1.825512
INFO:root:FL Epoch: 208 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :774
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496572
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363107
INFO:root:FL Epoch: 208 Norm Difference for worker 774 is 1.644844
INFO:root:FL Epoch: 208 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :854
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531257
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226428
INFO:root:FL Epoch: 208 Norm Difference for worker 854 is 1.556367
INFO:root:FL Epoch: 208 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1449
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765824
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393886
INFO:root:FL Epoch: 208 Norm Difference for worker 1449 is 1.818932
INFO:root:FL Epoch: 208 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :741
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378684
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416157
INFO:root:FL Epoch: 208 Norm Difference for worker 741 is 1.689801
INFO:root:FL Epoch: 208 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :740
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590587
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233292
INFO:root:FL Epoch: 208 Norm Difference for worker 740 is 1.660128
INFO:root:FL Epoch: 208 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1869
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702881
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157015
INFO:root:FL Epoch: 208 Norm Difference for worker 1869 is 1.564991
INFO:root:FL Epoch: 208 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1080
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607549
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432025
INFO:root:FL Epoch: 208 Norm Difference for worker 1080 is 1.811621
INFO:root:FL Epoch: 208 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1637
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384424
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495376
INFO:root:FL Epoch: 208 Norm Difference for worker 1637 is 1.788332
INFO:root:FL Epoch: 208 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1546
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254996
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520855
INFO:root:FL Epoch: 208 Norm Difference for worker 1546 is 1.62834
INFO:root:FL Epoch: 208 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 6 1 4 8], which are global users: [740, 1546, 854, 1869, 774, 741, 1637]
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.48042992633931775 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.3533889626463254                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1904
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474847
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274112
INFO:root:FL Epoch: 209 Norm Difference for worker 1904 is 1.763474
INFO:root:FL Epoch: 209 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1753
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654448
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302935
INFO:root:FL Epoch: 209 Norm Difference for worker 1753 is 1.644277
INFO:root:FL Epoch: 209 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1821
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620338
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351595
INFO:root:FL Epoch: 209 Norm Difference for worker 1821 is 1.668023
INFO:root:FL Epoch: 209 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1207
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571237
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330246
INFO:root:FL Epoch: 209 Norm Difference for worker 1207 is 1.656716
INFO:root:FL Epoch: 209 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :9
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 9 is 1.727605
INFO:root:FL Epoch: 209 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1378
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465534
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294208
INFO:root:FL Epoch: 209 Norm Difference for worker 1378 is 1.731918
INFO:root:FL Epoch: 209 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :211
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.718027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 211 is 1.739589
INFO:root:FL Epoch: 209 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :883
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370998
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243110
INFO:root:FL Epoch: 209 Norm Difference for worker 883 is 1.710552
INFO:root:FL Epoch: 209 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :876
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412594
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399890
INFO:root:FL Epoch: 209 Norm Difference for worker 876 is 1.770784
INFO:root:FL Epoch: 209 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :812
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846787
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341069
INFO:root:FL Epoch: 209 Norm Difference for worker 812 is 1.681285
INFO:root:FL Epoch: 209 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [1 9 2 3 4 6 7], which are global users: [1753, 812, 1821, 1207, 9, 211, 883]
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.4796944470966564 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.36636557181676227                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :321
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 321 is 1.701599
INFO:root:FL Epoch: 210 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :758
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715694
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273178
INFO:root:FL Epoch: 210 Norm Difference for worker 758 is 1.555544
INFO:root:FL Epoch: 210 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :550
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493455
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261532
INFO:root:FL Epoch: 210 Norm Difference for worker 550 is 1.571333
INFO:root:FL Epoch: 210 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1387
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507269
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171529
INFO:root:FL Epoch: 210 Norm Difference for worker 1387 is 1.568029
INFO:root:FL Epoch: 210 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1806
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476480
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352904
INFO:root:FL Epoch: 210 Norm Difference for worker 1806 is 1.517778
INFO:root:FL Epoch: 210 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587587
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318694
INFO:root:FL Epoch: 210 Norm Difference for worker 760 is 1.631141
INFO:root:FL Epoch: 210 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :316
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.258730
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 316 is 1.541677
INFO:root:FL Epoch: 210 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1694
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.938134
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410771
INFO:root:FL Epoch: 210 Norm Difference for worker 1694 is 1.674094
INFO:root:FL Epoch: 210 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :937
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373037
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305940
INFO:root:FL Epoch: 210 Norm Difference for worker 937 is 1.573322
INFO:root:FL Epoch: 210 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1178
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538183
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402421
INFO:root:FL Epoch: 210 Norm Difference for worker 1178 is 1.573078
INFO:root:FL Epoch: 210 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 8 9 1], which are global users: [316, 1806, 550, 1387, 937, 1178, 758]
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.44606946671710296 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.33069466551144916                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358217
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151412
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.15885349735617638 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.1742802195250988 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.323449
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333714
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399126
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.154790119578441 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.17472452148795128 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.319497
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383188
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374023
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.14288421471913657 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.17050082385540008 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.343475
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1428
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351538
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201370
INFO:root:FL Epoch: 211 Norm Difference for worker 1428 is 1.626641
INFO:root:FL Epoch: 211 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :391
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589849
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466124
INFO:root:FL Epoch: 211 Norm Difference for worker 391 is 1.761575
INFO:root:FL Epoch: 211 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1560
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540289
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192299
INFO:root:FL Epoch: 211 Norm Difference for worker 1560 is 1.444275
INFO:root:FL Epoch: 211 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1489
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436591
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443705
INFO:root:FL Epoch: 211 Norm Difference for worker 1489 is 1.754354
INFO:root:FL Epoch: 211 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :106
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 106 is 1.520527
INFO:root:FL Epoch: 211 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :729
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540169
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284964
INFO:root:FL Epoch: 211 Norm Difference for worker 729 is 1.587019
INFO:root:FL Epoch: 211 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1080
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.899116
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345083
INFO:root:FL Epoch: 211 Norm Difference for worker 1080 is 1.669794
INFO:root:FL Epoch: 211 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 8], which are global users: [106, 0, 2, 1428, 1, 1560, 729]
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.4389097743174609 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.22233087693651518                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :850
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562273
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185222
INFO:root:FL Epoch: 212 Norm Difference for worker 850 is 1.661461
INFO:root:FL Epoch: 212 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1190
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455187
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398822
INFO:root:FL Epoch: 212 Norm Difference for worker 1190 is 1.628921
INFO:root:FL Epoch: 212 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :991
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378946
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200609
INFO:root:FL Epoch: 212 Norm Difference for worker 991 is 1.731934
INFO:root:FL Epoch: 212 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :137
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 137 is 1.779411
INFO:root:FL Epoch: 212 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1175
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395050
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208347
INFO:root:FL Epoch: 212 Norm Difference for worker 1175 is 1.651703
INFO:root:FL Epoch: 212 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1765
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578787
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348982
INFO:root:FL Epoch: 212 Norm Difference for worker 1765 is 1.543722
INFO:root:FL Epoch: 212 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1107
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466325
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281137
INFO:root:FL Epoch: 212 Norm Difference for worker 1107 is 1.581671
INFO:root:FL Epoch: 212 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :415
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519761
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361681
INFO:root:FL Epoch: 212 Norm Difference for worker 415 is 1.737461
INFO:root:FL Epoch: 212 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1168
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518595
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311921
INFO:root:FL Epoch: 212 Norm Difference for worker 1168 is 1.607423
INFO:root:FL Epoch: 212 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :123
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431486
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 123 is 1.780819
INFO:root:FL Epoch: 212 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 6 1 4 2], which are global users: [1765, 850, 1168, 1107, 1190, 1175, 991]
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.4520718464080025 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.19331385071078935                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1125
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436523
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310781
INFO:root:FL Epoch: 213 Norm Difference for worker 1125 is 1.787651
INFO:root:FL Epoch: 213 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :873
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586321
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313331
INFO:root:FL Epoch: 213 Norm Difference for worker 873 is 1.820724
INFO:root:FL Epoch: 213 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1501
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310659
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349900
INFO:root:FL Epoch: 213 Norm Difference for worker 1501 is 1.922803
INFO:root:FL Epoch: 213 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1370
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645446
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232436
INFO:root:FL Epoch: 213 Norm Difference for worker 1370 is 1.737443
INFO:root:FL Epoch: 213 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1513
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662362
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328111
INFO:root:FL Epoch: 213 Norm Difference for worker 1513 is 1.758324
INFO:root:FL Epoch: 213 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :744
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832660
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151130
INFO:root:FL Epoch: 213 Norm Difference for worker 744 is 1.690462
INFO:root:FL Epoch: 213 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :533
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632541
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491593
INFO:root:FL Epoch: 213 Norm Difference for worker 533 is 2.052472
INFO:root:FL Epoch: 213 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1237
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431059
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215970
INFO:root:FL Epoch: 213 Norm Difference for worker 1237 is 1.761867
INFO:root:FL Epoch: 213 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1929
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402520
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137977
INFO:root:FL Epoch: 213 Norm Difference for worker 1929 is 1.575011
INFO:root:FL Epoch: 213 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1117
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333904
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325551
INFO:root:FL Epoch: 213 Norm Difference for worker 1117 is 1.652321
INFO:root:FL Epoch: 213 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 7 4 0], which are global users: [744, 1117, 1929, 1370, 1237, 1513, 1125]
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.454613794298733 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.22793032228946686                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1192
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626635
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172426
INFO:root:FL Epoch: 214 Norm Difference for worker 1192 is 1.73933
INFO:root:FL Epoch: 214 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1056
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594301
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277795
INFO:root:FL Epoch: 214 Norm Difference for worker 1056 is 1.705214
INFO:root:FL Epoch: 214 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :257
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.330955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 257 is 1.728262
INFO:root:FL Epoch: 214 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :852
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619357
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257151
INFO:root:FL Epoch: 214 Norm Difference for worker 852 is 1.724852
INFO:root:FL Epoch: 214 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1024
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442022
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462075
INFO:root:FL Epoch: 214 Norm Difference for worker 1024 is 1.784937
INFO:root:FL Epoch: 214 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1453
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494028
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162891
INFO:root:FL Epoch: 214 Norm Difference for worker 1453 is 1.662173
INFO:root:FL Epoch: 214 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1392
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681818
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363411
INFO:root:FL Epoch: 214 Norm Difference for worker 1392 is 1.661637
INFO:root:FL Epoch: 214 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1700
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379649
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267588
INFO:root:FL Epoch: 214 Norm Difference for worker 1700 is 1.678627
INFO:root:FL Epoch: 214 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :203
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 203 is 1.859689
INFO:root:FL Epoch: 214 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :661
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844131
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324614
INFO:root:FL Epoch: 214 Norm Difference for worker 661 is 1.83839
INFO:root:FL Epoch: 214 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 6], which are global users: [1700, 1192, 257, 852, 1056, 1453, 1392]
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.44380521248368654 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.2995931829015414                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :408
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423417
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152610
INFO:root:FL Epoch: 215 Norm Difference for worker 408 is 1.585437
INFO:root:FL Epoch: 215 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1362
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484057
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247060
INFO:root:FL Epoch: 215 Norm Difference for worker 1362 is 1.757382
INFO:root:FL Epoch: 215 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :158
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 158 is 1.791497
INFO:root:FL Epoch: 215 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :368
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696813
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310179
INFO:root:FL Epoch: 215 Norm Difference for worker 368 is 1.738277
INFO:root:FL Epoch: 215 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :468
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792299
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288947
INFO:root:FL Epoch: 215 Norm Difference for worker 468 is 1.696371
INFO:root:FL Epoch: 215 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1463
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739100
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378701
INFO:root:FL Epoch: 215 Norm Difference for worker 1463 is 1.947089
INFO:root:FL Epoch: 215 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :341
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381228
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341170
INFO:root:FL Epoch: 215 Norm Difference for worker 341 is 1.922942
INFO:root:FL Epoch: 215 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1793
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775100
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450075
INFO:root:FL Epoch: 215 Norm Difference for worker 1793 is 1.788251
INFO:root:FL Epoch: 215 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :609
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802889
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219843
INFO:root:FL Epoch: 215 Norm Difference for worker 609 is 1.731213
INFO:root:FL Epoch: 215 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :594
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370637
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202214
INFO:root:FL Epoch: 215 Norm Difference for worker 594 is 1.781045
INFO:root:FL Epoch: 215 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [0 4 8 9 1 3 2], which are global users: [408, 468, 609, 594, 1362, 368, 158]
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.4633684806963977 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.28538741171360016                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1256
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325483
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279958
INFO:root:FL Epoch: 216 Norm Difference for worker 1256 is 1.607855
INFO:root:FL Epoch: 216 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1698
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317908
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277653
INFO:root:FL Epoch: 216 Norm Difference for worker 1698 is 1.669459
INFO:root:FL Epoch: 216 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :318
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.853387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 318 is 1.530465
INFO:root:FL Epoch: 216 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1075
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363428
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285367
INFO:root:FL Epoch: 216 Norm Difference for worker 1075 is 1.62221
INFO:root:FL Epoch: 216 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :427
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612754
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416155
INFO:root:FL Epoch: 216 Norm Difference for worker 427 is 1.630806
INFO:root:FL Epoch: 216 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :895
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338292
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177272
INFO:root:FL Epoch: 216 Norm Difference for worker 895 is 1.669227
INFO:root:FL Epoch: 216 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1686
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431390
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218927
INFO:root:FL Epoch: 216 Norm Difference for worker 1686 is 1.630955
INFO:root:FL Epoch: 216 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :939
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751803
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411814
INFO:root:FL Epoch: 216 Norm Difference for worker 939 is 1.765994
INFO:root:FL Epoch: 216 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1008
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535123
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507764
INFO:root:FL Epoch: 216 Norm Difference for worker 1008 is 1.818477
INFO:root:FL Epoch: 216 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1785
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513792
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312278
INFO:root:FL Epoch: 216 Norm Difference for worker 1785 is 1.666442
INFO:root:FL Epoch: 216 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 9 4 5], which are global users: [1686, 1256, 318, 1075, 1785, 427, 895]
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.4433329596238978 and Test Accuracy:82.05882352941177 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.3375730613867442                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :795
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458784
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241441
INFO:root:FL Epoch: 217 Norm Difference for worker 795 is 1.656427
INFO:root:FL Epoch: 217 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1488
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474830
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267817
INFO:root:FL Epoch: 217 Norm Difference for worker 1488 is 1.695693
INFO:root:FL Epoch: 217 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :830
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709494
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489594
INFO:root:FL Epoch: 217 Norm Difference for worker 830 is 1.615175
INFO:root:FL Epoch: 217 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1412
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657319
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191611
INFO:root:FL Epoch: 217 Norm Difference for worker 1412 is 1.78897
INFO:root:FL Epoch: 217 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1025
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307128
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204429
INFO:root:FL Epoch: 217 Norm Difference for worker 1025 is 1.721575
INFO:root:FL Epoch: 217 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422601
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173052
INFO:root:FL Epoch: 217 Norm Difference for worker 1652 is 1.735258
INFO:root:FL Epoch: 217 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :631
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590346
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192435
INFO:root:FL Epoch: 217 Norm Difference for worker 631 is 1.692821
INFO:root:FL Epoch: 217 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1898
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417937
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373394
INFO:root:FL Epoch: 217 Norm Difference for worker 1898 is 1.723131
INFO:root:FL Epoch: 217 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :872
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252460
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323571
INFO:root:FL Epoch: 217 Norm Difference for worker 872 is 1.603622
INFO:root:FL Epoch: 217 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :698
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398558
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377517
INFO:root:FL Epoch: 217 Norm Difference for worker 698 is 1.793494
INFO:root:FL Epoch: 217 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [1898, 795, 830, 872, 1488, 1652, 631]
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.4629031454815584 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.3912448485692342                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1823
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580420
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179874
INFO:root:FL Epoch: 218 Norm Difference for worker 1823 is 1.640498
INFO:root:FL Epoch: 218 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :16
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.718814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 16 is 1.662238
INFO:root:FL Epoch: 218 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1683
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476988
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408340
INFO:root:FL Epoch: 218 Norm Difference for worker 1683 is 1.758742
INFO:root:FL Epoch: 218 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1802
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419805
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420579
INFO:root:FL Epoch: 218 Norm Difference for worker 1802 is 1.60078
INFO:root:FL Epoch: 218 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :663
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647945
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208562
INFO:root:FL Epoch: 218 Norm Difference for worker 663 is 1.529145
INFO:root:FL Epoch: 218 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1406
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507192
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305580
INFO:root:FL Epoch: 218 Norm Difference for worker 1406 is 1.704684
INFO:root:FL Epoch: 218 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1358
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249132
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197342
INFO:root:FL Epoch: 218 Norm Difference for worker 1358 is 1.580477
INFO:root:FL Epoch: 218 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :240
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642834
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 240 is 1.762422
INFO:root:FL Epoch: 218 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :101
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 101 is 1.65573
INFO:root:FL Epoch: 218 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1363
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708180
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384402
INFO:root:FL Epoch: 218 Norm Difference for worker 1363 is 1.801424
INFO:root:FL Epoch: 218 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 201 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [3 4 6 0 8 1 5], which are global users: [1802, 663, 1358, 1823, 101, 16, 1406]
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.4469845663098728 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.3859812716643016                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 219 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :185
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229644
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 185 is 1.530378
INFO:root:FL Epoch: 219 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1693
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573530
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367030
INFO:root:FL Epoch: 219 Norm Difference for worker 1693 is 1.591607
INFO:root:FL Epoch: 219 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :737
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493254
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323329
INFO:root:FL Epoch: 219 Norm Difference for worker 737 is 1.683368
INFO:root:FL Epoch: 219 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1553
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423797
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179618
INFO:root:FL Epoch: 219 Norm Difference for worker 1553 is 1.67686
INFO:root:FL Epoch: 219 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :560
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427516
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383387
INFO:root:FL Epoch: 219 Norm Difference for worker 560 is 1.583331
INFO:root:FL Epoch: 219 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1190
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246308
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155181
INFO:root:FL Epoch: 219 Norm Difference for worker 1190 is 1.472422
INFO:root:FL Epoch: 219 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :926
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461773
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203845
INFO:root:FL Epoch: 219 Norm Difference for worker 926 is 1.44304
INFO:root:FL Epoch: 219 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :912
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487654
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515625
INFO:root:FL Epoch: 219 Norm Difference for worker 912 is 1.644129
INFO:root:FL Epoch: 219 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497123
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364794
INFO:root:FL Epoch: 219 Norm Difference for worker 1477 is 1.62791
INFO:root:FL Epoch: 219 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :173
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 173 is 1.666784
INFO:root:FL Epoch: 219 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 6 5 4 7 8], which are global users: [1693, 185, 926, 1190, 560, 912, 1477]
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.4556689052020802 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.3137878080209096                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1326
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636182
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624679
INFO:root:FL Epoch: 220 Norm Difference for worker 1326 is 1.707454
INFO:root:FL Epoch: 220 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :919
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443360
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350891
INFO:root:FL Epoch: 220 Norm Difference for worker 919 is 1.765987
INFO:root:FL Epoch: 220 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1829
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 1.042686
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323416
INFO:root:FL Epoch: 220 Norm Difference for worker 1829 is 1.688244
INFO:root:FL Epoch: 220 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1536
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.976667
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242566
INFO:root:FL Epoch: 220 Norm Difference for worker 1536 is 1.683766
INFO:root:FL Epoch: 220 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1533
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604840
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280563
INFO:root:FL Epoch: 220 Norm Difference for worker 1533 is 1.714897
INFO:root:FL Epoch: 220 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1562
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371690
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233973
INFO:root:FL Epoch: 220 Norm Difference for worker 1562 is 1.629103
INFO:root:FL Epoch: 220 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :524
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480113
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427241
INFO:root:FL Epoch: 220 Norm Difference for worker 524 is 1.548816
INFO:root:FL Epoch: 220 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :652
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537770
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251084
INFO:root:FL Epoch: 220 Norm Difference for worker 652 is 1.596154
INFO:root:FL Epoch: 220 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1778
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634764
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333733
INFO:root:FL Epoch: 220 Norm Difference for worker 1778 is 1.692601
INFO:root:FL Epoch: 220 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :59
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.330657
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225491
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 59 is 1.689849
INFO:root:FL Epoch: 220 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 7 6 0 4 2], which are global users: [1562, 59, 652, 524, 1326, 1533, 1829]
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.4652369110023274 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.26668184250593185                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279729
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220025
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.15159522742033005 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.17323214784264565 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.321041
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375801
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168236
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.12797199934720993 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.17247679829597473 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.322763
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213441
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154715
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.14437332252661386 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.17837653830647468 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.308233
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :316
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 316 is 1.610546
INFO:root:FL Epoch: 221 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1143
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474104
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297736
INFO:root:FL Epoch: 221 Norm Difference for worker 1143 is 1.662209
INFO:root:FL Epoch: 221 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :39
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647667
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 39 is 1.672868
INFO:root:FL Epoch: 221 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :451
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405419
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235118
INFO:root:FL Epoch: 221 Norm Difference for worker 451 is 1.712854
INFO:root:FL Epoch: 221 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1522
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574762
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287449
INFO:root:FL Epoch: 221 Norm Difference for worker 1522 is 1.56399
INFO:root:FL Epoch: 221 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1199
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511508
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510949
INFO:root:FL Epoch: 221 Norm Difference for worker 1199 is 1.606788
INFO:root:FL Epoch: 221 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1403
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566115
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219832
INFO:root:FL Epoch: 221 Norm Difference for worker 1403 is 1.732704
INFO:root:FL Epoch: 221 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 4], which are global users: [1522, 0, 2, 316, 1, 1199, 1143]
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.45475349005530863 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.21821659182508787                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1432
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358828
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218608
INFO:root:FL Epoch: 222 Norm Difference for worker 1432 is 1.606863
INFO:root:FL Epoch: 222 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1879
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508894
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283986
INFO:root:FL Epoch: 222 Norm Difference for worker 1879 is 1.701622
INFO:root:FL Epoch: 222 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1374
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576492
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293057
INFO:root:FL Epoch: 222 Norm Difference for worker 1374 is 1.635675
INFO:root:FL Epoch: 222 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :138
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 138 is 1.853576
INFO:root:FL Epoch: 222 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1818
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555531
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301277
INFO:root:FL Epoch: 222 Norm Difference for worker 1818 is 1.734336
INFO:root:FL Epoch: 222 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1897
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429955
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228941
INFO:root:FL Epoch: 222 Norm Difference for worker 1897 is 1.681592
INFO:root:FL Epoch: 222 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1713
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460395
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261810
INFO:root:FL Epoch: 222 Norm Difference for worker 1713 is 1.630391
INFO:root:FL Epoch: 222 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1190
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255725
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228989
INFO:root:FL Epoch: 222 Norm Difference for worker 1190 is 1.412862
INFO:root:FL Epoch: 222 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753982
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396194
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 1.829417
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1704
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641978
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549859
INFO:root:FL Epoch: 222 Norm Difference for worker 1704 is 1.756416
INFO:root:FL Epoch: 222 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 5 9], which are global users: [1713, 1432, 1374, 1190, 1879, 1897, 1704]
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.44618964195251465 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.2655413957933585                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 270 is 1.421845
INFO:root:FL Epoch: 223 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :754
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634204
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255579
INFO:root:FL Epoch: 223 Norm Difference for worker 754 is 1.729282
INFO:root:FL Epoch: 223 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :153
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 153 is 1.553008
INFO:root:FL Epoch: 223 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :729
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515020
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287111
INFO:root:FL Epoch: 223 Norm Difference for worker 729 is 1.558207
INFO:root:FL Epoch: 223 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471879
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223591
INFO:root:FL Epoch: 223 Norm Difference for worker 1270 is 1.482116
INFO:root:FL Epoch: 223 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :198
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 198 is 1.748111
INFO:root:FL Epoch: 223 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :422
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598542
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272960
INFO:root:FL Epoch: 223 Norm Difference for worker 422 is 1.674756
INFO:root:FL Epoch: 223 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :357
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400541
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230185
INFO:root:FL Epoch: 223 Norm Difference for worker 357 is 1.579661
INFO:root:FL Epoch: 223 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1197
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546547
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341411
INFO:root:FL Epoch: 223 Norm Difference for worker 1197 is 1.72622
INFO:root:FL Epoch: 223 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1215
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304605
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198885
INFO:root:FL Epoch: 223 Norm Difference for worker 1215 is 1.652446
INFO:root:FL Epoch: 223 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [0 4 3 2 7 9 6], which are global users: [270, 1270, 729, 153, 357, 1215, 422]
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.4430604962741627 and Test Accuracy:80.0 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.26514022548993427                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :1695
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545373
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342747
INFO:root:FL Epoch: 224 Norm Difference for worker 1695 is 1.778037
INFO:root:FL Epoch: 224 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753627
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573689
INFO:root:FL Epoch: 224 Norm Difference for worker 1865 is 1.86178
INFO:root:FL Epoch: 224 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1713
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341104
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199440
INFO:root:FL Epoch: 224 Norm Difference for worker 1713 is 1.490726
INFO:root:FL Epoch: 224 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :297
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.321585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.215405
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 297 is 1.616829
INFO:root:FL Epoch: 224 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1928
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302218
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291714
INFO:root:FL Epoch: 224 Norm Difference for worker 1928 is 1.697564
INFO:root:FL Epoch: 224 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1649
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760270
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258777
INFO:root:FL Epoch: 224 Norm Difference for worker 1649 is 1.744335
INFO:root:FL Epoch: 224 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :866
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601047
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464416
INFO:root:FL Epoch: 224 Norm Difference for worker 866 is 1.793242
INFO:root:FL Epoch: 224 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1522
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382427
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191320
INFO:root:FL Epoch: 224 Norm Difference for worker 1522 is 1.468094
INFO:root:FL Epoch: 224 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :950
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465186
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259908
INFO:root:FL Epoch: 224 Norm Difference for worker 950 is 1.628104
INFO:root:FL Epoch: 224 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1672
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333253
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216121
INFO:root:FL Epoch: 224 Norm Difference for worker 1672 is 1.616725
INFO:root:FL Epoch: 224 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 8 4 5], which are global users: [1522, 1672, 1713, 297, 950, 1928, 1649]
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.4500601484495051 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.24689139425754547                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :772
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741887
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445928
INFO:root:FL Epoch: 225 Norm Difference for worker 772 is 1.78366
INFO:root:FL Epoch: 225 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :146
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 146 is 1.82111
INFO:root:FL Epoch: 225 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :483
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304902
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136244
INFO:root:FL Epoch: 225 Norm Difference for worker 483 is 1.687495
INFO:root:FL Epoch: 225 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :630
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 1.013816
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465755
INFO:root:FL Epoch: 225 Norm Difference for worker 630 is 1.824174
INFO:root:FL Epoch: 225 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1459
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601888
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275072
INFO:root:FL Epoch: 225 Norm Difference for worker 1459 is 1.880895
INFO:root:FL Epoch: 225 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1607
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638152
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197375
INFO:root:FL Epoch: 225 Norm Difference for worker 1607 is 1.653727
INFO:root:FL Epoch: 225 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1636
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852287
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252598
INFO:root:FL Epoch: 225 Norm Difference for worker 1636 is 1.631102
INFO:root:FL Epoch: 225 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1906
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461714
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256065
INFO:root:FL Epoch: 225 Norm Difference for worker 1906 is 1.761284
INFO:root:FL Epoch: 225 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1540
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674628
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448209
INFO:root:FL Epoch: 225 Norm Difference for worker 1540 is 1.797424
INFO:root:FL Epoch: 225 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :320
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707552
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 320 is 1.660977
INFO:root:FL Epoch: 225 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 6 0 7 8], which are global users: [1607, 320, 483, 1636, 772, 1906, 1540]
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.44061170956667733 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.28638895601034164                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :607
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550847
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134877
INFO:root:FL Epoch: 226 Norm Difference for worker 607 is 1.756462
INFO:root:FL Epoch: 226 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1256
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377013
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217078
INFO:root:FL Epoch: 226 Norm Difference for worker 1256 is 1.617998
INFO:root:FL Epoch: 226 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :305
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 305 is 1.612087
INFO:root:FL Epoch: 226 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1249
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827515
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220951
INFO:root:FL Epoch: 226 Norm Difference for worker 1249 is 1.686849
INFO:root:FL Epoch: 226 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1338
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649244
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290558
INFO:root:FL Epoch: 226 Norm Difference for worker 1338 is 1.58003
INFO:root:FL Epoch: 226 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :942
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670870
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222959
INFO:root:FL Epoch: 226 Norm Difference for worker 942 is 1.64327
INFO:root:FL Epoch: 226 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1340
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726397
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338971
INFO:root:FL Epoch: 226 Norm Difference for worker 1340 is 1.741694
INFO:root:FL Epoch: 226 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :822
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512356
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368909
INFO:root:FL Epoch: 226 Norm Difference for worker 822 is 1.709663
INFO:root:FL Epoch: 226 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :41
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.268937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 41 is 1.631371
INFO:root:FL Epoch: 226 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1770
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459922
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250042
INFO:root:FL Epoch: 226 Norm Difference for worker 1770 is 1.577529
INFO:root:FL Epoch: 226 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [9 4 8 5 1 2 3], which are global users: [1770, 1338, 41, 942, 1256, 305, 1249]
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.446720070698682 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.2657462768256664                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 227 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :77
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.168087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 77 is 1.442024
INFO:root:FL Epoch: 227 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :907
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436908
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264512
INFO:root:FL Epoch: 227 Norm Difference for worker 907 is 1.731748
INFO:root:FL Epoch: 227 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :431
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535998
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245489
INFO:root:FL Epoch: 227 Norm Difference for worker 431 is 1.64774
INFO:root:FL Epoch: 227 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1546
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462866
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173441
INFO:root:FL Epoch: 227 Norm Difference for worker 1546 is 1.579607
INFO:root:FL Epoch: 227 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1892
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435374
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193276
INFO:root:FL Epoch: 227 Norm Difference for worker 1892 is 1.708724
INFO:root:FL Epoch: 227 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :70
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.187414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 70 is 1.567191
INFO:root:FL Epoch: 227 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1513
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576952
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354552
INFO:root:FL Epoch: 227 Norm Difference for worker 1513 is 1.596476
INFO:root:FL Epoch: 227 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :959
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272699
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247085
INFO:root:FL Epoch: 227 Norm Difference for worker 959 is 1.65892
INFO:root:FL Epoch: 227 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :274
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 274 is 1.654666
INFO:root:FL Epoch: 227 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :157
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 157 is 1.700168
INFO:root:FL Epoch: 227 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 201 201]
INFO:root:Num selected data points: [201 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 0 6 3 4 8 7], which are global users: [70, 77, 1513, 1546, 1892, 274, 959]
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.45075584159177895 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.2284612183769544                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :683
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510052
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383025
INFO:root:FL Epoch: 228 Norm Difference for worker 683 is 1.819678
INFO:root:FL Epoch: 228 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1670
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485916
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213192
INFO:root:FL Epoch: 228 Norm Difference for worker 1670 is 1.736354
INFO:root:FL Epoch: 228 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1846
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821425
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165425
INFO:root:FL Epoch: 228 Norm Difference for worker 1846 is 1.715665
INFO:root:FL Epoch: 228 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :949
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522127
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223237
INFO:root:FL Epoch: 228 Norm Difference for worker 949 is 1.829842
INFO:root:FL Epoch: 228 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1749
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658865
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248641
INFO:root:FL Epoch: 228 Norm Difference for worker 1749 is 1.697132
INFO:root:FL Epoch: 228 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1722
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391277
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167376
INFO:root:FL Epoch: 228 Norm Difference for worker 1722 is 1.636274
INFO:root:FL Epoch: 228 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :993
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618769
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171179
INFO:root:FL Epoch: 228 Norm Difference for worker 993 is 2.224454
INFO:root:FL Epoch: 228 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1085
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673980
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329711
INFO:root:FL Epoch: 228 Norm Difference for worker 1085 is 1.706786
INFO:root:FL Epoch: 228 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :948
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513975
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248089
INFO:root:FL Epoch: 228 Norm Difference for worker 948 is 1.796278
INFO:root:FL Epoch: 228 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1414
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357817
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378971
INFO:root:FL Epoch: 228 Norm Difference for worker 1414 is 1.693771
INFO:root:FL Epoch: 228 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 4 7 1 8], which are global users: [1722, 1414, 1846, 1749, 1085, 1670, 948]
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.4634566324598649 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.24028151606520018                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :958
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570410
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312712
INFO:root:FL Epoch: 229 Norm Difference for worker 958 is 1.776657
INFO:root:FL Epoch: 229 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :924
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424020
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316422
INFO:root:FL Epoch: 229 Norm Difference for worker 924 is 1.672709
INFO:root:FL Epoch: 229 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :923
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648782
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466989
INFO:root:FL Epoch: 229 Norm Difference for worker 923 is 1.75287
INFO:root:FL Epoch: 229 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :170
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.175633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 170 is 1.576993
INFO:root:FL Epoch: 229 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1886
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547060
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338671
INFO:root:FL Epoch: 229 Norm Difference for worker 1886 is 1.730688
INFO:root:FL Epoch: 229 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :71
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292930
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 71 is 1.582128
INFO:root:FL Epoch: 229 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :912
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586850
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283389
INFO:root:FL Epoch: 229 Norm Difference for worker 912 is 1.636229
INFO:root:FL Epoch: 229 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1134
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310223
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200033
INFO:root:FL Epoch: 229 Norm Difference for worker 1134 is 1.799598
INFO:root:FL Epoch: 229 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1808
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552608
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430516
INFO:root:FL Epoch: 229 Norm Difference for worker 1808 is 1.731313
INFO:root:FL Epoch: 229 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1870
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396193
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251615
INFO:root:FL Epoch: 229 Norm Difference for worker 1870 is 1.694852
INFO:root:FL Epoch: 229 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 201 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 5 9], which are global users: [912, 1886, 1808, 170, 924, 71, 1870]
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.47489253913655 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.29139333466688794                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :1469
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254024
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415612
INFO:root:FL Epoch: 230 Norm Difference for worker 1469 is 1.755513
INFO:root:FL Epoch: 230 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :582
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761349
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575765
INFO:root:FL Epoch: 230 Norm Difference for worker 582 is 1.696672
INFO:root:FL Epoch: 230 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :963
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374696
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386598
INFO:root:FL Epoch: 230 Norm Difference for worker 963 is 1.757973
INFO:root:FL Epoch: 230 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :936
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789953
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242087
INFO:root:FL Epoch: 230 Norm Difference for worker 936 is 1.657621
INFO:root:FL Epoch: 230 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1610
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625269
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353872
INFO:root:FL Epoch: 230 Norm Difference for worker 1610 is 1.70575
INFO:root:FL Epoch: 230 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1285
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290788
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230605
INFO:root:FL Epoch: 230 Norm Difference for worker 1285 is 1.526959
INFO:root:FL Epoch: 230 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :954
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479808
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427021
INFO:root:FL Epoch: 230 Norm Difference for worker 954 is 1.681244
INFO:root:FL Epoch: 230 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :660
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465550
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186387
INFO:root:FL Epoch: 230 Norm Difference for worker 660 is 1.621037
INFO:root:FL Epoch: 230 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :200
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 200 is 1.731721
INFO:root:FL Epoch: 230 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :238
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611093
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 238 is 1.786417
INFO:root:FL Epoch: 230 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 8 3 1 5 6], which are global users: [660, 1469, 200, 936, 582, 1285, 954]
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.4712051994660321 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.3003080189228058                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195128
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247666
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.11991313596566518 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.1575987681746483 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.330058
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.214164
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228439
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.11919704327980678 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.15850196927785873 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.309705
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306817
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340341
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.11444104711214702 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.16202791556715965 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.321539
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :182
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537720
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.193371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 182 is 1.635447
INFO:root:FL Epoch: 231 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :207
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729855
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 207 is 1.682854
INFO:root:FL Epoch: 231 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1332
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617251
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367914
INFO:root:FL Epoch: 231 Norm Difference for worker 1332 is 1.604973
INFO:root:FL Epoch: 231 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :956
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422689
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362818
INFO:root:FL Epoch: 231 Norm Difference for worker 956 is 1.7178
INFO:root:FL Epoch: 231 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512487
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415637
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 1.665017
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1364
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749273
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229149
INFO:root:FL Epoch: 231 Norm Difference for worker 1364 is 1.555227
INFO:root:FL Epoch: 231 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :648
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623581
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345458
INFO:root:FL Epoch: 231 Norm Difference for worker 648 is 1.674006
INFO:root:FL Epoch: 231 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [8 0 2 3 1 5 9], which are global users: [1364, 0, 2, 182, 1, 1332, 648]
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.4634692931876463 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.19695322215557098                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1755
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417374
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215475
INFO:root:FL Epoch: 232 Norm Difference for worker 1755 is 1.533074
INFO:root:FL Epoch: 232 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1533
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584316
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211224
INFO:root:FL Epoch: 232 Norm Difference for worker 1533 is 1.717736
INFO:root:FL Epoch: 232 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1003
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325922
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156533
INFO:root:FL Epoch: 232 Norm Difference for worker 1003 is 1.505854
INFO:root:FL Epoch: 232 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1514
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360088
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266822
INFO:root:FL Epoch: 232 Norm Difference for worker 1514 is 1.784321
INFO:root:FL Epoch: 232 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :482
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757116
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327496
INFO:root:FL Epoch: 232 Norm Difference for worker 482 is 1.607971
INFO:root:FL Epoch: 232 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :38
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615107
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.198247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 38 is 1.534742
INFO:root:FL Epoch: 232 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1305
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461714
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332433
INFO:root:FL Epoch: 232 Norm Difference for worker 1305 is 1.651713
INFO:root:FL Epoch: 232 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :806
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.911514
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630664
INFO:root:FL Epoch: 232 Norm Difference for worker 806 is 1.762562
INFO:root:FL Epoch: 232 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277349
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238129
INFO:root:FL Epoch: 232 Norm Difference for worker 1291 is 1.583925
INFO:root:FL Epoch: 232 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1342
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917714
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149264
INFO:root:FL Epoch: 232 Norm Difference for worker 1342 is 1.587384
INFO:root:FL Epoch: 232 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 9 8 4 6], which are global users: [38, 1755, 1003, 1342, 1291, 482, 1305]
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.4552396833896637 and Test Accuracy:80.0 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.19385443752010664                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1736
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739800
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304024
INFO:root:FL Epoch: 233 Norm Difference for worker 1736 is 1.923088
INFO:root:FL Epoch: 233 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1347
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349965
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244685
INFO:root:FL Epoch: 233 Norm Difference for worker 1347 is 1.980528
INFO:root:FL Epoch: 233 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :965
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496344
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174315
INFO:root:FL Epoch: 233 Norm Difference for worker 965 is 1.644761
INFO:root:FL Epoch: 233 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1370
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652623
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273375
INFO:root:FL Epoch: 233 Norm Difference for worker 1370 is 1.623225
INFO:root:FL Epoch: 233 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :121
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435909
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 121 is 1.753432
INFO:root:FL Epoch: 233 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1393
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370641
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344692
INFO:root:FL Epoch: 233 Norm Difference for worker 1393 is 1.848329
INFO:root:FL Epoch: 233 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :456
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498017
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396481
INFO:root:FL Epoch: 233 Norm Difference for worker 456 is 1.676686
INFO:root:FL Epoch: 233 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1814
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471847
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229255
INFO:root:FL Epoch: 233 Norm Difference for worker 1814 is 1.696961
INFO:root:FL Epoch: 233 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1922
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329522
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470231
INFO:root:FL Epoch: 233 Norm Difference for worker 1922 is 1.631132
INFO:root:FL Epoch: 233 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :825
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383086
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191381
INFO:root:FL Epoch: 233 Norm Difference for worker 825 is 1.491402
INFO:root:FL Epoch: 233 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 9 2 3 8 7 4], which are global users: [456, 825, 965, 1370, 1922, 1814, 121]
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.45975115194040184 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.1930665336549282                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1426
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643449
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318556
INFO:root:FL Epoch: 234 Norm Difference for worker 1426 is 1.795202
INFO:root:FL Epoch: 234 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1515
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495483
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638121
INFO:root:FL Epoch: 234 Norm Difference for worker 1515 is 1.668605
INFO:root:FL Epoch: 234 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1029
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496428
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420991
INFO:root:FL Epoch: 234 Norm Difference for worker 1029 is 1.675279
INFO:root:FL Epoch: 234 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1283
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449879
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303186
INFO:root:FL Epoch: 234 Norm Difference for worker 1283 is 1.701082
INFO:root:FL Epoch: 234 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :292
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.283410
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.131852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 292 is 1.752907
INFO:root:FL Epoch: 234 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :988
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579857
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358862
INFO:root:FL Epoch: 234 Norm Difference for worker 988 is 1.63384
INFO:root:FL Epoch: 234 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :434
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577504
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258730
INFO:root:FL Epoch: 234 Norm Difference for worker 434 is 1.622871
INFO:root:FL Epoch: 234 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1197
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647878
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241347
INFO:root:FL Epoch: 234 Norm Difference for worker 1197 is 1.744983
INFO:root:FL Epoch: 234 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1772
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719612
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242100
INFO:root:FL Epoch: 234 Norm Difference for worker 1772 is 1.860069
INFO:root:FL Epoch: 234 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1338
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743363
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156218
INFO:root:FL Epoch: 234 Norm Difference for worker 1338 is 1.536487
INFO:root:FL Epoch: 234 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 9 2 3 1 5 4], which are global users: [434, 1338, 1029, 1283, 1515, 988, 292]
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.45957397012149587 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.21726017072796822                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :522
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573939
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293794
INFO:root:FL Epoch: 235 Norm Difference for worker 522 is 1.549825
INFO:root:FL Epoch: 235 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1084
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447292
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355885
INFO:root:FL Epoch: 235 Norm Difference for worker 1084 is 1.737834
INFO:root:FL Epoch: 235 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396805
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220409
INFO:root:FL Epoch: 235 Norm Difference for worker 794 is 1.695961
INFO:root:FL Epoch: 235 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1467
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414668
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334549
INFO:root:FL Epoch: 235 Norm Difference for worker 1467 is 1.652516
INFO:root:FL Epoch: 235 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354286
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375588
INFO:root:FL Epoch: 235 Norm Difference for worker 1794 is 1.741216
INFO:root:FL Epoch: 235 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1935
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363445
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397401
INFO:root:FL Epoch: 235 Norm Difference for worker 1935 is 1.716663
INFO:root:FL Epoch: 235 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521771
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227881
INFO:root:FL Epoch: 235 Norm Difference for worker 1180 is 1.640162
INFO:root:FL Epoch: 235 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1316
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605434
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302740
INFO:root:FL Epoch: 235 Norm Difference for worker 1316 is 1.629817
INFO:root:FL Epoch: 235 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1029
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262724
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305005
INFO:root:FL Epoch: 235 Norm Difference for worker 1029 is 1.510799
INFO:root:FL Epoch: 235 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1087
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.240067
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460088
INFO:root:FL Epoch: 235 Norm Difference for worker 1087 is 1.668446
INFO:root:FL Epoch: 235 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 7 9 2 3], which are global users: [1180, 522, 1029, 1316, 1087, 794, 1467]
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.47652514015927033 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.32830070704221725                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1500
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791281
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593167
INFO:root:FL Epoch: 236 Norm Difference for worker 1500 is 1.803176
INFO:root:FL Epoch: 236 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1518
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356067
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426413
INFO:root:FL Epoch: 236 Norm Difference for worker 1518 is 1.705876
INFO:root:FL Epoch: 236 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623563
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228144
INFO:root:FL Epoch: 236 Norm Difference for worker 1356 is 1.869727
INFO:root:FL Epoch: 236 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1009
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547964
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282994
INFO:root:FL Epoch: 236 Norm Difference for worker 1009 is 1.71407
INFO:root:FL Epoch: 236 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :923
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361554
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320514
INFO:root:FL Epoch: 236 Norm Difference for worker 923 is 1.698328
INFO:root:FL Epoch: 236 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1137
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604211
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372841
INFO:root:FL Epoch: 236 Norm Difference for worker 1137 is 1.842564
INFO:root:FL Epoch: 236 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1947
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495567
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372921
INFO:root:FL Epoch: 236 Norm Difference for worker 1947 is 1.586911
INFO:root:FL Epoch: 236 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488692
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375258
INFO:root:FL Epoch: 236 Norm Difference for worker 1178 is 1.582844
INFO:root:FL Epoch: 236 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :44
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 44 is 1.702572
INFO:root:FL Epoch: 236 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :161
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.315143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 161 is 1.599314
INFO:root:FL Epoch: 236 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 7 1 4 3], which are global users: [1947, 161, 44, 1178, 1518, 923, 1009]
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.4633161267813514 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.32480161388715106                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :312
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.922921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 312 is 1.593242
INFO:root:FL Epoch: 237 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1612
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544796
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287640
INFO:root:FL Epoch: 237 Norm Difference for worker 1612 is 1.685264
INFO:root:FL Epoch: 237 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1685
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681096
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365062
INFO:root:FL Epoch: 237 Norm Difference for worker 1685 is 1.656175
INFO:root:FL Epoch: 237 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :582
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756748
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327524
INFO:root:FL Epoch: 237 Norm Difference for worker 582 is 1.671335
INFO:root:FL Epoch: 237 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :797
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 1.032390
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315786
INFO:root:FL Epoch: 237 Norm Difference for worker 797 is 1.766842
INFO:root:FL Epoch: 237 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :600
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561443
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433399
INFO:root:FL Epoch: 237 Norm Difference for worker 600 is 1.868613
INFO:root:FL Epoch: 237 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :237
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378657
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 237 is 1.659053
INFO:root:FL Epoch: 237 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1308
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605497
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202731
INFO:root:FL Epoch: 237 Norm Difference for worker 1308 is 1.670463
INFO:root:FL Epoch: 237 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :534
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674351
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234173
INFO:root:FL Epoch: 237 Norm Difference for worker 534 is 1.655392
INFO:root:FL Epoch: 237 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :844
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.199787
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229076
INFO:root:FL Epoch: 237 Norm Difference for worker 844 is 1.434599
INFO:root:FL Epoch: 237 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [9 0 7 8 6 2 1], which are global users: [844, 312, 1308, 534, 237, 1685, 1612]
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.4719807417953716 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.30199318875869113                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :58
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.866606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.296751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 58 is 1.714922
INFO:root:FL Epoch: 238 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :859
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454007
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308331
INFO:root:FL Epoch: 238 Norm Difference for worker 859 is 1.643124
INFO:root:FL Epoch: 238 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :433
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251260
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239298
INFO:root:FL Epoch: 238 Norm Difference for worker 433 is 1.444289
INFO:root:FL Epoch: 238 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1026
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585084
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303972
INFO:root:FL Epoch: 238 Norm Difference for worker 1026 is 1.738521
INFO:root:FL Epoch: 238 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :994
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779177
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434163
INFO:root:FL Epoch: 238 Norm Difference for worker 994 is 1.635292
INFO:root:FL Epoch: 238 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1506
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308014
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247966
INFO:root:FL Epoch: 238 Norm Difference for worker 1506 is 1.528059
INFO:root:FL Epoch: 238 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :858
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395522
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329592
INFO:root:FL Epoch: 238 Norm Difference for worker 858 is 1.605774
INFO:root:FL Epoch: 238 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :763
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834197
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352952
INFO:root:FL Epoch: 238 Norm Difference for worker 763 is 1.662922
INFO:root:FL Epoch: 238 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1007
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548685
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309045
INFO:root:FL Epoch: 238 Norm Difference for worker 1007 is 1.552092
INFO:root:FL Epoch: 238 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :921
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533947
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398949
INFO:root:FL Epoch: 238 Norm Difference for worker 921 is 1.793745
INFO:root:FL Epoch: 238 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 8 1 5 6], which are global users: [763, 994, 433, 1007, 859, 1506, 858]
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.47749069858999815 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.317679521938165                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1052
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587167
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311093
INFO:root:FL Epoch: 239 Norm Difference for worker 1052 is 1.499302
INFO:root:FL Epoch: 239 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :845
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440255
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174423
INFO:root:FL Epoch: 239 Norm Difference for worker 845 is 1.591663
INFO:root:FL Epoch: 239 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :221
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 221 is 1.589511
INFO:root:FL Epoch: 239 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :456
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374138
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205208
INFO:root:FL Epoch: 239 Norm Difference for worker 456 is 1.506483
INFO:root:FL Epoch: 239 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :255
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410518
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 255 is 1.586588
INFO:root:FL Epoch: 239 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :587
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586730
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209422
INFO:root:FL Epoch: 239 Norm Difference for worker 587 is 1.603487
INFO:root:FL Epoch: 239 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :86
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 86 is 1.553603
INFO:root:FL Epoch: 239 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1398
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410340
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280569
INFO:root:FL Epoch: 239 Norm Difference for worker 1398 is 1.543887
INFO:root:FL Epoch: 239 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :451
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566975
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203526
INFO:root:FL Epoch: 239 Norm Difference for worker 451 is 1.583423
INFO:root:FL Epoch: 239 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1030
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629074
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370219
INFO:root:FL Epoch: 239 Norm Difference for worker 1030 is 1.705039
INFO:root:FL Epoch: 239 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [0 3 6 8 2 7 5], which are global users: [1052, 456, 86, 451, 221, 1398, 587]
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.4482781781869776 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.33027690400679904                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1503
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527166
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298017
INFO:root:FL Epoch: 240 Norm Difference for worker 1503 is 1.707396
INFO:root:FL Epoch: 240 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461434
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285779
INFO:root:FL Epoch: 240 Norm Difference for worker 627 is 1.635504
INFO:root:FL Epoch: 240 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1705
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267477
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300137
INFO:root:FL Epoch: 240 Norm Difference for worker 1705 is 1.6621
INFO:root:FL Epoch: 240 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1702
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691233
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320245
INFO:root:FL Epoch: 240 Norm Difference for worker 1702 is 1.687353
INFO:root:FL Epoch: 240 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1356
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482258
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379570
INFO:root:FL Epoch: 240 Norm Difference for worker 1356 is 1.814707
INFO:root:FL Epoch: 240 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :22
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 22 is 1.680808
INFO:root:FL Epoch: 240 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1709
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539507
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233208
INFO:root:FL Epoch: 240 Norm Difference for worker 1709 is 1.655687
INFO:root:FL Epoch: 240 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :31
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 31 is 1.651383
INFO:root:FL Epoch: 240 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :42
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339567
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 42 is 1.548754
INFO:root:FL Epoch: 240 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :358
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499132
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194563
INFO:root:FL Epoch: 240 Norm Difference for worker 358 is 1.589893
INFO:root:FL Epoch: 240 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 201 200]
INFO:root:Num selected data points: [201 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [7 9 8 3 1 5 0], which are global users: [31, 358, 42, 1702, 627, 22, 1503]
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.4586247328449698 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.3454614231983821                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265700
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362087
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.13706962143381438 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.16237953603267669 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.317376
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281563
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146200
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.15781144797801971 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.16281095817685126 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.306586
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340753
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307718
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.1592265566190084 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.16053733602166176 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.313216
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1593
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485745
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228594
INFO:root:FL Epoch: 241 Norm Difference for worker 1593 is 1.478922
INFO:root:FL Epoch: 241 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1631
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354161
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152953
INFO:root:FL Epoch: 241 Norm Difference for worker 1631 is 1.513029
INFO:root:FL Epoch: 241 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1647
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768847
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365370
INFO:root:FL Epoch: 241 Norm Difference for worker 1647 is 1.688071
INFO:root:FL Epoch: 241 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1726
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472277
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243983
INFO:root:FL Epoch: 241 Norm Difference for worker 1726 is 1.635178
INFO:root:FL Epoch: 241 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1002
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774029
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301159
INFO:root:FL Epoch: 241 Norm Difference for worker 1002 is 1.518865
INFO:root:FL Epoch: 241 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1907
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470664
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304732
INFO:root:FL Epoch: 241 Norm Difference for worker 1907 is 1.622152
INFO:root:FL Epoch: 241 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :518
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838829
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367234
INFO:root:FL Epoch: 241 Norm Difference for worker 518 is 1.629872
INFO:root:FL Epoch: 241 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 3 4 8 7], which are global users: [1, 0, 2, 1593, 1631, 1907, 1002]
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.4497203423696406 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.22967385376493135                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1813
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532167
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192106
INFO:root:FL Epoch: 242 Norm Difference for worker 1813 is 1.558574
INFO:root:FL Epoch: 242 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1657
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372946
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276895
INFO:root:FL Epoch: 242 Norm Difference for worker 1657 is 1.697159
INFO:root:FL Epoch: 242 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1921
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533549
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509647
INFO:root:FL Epoch: 242 Norm Difference for worker 1921 is 1.649309
INFO:root:FL Epoch: 242 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :123
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 123 is 1.633206
INFO:root:FL Epoch: 242 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :56
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 56 is 1.678109
INFO:root:FL Epoch: 242 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :975
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503900
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262766
INFO:root:FL Epoch: 242 Norm Difference for worker 975 is 1.651695
INFO:root:FL Epoch: 242 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1165
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683795
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246292
INFO:root:FL Epoch: 242 Norm Difference for worker 1165 is 1.539797
INFO:root:FL Epoch: 242 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :380
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651047
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276579
INFO:root:FL Epoch: 242 Norm Difference for worker 380 is 1.529164
INFO:root:FL Epoch: 242 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :313
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 313 is 1.528175
INFO:root:FL Epoch: 242 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1324
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383177
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195646
INFO:root:FL Epoch: 242 Norm Difference for worker 1324 is 1.619248
INFO:root:FL Epoch: 242 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [6 0 2 8 7 5 4], which are global users: [1165, 1813, 1921, 313, 380, 975, 56]
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.46947797782280865 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.2188394752641519                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1593
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388316
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271735
INFO:root:FL Epoch: 243 Norm Difference for worker 1593 is 1.394086
INFO:root:FL Epoch: 243 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1300
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539541
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279062
INFO:root:FL Epoch: 243 Norm Difference for worker 1300 is 1.575635
INFO:root:FL Epoch: 243 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :642
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614154
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387511
INFO:root:FL Epoch: 243 Norm Difference for worker 642 is 1.561877
INFO:root:FL Epoch: 243 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1371
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528366
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259667
INFO:root:FL Epoch: 243 Norm Difference for worker 1371 is 1.756518
INFO:root:FL Epoch: 243 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :278
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 278 is 1.691674
INFO:root:FL Epoch: 243 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :562
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436725
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249327
INFO:root:FL Epoch: 243 Norm Difference for worker 562 is 1.553339
INFO:root:FL Epoch: 243 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1220
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617488
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291842
INFO:root:FL Epoch: 243 Norm Difference for worker 1220 is 1.576006
INFO:root:FL Epoch: 243 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :620
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631887
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256138
INFO:root:FL Epoch: 243 Norm Difference for worker 620 is 1.613314
INFO:root:FL Epoch: 243 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :885
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668370
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277041
INFO:root:FL Epoch: 243 Norm Difference for worker 885 is 1.567799
INFO:root:FL Epoch: 243 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1473
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482132
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466870
INFO:root:FL Epoch: 243 Norm Difference for worker 1473 is 1.765952
INFO:root:FL Epoch: 243 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [620, 1593, 642, 885, 1300, 562, 1220]
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.4811974641154794 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.21575705086191496                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :828
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689005
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302913
INFO:root:FL Epoch: 244 Norm Difference for worker 828 is 1.882515
INFO:root:FL Epoch: 244 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1531
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715332
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331011
INFO:root:FL Epoch: 244 Norm Difference for worker 1531 is 1.720702
INFO:root:FL Epoch: 244 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :942
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614262
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369164
INFO:root:FL Epoch: 244 Norm Difference for worker 942 is 1.610805
INFO:root:FL Epoch: 244 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1585
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322682
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207472
INFO:root:FL Epoch: 244 Norm Difference for worker 1585 is 1.561416
INFO:root:FL Epoch: 244 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :214
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 214 is 1.63658
INFO:root:FL Epoch: 244 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1712
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569161
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249231
INFO:root:FL Epoch: 244 Norm Difference for worker 1712 is 1.597545
INFO:root:FL Epoch: 244 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :760
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431198
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439510
INFO:root:FL Epoch: 244 Norm Difference for worker 760 is 1.657119
INFO:root:FL Epoch: 244 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1577
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454055
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369575
INFO:root:FL Epoch: 244 Norm Difference for worker 1577 is 1.62043
INFO:root:FL Epoch: 244 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :161
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 161 is 1.555522
INFO:root:FL Epoch: 244 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :872
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489485
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250790
INFO:root:FL Epoch: 244 Norm Difference for worker 872 is 1.560638
INFO:root:FL Epoch: 244 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 201]
INFO:root:The chosen ones are users: [7 9 2 3 8 5 4], which are global users: [1577, 872, 942, 1585, 161, 1712, 214]
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.4707358181476593 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.28482859830061596                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 245 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :42
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386461
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 42 is 1.446545
INFO:root:FL Epoch: 245 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.285379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 320 is 1.614614
INFO:root:FL Epoch: 245 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1861
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360805
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304923
INFO:root:FL Epoch: 245 Norm Difference for worker 1861 is 1.702762
INFO:root:FL Epoch: 245 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :965
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388664
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179341
INFO:root:FL Epoch: 245 Norm Difference for worker 965 is 1.540966
INFO:root:FL Epoch: 245 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :484
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794966
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249511
INFO:root:FL Epoch: 245 Norm Difference for worker 484 is 1.754236
INFO:root:FL Epoch: 245 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :884
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357053
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323528
INFO:root:FL Epoch: 245 Norm Difference for worker 884 is 1.621691
INFO:root:FL Epoch: 245 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1238
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417081
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408724
INFO:root:FL Epoch: 245 Norm Difference for worker 1238 is 1.658604
INFO:root:FL Epoch: 245 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :214
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.208096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 214 is 1.450823
INFO:root:FL Epoch: 245 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1012
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427629
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275534
INFO:root:FL Epoch: 245 Norm Difference for worker 1012 is 1.619659
INFO:root:FL Epoch: 245 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :674
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343760
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238124
INFO:root:FL Epoch: 245 Norm Difference for worker 674 is 1.558504
INFO:root:FL Epoch: 245 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 201 201 200 200 201 200]
INFO:root:The chosen ones are users: [3 0 7 9 8 1 5], which are global users: [965, 42, 214, 674, 1012, 320, 884]
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.49133364417973685 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.27914487818876904                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :501
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477456
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400672
INFO:root:FL Epoch: 246 Norm Difference for worker 501 is 1.722258
INFO:root:FL Epoch: 246 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1726
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540827
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418609
INFO:root:FL Epoch: 246 Norm Difference for worker 1726 is 1.87628
INFO:root:FL Epoch: 246 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1606
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424037
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314684
INFO:root:FL Epoch: 246 Norm Difference for worker 1606 is 1.663055
INFO:root:FL Epoch: 246 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1903
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469632
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221719
INFO:root:FL Epoch: 246 Norm Difference for worker 1903 is 1.683058
INFO:root:FL Epoch: 246 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :59
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242017
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 59 is 1.562105
INFO:root:FL Epoch: 246 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1152
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371269
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336340
INFO:root:FL Epoch: 246 Norm Difference for worker 1152 is 1.725889
INFO:root:FL Epoch: 246 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :944
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415444
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258795
INFO:root:FL Epoch: 246 Norm Difference for worker 944 is 1.600263
INFO:root:FL Epoch: 246 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1138
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.886000
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238695
INFO:root:FL Epoch: 246 Norm Difference for worker 1138 is 1.714523
INFO:root:FL Epoch: 246 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :484
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371277
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233252
INFO:root:FL Epoch: 246 Norm Difference for worker 484 is 1.798833
INFO:root:FL Epoch: 246 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1176
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309142
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126526
INFO:root:FL Epoch: 246 Norm Difference for worker 1176 is 1.601335
INFO:root:FL Epoch: 246 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 4 2 0 3 7], which are global users: [944, 1176, 59, 1606, 501, 1903, 1138]
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.485584804240395 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.2836525117357572                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1188
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679371
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370616
INFO:root:FL Epoch: 247 Norm Difference for worker 1188 is 1.625107
INFO:root:FL Epoch: 247 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1113
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393621
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435331
INFO:root:FL Epoch: 247 Norm Difference for worker 1113 is 1.698357
INFO:root:FL Epoch: 247 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1084
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663603
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347930
INFO:root:FL Epoch: 247 Norm Difference for worker 1084 is 1.609691
INFO:root:FL Epoch: 247 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1606
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575911
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407085
INFO:root:FL Epoch: 247 Norm Difference for worker 1606 is 1.495184
INFO:root:FL Epoch: 247 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :769
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325310
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376035
INFO:root:FL Epoch: 247 Norm Difference for worker 769 is 1.751535
INFO:root:FL Epoch: 247 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :829
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874865
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403219
INFO:root:FL Epoch: 247 Norm Difference for worker 829 is 1.709461
INFO:root:FL Epoch: 247 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :116
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.938882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 116 is 1.631096
INFO:root:FL Epoch: 247 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :544
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401660
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346739
INFO:root:FL Epoch: 247 Norm Difference for worker 544 is 1.502893
INFO:root:FL Epoch: 247 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1566
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573545
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488377
INFO:root:FL Epoch: 247 Norm Difference for worker 1566 is 1.627173
INFO:root:FL Epoch: 247 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1301
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675249
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288688
INFO:root:FL Epoch: 247 Norm Difference for worker 1301 is 1.701829
INFO:root:FL Epoch: 247 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 3 6 2 0 1 8], which are global users: [544, 1606, 116, 1084, 1188, 1113, 1566]
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.4641425311565399 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.28008857121070224                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :36
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350006
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 36 is 1.65857
INFO:root:FL Epoch: 248 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1147
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518647
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284692
INFO:root:FL Epoch: 248 Norm Difference for worker 1147 is 1.611851
INFO:root:FL Epoch: 248 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :785
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517331
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191826
INFO:root:FL Epoch: 248 Norm Difference for worker 785 is 1.519145
INFO:root:FL Epoch: 248 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :826
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696092
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522108
INFO:root:FL Epoch: 248 Norm Difference for worker 826 is 1.569367
INFO:root:FL Epoch: 248 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :778
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663386
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392470
INFO:root:FL Epoch: 248 Norm Difference for worker 778 is 1.686691
INFO:root:FL Epoch: 248 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :373
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436119
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353564
INFO:root:FL Epoch: 248 Norm Difference for worker 373 is 1.62616
INFO:root:FL Epoch: 248 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1904
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496625
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338209
INFO:root:FL Epoch: 248 Norm Difference for worker 1904 is 1.664173
INFO:root:FL Epoch: 248 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :495
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696796
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368348
INFO:root:FL Epoch: 248 Norm Difference for worker 495 is 1.577186
INFO:root:FL Epoch: 248 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :501
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512425
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242995
INFO:root:FL Epoch: 248 Norm Difference for worker 501 is 1.451286
INFO:root:FL Epoch: 248 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :869
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437963
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352001
INFO:root:FL Epoch: 248 Norm Difference for worker 869 is 1.612186
INFO:root:FL Epoch: 248 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [2 8 3 1 7 5 6], which are global users: [785, 501, 826, 1147, 495, 373, 1904]
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.4630105723352993 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.25028254588445026                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :606
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666225
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165968
INFO:root:FL Epoch: 249 Norm Difference for worker 606 is 1.488487
INFO:root:FL Epoch: 249 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1727
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447695
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279686
INFO:root:FL Epoch: 249 Norm Difference for worker 1727 is 1.596069
INFO:root:FL Epoch: 249 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :935
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523759
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337228
INFO:root:FL Epoch: 249 Norm Difference for worker 935 is 1.601186
INFO:root:FL Epoch: 249 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :362
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458403
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463044
INFO:root:FL Epoch: 249 Norm Difference for worker 362 is 1.699733
INFO:root:FL Epoch: 249 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :666
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770203
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467432
INFO:root:FL Epoch: 249 Norm Difference for worker 666 is 1.792318
INFO:root:FL Epoch: 249 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :491
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387270
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289439
INFO:root:FL Epoch: 249 Norm Difference for worker 491 is 1.523928
INFO:root:FL Epoch: 249 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :80
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300889
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 80 is 1.422116
INFO:root:FL Epoch: 249 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1533
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485090
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233104
INFO:root:FL Epoch: 249 Norm Difference for worker 1533 is 1.537151
INFO:root:FL Epoch: 249 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :496
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541808
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335004
INFO:root:FL Epoch: 249 Norm Difference for worker 496 is 1.525501
INFO:root:FL Epoch: 249 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :290
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597963
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 290 is 1.750412
INFO:root:FL Epoch: 249 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 8 6 0 7 2 1], which are global users: [491, 496, 80, 606, 1533, 935, 1727]
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.461826832855449 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.2942855854829152                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 250 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :78
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 78 is 1.417256
INFO:root:FL Epoch: 250 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :296
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202511
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 296 is 1.635173
INFO:root:FL Epoch: 250 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1388
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642493
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219299
INFO:root:FL Epoch: 250 Norm Difference for worker 1388 is 1.548562
INFO:root:FL Epoch: 250 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :169
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470994
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 169 is 1.574219
INFO:root:FL Epoch: 250 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :351
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401621
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251472
INFO:root:FL Epoch: 250 Norm Difference for worker 351 is 1.545918
INFO:root:FL Epoch: 250 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1200
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675143
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371262
INFO:root:FL Epoch: 250 Norm Difference for worker 1200 is 1.570627
INFO:root:FL Epoch: 250 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1052
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565524
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378261
INFO:root:FL Epoch: 250 Norm Difference for worker 1052 is 1.464759
INFO:root:FL Epoch: 250 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :729
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579532
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163235
INFO:root:FL Epoch: 250 Norm Difference for worker 729 is 1.412795
INFO:root:FL Epoch: 250 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :151
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 151 is 1.562418
INFO:root:FL Epoch: 250 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1317
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719563
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272356
INFO:root:FL Epoch: 250 Norm Difference for worker 1317 is 1.50434
INFO:root:FL Epoch: 250 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 201 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 7 9 2 4 5], which are global users: [1052, 78, 729, 1317, 1388, 351, 1200]
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.4484703532036613 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.29429316023985547                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254820
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142905
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.11277000419795513 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.15640559941530227 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.301759
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288633
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107711
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.11861942956844966 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.15558920577168464 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.296679
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245256
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149697
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.11852776383360226 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.151643505692482 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.311992
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :764
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243939
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228564
INFO:root:FL Epoch: 251 Norm Difference for worker 764 is 1.532399
INFO:root:FL Epoch: 251 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1000
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413706
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304165
INFO:root:FL Epoch: 251 Norm Difference for worker 1000 is 1.708712
INFO:root:FL Epoch: 251 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :718
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576940
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149492
INFO:root:FL Epoch: 251 Norm Difference for worker 718 is 1.611515
INFO:root:FL Epoch: 251 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :697
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689979
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276682
INFO:root:FL Epoch: 251 Norm Difference for worker 697 is 1.780086
INFO:root:FL Epoch: 251 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :204
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.348567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 204 is 1.598603
INFO:root:FL Epoch: 251 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1862
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519785
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216372
INFO:root:FL Epoch: 251 Norm Difference for worker 1862 is 1.613104
INFO:root:FL Epoch: 251 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :913
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466535
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363831
INFO:root:FL Epoch: 251 Norm Difference for worker 913 is 1.687242
INFO:root:FL Epoch: 251 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 8], which are global users: [204, 0, 2, 764, 1, 718, 1862]
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.45154207068331104 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.2071329429745674                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1465
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571143
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278999
INFO:root:FL Epoch: 252 Norm Difference for worker 1465 is 1.681529
INFO:root:FL Epoch: 252 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664452
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178298
INFO:root:FL Epoch: 252 Norm Difference for worker 1481 is 1.783986
INFO:root:FL Epoch: 252 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1390
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318778
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273065
INFO:root:FL Epoch: 252 Norm Difference for worker 1390 is 1.634038
INFO:root:FL Epoch: 252 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1870
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666098
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320815
INFO:root:FL Epoch: 252 Norm Difference for worker 1870 is 1.556309
INFO:root:FL Epoch: 252 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :755
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486264
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163043
INFO:root:FL Epoch: 252 Norm Difference for worker 755 is 1.483626
INFO:root:FL Epoch: 252 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1728
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723616
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442963
INFO:root:FL Epoch: 252 Norm Difference for worker 1728 is 1.718254
INFO:root:FL Epoch: 252 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1074
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778271
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484466
INFO:root:FL Epoch: 252 Norm Difference for worker 1074 is 1.779679
INFO:root:FL Epoch: 252 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463922
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293122
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 1.690547
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1734
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483166
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319964
INFO:root:FL Epoch: 252 Norm Difference for worker 1734 is 1.692977
INFO:root:FL Epoch: 252 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1268
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450624
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241350
INFO:root:FL Epoch: 252 Norm Difference for worker 1268 is 1.590363
INFO:root:FL Epoch: 252 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 7 2 8 3 0], which are global users: [755, 1268, 655, 1390, 1734, 1870, 1465]
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.45073649637839375 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.20014909779032072                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1274
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724342
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296593
INFO:root:FL Epoch: 253 Norm Difference for worker 1274 is 1.616232
INFO:root:FL Epoch: 253 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1234
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745624
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167777
INFO:root:FL Epoch: 253 Norm Difference for worker 1234 is 1.710114
INFO:root:FL Epoch: 253 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :852
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592204
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266053
INFO:root:FL Epoch: 253 Norm Difference for worker 852 is 1.603348
INFO:root:FL Epoch: 253 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1737
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640652
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336556
INFO:root:FL Epoch: 253 Norm Difference for worker 1737 is 1.624024
INFO:root:FL Epoch: 253 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1163
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386706
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258830
INFO:root:FL Epoch: 253 Norm Difference for worker 1163 is 1.613357
INFO:root:FL Epoch: 253 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :213
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 213 is 1.720341
INFO:root:FL Epoch: 253 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1350
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361629
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570725
INFO:root:FL Epoch: 253 Norm Difference for worker 1350 is 1.725005
INFO:root:FL Epoch: 253 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :291
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 291 is 1.670678
INFO:root:FL Epoch: 253 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :800
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766114
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198806
INFO:root:FL Epoch: 253 Norm Difference for worker 800 is 1.61403
INFO:root:FL Epoch: 253 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1016
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699314
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318850
INFO:root:FL Epoch: 253 Norm Difference for worker 1016 is 1.670307
INFO:root:FL Epoch: 253 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [2 4 0 7 3 8 1], which are global users: [852, 1163, 1274, 291, 1737, 800, 1234]
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.44136324524879456 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.225929061571757                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 254 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1754
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283672
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258163
INFO:root:FL Epoch: 254 Norm Difference for worker 1754 is 1.507174
INFO:root:FL Epoch: 254 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1163
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412715
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351374
INFO:root:FL Epoch: 254 Norm Difference for worker 1163 is 1.417458
INFO:root:FL Epoch: 254 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :896
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642539
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212910
INFO:root:FL Epoch: 254 Norm Difference for worker 896 is 1.517402
INFO:root:FL Epoch: 254 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :38
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.163870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 38 is 1.374169
INFO:root:FL Epoch: 254 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1431
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476504
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260172
INFO:root:FL Epoch: 254 Norm Difference for worker 1431 is 1.543097
INFO:root:FL Epoch: 254 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :945
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291609
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232929
INFO:root:FL Epoch: 254 Norm Difference for worker 945 is 1.376965
INFO:root:FL Epoch: 254 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1882
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752888
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248687
INFO:root:FL Epoch: 254 Norm Difference for worker 1882 is 1.53931
INFO:root:FL Epoch: 254 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1311
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882031
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275276
INFO:root:FL Epoch: 254 Norm Difference for worker 1311 is 1.569325
INFO:root:FL Epoch: 254 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :721
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365671
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379439
INFO:root:FL Epoch: 254 Norm Difference for worker 721 is 1.722578
INFO:root:FL Epoch: 254 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :844
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497654
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312255
INFO:root:FL Epoch: 254 Norm Difference for worker 844 is 1.430097
INFO:root:FL Epoch: 254 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [3 9 5 0 2 1 6], which are global users: [38, 844, 945, 1754, 896, 1163, 1882]
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.457373031798531 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.2302974338332812                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1458
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561168
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165355
INFO:root:FL Epoch: 255 Norm Difference for worker 1458 is 1.567502
INFO:root:FL Epoch: 255 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :415
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361193
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284864
INFO:root:FL Epoch: 255 Norm Difference for worker 415 is 1.637802
INFO:root:FL Epoch: 255 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1593
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518408
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222913
INFO:root:FL Epoch: 255 Norm Difference for worker 1593 is 1.487317
INFO:root:FL Epoch: 255 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1941
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300794
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238397
INFO:root:FL Epoch: 255 Norm Difference for worker 1941 is 1.554772
INFO:root:FL Epoch: 255 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :575
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378422
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283524
INFO:root:FL Epoch: 255 Norm Difference for worker 575 is 1.74666
INFO:root:FL Epoch: 255 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1329
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441240
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238670
INFO:root:FL Epoch: 255 Norm Difference for worker 1329 is 1.615338
INFO:root:FL Epoch: 255 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :88
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369038
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 88 is 1.828914
INFO:root:FL Epoch: 255 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1317
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311765
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299054
INFO:root:FL Epoch: 255 Norm Difference for worker 1317 is 1.551574
INFO:root:FL Epoch: 255 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1582
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757302
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403803
INFO:root:FL Epoch: 255 Norm Difference for worker 1582 is 1.801592
INFO:root:FL Epoch: 255 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792605
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253938
INFO:root:FL Epoch: 255 Norm Difference for worker 1124 is 1.763253
INFO:root:FL Epoch: 255 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 4], which are global users: [1317, 1458, 1593, 1941, 415, 1329, 575]
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.4440562707536361 and Test Accuracy:80.0 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.24100927636027336                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1806
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416057
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512502
INFO:root:FL Epoch: 256 Norm Difference for worker 1806 is 1.525517
INFO:root:FL Epoch: 256 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :864
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467450
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188593
INFO:root:FL Epoch: 256 Norm Difference for worker 864 is 1.637409
INFO:root:FL Epoch: 256 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1226
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802187
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390693
INFO:root:FL Epoch: 256 Norm Difference for worker 1226 is 1.571184
INFO:root:FL Epoch: 256 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :325
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401946
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 325 is 1.549019
INFO:root:FL Epoch: 256 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :424
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557010
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234391
INFO:root:FL Epoch: 256 Norm Difference for worker 424 is 1.491259
INFO:root:FL Epoch: 256 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1188
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504152
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311181
INFO:root:FL Epoch: 256 Norm Difference for worker 1188 is 1.674064
INFO:root:FL Epoch: 256 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1760
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654107
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393642
INFO:root:FL Epoch: 256 Norm Difference for worker 1760 is 1.809547
INFO:root:FL Epoch: 256 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :100
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 100 is 1.558637
INFO:root:FL Epoch: 256 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1464
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365191
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224302
INFO:root:FL Epoch: 256 Norm Difference for worker 1464 is 1.533707
INFO:root:FL Epoch: 256 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :887
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466681
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183815
INFO:root:FL Epoch: 256 Norm Difference for worker 887 is 1.686384
INFO:root:FL Epoch: 256 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [4 0 7 2 1 3 8], which are global users: [424, 1806, 100, 1226, 864, 325, 1464]
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.445816753541722 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.1979259413977464                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1443
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481312
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318121
INFO:root:FL Epoch: 257 Norm Difference for worker 1443 is 1.649886
INFO:root:FL Epoch: 257 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :3
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 3 is 1.76719
INFO:root:FL Epoch: 257 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :324
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.310796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 324 is 1.577367
INFO:root:FL Epoch: 257 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :653
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615240
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312177
INFO:root:FL Epoch: 257 Norm Difference for worker 653 is 1.561027
INFO:root:FL Epoch: 257 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :780
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323426
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222375
INFO:root:FL Epoch: 257 Norm Difference for worker 780 is 1.661908
INFO:root:FL Epoch: 257 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :610
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442706
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310864
INFO:root:FL Epoch: 257 Norm Difference for worker 610 is 1.514828
INFO:root:FL Epoch: 257 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :309
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342585
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 309 is 1.68188
INFO:root:FL Epoch: 257 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :393
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762357
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308317
INFO:root:FL Epoch: 257 Norm Difference for worker 393 is 1.845968
INFO:root:FL Epoch: 257 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1556
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396223
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283116
INFO:root:FL Epoch: 257 Norm Difference for worker 1556 is 1.523061
INFO:root:FL Epoch: 257 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :602
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642375
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315900
INFO:root:FL Epoch: 257 Norm Difference for worker 602 is 1.664695
INFO:root:FL Epoch: 257 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 3 8 9 4], which are global users: [610, 1443, 324, 653, 1556, 602, 780]
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.4451641072245205 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.2565503269433975                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1162
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477110
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316271
INFO:root:FL Epoch: 258 Norm Difference for worker 1162 is 1.537716
INFO:root:FL Epoch: 258 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1887
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434235
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227040
INFO:root:FL Epoch: 258 Norm Difference for worker 1887 is 1.439541
INFO:root:FL Epoch: 258 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1228
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618639
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324705
INFO:root:FL Epoch: 258 Norm Difference for worker 1228 is 1.772665
INFO:root:FL Epoch: 258 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1028
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764528
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352326
INFO:root:FL Epoch: 258 Norm Difference for worker 1028 is 1.598186
INFO:root:FL Epoch: 258 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1657
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421135
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205186
INFO:root:FL Epoch: 258 Norm Difference for worker 1657 is 1.699524
INFO:root:FL Epoch: 258 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1687
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560396
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209397
INFO:root:FL Epoch: 258 Norm Difference for worker 1687 is 1.775439
INFO:root:FL Epoch: 258 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1086
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478025
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387777
INFO:root:FL Epoch: 258 Norm Difference for worker 1086 is 1.598744
INFO:root:FL Epoch: 258 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :388
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500704
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320011
INFO:root:FL Epoch: 258 Norm Difference for worker 388 is 1.643944
INFO:root:FL Epoch: 258 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :429
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422563
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150553
INFO:root:FL Epoch: 258 Norm Difference for worker 429 is 1.620883
INFO:root:FL Epoch: 258 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :973
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347201
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250196
INFO:root:FL Epoch: 258 Norm Difference for worker 973 is 1.629726
INFO:root:FL Epoch: 258 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 3 1 7 9], which are global users: [1086, 1162, 429, 1028, 1887, 388, 973]
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.4536662838038276 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.2758829966187477                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 259 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :9
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 9 is 1.570688
INFO:root:FL Epoch: 259 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1195
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484677
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349475
INFO:root:FL Epoch: 259 Norm Difference for worker 1195 is 1.64217
INFO:root:FL Epoch: 259 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :213
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 213 is 1.70563
INFO:root:FL Epoch: 259 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :53
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.845232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 53 is 1.538393
INFO:root:FL Epoch: 259 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :147
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.352117
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.167159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 147 is 1.488561
INFO:root:FL Epoch: 259 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1859
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854774
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282122
INFO:root:FL Epoch: 259 Norm Difference for worker 1859 is 1.676258
INFO:root:FL Epoch: 259 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :429
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496860
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269139
INFO:root:FL Epoch: 259 Norm Difference for worker 429 is 1.513939
INFO:root:FL Epoch: 259 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1183
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.994912
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148827
INFO:root:FL Epoch: 259 Norm Difference for worker 1183 is 1.543249
INFO:root:FL Epoch: 259 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1225
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578945
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457719
INFO:root:FL Epoch: 259 Norm Difference for worker 1225 is 1.696661
INFO:root:FL Epoch: 259 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1102
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400176
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346421
INFO:root:FL Epoch: 259 Norm Difference for worker 1102 is 1.598067
INFO:root:FL Epoch: 259 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 201 201 200 200]
INFO:root:The chosen ones are users: [6 4 7 3 0 1 9], which are global users: [429, 147, 1183, 53, 9, 1195, 1102]
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.45740697313757506 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.27163058891892433                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1793
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885481
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585005
INFO:root:FL Epoch: 260 Norm Difference for worker 1793 is 1.72572
INFO:root:FL Epoch: 260 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1652
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358741
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353145
INFO:root:FL Epoch: 260 Norm Difference for worker 1652 is 1.724701
INFO:root:FL Epoch: 260 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1184
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523632
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341399
INFO:root:FL Epoch: 260 Norm Difference for worker 1184 is 1.701819
INFO:root:FL Epoch: 260 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1482
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583686
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278744
INFO:root:FL Epoch: 260 Norm Difference for worker 1482 is 1.448515
INFO:root:FL Epoch: 260 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1085
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313441
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434378
INFO:root:FL Epoch: 260 Norm Difference for worker 1085 is 1.524493
INFO:root:FL Epoch: 260 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :257
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 257 is 1.697589
INFO:root:FL Epoch: 260 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1289
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232325
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212758
INFO:root:FL Epoch: 260 Norm Difference for worker 1289 is 1.401271
INFO:root:FL Epoch: 260 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1365
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279839
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143289
INFO:root:FL Epoch: 260 Norm Difference for worker 1365 is 1.552209
INFO:root:FL Epoch: 260 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :864
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536149
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182540
INFO:root:FL Epoch: 260 Norm Difference for worker 864 is 1.485895
INFO:root:FL Epoch: 260 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1611
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752315
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247433
INFO:root:FL Epoch: 260 Norm Difference for worker 1611 is 1.681027
INFO:root:FL Epoch: 260 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 4 8 3 7 5 9], which are global users: [1289, 1085, 864, 1482, 1365, 257, 1611]
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.4504033861791386 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.32331084956725437                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.192128
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320888
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.10554775409400463 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.13200935795903207 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.328332
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249557
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226365
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.08678640487293403 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.133086696267128 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.330042
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292694
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145912
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.09473212560017903 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.13137941733002662 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.325349
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :947
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629385
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205181
INFO:root:FL Epoch: 261 Norm Difference for worker 947 is 1.542154
INFO:root:FL Epoch: 261 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1647
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858959
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282208
INFO:root:FL Epoch: 261 Norm Difference for worker 1647 is 1.777746
INFO:root:FL Epoch: 261 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :422
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446023
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368984
INFO:root:FL Epoch: 261 Norm Difference for worker 422 is 1.625143
INFO:root:FL Epoch: 261 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :127
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 127 is 1.684577
INFO:root:FL Epoch: 261 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1270
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536908
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355611
INFO:root:FL Epoch: 261 Norm Difference for worker 1270 is 1.51536
INFO:root:FL Epoch: 261 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1475
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720055
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187921
INFO:root:FL Epoch: 261 Norm Difference for worker 1475 is 1.625792
INFO:root:FL Epoch: 261 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1332
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412836
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344239
INFO:root:FL Epoch: 261 Norm Difference for worker 1332 is 1.606999
INFO:root:FL Epoch: 261 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 9 8], which are global users: [1270, 0, 2, 947, 1, 1332, 1475]
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.46724430427831765 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.19084212432305017                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 262 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1712
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471879
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351589
INFO:root:FL Epoch: 262 Norm Difference for worker 1712 is 1.629536
INFO:root:FL Epoch: 262 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :818
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294314
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207195
INFO:root:FL Epoch: 262 Norm Difference for worker 818 is 1.54803
INFO:root:FL Epoch: 262 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :28
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 28 is 1.673124
INFO:root:FL Epoch: 262 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :800
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458536
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174631
INFO:root:FL Epoch: 262 Norm Difference for worker 800 is 1.596175
INFO:root:FL Epoch: 262 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :258
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636674
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 258 is 1.867295
INFO:root:FL Epoch: 262 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1584
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267932
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229006
INFO:root:FL Epoch: 262 Norm Difference for worker 1584 is 1.711709
INFO:root:FL Epoch: 262 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1423
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563482
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392652
INFO:root:FL Epoch: 262 Norm Difference for worker 1423 is 1.60567
INFO:root:FL Epoch: 262 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1175
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482202
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195056
INFO:root:FL Epoch: 262 Norm Difference for worker 1175 is 1.666894
INFO:root:FL Epoch: 262 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :625
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534685
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178094
INFO:root:FL Epoch: 262 Norm Difference for worker 625 is 1.70785
INFO:root:FL Epoch: 262 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1520
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474077
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383063
INFO:root:FL Epoch: 262 Norm Difference for worker 1520 is 1.665951
INFO:root:FL Epoch: 262 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 0 7 3 1 9 2], which are global users: [1423, 1712, 1175, 800, 818, 1520, 28]
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.45065603186102476 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.19211640705664954                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :979
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838285
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291144
INFO:root:FL Epoch: 263 Norm Difference for worker 979 is 1.814052
INFO:root:FL Epoch: 263 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1707
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675084
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415362
INFO:root:FL Epoch: 263 Norm Difference for worker 1707 is 1.667465
INFO:root:FL Epoch: 263 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :50
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320461
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 50 is 1.62598
INFO:root:FL Epoch: 263 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :20
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179369
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 20 is 1.604579
INFO:root:FL Epoch: 263 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :945
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439436
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210453
INFO:root:FL Epoch: 263 Norm Difference for worker 945 is 1.430483
INFO:root:FL Epoch: 263 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :232
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 232 is 1.70593
INFO:root:FL Epoch: 263 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1938
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536598
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331592
INFO:root:FL Epoch: 263 Norm Difference for worker 1938 is 1.614685
INFO:root:FL Epoch: 263 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1500
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555956
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170691
INFO:root:FL Epoch: 263 Norm Difference for worker 1500 is 1.795371
INFO:root:FL Epoch: 263 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :705
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550307
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318298
INFO:root:FL Epoch: 263 Norm Difference for worker 705 is 1.697783
INFO:root:FL Epoch: 263 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :970
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578993
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381540
INFO:root:FL Epoch: 263 Norm Difference for worker 970 is 1.664835
INFO:root:FL Epoch: 263 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 201 200 200 201]
INFO:root:The chosen ones are users: [6 4 2 3 1 9 5], which are global users: [1938, 945, 50, 20, 1707, 970, 232]
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.45174917403389425 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.2360903819402059                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1333
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538869
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364889
INFO:root:FL Epoch: 264 Norm Difference for worker 1333 is 1.755179
INFO:root:FL Epoch: 264 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1041
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419742
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293623
INFO:root:FL Epoch: 264 Norm Difference for worker 1041 is 1.65151
INFO:root:FL Epoch: 264 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :704
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411034
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213829
INFO:root:FL Epoch: 264 Norm Difference for worker 704 is 1.619374
INFO:root:FL Epoch: 264 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :272
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 272 is 1.516627
INFO:root:FL Epoch: 264 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1412
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432259
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321045
INFO:root:FL Epoch: 264 Norm Difference for worker 1412 is 1.72899
INFO:root:FL Epoch: 264 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1475
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487944
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141069
INFO:root:FL Epoch: 264 Norm Difference for worker 1475 is 1.451929
INFO:root:FL Epoch: 264 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1352
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535805
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249381
INFO:root:FL Epoch: 264 Norm Difference for worker 1352 is 1.708425
INFO:root:FL Epoch: 264 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1251
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466894
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203239
INFO:root:FL Epoch: 264 Norm Difference for worker 1251 is 1.776243
INFO:root:FL Epoch: 264 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :162
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 162 is 1.53524
INFO:root:FL Epoch: 264 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :202
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602944
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308919
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 202 is 1.779741
INFO:root:FL Epoch: 264 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 3 8 1 2 4 6], which are global users: [1475, 272, 162, 1041, 704, 1412, 1352]
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.47954365260460796 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.3044452543059985                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :1078
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610002
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208778
INFO:root:FL Epoch: 265 Norm Difference for worker 1078 is 1.613053
INFO:root:FL Epoch: 265 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :339
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698220
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 339 is 1.610036
INFO:root:FL Epoch: 265 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1327
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335024
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227921
INFO:root:FL Epoch: 265 Norm Difference for worker 1327 is 1.53178
INFO:root:FL Epoch: 265 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1482
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.182776
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186446
INFO:root:FL Epoch: 265 Norm Difference for worker 1482 is 1.462146
INFO:root:FL Epoch: 265 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1713
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565120
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379428
INFO:root:FL Epoch: 265 Norm Difference for worker 1713 is 1.46985
INFO:root:FL Epoch: 265 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1622
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692812
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260137
INFO:root:FL Epoch: 265 Norm Difference for worker 1622 is 1.549079
INFO:root:FL Epoch: 265 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1408
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574566
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289615
INFO:root:FL Epoch: 265 Norm Difference for worker 1408 is 1.65024
INFO:root:FL Epoch: 265 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1865
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674898
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308386
INFO:root:FL Epoch: 265 Norm Difference for worker 1865 is 1.688744
INFO:root:FL Epoch: 265 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1421
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545675
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183134
INFO:root:FL Epoch: 265 Norm Difference for worker 1421 is 1.413143
INFO:root:FL Epoch: 265 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :325
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.295723
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.180278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 325 is 1.509613
INFO:root:FL Epoch: 265 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 201 200 201 200]
INFO:root:The chosen ones are users: [3 4 8 9 2 1 5], which are global users: [1482, 1713, 1421, 325, 1327, 339, 1622]
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.461912404088413 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.31126799682776135                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417376
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341060
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 1.630955
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :857
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556677
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344651
INFO:root:FL Epoch: 266 Norm Difference for worker 857 is 1.886257
INFO:root:FL Epoch: 266 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :104
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.144682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 104 is 1.643217
INFO:root:FL Epoch: 266 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1713
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253472
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303483
INFO:root:FL Epoch: 266 Norm Difference for worker 1713 is 1.294623
INFO:root:FL Epoch: 266 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1448
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549371
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276623
INFO:root:FL Epoch: 266 Norm Difference for worker 1448 is 1.719782
INFO:root:FL Epoch: 266 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :21
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 21 is 1.568769
INFO:root:FL Epoch: 266 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :596
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508483
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366335
INFO:root:FL Epoch: 266 Norm Difference for worker 596 is 1.827729
INFO:root:FL Epoch: 266 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :894
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230085
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248398
INFO:root:FL Epoch: 266 Norm Difference for worker 894 is 1.690488
INFO:root:FL Epoch: 266 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1708
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878859
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350901
INFO:root:FL Epoch: 266 Norm Difference for worker 1708 is 1.772212
INFO:root:FL Epoch: 266 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1086
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493995
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236213
INFO:root:FL Epoch: 266 Norm Difference for worker 1086 is 1.519716
INFO:root:FL Epoch: 266 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [3 9 5 0 2 7 4], which are global users: [1713, 1086, 21, 1494, 104, 894, 1448]
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.4665682245703304 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.2766539628307025                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407084
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288096
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 1.517398
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1281
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709312
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269123
INFO:root:FL Epoch: 267 Norm Difference for worker 1281 is 1.421143
INFO:root:FL Epoch: 267 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :462
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615285
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261570
INFO:root:FL Epoch: 267 Norm Difference for worker 462 is 1.624749
INFO:root:FL Epoch: 267 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1092
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487583
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449892
INFO:root:FL Epoch: 267 Norm Difference for worker 1092 is 1.660753
INFO:root:FL Epoch: 267 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :606
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563006
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292455
INFO:root:FL Epoch: 267 Norm Difference for worker 606 is 1.519081
INFO:root:FL Epoch: 267 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1605
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748999
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326539
INFO:root:FL Epoch: 267 Norm Difference for worker 1605 is 1.689393
INFO:root:FL Epoch: 267 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :925
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306240
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249459
INFO:root:FL Epoch: 267 Norm Difference for worker 925 is 1.447378
INFO:root:FL Epoch: 267 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :434
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263176
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147498
INFO:root:FL Epoch: 267 Norm Difference for worker 434 is 1.501054
INFO:root:FL Epoch: 267 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :484
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466866
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330873
INFO:root:FL Epoch: 267 Norm Difference for worker 484 is 1.777544
INFO:root:FL Epoch: 267 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :348
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279478
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505839
INFO:root:FL Epoch: 267 Norm Difference for worker 348 is 1.612207
INFO:root:FL Epoch: 267 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 6 4 7 9 3], which are global users: [1281, 684, 925, 606, 434, 348, 1092]
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.45883694378768697 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.2514667833844821                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1881
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531359
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246345
INFO:root:FL Epoch: 268 Norm Difference for worker 1881 is 1.516977
INFO:root:FL Epoch: 268 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :711
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519344
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233458
INFO:root:FL Epoch: 268 Norm Difference for worker 711 is 1.621425
INFO:root:FL Epoch: 268 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1677
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464967
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402227
INFO:root:FL Epoch: 268 Norm Difference for worker 1677 is 1.616995
INFO:root:FL Epoch: 268 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :664
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524822
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278294
INFO:root:FL Epoch: 268 Norm Difference for worker 664 is 1.71448
INFO:root:FL Epoch: 268 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :661
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387949
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503391
INFO:root:FL Epoch: 268 Norm Difference for worker 661 is 1.695405
INFO:root:FL Epoch: 268 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1595
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403429
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424481
INFO:root:FL Epoch: 268 Norm Difference for worker 1595 is 1.502665
INFO:root:FL Epoch: 268 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :304
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 304 is 1.571611
INFO:root:FL Epoch: 268 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1712
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339177
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256946
INFO:root:FL Epoch: 268 Norm Difference for worker 1712 is 1.446416
INFO:root:FL Epoch: 268 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1175
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371302
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141505
INFO:root:FL Epoch: 268 Norm Difference for worker 1175 is 1.583837
INFO:root:FL Epoch: 268 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1844
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436053
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217526
INFO:root:FL Epoch: 268 Norm Difference for worker 1844 is 1.460832
INFO:root:FL Epoch: 268 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 7 0 8 6 1], which are global users: [1595, 1844, 1712, 1881, 1175, 304, 711]
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.45111311884487376 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.20064844687779745                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1376
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489372
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168431
INFO:root:FL Epoch: 269 Norm Difference for worker 1376 is 1.679345
INFO:root:FL Epoch: 269 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :336
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 336 is 1.669833
INFO:root:FL Epoch: 269 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1276
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468118
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299730
INFO:root:FL Epoch: 269 Norm Difference for worker 1276 is 1.687978
INFO:root:FL Epoch: 269 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1589
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254454
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188339
INFO:root:FL Epoch: 269 Norm Difference for worker 1589 is 1.748834
INFO:root:FL Epoch: 269 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :673
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477419
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300644
INFO:root:FL Epoch: 269 Norm Difference for worker 673 is 1.611176
INFO:root:FL Epoch: 269 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :525
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788850
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247632
INFO:root:FL Epoch: 269 Norm Difference for worker 525 is 1.745613
INFO:root:FL Epoch: 269 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :278
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216150
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 278 is 1.823524
INFO:root:FL Epoch: 269 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1929
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561745
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151887
INFO:root:FL Epoch: 269 Norm Difference for worker 1929 is 1.498457
INFO:root:FL Epoch: 269 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :883
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489528
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291174
INFO:root:FL Epoch: 269 Norm Difference for worker 883 is 1.675675
INFO:root:FL Epoch: 269 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :602
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397372
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185809
INFO:root:FL Epoch: 269 Norm Difference for worker 602 is 1.561693
INFO:root:FL Epoch: 269 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 9 4 2 0 8 1], which are global users: [1929, 602, 673, 1276, 1376, 883, 336]
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.45078145756441 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.2258559949696064                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :642
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595574
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208511
INFO:root:FL Epoch: 270 Norm Difference for worker 642 is 1.650169
INFO:root:FL Epoch: 270 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :292
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 292 is 1.644844
INFO:root:FL Epoch: 270 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1822
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580620
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234559
INFO:root:FL Epoch: 270 Norm Difference for worker 1822 is 1.709188
INFO:root:FL Epoch: 270 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :896
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498277
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410214
INFO:root:FL Epoch: 270 Norm Difference for worker 896 is 1.526834
INFO:root:FL Epoch: 270 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :733
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611736
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268260
INFO:root:FL Epoch: 270 Norm Difference for worker 733 is 1.72775
INFO:root:FL Epoch: 270 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :899
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318712
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207959
INFO:root:FL Epoch: 270 Norm Difference for worker 899 is 1.676031
INFO:root:FL Epoch: 270 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :640
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740059
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197649
INFO:root:FL Epoch: 270 Norm Difference for worker 640 is 1.587081
INFO:root:FL Epoch: 270 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1499
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540207
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257810
INFO:root:FL Epoch: 270 Norm Difference for worker 1499 is 1.53035
INFO:root:FL Epoch: 270 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :203
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 203 is 1.611982
INFO:root:FL Epoch: 270 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :906
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460730
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133912
INFO:root:FL Epoch: 270 Norm Difference for worker 906 is 1.495346
INFO:root:FL Epoch: 270 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [7 9 8 3 1 5 6], which are global users: [1499, 906, 203, 896, 292, 899, 640]
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.4542434233076432 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.2730529010295868                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.152035
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127089
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.12320288146535556 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.13382005356252194 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.291714
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315994
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299872
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.11969547842939694 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.13451104760169982 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.292607
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.149773
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214896
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.12330017859737079 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.13703241422772408 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.28319
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1386
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443534
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146123
INFO:root:FL Epoch: 271 Norm Difference for worker 1386 is 1.509442
INFO:root:FL Epoch: 271 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :312
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.234215
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 312 is 1.477097
INFO:root:FL Epoch: 271 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :273
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 273 is 1.483884
INFO:root:FL Epoch: 271 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :324
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 324 is 1.529081
INFO:root:FL Epoch: 271 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :868
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399175
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242112
INFO:root:FL Epoch: 271 Norm Difference for worker 868 is 1.650322
INFO:root:FL Epoch: 271 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :587
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.906514
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296179
INFO:root:FL Epoch: 271 Norm Difference for worker 587 is 1.539747
INFO:root:FL Epoch: 271 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1406
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460755
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191593
INFO:root:FL Epoch: 271 Norm Difference for worker 1406 is 1.542043
INFO:root:FL Epoch: 271 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 201 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 201 200 201]
INFO:root:The chosen ones are users: [1 0 2 5 4 3 6], which are global users: [1, 0, 2, 273, 312, 1386, 324]
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.44206881347824545 and Test Accuracy:80.0 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.15443279035389423                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1369
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752081
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237290
INFO:root:FL Epoch: 272 Norm Difference for worker 1369 is 1.709526
INFO:root:FL Epoch: 272 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1078
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514916
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237771
INFO:root:FL Epoch: 272 Norm Difference for worker 1078 is 1.645177
INFO:root:FL Epoch: 272 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :946
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589578
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279585
INFO:root:FL Epoch: 272 Norm Difference for worker 946 is 1.52726
INFO:root:FL Epoch: 272 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1596
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518869
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355194
INFO:root:FL Epoch: 272 Norm Difference for worker 1596 is 1.643268
INFO:root:FL Epoch: 272 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1754
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601086
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268053
INFO:root:FL Epoch: 272 Norm Difference for worker 1754 is 1.528653
INFO:root:FL Epoch: 272 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1893
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648840
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369062
INFO:root:FL Epoch: 272 Norm Difference for worker 1893 is 1.807639
INFO:root:FL Epoch: 272 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :76
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483503
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 76 is 1.698628
INFO:root:FL Epoch: 272 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.193262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 1.641116
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1514
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745436
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448282
INFO:root:FL Epoch: 272 Norm Difference for worker 1514 is 1.707778
INFO:root:FL Epoch: 272 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :134
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.140416
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 134 is 1.571472
INFO:root:FL Epoch: 272 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 200 201]
INFO:root:Num selected data points: [200 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [2 4 9 7 3 8 1], which are global users: [946, 1754, 134, 35, 1596, 1514, 1078]
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.45685383677482605 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.22473805397748947                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1624
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392804
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218768
INFO:root:FL Epoch: 273 Norm Difference for worker 1624 is 1.49084
INFO:root:FL Epoch: 273 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1303
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883969
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211104
INFO:root:FL Epoch: 273 Norm Difference for worker 1303 is 1.551508
INFO:root:FL Epoch: 273 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1603
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576156
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261741
INFO:root:FL Epoch: 273 Norm Difference for worker 1603 is 1.510206
INFO:root:FL Epoch: 273 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :789
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573227
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338516
INFO:root:FL Epoch: 273 Norm Difference for worker 789 is 1.488438
INFO:root:FL Epoch: 273 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1461
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279377
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282098
INFO:root:FL Epoch: 273 Norm Difference for worker 1461 is 1.503963
INFO:root:FL Epoch: 273 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1439
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710413
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264154
INFO:root:FL Epoch: 273 Norm Difference for worker 1439 is 1.61894
INFO:root:FL Epoch: 273 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :566
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760248
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306135
INFO:root:FL Epoch: 273 Norm Difference for worker 566 is 1.610083
INFO:root:FL Epoch: 273 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :614
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472661
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388990
INFO:root:FL Epoch: 273 Norm Difference for worker 614 is 1.642762
INFO:root:FL Epoch: 273 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :747
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482843
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385838
INFO:root:FL Epoch: 273 Norm Difference for worker 747 is 1.533922
INFO:root:FL Epoch: 273 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1857
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486889
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297585
INFO:root:FL Epoch: 273 Norm Difference for worker 1857 is 1.667494
INFO:root:FL Epoch: 273 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [0 4 8 2 1 3 6], which are global users: [1624, 1461, 747, 1603, 1303, 789, 566]
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.4537469306412865 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.25056468695402145                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :722
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579789
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365120
INFO:root:FL Epoch: 274 Norm Difference for worker 722 is 1.609996
INFO:root:FL Epoch: 274 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1292
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562730
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449782
INFO:root:FL Epoch: 274 Norm Difference for worker 1292 is 1.671311
INFO:root:FL Epoch: 274 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :200
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698498
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 200 is 1.634965
INFO:root:FL Epoch: 274 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1745
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361424
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291711
INFO:root:FL Epoch: 274 Norm Difference for worker 1745 is 1.50562
INFO:root:FL Epoch: 274 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1317
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367547
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201078
INFO:root:FL Epoch: 274 Norm Difference for worker 1317 is 1.52619
INFO:root:FL Epoch: 274 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :888
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527178
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245888
INFO:root:FL Epoch: 274 Norm Difference for worker 888 is 1.548377
INFO:root:FL Epoch: 274 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :600
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277093
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271195
INFO:root:FL Epoch: 274 Norm Difference for worker 600 is 1.539213
INFO:root:FL Epoch: 274 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1582
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653257
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340367
INFO:root:FL Epoch: 274 Norm Difference for worker 1582 is 1.781794
INFO:root:FL Epoch: 274 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :122
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.258311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 122 is 1.488644
INFO:root:FL Epoch: 274 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1276
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443221
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258659
INFO:root:FL Epoch: 274 Norm Difference for worker 1276 is 1.405384
INFO:root:FL Epoch: 274 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [5 9 8 3 6 4 2], which are global users: [888, 1276, 122, 1745, 600, 1317, 200]
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.44743621349334717 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.25010628004868823                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :1037
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405401
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301682
INFO:root:FL Epoch: 275 Norm Difference for worker 1037 is 1.608647
INFO:root:FL Epoch: 275 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1924
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327835
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326568
INFO:root:FL Epoch: 275 Norm Difference for worker 1924 is 1.539632
INFO:root:FL Epoch: 275 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1138
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746726
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230338
INFO:root:FL Epoch: 275 Norm Difference for worker 1138 is 1.781302
INFO:root:FL Epoch: 275 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :939
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747522
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453496
INFO:root:FL Epoch: 275 Norm Difference for worker 939 is 1.774624
INFO:root:FL Epoch: 275 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :622
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784427
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275121
INFO:root:FL Epoch: 275 Norm Difference for worker 622 is 1.627674
INFO:root:FL Epoch: 275 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1818
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727305
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386450
INFO:root:FL Epoch: 275 Norm Difference for worker 1818 is 1.588869
INFO:root:FL Epoch: 275 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :213
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.932957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 213 is 1.780661
INFO:root:FL Epoch: 275 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1662
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736847
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175878
INFO:root:FL Epoch: 275 Norm Difference for worker 1662 is 1.603904
INFO:root:FL Epoch: 275 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :829
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449060
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314757
INFO:root:FL Epoch: 275 Norm Difference for worker 829 is 1.722655
INFO:root:FL Epoch: 275 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :968
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482892
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380630
INFO:root:FL Epoch: 275 Norm Difference for worker 968 is 1.568385
INFO:root:FL Epoch: 275 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 9 7 4 5 8], which are global users: [1924, 1037, 968, 1662, 622, 1818, 829]
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.42886139890726876 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.2521832101047039                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 276 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :20
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517701
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 20 is 1.454458
INFO:root:FL Epoch: 276 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1906
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398036
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413196
INFO:root:FL Epoch: 276 Norm Difference for worker 1906 is 1.515818
INFO:root:FL Epoch: 276 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :168
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357117
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 168 is 1.599723
INFO:root:FL Epoch: 276 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :97
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255900
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 97 is 1.545949
INFO:root:FL Epoch: 276 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :947
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254098
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188628
INFO:root:FL Epoch: 276 Norm Difference for worker 947 is 1.355466
INFO:root:FL Epoch: 276 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :950
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394695
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309135
INFO:root:FL Epoch: 276 Norm Difference for worker 950 is 1.407106
INFO:root:FL Epoch: 276 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1018
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425611
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216667
INFO:root:FL Epoch: 276 Norm Difference for worker 1018 is 1.463845
INFO:root:FL Epoch: 276 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :477
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694254
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455212
INFO:root:FL Epoch: 276 Norm Difference for worker 477 is 1.49518
INFO:root:FL Epoch: 276 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1388
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230461
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295986
INFO:root:FL Epoch: 276 Norm Difference for worker 1388 is 1.463165
INFO:root:FL Epoch: 276 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1776
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480212
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216449
INFO:root:FL Epoch: 276 Norm Difference for worker 1776 is 1.516349
INFO:root:FL Epoch: 276 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 4 6 0 9 1 8], which are global users: [950, 947, 1018, 20, 1776, 1906, 1388]
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.4388418215162614 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.25987226019303006                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :140
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365720
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 140 is 1.612377
INFO:root:FL Epoch: 277 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1142
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477812
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196395
INFO:root:FL Epoch: 277 Norm Difference for worker 1142 is 1.469774
INFO:root:FL Epoch: 277 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :362
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677321
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285948
INFO:root:FL Epoch: 277 Norm Difference for worker 362 is 1.607433
INFO:root:FL Epoch: 277 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :200
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 200 is 1.520665
INFO:root:FL Epoch: 277 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :503
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283661
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194794
INFO:root:FL Epoch: 277 Norm Difference for worker 503 is 1.388658
INFO:root:FL Epoch: 277 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1050
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384470
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277374
INFO:root:FL Epoch: 277 Norm Difference for worker 1050 is 1.556687
INFO:root:FL Epoch: 277 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :405
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347135
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190173
INFO:root:FL Epoch: 277 Norm Difference for worker 405 is 1.555515
INFO:root:FL Epoch: 277 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1577
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687977
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225593
INFO:root:FL Epoch: 277 Norm Difference for worker 1577 is 1.540371
INFO:root:FL Epoch: 277 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1490
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871635
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226782
INFO:root:FL Epoch: 277 Norm Difference for worker 1490 is 1.502047
INFO:root:FL Epoch: 277 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543844
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293910
INFO:root:FL Epoch: 277 Norm Difference for worker 1483 is 1.39845
INFO:root:FL Epoch: 277 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 3 8 5 1 7], which are global users: [503, 1483, 200, 1490, 1050, 1142, 1577]
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.459771990776062 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.23325623075167337                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 278 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :103
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 103 is 1.453669
INFO:root:FL Epoch: 278 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :304
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 304 is 1.497738
INFO:root:FL Epoch: 278 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1032
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309564
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476422
INFO:root:FL Epoch: 278 Norm Difference for worker 1032 is 1.572176
INFO:root:FL Epoch: 278 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :468
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420875
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332098
INFO:root:FL Epoch: 278 Norm Difference for worker 468 is 1.581907
INFO:root:FL Epoch: 278 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1597
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717099
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308179
INFO:root:FL Epoch: 278 Norm Difference for worker 1597 is 1.473353
INFO:root:FL Epoch: 278 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :227
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413883
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 227 is 1.530115
INFO:root:FL Epoch: 278 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :380
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402964
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421410
INFO:root:FL Epoch: 278 Norm Difference for worker 380 is 1.602186
INFO:root:FL Epoch: 278 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :825
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484845
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158228
INFO:root:FL Epoch: 278 Norm Difference for worker 825 is 1.505277
INFO:root:FL Epoch: 278 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1670
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754218
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239305
INFO:root:FL Epoch: 278 Norm Difference for worker 1670 is 1.492399
INFO:root:FL Epoch: 278 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1007
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538958
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225280
INFO:root:FL Epoch: 278 Norm Difference for worker 1007 is 1.547049
INFO:root:FL Epoch: 278 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 201 201 200 200]
INFO:root:The chosen ones are users: [4 0 7 5 1 8 9], which are global users: [1597, 103, 825, 227, 304, 1670, 1007]
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.46719035856864033 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.27589062104622525                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1013
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903864
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437115
INFO:root:FL Epoch: 279 Norm Difference for worker 1013 is 1.739244
INFO:root:FL Epoch: 279 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :873
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472525
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366912
INFO:root:FL Epoch: 279 Norm Difference for worker 873 is 1.59302
INFO:root:FL Epoch: 279 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1343
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406177
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324001
INFO:root:FL Epoch: 279 Norm Difference for worker 1343 is 1.515217
INFO:root:FL Epoch: 279 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1746
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398864
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352780
INFO:root:FL Epoch: 279 Norm Difference for worker 1746 is 1.701212
INFO:root:FL Epoch: 279 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :499
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496036
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168550
INFO:root:FL Epoch: 279 Norm Difference for worker 499 is 1.515196
INFO:root:FL Epoch: 279 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1131
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688005
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395389
INFO:root:FL Epoch: 279 Norm Difference for worker 1131 is 1.695376
INFO:root:FL Epoch: 279 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :310
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 310 is 1.585433
INFO:root:FL Epoch: 279 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :223
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.308947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 223 is 1.688464
INFO:root:FL Epoch: 279 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1692
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615830
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389638
INFO:root:FL Epoch: 279 Norm Difference for worker 1692 is 1.756971
INFO:root:FL Epoch: 279 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1352
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616169
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236444
INFO:root:FL Epoch: 279 Norm Difference for worker 1352 is 1.554342
INFO:root:FL Epoch: 279 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [4 9 6 2 1 7 5], which are global users: [499, 1352, 310, 1343, 873, 223, 1131]
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.4867728352546692 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.37666143228610355                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1925
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309728
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313239
INFO:root:FL Epoch: 280 Norm Difference for worker 1925 is 1.639467
INFO:root:FL Epoch: 280 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1145
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465879
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281306
INFO:root:FL Epoch: 280 Norm Difference for worker 1145 is 1.574587
INFO:root:FL Epoch: 280 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :636
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508113
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279876
INFO:root:FL Epoch: 280 Norm Difference for worker 636 is 1.664975
INFO:root:FL Epoch: 280 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1906
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721048
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356233
INFO:root:FL Epoch: 280 Norm Difference for worker 1906 is 1.567307
INFO:root:FL Epoch: 280 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1542
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556975
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404181
INFO:root:FL Epoch: 280 Norm Difference for worker 1542 is 1.565878
INFO:root:FL Epoch: 280 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :348
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361722
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247297
INFO:root:FL Epoch: 280 Norm Difference for worker 348 is 1.465187
INFO:root:FL Epoch: 280 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :704
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797985
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341798
INFO:root:FL Epoch: 280 Norm Difference for worker 704 is 1.416354
INFO:root:FL Epoch: 280 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1809
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497529
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296080
INFO:root:FL Epoch: 280 Norm Difference for worker 1809 is 1.498066
INFO:root:FL Epoch: 280 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1212
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634150
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307128
INFO:root:FL Epoch: 280 Norm Difference for worker 1212 is 1.504386
INFO:root:FL Epoch: 280 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1390
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428446
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218599
INFO:root:FL Epoch: 280 Norm Difference for worker 1390 is 1.422493
INFO:root:FL Epoch: 280 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 3 7 5 4], which are global users: [704, 1390, 1212, 1906, 1809, 348, 1542]
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.4655630781370051 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.3235944335659345                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.161539
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142339
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.11029308040936787 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.12724943421781063 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.299296
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310127
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153950
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.11476434643069904 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.12630175724625586 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.295769
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.210795
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137310
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.12626219416658083 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.13000450879335404 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.275548
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :907
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428857
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354975
INFO:root:FL Epoch: 281 Norm Difference for worker 907 is 1.556853
INFO:root:FL Epoch: 281 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :330
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 330 is 1.638174
INFO:root:FL Epoch: 281 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1916
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264989
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317104
INFO:root:FL Epoch: 281 Norm Difference for worker 1916 is 1.478885
INFO:root:FL Epoch: 281 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1435
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452809
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376363
INFO:root:FL Epoch: 281 Norm Difference for worker 1435 is 1.515133
INFO:root:FL Epoch: 281 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1385
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718356
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263025
INFO:root:FL Epoch: 281 Norm Difference for worker 1385 is 1.522485
INFO:root:FL Epoch: 281 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1108
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453123
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472514
INFO:root:FL Epoch: 281 Norm Difference for worker 1108 is 1.583405
INFO:root:FL Epoch: 281 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :449
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486775
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170403
INFO:root:FL Epoch: 281 Norm Difference for worker 449 is 1.546393
INFO:root:FL Epoch: 281 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 5 9], which are global users: [1435, 0, 2, 1385, 1, 1916, 449]
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.46852879138553843 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.19346298898259798                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 282 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :194
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 194 is 1.59253
INFO:root:FL Epoch: 282 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1670
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260513
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201052
INFO:root:FL Epoch: 282 Norm Difference for worker 1670 is 1.527018
INFO:root:FL Epoch: 282 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :368
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591168
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324774
INFO:root:FL Epoch: 282 Norm Difference for worker 368 is 1.592499
INFO:root:FL Epoch: 282 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1195
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459026
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214930
INFO:root:FL Epoch: 282 Norm Difference for worker 1195 is 1.516679
INFO:root:FL Epoch: 282 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1701
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248239
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247183
INFO:root:FL Epoch: 282 Norm Difference for worker 1701 is 1.545248
INFO:root:FL Epoch: 282 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :24
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 24 is 1.550453
INFO:root:FL Epoch: 282 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1893
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553049
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291453
INFO:root:FL Epoch: 282 Norm Difference for worker 1893 is 1.66757
INFO:root:FL Epoch: 282 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1109
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659720
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195207
INFO:root:FL Epoch: 282 Norm Difference for worker 1109 is 1.619924
INFO:root:FL Epoch: 282 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1734
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619556
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204603
INFO:root:FL Epoch: 282 Norm Difference for worker 1734 is 1.478895
INFO:root:FL Epoch: 282 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.249874
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.183618
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 1.41683
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 201 201]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 0], which are global users: [1734, 324, 368, 1195, 1670, 24, 194]
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.4594574535594267 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.21907822787761688                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :177
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.196324
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 177 is 1.614132
INFO:root:FL Epoch: 283 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :4
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 4 is 1.582903
INFO:root:FL Epoch: 283 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1015
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505324
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233777
INFO:root:FL Epoch: 283 Norm Difference for worker 1015 is 1.571499
INFO:root:FL Epoch: 283 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :346
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296953
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217493
INFO:root:FL Epoch: 283 Norm Difference for worker 346 is 1.468211
INFO:root:FL Epoch: 283 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :215
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 215 is 1.504463
INFO:root:FL Epoch: 283 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :938
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444559
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399075
INFO:root:FL Epoch: 283 Norm Difference for worker 938 is 1.662349
INFO:root:FL Epoch: 283 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1805
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367012
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339089
INFO:root:FL Epoch: 283 Norm Difference for worker 1805 is 1.672334
INFO:root:FL Epoch: 283 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :495
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601981
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148208
INFO:root:FL Epoch: 283 Norm Difference for worker 495 is 1.576847
INFO:root:FL Epoch: 283 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :999
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309643
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349698
INFO:root:FL Epoch: 283 Norm Difference for worker 999 is 1.539518
INFO:root:FL Epoch: 283 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1886
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688267
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322590
INFO:root:FL Epoch: 283 Norm Difference for worker 1886 is 1.542638
INFO:root:FL Epoch: 283 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 4 8 3 1 9 2], which are global users: [495, 215, 999, 346, 4, 1886, 1015]
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.4639793862314785 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.21390597273906073                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :386
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419824
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257405
INFO:root:FL Epoch: 284 Norm Difference for worker 386 is 1.415125
INFO:root:FL Epoch: 284 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1503
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311971
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249524
INFO:root:FL Epoch: 284 Norm Difference for worker 1503 is 1.620724
INFO:root:FL Epoch: 284 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1701
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438210
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482398
INFO:root:FL Epoch: 284 Norm Difference for worker 1701 is 1.508597
INFO:root:FL Epoch: 284 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :862
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571865
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246279
INFO:root:FL Epoch: 284 Norm Difference for worker 862 is 1.702362
INFO:root:FL Epoch: 284 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1169
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767416
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345549
INFO:root:FL Epoch: 284 Norm Difference for worker 1169 is 1.538228
INFO:root:FL Epoch: 284 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :346
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431557
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209807
INFO:root:FL Epoch: 284 Norm Difference for worker 346 is 1.362134
INFO:root:FL Epoch: 284 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577144
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284717
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 1.54225
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1492
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403067
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233879
INFO:root:FL Epoch: 284 Norm Difference for worker 1492 is 1.467431
INFO:root:FL Epoch: 284 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1401
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563213
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325902
INFO:root:FL Epoch: 284 Norm Difference for worker 1401 is 1.596357
INFO:root:FL Epoch: 284 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :424
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574756
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277022
INFO:root:FL Epoch: 284 Norm Difference for worker 424 is 1.438738
INFO:root:FL Epoch: 284 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 9 7 4 2 6], which are global users: [346, 386, 424, 1492, 1169, 1701, 852]
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.4748694475959329 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.2726247397561868                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :1837
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420232
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284152
INFO:root:FL Epoch: 285 Norm Difference for worker 1837 is 1.562942
INFO:root:FL Epoch: 285 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :824
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761464
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381015
INFO:root:FL Epoch: 285 Norm Difference for worker 824 is 1.524885
INFO:root:FL Epoch: 285 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1007
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546466
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276781
INFO:root:FL Epoch: 285 Norm Difference for worker 1007 is 1.54468
INFO:root:FL Epoch: 285 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :253
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 253 is 1.502246
INFO:root:FL Epoch: 285 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1875
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364873
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219241
INFO:root:FL Epoch: 285 Norm Difference for worker 1875 is 1.656874
INFO:root:FL Epoch: 285 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :985
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718478
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362906
INFO:root:FL Epoch: 285 Norm Difference for worker 985 is 1.604191
INFO:root:FL Epoch: 285 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1657
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271756
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269002
INFO:root:FL Epoch: 285 Norm Difference for worker 1657 is 1.614042
INFO:root:FL Epoch: 285 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :468
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416951
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238502
INFO:root:FL Epoch: 285 Norm Difference for worker 468 is 1.605684
INFO:root:FL Epoch: 285 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1548
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446300
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307719
INFO:root:FL Epoch: 285 Norm Difference for worker 1548 is 1.659953
INFO:root:FL Epoch: 285 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1947
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572956
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253057
INFO:root:FL Epoch: 285 Norm Difference for worker 1947 is 1.421651
INFO:root:FL Epoch: 285 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [1 9 2 3 0 7 5], which are global users: [824, 1947, 1007, 253, 1837, 468, 985]
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.47162825044463663 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.2910940498113632                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1275
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395539
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133634
INFO:root:FL Epoch: 286 Norm Difference for worker 1275 is 1.485456
INFO:root:FL Epoch: 286 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1599
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725696
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352859
INFO:root:FL Epoch: 286 Norm Difference for worker 1599 is 1.645768
INFO:root:FL Epoch: 286 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :419
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589869
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212978
INFO:root:FL Epoch: 286 Norm Difference for worker 419 is 1.414735
INFO:root:FL Epoch: 286 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :900
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491766
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422078
INFO:root:FL Epoch: 286 Norm Difference for worker 900 is 1.519354
INFO:root:FL Epoch: 286 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :474
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533412
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234298
INFO:root:FL Epoch: 286 Norm Difference for worker 474 is 1.703084
INFO:root:FL Epoch: 286 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :471
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393969
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248615
INFO:root:FL Epoch: 286 Norm Difference for worker 471 is 1.670567
INFO:root:FL Epoch: 286 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1727
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548521
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231839
INFO:root:FL Epoch: 286 Norm Difference for worker 1727 is 1.496739
INFO:root:FL Epoch: 286 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :881
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376483
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186433
INFO:root:FL Epoch: 286 Norm Difference for worker 881 is 1.408337
INFO:root:FL Epoch: 286 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :697
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348509
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415467
INFO:root:FL Epoch: 286 Norm Difference for worker 697 is 1.689931
INFO:root:FL Epoch: 286 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :483
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562741
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305213
INFO:root:FL Epoch: 286 Norm Difference for worker 483 is 1.509448
INFO:root:FL Epoch: 286 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 0 6 1], which are global users: [881, 483, 419, 900, 1275, 1727, 1599]
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.4438877912128673 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.23220525806148848                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1262
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631494
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469239
INFO:root:FL Epoch: 287 Norm Difference for worker 1262 is 1.746095
INFO:root:FL Epoch: 287 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :690
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522027
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141614
INFO:root:FL Epoch: 287 Norm Difference for worker 690 is 1.62438
INFO:root:FL Epoch: 287 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :59
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 59 is 1.463318
INFO:root:FL Epoch: 287 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1825
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564882
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395916
INFO:root:FL Epoch: 287 Norm Difference for worker 1825 is 1.592142
INFO:root:FL Epoch: 287 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709662
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289219
INFO:root:FL Epoch: 287 Norm Difference for worker 509 is 1.778754
INFO:root:FL Epoch: 287 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :444
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565880
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238855
INFO:root:FL Epoch: 287 Norm Difference for worker 444 is 1.717184
INFO:root:FL Epoch: 287 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :246
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.808919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 246 is 1.607501
INFO:root:FL Epoch: 287 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :841
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540831
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319988
INFO:root:FL Epoch: 287 Norm Difference for worker 841 is 1.566749
INFO:root:FL Epoch: 287 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :417
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400625
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480566
INFO:root:FL Epoch: 287 Norm Difference for worker 417 is 1.661896
INFO:root:FL Epoch: 287 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512727
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189918
INFO:root:FL Epoch: 287 Norm Difference for worker 1509 is 1.631794
INFO:root:FL Epoch: 287 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 3 2 7 9 1 8], which are global users: [246, 1825, 59, 841, 1509, 690, 417]
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.441188023370855 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.22377603501081467                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :893
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543599
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278215
INFO:root:FL Epoch: 288 Norm Difference for worker 893 is 1.474936
INFO:root:FL Epoch: 288 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :133
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 133 is 1.504526
INFO:root:FL Epoch: 288 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :732
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579640
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387448
INFO:root:FL Epoch: 288 Norm Difference for worker 732 is 1.522151
INFO:root:FL Epoch: 288 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471066
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383035
INFO:root:FL Epoch: 288 Norm Difference for worker 912 is 1.400171
INFO:root:FL Epoch: 288 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :831
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640377
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158929
INFO:root:FL Epoch: 288 Norm Difference for worker 831 is 1.489179
INFO:root:FL Epoch: 288 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1258
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587006
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113394
INFO:root:FL Epoch: 288 Norm Difference for worker 1258 is 1.481516
INFO:root:FL Epoch: 288 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1406
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427309
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346723
INFO:root:FL Epoch: 288 Norm Difference for worker 1406 is 1.497072
INFO:root:FL Epoch: 288 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :510
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361950
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259326
INFO:root:FL Epoch: 288 Norm Difference for worker 510 is 1.470632
INFO:root:FL Epoch: 288 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :75
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539050
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.366193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 75 is 1.606054
INFO:root:FL Epoch: 288 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1065
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865502
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393927
INFO:root:FL Epoch: 288 Norm Difference for worker 1065 is 1.564059
INFO:root:FL Epoch: 288 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [3 4 0 7 6 5 1], which are global users: [912, 831, 893, 510, 1406, 1258, 133]
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.4499494748957017 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.2198267417649428                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :444
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619708
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212783
INFO:root:FL Epoch: 289 Norm Difference for worker 444 is 1.58179
INFO:root:FL Epoch: 289 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1645
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543560
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264121
INFO:root:FL Epoch: 289 Norm Difference for worker 1645 is 1.390459
INFO:root:FL Epoch: 289 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :199
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 199 is 1.731925
INFO:root:FL Epoch: 289 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :500
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387645
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331333
INFO:root:FL Epoch: 289 Norm Difference for worker 500 is 1.492573
INFO:root:FL Epoch: 289 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :917
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645281
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379441
INFO:root:FL Epoch: 289 Norm Difference for worker 917 is 1.644391
INFO:root:FL Epoch: 289 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1421
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332616
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209955
INFO:root:FL Epoch: 289 Norm Difference for worker 1421 is 1.376539
INFO:root:FL Epoch: 289 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1485
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507773
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325238
INFO:root:FL Epoch: 289 Norm Difference for worker 1485 is 1.442043
INFO:root:FL Epoch: 289 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :306
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.139167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 306 is 1.482183
INFO:root:FL Epoch: 289 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :638
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564266
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283111
INFO:root:FL Epoch: 289 Norm Difference for worker 638 is 1.412098
INFO:root:FL Epoch: 289 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1471
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495648
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322070
INFO:root:FL Epoch: 289 Norm Difference for worker 1471 is 1.5362
INFO:root:FL Epoch: 289 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 8 3 1 5 6], which are global users: [306, 1471, 638, 500, 1645, 1421, 1485]
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.44759924709796906 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.24260046953956285                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1328
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526168
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231430
INFO:root:FL Epoch: 290 Norm Difference for worker 1328 is 1.553856
INFO:root:FL Epoch: 290 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :498
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467562
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219726
INFO:root:FL Epoch: 290 Norm Difference for worker 498 is 1.464692
INFO:root:FL Epoch: 290 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1566
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769567
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250884
INFO:root:FL Epoch: 290 Norm Difference for worker 1566 is 1.495813
INFO:root:FL Epoch: 290 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1908
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327437
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245049
INFO:root:FL Epoch: 290 Norm Difference for worker 1908 is 1.567324
INFO:root:FL Epoch: 290 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1688
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583391
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294020
INFO:root:FL Epoch: 290 Norm Difference for worker 1688 is 1.506705
INFO:root:FL Epoch: 290 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :885
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431506
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213206
INFO:root:FL Epoch: 290 Norm Difference for worker 885 is 1.502035
INFO:root:FL Epoch: 290 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :907
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420265
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309020
INFO:root:FL Epoch: 290 Norm Difference for worker 907 is 1.513563
INFO:root:FL Epoch: 290 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1256
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569742
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287222
INFO:root:FL Epoch: 290 Norm Difference for worker 1256 is 1.413133
INFO:root:FL Epoch: 290 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1058
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346558
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234609
INFO:root:FL Epoch: 290 Norm Difference for worker 1058 is 1.681487
INFO:root:FL Epoch: 290 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1876
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681769
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223026
INFO:root:FL Epoch: 290 Norm Difference for worker 1876 is 1.671567
INFO:root:FL Epoch: 290 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 7 1 5 0], which are global users: [907, 1688, 1566, 1256, 498, 885, 1328]
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.4487960654146531 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.24768920491139093                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235252
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121837
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.12912243356307349 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.13417662754654885 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.239111
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206518
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174736
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.13454512506723404 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.13202748969197273 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.241579
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.173342
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313485
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.13859859108924866 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.13036724478006362 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.243025
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1366
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362152
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277788
INFO:root:FL Epoch: 291 Norm Difference for worker 1366 is 1.552116
INFO:root:FL Epoch: 291 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1025
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787761
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317434
INFO:root:FL Epoch: 291 Norm Difference for worker 1025 is 1.569669
INFO:root:FL Epoch: 291 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1801
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508063
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394023
INFO:root:FL Epoch: 291 Norm Difference for worker 1801 is 1.577871
INFO:root:FL Epoch: 291 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1023
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420739
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381162
INFO:root:FL Epoch: 291 Norm Difference for worker 1023 is 1.448578
INFO:root:FL Epoch: 291 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :476
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247636
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159305
INFO:root:FL Epoch: 291 Norm Difference for worker 476 is 1.654837
INFO:root:FL Epoch: 291 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401115
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310306
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 1.699266
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1114
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316323
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396677
INFO:root:FL Epoch: 291 Norm Difference for worker 1114 is 1.653103
INFO:root:FL Epoch: 291 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 4 5], which are global users: [1023, 0, 2, 1366, 1, 1025, 1801]
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.4395619315259597 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.18000469108422598                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1472
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440995
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278161
INFO:root:FL Epoch: 292 Norm Difference for worker 1472 is 1.692342
INFO:root:FL Epoch: 292 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1744
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.980523
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188908
INFO:root:FL Epoch: 292 Norm Difference for worker 1744 is 1.495819
INFO:root:FL Epoch: 292 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :373
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535880
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245712
INFO:root:FL Epoch: 292 Norm Difference for worker 373 is 1.647885
INFO:root:FL Epoch: 292 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1755
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462432
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304607
INFO:root:FL Epoch: 292 Norm Difference for worker 1755 is 1.458895
INFO:root:FL Epoch: 292 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1251
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538653
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288223
INFO:root:FL Epoch: 292 Norm Difference for worker 1251 is 1.624503
INFO:root:FL Epoch: 292 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :364
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315234
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253727
INFO:root:FL Epoch: 292 Norm Difference for worker 364 is 1.589011
INFO:root:FL Epoch: 292 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :894
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274259
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150251
INFO:root:FL Epoch: 292 Norm Difference for worker 894 is 1.407597
INFO:root:FL Epoch: 292 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1005
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609717
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435392
INFO:root:FL Epoch: 292 Norm Difference for worker 1005 is 1.60438
INFO:root:FL Epoch: 292 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :388
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351441
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246578
INFO:root:FL Epoch: 292 Norm Difference for worker 388 is 1.474853
INFO:root:FL Epoch: 292 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1242
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288972
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240778
INFO:root:FL Epoch: 292 Norm Difference for worker 1242 is 1.542099
INFO:root:FL Epoch: 292 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 3 1 4 5], which are global users: [894, 1242, 388, 1755, 1744, 1251, 364]
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.4661711384268368 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.18543048575520515                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1224
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686733
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453566
INFO:root:FL Epoch: 293 Norm Difference for worker 1224 is 1.671181
INFO:root:FL Epoch: 293 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :983
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641092
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425266
INFO:root:FL Epoch: 293 Norm Difference for worker 983 is 1.747644
INFO:root:FL Epoch: 293 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1414
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704765
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212993
INFO:root:FL Epoch: 293 Norm Difference for worker 1414 is 1.575388
INFO:root:FL Epoch: 293 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1763
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671881
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226360
INFO:root:FL Epoch: 293 Norm Difference for worker 1763 is 1.58618
INFO:root:FL Epoch: 293 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :305
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.265226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 305 is 1.474138
INFO:root:FL Epoch: 293 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :650
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353685
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669690
INFO:root:FL Epoch: 293 Norm Difference for worker 650 is 1.612432
INFO:root:FL Epoch: 293 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1660
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454290
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294357
INFO:root:FL Epoch: 293 Norm Difference for worker 1660 is 1.496403
INFO:root:FL Epoch: 293 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1700
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270942
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254460
INFO:root:FL Epoch: 293 Norm Difference for worker 1700 is 1.458806
INFO:root:FL Epoch: 293 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1483
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769041
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177569
INFO:root:FL Epoch: 293 Norm Difference for worker 1483 is 1.338783
INFO:root:FL Epoch: 293 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :860
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586391
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345078
INFO:root:FL Epoch: 293 Norm Difference for worker 860 is 1.696509
INFO:root:FL Epoch: 293 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 3 8 5 6], which are global users: [1700, 305, 1414, 1763, 1483, 650, 1660]
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.4641118189867805 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.14210678761204085                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :318
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246634
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 318 is 1.459983
INFO:root:FL Epoch: 294 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1700
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.214407
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249811
INFO:root:FL Epoch: 294 Norm Difference for worker 1700 is 1.286716
INFO:root:FL Epoch: 294 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :951
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719498
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249866
INFO:root:FL Epoch: 294 Norm Difference for worker 951 is 1.574694
INFO:root:FL Epoch: 294 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1022
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432779
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207738
INFO:root:FL Epoch: 294 Norm Difference for worker 1022 is 1.45046
INFO:root:FL Epoch: 294 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1087
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277713
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191974
INFO:root:FL Epoch: 294 Norm Difference for worker 1087 is 1.481152
INFO:root:FL Epoch: 294 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :931
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573025
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261705
INFO:root:FL Epoch: 294 Norm Difference for worker 931 is 1.60204
INFO:root:FL Epoch: 294 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :653
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408454
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251350
INFO:root:FL Epoch: 294 Norm Difference for worker 653 is 1.518546
INFO:root:FL Epoch: 294 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :272
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 272 is 1.350691
INFO:root:FL Epoch: 294 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1459
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544669
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387428
INFO:root:FL Epoch: 294 Norm Difference for worker 1459 is 1.629684
INFO:root:FL Epoch: 294 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1399
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325846
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209739
INFO:root:FL Epoch: 294 Norm Difference for worker 1399 is 1.541564
INFO:root:FL Epoch: 294 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 7 3 4 6 9], which are global users: [1700, 318, 272, 1022, 1087, 653, 1399]
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.47391368536388173 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.21465042357643446                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :675
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563621
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286822
INFO:root:FL Epoch: 295 Norm Difference for worker 675 is 1.704397
INFO:root:FL Epoch: 295 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1942
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529932
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261285
INFO:root:FL Epoch: 295 Norm Difference for worker 1942 is 1.660014
INFO:root:FL Epoch: 295 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1406
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607900
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190987
INFO:root:FL Epoch: 295 Norm Difference for worker 1406 is 1.422679
INFO:root:FL Epoch: 295 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1321
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567165
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285004
INFO:root:FL Epoch: 295 Norm Difference for worker 1321 is 1.6823
INFO:root:FL Epoch: 295 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :443
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452914
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437039
INFO:root:FL Epoch: 295 Norm Difference for worker 443 is 1.696814
INFO:root:FL Epoch: 295 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :427
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491561
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256715
INFO:root:FL Epoch: 295 Norm Difference for worker 427 is 1.543926
INFO:root:FL Epoch: 295 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1883
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612878
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397748
INFO:root:FL Epoch: 295 Norm Difference for worker 1883 is 1.626716
INFO:root:FL Epoch: 295 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :918
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509856
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267278
INFO:root:FL Epoch: 295 Norm Difference for worker 918 is 1.571619
INFO:root:FL Epoch: 295 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :638
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644393
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370921
INFO:root:FL Epoch: 295 Norm Difference for worker 638 is 1.420616
INFO:root:FL Epoch: 295 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1630
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494350
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487291
INFO:root:FL Epoch: 295 Norm Difference for worker 1630 is 1.751514
INFO:root:FL Epoch: 295 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 8 2 7 6 1 3], which are global users: [427, 638, 1406, 918, 1883, 1942, 1321]
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.4798853923292721 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.22869328781962395                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1480
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546836
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223709
INFO:root:FL Epoch: 296 Norm Difference for worker 1480 is 1.661253
INFO:root:FL Epoch: 296 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :79
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465768
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 79 is 1.511758
INFO:root:FL Epoch: 296 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1343
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426140
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149919
INFO:root:FL Epoch: 296 Norm Difference for worker 1343 is 1.499748
INFO:root:FL Epoch: 296 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1312
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617314
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200997
INFO:root:FL Epoch: 296 Norm Difference for worker 1312 is 1.491141
INFO:root:FL Epoch: 296 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :198
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 198 is 1.557327
INFO:root:FL Epoch: 296 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611146
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238520
INFO:root:FL Epoch: 296 Norm Difference for worker 1941 is 1.405627
INFO:root:FL Epoch: 296 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :975
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467786
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164448
INFO:root:FL Epoch: 296 Norm Difference for worker 975 is 1.60473
INFO:root:FL Epoch: 296 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :496
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285509
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178299
INFO:root:FL Epoch: 296 Norm Difference for worker 496 is 1.47995
INFO:root:FL Epoch: 296 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472946
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441053
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 1.545972
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1032
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376614
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217216
INFO:root:FL Epoch: 296 Norm Difference for worker 1032 is 1.485764
INFO:root:FL Epoch: 296 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [496, 1032, 1343, 1312, 79, 1941, 1075]
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.4446708559989929 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.24452038606007895                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :1570
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544503
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149463
INFO:root:FL Epoch: 297 Norm Difference for worker 1570 is 1.483261
INFO:root:FL Epoch: 297 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1715
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549338
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344245
INFO:root:FL Epoch: 297 Norm Difference for worker 1715 is 1.683097
INFO:root:FL Epoch: 297 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468438
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361382
INFO:root:FL Epoch: 297 Norm Difference for worker 1205 is 1.484819
INFO:root:FL Epoch: 297 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1159
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533031
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308811
INFO:root:FL Epoch: 297 Norm Difference for worker 1159 is 1.595582
INFO:root:FL Epoch: 297 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1186
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659057
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271555
INFO:root:FL Epoch: 297 Norm Difference for worker 1186 is 1.779542
INFO:root:FL Epoch: 297 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :734
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564695
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289852
INFO:root:FL Epoch: 297 Norm Difference for worker 734 is 1.360922
INFO:root:FL Epoch: 297 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1461
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436480
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241926
INFO:root:FL Epoch: 297 Norm Difference for worker 1461 is 1.450592
INFO:root:FL Epoch: 297 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :100
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.325547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 100 is 1.641235
INFO:root:FL Epoch: 297 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :989
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759995
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349347
INFO:root:FL Epoch: 297 Norm Difference for worker 989 is 1.548847
INFO:root:FL Epoch: 297 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1614
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406886
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377818
INFO:root:FL Epoch: 297 Norm Difference for worker 1614 is 1.663394
INFO:root:FL Epoch: 297 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 8 2 0 6 7 3], which are global users: [734, 989, 1205, 1570, 1461, 100, 1159]
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.47056976486654845 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.25298621505498886                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :535
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732673
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300754
INFO:root:FL Epoch: 298 Norm Difference for worker 535 is 1.511139
INFO:root:FL Epoch: 298 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :268
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 268 is 1.638771
INFO:root:FL Epoch: 298 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :968
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360208
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364761
INFO:root:FL Epoch: 298 Norm Difference for worker 968 is 1.506058
INFO:root:FL Epoch: 298 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :728
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643575
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417714
INFO:root:FL Epoch: 298 Norm Difference for worker 728 is 1.658895
INFO:root:FL Epoch: 298 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :188
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.223873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 188 is 1.476618
INFO:root:FL Epoch: 298 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1851
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688284
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417289
INFO:root:FL Epoch: 298 Norm Difference for worker 1851 is 1.622403
INFO:root:FL Epoch: 298 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1892
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337656
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351816
INFO:root:FL Epoch: 298 Norm Difference for worker 1892 is 1.442763
INFO:root:FL Epoch: 298 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :580
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343798
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344106
INFO:root:FL Epoch: 298 Norm Difference for worker 580 is 1.61146
INFO:root:FL Epoch: 298 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1226
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422905
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265295
INFO:root:FL Epoch: 298 Norm Difference for worker 1226 is 1.573873
INFO:root:FL Epoch: 298 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1003
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458414
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160479
INFO:root:FL Epoch: 298 Norm Difference for worker 1003 is 1.427044
INFO:root:FL Epoch: 298 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 4 0 2 8 7], which are global users: [1892, 1003, 188, 535, 968, 1226, 580]
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.4614509764839621 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.20214545354247093                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1318
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616307
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189262
INFO:root:FL Epoch: 299 Norm Difference for worker 1318 is 1.517155
INFO:root:FL Epoch: 299 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463530
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214321
INFO:root:FL Epoch: 299 Norm Difference for worker 1648 is 1.572701
INFO:root:FL Epoch: 299 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :781
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674398
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335894
INFO:root:FL Epoch: 299 Norm Difference for worker 781 is 1.558753
INFO:root:FL Epoch: 299 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1817
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546752
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283856
INFO:root:FL Epoch: 299 Norm Difference for worker 1817 is 1.631551
INFO:root:FL Epoch: 299 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657630
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244139
INFO:root:FL Epoch: 299 Norm Difference for worker 648 is 1.479977
INFO:root:FL Epoch: 299 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :144
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.796387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 144 is 1.62903
INFO:root:FL Epoch: 299 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1139
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429147
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233795
INFO:root:FL Epoch: 299 Norm Difference for worker 1139 is 1.476445
INFO:root:FL Epoch: 299 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1156
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350166
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186409
INFO:root:FL Epoch: 299 Norm Difference for worker 1156 is 1.423994
INFO:root:FL Epoch: 299 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :598
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669302
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344740
INFO:root:FL Epoch: 299 Norm Difference for worker 598 is 1.61465
INFO:root:FL Epoch: 299 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :650
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542537
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181683
INFO:root:FL Epoch: 299 Norm Difference for worker 650 is 1.603899
INFO:root:FL Epoch: 299 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 7 4 2 3 9], which are global users: [1139, 1318, 1156, 648, 781, 1817, 650]
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.45836170631296497 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.1857658252120018                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1467
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384886
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184652
INFO:root:FL Epoch: 300 Norm Difference for worker 1467 is 1.505581
INFO:root:FL Epoch: 300 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1937
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301322
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269678
INFO:root:FL Epoch: 300 Norm Difference for worker 1937 is 1.681069
INFO:root:FL Epoch: 300 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1312
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287497
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.128173
INFO:root:FL Epoch: 300 Norm Difference for worker 1312 is 1.382467
INFO:root:FL Epoch: 300 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1780
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523802
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344927
INFO:root:FL Epoch: 300 Norm Difference for worker 1780 is 1.380612
INFO:root:FL Epoch: 300 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :228
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.215920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 228 is 1.527987
INFO:root:FL Epoch: 300 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :852
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741634
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216028
INFO:root:FL Epoch: 300 Norm Difference for worker 852 is 1.516685
INFO:root:FL Epoch: 300 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :941
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597421
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313220
INFO:root:FL Epoch: 300 Norm Difference for worker 941 is 1.491618
INFO:root:FL Epoch: 300 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1896
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400839
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256297
INFO:root:FL Epoch: 300 Norm Difference for worker 1896 is 1.509922
INFO:root:FL Epoch: 300 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :414
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288400
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493681
INFO:root:FL Epoch: 300 Norm Difference for worker 414 is 1.584221
INFO:root:FL Epoch: 300 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1088
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478634
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218170
INFO:root:FL Epoch: 300 Norm Difference for worker 1088 is 1.399296
INFO:root:FL Epoch: 300 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 9 2 3 0 7 4], which are global users: [941, 1088, 1312, 1780, 1467, 1896, 228]
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.46591535736532774 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.21907621373732886                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 1443, 486, 588, 551, 1025, 195, 320]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235656
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.120012
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.11186522369583447 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.11709446385502816 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.253759
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.183676
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204241
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.10429093427956104 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.11756502464413643 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.249691
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295801
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227425
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.11007123378415902 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.11456229388713837 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.260252
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1443
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492600
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174994
INFO:root:FL Epoch: 301 Norm Difference for worker 1443 is 1.560632
INFO:root:FL Epoch: 301 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :486
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288258
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324709
INFO:root:FL Epoch: 301 Norm Difference for worker 486 is 1.530002
INFO:root:FL Epoch: 301 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :588
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842690
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369468
INFO:root:FL Epoch: 301 Norm Difference for worker 588 is 1.635399
INFO:root:FL Epoch: 301 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :551
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579985
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276347
INFO:root:FL Epoch: 301 Norm Difference for worker 551 is 1.589862
INFO:root:FL Epoch: 301 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1025
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619916
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339459
INFO:root:FL Epoch: 301 Norm Difference for worker 1025 is 1.594643
INFO:root:FL Epoch: 301 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :195
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 195 is 1.510977
INFO:root:FL Epoch: 301 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :320
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 320 is 1.55563
INFO:root:FL Epoch: 301 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [1 0 2 8 4 3 9], which are global users: [1, 0, 2, 195, 486, 1443, 320]
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.4588903364013223 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.15203777079780897                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [905, 877, 1238, 1840, 1610, 287, 910, 204, 609, 1756]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :905
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640822
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411375
INFO:root:FL Epoch: 302 Norm Difference for worker 905 is 1.662036
INFO:root:FL Epoch: 302 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :877
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668092
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306129
INFO:root:FL Epoch: 302 Norm Difference for worker 877 is 1.544573
INFO:root:FL Epoch: 302 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1238
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470318
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320637
INFO:root:FL Epoch: 302 Norm Difference for worker 1238 is 1.585677
INFO:root:FL Epoch: 302 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1840
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568928
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256650
INFO:root:FL Epoch: 302 Norm Difference for worker 1840 is 1.620568
INFO:root:FL Epoch: 302 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1610
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492134
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429433
INFO:root:FL Epoch: 302 Norm Difference for worker 1610 is 1.644937
INFO:root:FL Epoch: 302 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :287
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762903
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392008
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 287 is 1.607204
INFO:root:FL Epoch: 302 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :910
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383270
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226172
INFO:root:FL Epoch: 302 Norm Difference for worker 910 is 1.454543
INFO:root:FL Epoch: 302 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :204
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 204 is 1.477104
INFO:root:FL Epoch: 302 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :609
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666922
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287630
INFO:root:FL Epoch: 302 Norm Difference for worker 609 is 1.63748
INFO:root:FL Epoch: 302 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1756
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257150
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180999
INFO:root:FL Epoch: 302 Norm Difference for worker 1756 is 1.635487
INFO:root:FL Epoch: 302 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 7 2 6 1 8 3], which are global users: [287, 204, 1238, 910, 877, 609, 1840]
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.48371312372824726 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.19107002764940262                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1753, 1756, 1355, 139, 584, 1564, 174, 1418, 1113, 648]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1753
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615981
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186645
INFO:root:FL Epoch: 303 Norm Difference for worker 1753 is 1.42581
INFO:root:FL Epoch: 303 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1756
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352610
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278082
INFO:root:FL Epoch: 303 Norm Difference for worker 1756 is 1.532199
INFO:root:FL Epoch: 303 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1355
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592375
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408075
INFO:root:FL Epoch: 303 Norm Difference for worker 1355 is 1.574429
INFO:root:FL Epoch: 303 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :139
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.197198
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 139 is 1.499562
INFO:root:FL Epoch: 303 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :584
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484895
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179558
INFO:root:FL Epoch: 303 Norm Difference for worker 584 is 1.578738
INFO:root:FL Epoch: 303 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1564
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882944
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215833
INFO:root:FL Epoch: 303 Norm Difference for worker 1564 is 1.472245
INFO:root:FL Epoch: 303 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :174
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.810805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 174 is 1.607767
INFO:root:FL Epoch: 303 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1418
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635046
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467740
INFO:root:FL Epoch: 303 Norm Difference for worker 1418 is 1.561844
INFO:root:FL Epoch: 303 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1113
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460417
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386058
INFO:root:FL Epoch: 303 Norm Difference for worker 1113 is 1.533934
INFO:root:FL Epoch: 303 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :648
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339447
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235978
INFO:root:FL Epoch: 303 Norm Difference for worker 648 is 1.461035
INFO:root:FL Epoch: 303 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [0 9 7 5 1 3 8], which are global users: [1753, 648, 1418, 1564, 1756, 139, 1113]
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.47362159280215993 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.18680759767691293                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [315, 691, 657, 599, 1341, 285, 1303, 1544, 468, 755]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 304 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :315
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710061
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 315 is 1.487401
INFO:root:FL Epoch: 304 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :691
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403959
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332646
INFO:root:FL Epoch: 304 Norm Difference for worker 691 is 1.457569
INFO:root:FL Epoch: 304 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :657
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417328
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256768
INFO:root:FL Epoch: 304 Norm Difference for worker 657 is 1.561973
INFO:root:FL Epoch: 304 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :599
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479801
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311936
INFO:root:FL Epoch: 304 Norm Difference for worker 599 is 1.430453
INFO:root:FL Epoch: 304 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1341
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645394
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349103
INFO:root:FL Epoch: 304 Norm Difference for worker 1341 is 1.501241
INFO:root:FL Epoch: 304 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :285
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.215373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 285 is 1.396929
INFO:root:FL Epoch: 304 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1303
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515766
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286391
INFO:root:FL Epoch: 304 Norm Difference for worker 1303 is 1.435398
INFO:root:FL Epoch: 304 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1544
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498583
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343994
INFO:root:FL Epoch: 304 Norm Difference for worker 1544 is 1.538873
INFO:root:FL Epoch: 304 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :468
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356778
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322721
INFO:root:FL Epoch: 304 Norm Difference for worker 468 is 1.430613
INFO:root:FL Epoch: 304 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :755
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291250
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260766
INFO:root:FL Epoch: 304 Norm Difference for worker 755 is 1.364226
INFO:root:FL Epoch: 304 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 1 4 6], which are global users: [285, 755, 468, 599, 691, 1341, 1303]
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.47025401276700635 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.19234337781866392                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [28, 1394, 832, 101, 1000, 1708, 385, 352, 1307, 941]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 305 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :28
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 28 is 1.378847
INFO:root:FL Epoch: 305 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1394
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571439
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210562
INFO:root:FL Epoch: 305 Norm Difference for worker 1394 is 1.619415
INFO:root:FL Epoch: 305 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :832
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437202
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407292
INFO:root:FL Epoch: 305 Norm Difference for worker 832 is 1.670496
INFO:root:FL Epoch: 305 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :101
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 101 is 1.380377
INFO:root:FL Epoch: 305 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1000
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690616
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373512
INFO:root:FL Epoch: 305 Norm Difference for worker 1000 is 1.8857
INFO:root:FL Epoch: 305 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1708
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565664
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446396
INFO:root:FL Epoch: 305 Norm Difference for worker 1708 is 1.623318
INFO:root:FL Epoch: 305 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :385
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496012
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463047
INFO:root:FL Epoch: 305 Norm Difference for worker 385 is 1.603932
INFO:root:FL Epoch: 305 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :352
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514132
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313331
INFO:root:FL Epoch: 305 Norm Difference for worker 352 is 1.466621
INFO:root:FL Epoch: 305 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1307
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574138
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392290
INFO:root:FL Epoch: 305 Norm Difference for worker 1307 is 1.477415
INFO:root:FL Epoch: 305 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :941
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405724
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310821
INFO:root:FL Epoch: 305 Norm Difference for worker 941 is 2.139124
INFO:root:FL Epoch: 305 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [0 3 7 6 8 5 1], which are global users: [28, 101, 352, 385, 1307, 1708, 1394]
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.44638706130139966 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.2075334849456946                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [1489, 606, 1775, 681, 834, 643, 1374, 711, 1459, 538]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 306 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :1489
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461385
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401937
INFO:root:FL Epoch: 306 Norm Difference for worker 1489 is 1.634905
INFO:root:FL Epoch: 306 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :606
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420711
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229571
INFO:root:FL Epoch: 306 Norm Difference for worker 606 is 1.361797
INFO:root:FL Epoch: 306 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1775
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808951
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409840
INFO:root:FL Epoch: 306 Norm Difference for worker 1775 is 1.55938
INFO:root:FL Epoch: 306 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :681
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390828
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348876
INFO:root:FL Epoch: 306 Norm Difference for worker 681 is 1.524437
INFO:root:FL Epoch: 306 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :834
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577198
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266393
INFO:root:FL Epoch: 306 Norm Difference for worker 834 is 1.588609
INFO:root:FL Epoch: 306 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :643
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393525
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320655
INFO:root:FL Epoch: 306 Norm Difference for worker 643 is 1.497613
INFO:root:FL Epoch: 306 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1374
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581745
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378429
INFO:root:FL Epoch: 306 Norm Difference for worker 1374 is 1.464181
INFO:root:FL Epoch: 306 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :711
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330910
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303490
INFO:root:FL Epoch: 306 Norm Difference for worker 711 is 1.491649
INFO:root:FL Epoch: 306 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1459
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888956
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470663
INFO:root:FL Epoch: 306 Norm Difference for worker 1459 is 1.656155
INFO:root:FL Epoch: 306 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :538
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386023
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327763
INFO:root:FL Epoch: 306 Norm Difference for worker 538 is 1.459218
INFO:root:FL Epoch: 306 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [711, 538, 1775, 681, 606, 643, 1374]
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.4388380147078458 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.1559831090271473                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [906, 614, 1894, 1327, 596, 1690, 1186, 1923, 510, 784]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :906
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391441
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116515
INFO:root:FL Epoch: 307 Norm Difference for worker 906 is 1.341552
INFO:root:FL Epoch: 307 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :614
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483862
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445403
INFO:root:FL Epoch: 307 Norm Difference for worker 614 is 1.545768
INFO:root:FL Epoch: 307 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1894
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674965
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185218
INFO:root:FL Epoch: 307 Norm Difference for worker 1894 is 1.470572
INFO:root:FL Epoch: 307 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1327
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267275
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431608
INFO:root:FL Epoch: 307 Norm Difference for worker 1327 is 1.462421
INFO:root:FL Epoch: 307 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :596
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562050
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350552
INFO:root:FL Epoch: 307 Norm Difference for worker 596 is 1.539072
INFO:root:FL Epoch: 307 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1690
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516739
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324359
INFO:root:FL Epoch: 307 Norm Difference for worker 1690 is 1.494061
INFO:root:FL Epoch: 307 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1186
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495758
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345225
INFO:root:FL Epoch: 307 Norm Difference for worker 1186 is 1.675984
INFO:root:FL Epoch: 307 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1923
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429373
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380689
INFO:root:FL Epoch: 307 Norm Difference for worker 1923 is 1.502895
INFO:root:FL Epoch: 307 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :510
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513914
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246520
INFO:root:FL Epoch: 307 Norm Difference for worker 510 is 1.413421
INFO:root:FL Epoch: 307 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :784
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421968
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306588
INFO:root:FL Epoch: 307 Norm Difference for worker 784 is 1.400133
INFO:root:FL Epoch: 307 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [0 9 3 2 8 5 7], which are global users: [906, 784, 1327, 1894, 510, 1690, 1923]
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.4402700680143693 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.16371428221464157                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [1266, 207, 1584, 252, 1605, 1486, 1617, 525, 1340, 1914]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 308 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :1266
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675588
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423966
INFO:root:FL Epoch: 308 Norm Difference for worker 1266 is 1.600224
INFO:root:FL Epoch: 308 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :207
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 207 is 1.65007
INFO:root:FL Epoch: 308 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1584
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439029
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270186
INFO:root:FL Epoch: 308 Norm Difference for worker 1584 is 1.556117
INFO:root:FL Epoch: 308 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :252
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 252 is 1.669778
INFO:root:FL Epoch: 308 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1605
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653470
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230737
INFO:root:FL Epoch: 308 Norm Difference for worker 1605 is 1.61237
INFO:root:FL Epoch: 308 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1486
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542867
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227362
INFO:root:FL Epoch: 308 Norm Difference for worker 1486 is 1.61176
INFO:root:FL Epoch: 308 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1617
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508757
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451761
INFO:root:FL Epoch: 308 Norm Difference for worker 1617 is 1.575695
INFO:root:FL Epoch: 308 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :525
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620761
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180250
INFO:root:FL Epoch: 308 Norm Difference for worker 525 is 1.669308
INFO:root:FL Epoch: 308 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1340
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642649
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202197
INFO:root:FL Epoch: 308 Norm Difference for worker 1340 is 1.581083
INFO:root:FL Epoch: 308 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1914
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607237
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209542
INFO:root:FL Epoch: 308 Norm Difference for worker 1914 is 1.542282
INFO:root:FL Epoch: 308 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 4 2 0 5], which are global users: [1617, 1914, 1340, 1605, 1584, 1266, 1486]
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.4347633719444275 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.16358443722128868                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [21, 1041, 1494, 370, 1006, 19, 1204, 583, 1772, 502]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 309 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :21
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.136774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 21 is 1.344654
INFO:root:FL Epoch: 309 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1041
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623625
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209954
INFO:root:FL Epoch: 309 Norm Difference for worker 1041 is 1.444622
INFO:root:FL Epoch: 309 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1494
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913747
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211548
INFO:root:FL Epoch: 309 Norm Difference for worker 1494 is 1.349953
INFO:root:FL Epoch: 309 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :370
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471927
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288391
INFO:root:FL Epoch: 309 Norm Difference for worker 370 is 1.394798
INFO:root:FL Epoch: 309 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1006
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609083
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378404
INFO:root:FL Epoch: 309 Norm Difference for worker 1006 is 1.401773
INFO:root:FL Epoch: 309 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :19
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 19 is 1.475092
INFO:root:FL Epoch: 309 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1204
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318061
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265059
INFO:root:FL Epoch: 309 Norm Difference for worker 1204 is 1.445881
INFO:root:FL Epoch: 309 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :583
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307018
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274195
INFO:root:FL Epoch: 309 Norm Difference for worker 583 is 1.492979
INFO:root:FL Epoch: 309 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1772
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540326
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468385
INFO:root:FL Epoch: 309 Norm Difference for worker 1772 is 1.461978
INFO:root:FL Epoch: 309 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :502
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558994
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295114
INFO:root:FL Epoch: 309 Norm Difference for worker 502 is 1.40754
INFO:root:FL Epoch: 309 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 3 4 9 1], which are global users: [19, 21, 1494, 370, 1006, 502, 1041]
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.4318649330559899 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.21405542145172754                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [167, 201, 537, 1676, 1913, 909, 1534, 585, 658, 1332]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 310 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :167
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.364226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 167 is 1.499745
INFO:root:FL Epoch: 310 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :201
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 201 is 1.534952
INFO:root:FL Epoch: 310 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :537
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515390
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432371
INFO:root:FL Epoch: 310 Norm Difference for worker 537 is 1.625088
INFO:root:FL Epoch: 310 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1676
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489902
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300212
INFO:root:FL Epoch: 310 Norm Difference for worker 1676 is 1.570028
INFO:root:FL Epoch: 310 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1913
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610477
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186750
INFO:root:FL Epoch: 310 Norm Difference for worker 1913 is 1.454568
INFO:root:FL Epoch: 310 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :909
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391500
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243936
INFO:root:FL Epoch: 310 Norm Difference for worker 909 is 1.452862
INFO:root:FL Epoch: 310 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1534
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213524
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213610
INFO:root:FL Epoch: 310 Norm Difference for worker 1534 is 1.381632
INFO:root:FL Epoch: 310 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :585
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777525
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309311
INFO:root:FL Epoch: 310 Norm Difference for worker 585 is 1.475246
INFO:root:FL Epoch: 310 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :658
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774891
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312376
INFO:root:FL Epoch: 310 Norm Difference for worker 658 is 1.622534
INFO:root:FL Epoch: 310 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1332
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593585
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248470
INFO:root:FL Epoch: 310 Norm Difference for worker 1332 is 1.396203
INFO:root:FL Epoch: 310 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 201]
INFO:root:The chosen ones are users: [5 9 7 6 4 0 1], which are global users: [909, 1332, 585, 1534, 1913, 167, 201]
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.4500395830939798 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.1926754837234815                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 1910, 621, 208, 1255, 860, 680, 1770]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242260
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116268
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.11926559483011563 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.1432042822241783 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.221981
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237375
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186889
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.11593160467843215 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.14507355988025666 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.226357
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355610
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261658
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.11847306291262309 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.14433362409472467 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.224337
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1910
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327004
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203618
INFO:root:FL Epoch: 311 Norm Difference for worker 1910 is 1.504074
INFO:root:FL Epoch: 311 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :621
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472035
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225070
INFO:root:FL Epoch: 311 Norm Difference for worker 621 is 1.387679
INFO:root:FL Epoch: 311 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :208
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 208 is 1.444974
INFO:root:FL Epoch: 311 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1255
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512661
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360470
INFO:root:FL Epoch: 311 Norm Difference for worker 1255 is 1.576732
INFO:root:FL Epoch: 311 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :860
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690620
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186651
INFO:root:FL Epoch: 311 Norm Difference for worker 860 is 1.485169
INFO:root:FL Epoch: 311 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :680
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412294
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351888
INFO:root:FL Epoch: 311 Norm Difference for worker 680 is 1.515348
INFO:root:FL Epoch: 311 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1770
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288774
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227505
INFO:root:FL Epoch: 311 Norm Difference for worker 1770 is 1.328018
INFO:root:FL Epoch: 311 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [1 0 2 9 7 4 5], which are global users: [1, 0, 2, 1770, 860, 621, 208]
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.4548787842778599 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.13504448160529137                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [682, 445, 1687, 664, 651, 289, 709, 742, 1093, 800]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :682
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535481
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277511
INFO:root:FL Epoch: 312 Norm Difference for worker 682 is 1.752388
INFO:root:FL Epoch: 312 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :445
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667826
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257400
INFO:root:FL Epoch: 312 Norm Difference for worker 445 is 1.468541
INFO:root:FL Epoch: 312 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1687
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321203
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292855
INFO:root:FL Epoch: 312 Norm Difference for worker 1687 is 1.589386
INFO:root:FL Epoch: 312 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :664
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828880
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546549
INFO:root:FL Epoch: 312 Norm Difference for worker 664 is 1.556281
INFO:root:FL Epoch: 312 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :651
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465691
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270182
INFO:root:FL Epoch: 312 Norm Difference for worker 651 is 1.524533
INFO:root:FL Epoch: 312 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :289
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.156920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 289 is 1.348794
INFO:root:FL Epoch: 312 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :709
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326994
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204502
INFO:root:FL Epoch: 312 Norm Difference for worker 709 is 1.37263
INFO:root:FL Epoch: 312 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :742
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394493
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178163
INFO:root:FL Epoch: 312 Norm Difference for worker 742 is 1.368738
INFO:root:FL Epoch: 312 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1093
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500811
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165817
INFO:root:FL Epoch: 312 Norm Difference for worker 1093 is 1.446348
INFO:root:FL Epoch: 312 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :800
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579608
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116044
INFO:root:FL Epoch: 312 Norm Difference for worker 800 is 1.405012
INFO:root:FL Epoch: 312 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 9 8 7 1 5 4], which are global users: [709, 800, 1093, 742, 445, 289, 651]
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.4621780786444159 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.13416736324628195                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [1508, 834, 1190, 29, 1700, 246, 1120, 1788, 578, 729]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :1508
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888172
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170794
INFO:root:FL Epoch: 313 Norm Difference for worker 1508 is 1.456403
INFO:root:FL Epoch: 313 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :834
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735673
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391168
INFO:root:FL Epoch: 313 Norm Difference for worker 834 is 1.61564
INFO:root:FL Epoch: 313 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1190
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565984
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134747
INFO:root:FL Epoch: 313 Norm Difference for worker 1190 is 1.332748
INFO:root:FL Epoch: 313 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :29
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260285
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 29 is 1.611943
INFO:root:FL Epoch: 313 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1700
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333497
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139684
INFO:root:FL Epoch: 313 Norm Difference for worker 1700 is 1.320481
INFO:root:FL Epoch: 313 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :246
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.769694
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 246 is 1.572058
INFO:root:FL Epoch: 313 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1120
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468401
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534802
INFO:root:FL Epoch: 313 Norm Difference for worker 1120 is 1.662501
INFO:root:FL Epoch: 313 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1788
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410298
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399144
INFO:root:FL Epoch: 313 Norm Difference for worker 1788 is 1.609868
INFO:root:FL Epoch: 313 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :578
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692381
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359533
INFO:root:FL Epoch: 313 Norm Difference for worker 578 is 1.578311
INFO:root:FL Epoch: 313 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :729
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450561
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240501
INFO:root:FL Epoch: 313 Norm Difference for worker 729 is 1.458925
INFO:root:FL Epoch: 313 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [2 4 9 0 8 7 5], which are global users: [1190, 1700, 729, 1508, 578, 1788, 246]
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.4457715048509486 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.1676489089926084                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [1599, 1102, 743, 1678, 1810, 800, 1839, 750, 1145, 1449]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :1599
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377526
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302343
INFO:root:FL Epoch: 314 Norm Difference for worker 1599 is 1.460762
INFO:root:FL Epoch: 314 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1102
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299681
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396167
INFO:root:FL Epoch: 314 Norm Difference for worker 1102 is 1.502637
INFO:root:FL Epoch: 314 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :743
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589458
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186371
INFO:root:FL Epoch: 314 Norm Difference for worker 743 is 1.500181
INFO:root:FL Epoch: 314 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1678
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273578
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191660
INFO:root:FL Epoch: 314 Norm Difference for worker 1678 is 1.40579
INFO:root:FL Epoch: 314 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1810
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408972
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171560
INFO:root:FL Epoch: 314 Norm Difference for worker 1810 is 1.31759
INFO:root:FL Epoch: 314 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :800
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484984
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162063
INFO:root:FL Epoch: 314 Norm Difference for worker 800 is 1.313709
INFO:root:FL Epoch: 314 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1839
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696293
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274927
INFO:root:FL Epoch: 314 Norm Difference for worker 1839 is 1.526787
INFO:root:FL Epoch: 314 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :750
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697332
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405406
INFO:root:FL Epoch: 314 Norm Difference for worker 750 is 1.545739
INFO:root:FL Epoch: 314 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1145
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645122
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215720
INFO:root:FL Epoch: 314 Norm Difference for worker 1145 is 1.601346
INFO:root:FL Epoch: 314 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1449
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557531
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454084
INFO:root:FL Epoch: 314 Norm Difference for worker 1449 is 1.706433
INFO:root:FL Epoch: 314 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 0 1 7], which are global users: [800, 1810, 743, 1678, 1599, 1102, 750]
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.47636637442252217 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.17037382846077284                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [984, 720, 1397, 1394, 1003, 1673, 1271, 1114, 1740, 185]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 315 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :984
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580320
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277956
INFO:root:FL Epoch: 315 Norm Difference for worker 984 is 1.5458
INFO:root:FL Epoch: 315 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :720
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615304
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272937
INFO:root:FL Epoch: 315 Norm Difference for worker 720 is 1.506075
INFO:root:FL Epoch: 315 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1397
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342460
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185391
INFO:root:FL Epoch: 315 Norm Difference for worker 1397 is 1.490606
INFO:root:FL Epoch: 315 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1394
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491247
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194845
INFO:root:FL Epoch: 315 Norm Difference for worker 1394 is 1.536082
INFO:root:FL Epoch: 315 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1003
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558062
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189680
INFO:root:FL Epoch: 315 Norm Difference for worker 1003 is 1.417723
INFO:root:FL Epoch: 315 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1673
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592306
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391399
INFO:root:FL Epoch: 315 Norm Difference for worker 1673 is 1.551962
INFO:root:FL Epoch: 315 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1271
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385404
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307477
INFO:root:FL Epoch: 315 Norm Difference for worker 1271 is 1.489231
INFO:root:FL Epoch: 315 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1114
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529888
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322424
INFO:root:FL Epoch: 315 Norm Difference for worker 1114 is 1.566473
INFO:root:FL Epoch: 315 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1740
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521833
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228042
INFO:root:FL Epoch: 315 Norm Difference for worker 1740 is 1.500208
INFO:root:FL Epoch: 315 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :185
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.243540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 185 is 1.413224
INFO:root:FL Epoch: 315 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 8 2 1 3 6], which are global users: [1003, 185, 1740, 1397, 720, 1394, 1271]
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.45884447413332324 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.17990474527080855                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [1324, 1278, 397, 409, 691, 951, 145, 665, 1649, 1550]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :1324
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544947
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327679
INFO:root:FL Epoch: 316 Norm Difference for worker 1324 is 1.46376
INFO:root:FL Epoch: 316 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1278
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539977
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316256
INFO:root:FL Epoch: 316 Norm Difference for worker 1278 is 1.548295
INFO:root:FL Epoch: 316 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :397
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295526
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220574
INFO:root:FL Epoch: 316 Norm Difference for worker 397 is 1.51286
INFO:root:FL Epoch: 316 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :409
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577759
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206174
INFO:root:FL Epoch: 316 Norm Difference for worker 409 is 1.469172
INFO:root:FL Epoch: 316 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :691
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423273
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378071
INFO:root:FL Epoch: 316 Norm Difference for worker 691 is 1.452226
INFO:root:FL Epoch: 316 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :951
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801093
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265748
INFO:root:FL Epoch: 316 Norm Difference for worker 951 is 1.608385
INFO:root:FL Epoch: 316 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :145
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295029
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 145 is 1.351725
INFO:root:FL Epoch: 316 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :665
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421670
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272443
INFO:root:FL Epoch: 316 Norm Difference for worker 665 is 1.462174
INFO:root:FL Epoch: 316 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1649
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393285
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239461
INFO:root:FL Epoch: 316 Norm Difference for worker 1649 is 1.503909
INFO:root:FL Epoch: 316 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1550
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534315
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184106
INFO:root:FL Epoch: 316 Norm Difference for worker 1550 is 1.394218
INFO:root:FL Epoch: 316 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 9 6 4 7 0 8], which are global users: [409, 1550, 145, 691, 665, 1324, 1649]
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.46615131988244896 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.17642937476436296                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [596, 425, 327, 614, 1586, 1405, 196, 226, 526, 243]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :596
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847329
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212623
INFO:root:FL Epoch: 317 Norm Difference for worker 596 is 1.647474
INFO:root:FL Epoch: 317 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :425
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701254
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304407
INFO:root:FL Epoch: 317 Norm Difference for worker 425 is 1.749412
INFO:root:FL Epoch: 317 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :327
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.874709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 327 is 1.813061
INFO:root:FL Epoch: 317 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :614
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658318
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523092
INFO:root:FL Epoch: 317 Norm Difference for worker 614 is 1.622443
INFO:root:FL Epoch: 317 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1586
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629322
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251194
INFO:root:FL Epoch: 317 Norm Difference for worker 1586 is 1.566443
INFO:root:FL Epoch: 317 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1405
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437447
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187225
INFO:root:FL Epoch: 317 Norm Difference for worker 1405 is 1.481206
INFO:root:FL Epoch: 317 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :196
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 196 is 1.531859
INFO:root:FL Epoch: 317 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :226
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492417
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 226 is 1.563946
INFO:root:FL Epoch: 317 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :526
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239653
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358591
INFO:root:FL Epoch: 317 Norm Difference for worker 526 is 1.68179
INFO:root:FL Epoch: 317 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :243
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.353116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 243 is 1.443067
INFO:root:FL Epoch: 317 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 201 200 201]
INFO:root:Num selected data points: [200 201 201 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 6 4 3 7 8], which are global users: [1405, 243, 196, 1586, 614, 226, 526]
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.46152464168913226 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.18223686640461287                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [253, 748, 1265, 1438, 1466, 1310, 171, 1495, 820, 920]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :253
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 253 is 1.408663
INFO:root:FL Epoch: 318 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :748
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670007
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326556
INFO:root:FL Epoch: 318 Norm Difference for worker 748 is 1.641347
INFO:root:FL Epoch: 318 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1265
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344997
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292636
INFO:root:FL Epoch: 318 Norm Difference for worker 1265 is 1.50812
INFO:root:FL Epoch: 318 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1438
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812890
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414542
INFO:root:FL Epoch: 318 Norm Difference for worker 1438 is 1.503447
INFO:root:FL Epoch: 318 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1466
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483851
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534927
INFO:root:FL Epoch: 318 Norm Difference for worker 1466 is 1.600073
INFO:root:FL Epoch: 318 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1310
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338308
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214897
INFO:root:FL Epoch: 318 Norm Difference for worker 1310 is 1.438353
INFO:root:FL Epoch: 318 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :171
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.921210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.193747
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 171 is 1.478167
INFO:root:FL Epoch: 318 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1495
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613954
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421700
INFO:root:FL Epoch: 318 Norm Difference for worker 1495 is 1.621767
INFO:root:FL Epoch: 318 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :820
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 1.032395
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353002
INFO:root:FL Epoch: 318 Norm Difference for worker 820 is 1.462238
INFO:root:FL Epoch: 318 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :920
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563331
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401241
INFO:root:FL Epoch: 318 Norm Difference for worker 920 is 1.677313
INFO:root:FL Epoch: 318 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 8 5 4], which are global users: [171, 253, 1265, 1438, 820, 1310, 1466]
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.4590236798805349 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.1826428547501564                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1365, 504, 564, 1732, 1905, 1719, 1514, 629, 929, 1382]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1365
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442583
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206400
INFO:root:FL Epoch: 319 Norm Difference for worker 1365 is 1.375322
INFO:root:FL Epoch: 319 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :504
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578592
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379452
INFO:root:FL Epoch: 319 Norm Difference for worker 504 is 1.422041
INFO:root:FL Epoch: 319 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :564
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355183
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184492
INFO:root:FL Epoch: 319 Norm Difference for worker 564 is 1.385731
INFO:root:FL Epoch: 319 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1732
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740809
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310943
INFO:root:FL Epoch: 319 Norm Difference for worker 1732 is 1.498326
INFO:root:FL Epoch: 319 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1905
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500769
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249900
INFO:root:FL Epoch: 319 Norm Difference for worker 1905 is 1.234172
INFO:root:FL Epoch: 319 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1719
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390612
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329626
INFO:root:FL Epoch: 319 Norm Difference for worker 1719 is 1.284976
INFO:root:FL Epoch: 319 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1514
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577545
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266435
INFO:root:FL Epoch: 319 Norm Difference for worker 1514 is 1.397403
INFO:root:FL Epoch: 319 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :629
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401467
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335300
INFO:root:FL Epoch: 319 Norm Difference for worker 629 is 1.351713
INFO:root:FL Epoch: 319 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :929
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698278
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308809
INFO:root:FL Epoch: 319 Norm Difference for worker 929 is 1.504034
INFO:root:FL Epoch: 319 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1382
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617423
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261566
INFO:root:FL Epoch: 319 Norm Difference for worker 1382 is 1.518297
INFO:root:FL Epoch: 319 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 7 0 2 6 1], which are global users: [1719, 1905, 629, 1365, 564, 1514, 504]
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.45329389063750997 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.1951354183256626                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [64, 124, 326, 1653, 535, 1504, 1731, 1934, 1210, 1637]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 320 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :64
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 64 is 1.543172
INFO:root:FL Epoch: 320 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :124
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 124 is 1.506706
INFO:root:FL Epoch: 320 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :326
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.348386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.107366
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 326 is 1.470892
INFO:root:FL Epoch: 320 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1653
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514285
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240656
INFO:root:FL Epoch: 320 Norm Difference for worker 1653 is 1.488729
INFO:root:FL Epoch: 320 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :535
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494857
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563193
INFO:root:FL Epoch: 320 Norm Difference for worker 535 is 1.505958
INFO:root:FL Epoch: 320 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1504
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310188
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251816
INFO:root:FL Epoch: 320 Norm Difference for worker 1504 is 1.554805
INFO:root:FL Epoch: 320 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1731
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361389
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204375
INFO:root:FL Epoch: 320 Norm Difference for worker 1731 is 1.412998
INFO:root:FL Epoch: 320 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1934
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549917
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279241
INFO:root:FL Epoch: 320 Norm Difference for worker 1934 is 1.497374
INFO:root:FL Epoch: 320 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1210
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672854
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403474
INFO:root:FL Epoch: 320 Norm Difference for worker 1210 is 1.480611
INFO:root:FL Epoch: 320 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1637
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379937
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257879
INFO:root:FL Epoch: 320 Norm Difference for worker 1637 is 1.549513
INFO:root:FL Epoch: 320 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 0 7 8], which are global users: [1731, 535, 326, 1653, 64, 1934, 1210]
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.45870061306392446 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.20257368683815002                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 1219, 1730, 471, 792, 1830, 1466, 619]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.222380
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227486
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.11990466465552647 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.1211060881614685 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.213858
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259215
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154282
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.12543736149867377 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.12313395589590073 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.210138
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.197682
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239050
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.11458757519721985 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.12085487470030784 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.220745
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1219
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497910
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471122
INFO:root:FL Epoch: 321 Norm Difference for worker 1219 is 1.539363
INFO:root:FL Epoch: 321 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1730
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604791
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315043
INFO:root:FL Epoch: 321 Norm Difference for worker 1730 is 1.536823
INFO:root:FL Epoch: 321 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :471
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.109224
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239114
INFO:root:FL Epoch: 321 Norm Difference for worker 471 is 1.520214
INFO:root:FL Epoch: 321 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :792
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460802
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377390
INFO:root:FL Epoch: 321 Norm Difference for worker 792 is 1.482874
INFO:root:FL Epoch: 321 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1830
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442689
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204084
INFO:root:FL Epoch: 321 Norm Difference for worker 1830 is 1.517457
INFO:root:FL Epoch: 321 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1466
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221266
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297226
INFO:root:FL Epoch: 321 Norm Difference for worker 1466 is 1.443036
INFO:root:FL Epoch: 321 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :619
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684582
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216363
INFO:root:FL Epoch: 321 Norm Difference for worker 619 is 1.551757
INFO:root:FL Epoch: 321 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [1830, 0, 2, 1466, 1, 471, 792]
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.45368388470481424 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.18024909496307373                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [832, 612, 600, 982, 1725, 1224, 539, 3, 1510, 673]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :832
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457355
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537226
INFO:root:FL Epoch: 322 Norm Difference for worker 832 is 1.662672
INFO:root:FL Epoch: 322 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :612
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807907
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311862
INFO:root:FL Epoch: 322 Norm Difference for worker 612 is 1.476437
INFO:root:FL Epoch: 322 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :600
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263985
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244153
INFO:root:FL Epoch: 322 Norm Difference for worker 600 is 1.430399
INFO:root:FL Epoch: 322 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :982
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666790
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501055
INFO:root:FL Epoch: 322 Norm Difference for worker 982 is 1.542461
INFO:root:FL Epoch: 322 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1725
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588830
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324589
INFO:root:FL Epoch: 322 Norm Difference for worker 1725 is 1.623742
INFO:root:FL Epoch: 322 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1224
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706371
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330576
INFO:root:FL Epoch: 322 Norm Difference for worker 1224 is 1.483949
INFO:root:FL Epoch: 322 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :539
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425822
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291220
INFO:root:FL Epoch: 322 Norm Difference for worker 539 is 1.517801
INFO:root:FL Epoch: 322 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :3
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387848
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 3 is 1.572685
INFO:root:FL Epoch: 322 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1510
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796122
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319711
INFO:root:FL Epoch: 322 Norm Difference for worker 1510 is 1.674688
INFO:root:FL Epoch: 322 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :673
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348363
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333801
INFO:root:FL Epoch: 322 Norm Difference for worker 673 is 1.44936
INFO:root:FL Epoch: 322 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [3, 673, 600, 982, 612, 1224, 539]
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.4630475885727826 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.19285327071944872                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [888, 344, 814, 1493, 639, 1448, 256, 461, 1908, 337]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :888
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390298
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190880
INFO:root:FL Epoch: 323 Norm Difference for worker 888 is 1.340966
INFO:root:FL Epoch: 323 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :344
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538014
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323634
INFO:root:FL Epoch: 323 Norm Difference for worker 344 is 1.50762
INFO:root:FL Epoch: 323 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :814
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601749
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141555
INFO:root:FL Epoch: 323 Norm Difference for worker 814 is 1.312942
INFO:root:FL Epoch: 323 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1493
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706861
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309963
INFO:root:FL Epoch: 323 Norm Difference for worker 1493 is 1.493847
INFO:root:FL Epoch: 323 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :639
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351166
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265889
INFO:root:FL Epoch: 323 Norm Difference for worker 639 is 1.343571
INFO:root:FL Epoch: 323 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1448
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351303
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321344
INFO:root:FL Epoch: 323 Norm Difference for worker 1448 is 1.455785
INFO:root:FL Epoch: 323 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :256
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 256 is 1.42484
INFO:root:FL Epoch: 323 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :461
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352965
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306895
INFO:root:FL Epoch: 323 Norm Difference for worker 461 is 1.420934
INFO:root:FL Epoch: 323 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1908
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400475
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222956
INFO:root:FL Epoch: 323 Norm Difference for worker 1908 is 1.381005
INFO:root:FL Epoch: 323 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :337
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205473
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 337 is 1.35705
INFO:root:FL Epoch: 323 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 200 200 201 200 201 200]
INFO:root:The chosen ones are users: [0 4 2 9 7 6 8], which are global users: [888, 639, 814, 337, 461, 256, 1908]
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.4456921167233411 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.2471937413016955                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1471, 1574, 1571, 563, 1944, 1599, 1205, 843, 1897, 1775]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1471
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372188
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234003
INFO:root:FL Epoch: 324 Norm Difference for worker 1471 is 1.387817
INFO:root:FL Epoch: 324 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1574
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493243
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152908
INFO:root:FL Epoch: 324 Norm Difference for worker 1574 is 1.504298
INFO:root:FL Epoch: 324 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1571
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433458
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301994
INFO:root:FL Epoch: 324 Norm Difference for worker 1571 is 1.362526
INFO:root:FL Epoch: 324 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :563
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352557
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250204
INFO:root:FL Epoch: 324 Norm Difference for worker 563 is 1.33883
INFO:root:FL Epoch: 324 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1944
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602744
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331909
INFO:root:FL Epoch: 324 Norm Difference for worker 1944 is 1.307822
INFO:root:FL Epoch: 324 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1599
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618925
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242314
INFO:root:FL Epoch: 324 Norm Difference for worker 1599 is 1.2881
INFO:root:FL Epoch: 324 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1205
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329315
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239299
INFO:root:FL Epoch: 324 Norm Difference for worker 1205 is 1.357289
INFO:root:FL Epoch: 324 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :843
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533631
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220011
INFO:root:FL Epoch: 324 Norm Difference for worker 843 is 1.447348
INFO:root:FL Epoch: 324 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1897
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416754
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179872
INFO:root:FL Epoch: 324 Norm Difference for worker 1897 is 1.432614
INFO:root:FL Epoch: 324 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1775
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501797
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330491
INFO:root:FL Epoch: 324 Norm Difference for worker 1775 is 1.388791
INFO:root:FL Epoch: 324 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 6 0 9], which are global users: [1599, 1944, 1571, 563, 1205, 1471, 1775]
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.45231807757826414 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.18989656617244086                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [1096, 570, 779, 298, 1125, 1322, 856, 1417, 826, 661]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :1096
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479588
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336394
INFO:root:FL Epoch: 325 Norm Difference for worker 1096 is 1.494656
INFO:root:FL Epoch: 325 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :570
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737921
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262834
INFO:root:FL Epoch: 325 Norm Difference for worker 570 is 1.441542
INFO:root:FL Epoch: 325 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :779
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489288
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515919
INFO:root:FL Epoch: 325 Norm Difference for worker 779 is 1.541867
INFO:root:FL Epoch: 325 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :298
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 298 is 1.501526
INFO:root:FL Epoch: 325 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1125
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626194
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261834
INFO:root:FL Epoch: 325 Norm Difference for worker 1125 is 1.464852
INFO:root:FL Epoch: 325 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1322
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408754
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257652
INFO:root:FL Epoch: 325 Norm Difference for worker 1322 is 1.603081
INFO:root:FL Epoch: 325 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :856
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771220
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430909
INFO:root:FL Epoch: 325 Norm Difference for worker 856 is 1.677782
INFO:root:FL Epoch: 325 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1417
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.987102
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506884
INFO:root:FL Epoch: 325 Norm Difference for worker 1417 is 1.475699
INFO:root:FL Epoch: 325 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :826
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448322
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502084
INFO:root:FL Epoch: 325 Norm Difference for worker 826 is 1.507921
INFO:root:FL Epoch: 325 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :661
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618771
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311013
INFO:root:FL Epoch: 325 Norm Difference for worker 661 is 1.52847
INFO:root:FL Epoch: 325 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 4 0 7 9 8 2], which are global users: [570, 1125, 1096, 1417, 661, 826, 779]
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.45797450752819285 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.20910404374202093                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [354, 951, 1777, 867, 1140, 1467, 525, 13, 1011, 386]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :354
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704663
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167915
INFO:root:FL Epoch: 326 Norm Difference for worker 354 is 1.384795
INFO:root:FL Epoch: 326 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :951
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495045
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357903
INFO:root:FL Epoch: 326 Norm Difference for worker 951 is 1.45106
INFO:root:FL Epoch: 326 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1777
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792577
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361381
INFO:root:FL Epoch: 326 Norm Difference for worker 1777 is 1.428627
INFO:root:FL Epoch: 326 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :867
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448691
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282641
INFO:root:FL Epoch: 326 Norm Difference for worker 867 is 1.329544
INFO:root:FL Epoch: 326 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1140
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750229
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308551
INFO:root:FL Epoch: 326 Norm Difference for worker 1140 is 1.435392
INFO:root:FL Epoch: 326 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1467
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458224
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251600
INFO:root:FL Epoch: 326 Norm Difference for worker 1467 is 1.356745
INFO:root:FL Epoch: 326 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :525
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453395
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287120
INFO:root:FL Epoch: 326 Norm Difference for worker 525 is 1.457369
INFO:root:FL Epoch: 326 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :13
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.367670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333098
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 13 is 1.372604
INFO:root:FL Epoch: 326 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1011
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266550
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341984
INFO:root:FL Epoch: 326 Norm Difference for worker 1011 is 1.360927
INFO:root:FL Epoch: 326 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :386
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568176
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168811
INFO:root:FL Epoch: 326 Norm Difference for worker 386 is 1.271947
INFO:root:FL Epoch: 326 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 8 3 0 7 4], which are global users: [1467, 386, 1011, 867, 354, 13, 1140]
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.46396155041806836 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.1976663110156854                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [394, 43, 1946, 202, 357, 879, 365, 105, 548, 1176]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 327 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :394
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345198
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289604
INFO:root:FL Epoch: 327 Norm Difference for worker 394 is 1.435127
INFO:root:FL Epoch: 327 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :43
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.776824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 43 is 1.495167
INFO:root:FL Epoch: 327 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1946
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372661
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289809
INFO:root:FL Epoch: 327 Norm Difference for worker 1946 is 1.375534
INFO:root:FL Epoch: 327 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :202
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.862102
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 202 is 1.482488
INFO:root:FL Epoch: 327 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :357
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444077
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255883
INFO:root:FL Epoch: 327 Norm Difference for worker 357 is 1.343838
INFO:root:FL Epoch: 327 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :879
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537154
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234773
INFO:root:FL Epoch: 327 Norm Difference for worker 879 is 1.519484
INFO:root:FL Epoch: 327 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :365
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660651
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299746
INFO:root:FL Epoch: 327 Norm Difference for worker 365 is 1.394333
INFO:root:FL Epoch: 327 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :105
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 105 is 1.596579
INFO:root:FL Epoch: 327 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :548
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417618
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536800
INFO:root:FL Epoch: 327 Norm Difference for worker 548 is 1.519488
INFO:root:FL Epoch: 327 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1176
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743770
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308541
INFO:root:FL Epoch: 327 Norm Difference for worker 1176 is 1.471734
INFO:root:FL Epoch: 327 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 4 2 0 1 9 5], which are global users: [365, 357, 1946, 394, 43, 1176, 879]
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.46115042970461007 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.1647581234574318                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [1232, 710, 1540, 1486, 1881, 795, 1174, 1718, 1621, 1011]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 328 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :1232
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583790
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529735
INFO:root:FL Epoch: 328 Norm Difference for worker 1232 is 1.444629
INFO:root:FL Epoch: 328 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :710
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277121
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437258
INFO:root:FL Epoch: 328 Norm Difference for worker 710 is 1.431811
INFO:root:FL Epoch: 328 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1540
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373911
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336921
INFO:root:FL Epoch: 328 Norm Difference for worker 1540 is 1.413762
INFO:root:FL Epoch: 328 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1486
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424983
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160683
INFO:root:FL Epoch: 328 Norm Difference for worker 1486 is 1.422477
INFO:root:FL Epoch: 328 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1881
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.207967
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148903
INFO:root:FL Epoch: 328 Norm Difference for worker 1881 is 1.354295
INFO:root:FL Epoch: 328 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :795
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480129
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298501
INFO:root:FL Epoch: 328 Norm Difference for worker 795 is 1.380062
INFO:root:FL Epoch: 328 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1174
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578921
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459014
INFO:root:FL Epoch: 328 Norm Difference for worker 1174 is 1.514739
INFO:root:FL Epoch: 328 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1718
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504781
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346949
INFO:root:FL Epoch: 328 Norm Difference for worker 1718 is 1.4168
INFO:root:FL Epoch: 328 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1621
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484994
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185841
INFO:root:FL Epoch: 328 Norm Difference for worker 1621 is 1.42601
INFO:root:FL Epoch: 328 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1011
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276453
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351781
INFO:root:FL Epoch: 328 Norm Difference for worker 1011 is 1.353873
INFO:root:FL Epoch: 328 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 9 1 2 0 7], which are global users: [795, 1881, 1011, 710, 1540, 1232, 1718]
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.44893964423852806 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.15530281762282053                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [991, 1293, 318, 707, 1256, 1006, 474, 1060, 1599, 1142]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 329 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :991
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446099
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366990
INFO:root:FL Epoch: 329 Norm Difference for worker 991 is 1.436944
INFO:root:FL Epoch: 329 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1293
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752233
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229238
INFO:root:FL Epoch: 329 Norm Difference for worker 1293 is 1.33744
INFO:root:FL Epoch: 329 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :318
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332518
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.245123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 318 is 1.338377
INFO:root:FL Epoch: 329 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :707
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689972
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199321
INFO:root:FL Epoch: 329 Norm Difference for worker 707 is 1.427075
INFO:root:FL Epoch: 329 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1256
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317650
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241568
INFO:root:FL Epoch: 329 Norm Difference for worker 1256 is 1.326688
INFO:root:FL Epoch: 329 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1006
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429933
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183920
INFO:root:FL Epoch: 329 Norm Difference for worker 1006 is 1.430544
INFO:root:FL Epoch: 329 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :474
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610970
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274416
INFO:root:FL Epoch: 329 Norm Difference for worker 474 is 1.605424
INFO:root:FL Epoch: 329 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1060
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316970
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364261
INFO:root:FL Epoch: 329 Norm Difference for worker 1060 is 1.544354
INFO:root:FL Epoch: 329 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1599
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.218958
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195277
INFO:root:FL Epoch: 329 Norm Difference for worker 1599 is 1.311042
INFO:root:FL Epoch: 329 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1142
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581753
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270509
INFO:root:FL Epoch: 329 Norm Difference for worker 1142 is 1.355957
INFO:root:FL Epoch: 329 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [8 4 2 9 5 1 0], which are global users: [1599, 1256, 318, 1142, 1006, 1293, 991]
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.448417265625561 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.153908833861351                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [824, 956, 806, 259, 128, 1910, 388, 1464, 189, 1100]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :824
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510109
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352972
INFO:root:FL Epoch: 330 Norm Difference for worker 824 is 1.382303
INFO:root:FL Epoch: 330 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :956
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612148
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261580
INFO:root:FL Epoch: 330 Norm Difference for worker 956 is 1.596914
INFO:root:FL Epoch: 330 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :806
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818700
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231389
INFO:root:FL Epoch: 330 Norm Difference for worker 806 is 1.648153
INFO:root:FL Epoch: 330 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :259
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 259 is 1.543785
INFO:root:FL Epoch: 330 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :128
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 128 is 1.624177
INFO:root:FL Epoch: 330 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1910
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596159
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431384
INFO:root:FL Epoch: 330 Norm Difference for worker 1910 is 1.562995
INFO:root:FL Epoch: 330 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :388
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.169805
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203091
INFO:root:FL Epoch: 330 Norm Difference for worker 388 is 1.38306
INFO:root:FL Epoch: 330 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1464
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378272
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324298
INFO:root:FL Epoch: 330 Norm Difference for worker 1464 is 1.412261
INFO:root:FL Epoch: 330 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :189
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.279633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 189 is 1.498594
INFO:root:FL Epoch: 330 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1100
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377213
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299791
INFO:root:FL Epoch: 330 Norm Difference for worker 1100 is 1.460968
INFO:root:FL Epoch: 330 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [6 0 7 9 8 3 5], which are global users: [388, 824, 1464, 1100, 189, 259, 1910]
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.44653047182980704 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.21968996276458105                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 218, 858, 782, 846, 1181, 420, 726]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285384
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162880
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.1227845810353756 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.11608015894889831 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.228367
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.165104
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153045
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.11318049083153407 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.11614405810832977 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.234814
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.120757
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275998
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.11853763461112976 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.11865717098116875 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.218232
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :218
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 218 is 1.444713
INFO:root:FL Epoch: 331 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :858
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636129
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321565
INFO:root:FL Epoch: 331 Norm Difference for worker 858 is 1.434261
INFO:root:FL Epoch: 331 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :782
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617178
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349169
INFO:root:FL Epoch: 331 Norm Difference for worker 782 is 1.520158
INFO:root:FL Epoch: 331 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :846
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606727
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378483
INFO:root:FL Epoch: 331 Norm Difference for worker 846 is 1.693284
INFO:root:FL Epoch: 331 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1181
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382597
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145882
INFO:root:FL Epoch: 331 Norm Difference for worker 1181 is 1.346089
INFO:root:FL Epoch: 331 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :420
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599671
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315175
INFO:root:FL Epoch: 331 Norm Difference for worker 420 is 1.586419
INFO:root:FL Epoch: 331 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :726
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624721
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137628
INFO:root:FL Epoch: 331 Norm Difference for worker 726 is 1.578699
INFO:root:FL Epoch: 331 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 4 5], which are global users: [1181, 0, 2, 218, 1, 858, 782]
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.4605756402015686 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.1596560776233673                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1137, 943, 1384, 478, 1853, 836, 1335, 1385, 333, 848]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1137
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631805
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305929
INFO:root:FL Epoch: 332 Norm Difference for worker 1137 is 1.610253
INFO:root:FL Epoch: 332 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :943
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869237
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382567
INFO:root:FL Epoch: 332 Norm Difference for worker 943 is 1.521011
INFO:root:FL Epoch: 332 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1384
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654854
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333719
INFO:root:FL Epoch: 332 Norm Difference for worker 1384 is 1.512574
INFO:root:FL Epoch: 332 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :478
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433927
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219944
INFO:root:FL Epoch: 332 Norm Difference for worker 478 is 1.404264
INFO:root:FL Epoch: 332 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1853
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765347
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194348
INFO:root:FL Epoch: 332 Norm Difference for worker 1853 is 1.652156
INFO:root:FL Epoch: 332 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :836
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448396
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193171
INFO:root:FL Epoch: 332 Norm Difference for worker 836 is 1.449629
INFO:root:FL Epoch: 332 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1335
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286088
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212429
INFO:root:FL Epoch: 332 Norm Difference for worker 1335 is 1.519379
INFO:root:FL Epoch: 332 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1385
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409163
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267696
INFO:root:FL Epoch: 332 Norm Difference for worker 1385 is 1.410552
INFO:root:FL Epoch: 332 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :333
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 333 is 1.555086
INFO:root:FL Epoch: 332 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :848
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496122
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214177
INFO:root:FL Epoch: 332 Norm Difference for worker 848 is 1.5779
INFO:root:FL Epoch: 332 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [7 3 5 2 8 1 9], which are global users: [1385, 478, 836, 1384, 333, 943, 848]
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.44706063936738405 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.1882693370183309                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [754, 1821, 539, 906, 684, 557, 1509, 1785, 340, 645]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :754
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232946
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193550
INFO:root:FL Epoch: 333 Norm Difference for worker 754 is 1.349592
INFO:root:FL Epoch: 333 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1821
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350540
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373577
INFO:root:FL Epoch: 333 Norm Difference for worker 1821 is 1.409803
INFO:root:FL Epoch: 333 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :539
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545879
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254012
INFO:root:FL Epoch: 333 Norm Difference for worker 539 is 1.493139
INFO:root:FL Epoch: 333 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :906
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341157
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.112981
INFO:root:FL Epoch: 333 Norm Difference for worker 906 is 1.248337
INFO:root:FL Epoch: 333 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :684
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267313
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440487
INFO:root:FL Epoch: 333 Norm Difference for worker 684 is 1.407974
INFO:root:FL Epoch: 333 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :557
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432059
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428326
INFO:root:FL Epoch: 333 Norm Difference for worker 557 is 1.400281
INFO:root:FL Epoch: 333 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1509
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465405
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403882
INFO:root:FL Epoch: 333 Norm Difference for worker 1509 is 1.391742
INFO:root:FL Epoch: 333 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1785
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358491
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186327
INFO:root:FL Epoch: 333 Norm Difference for worker 1785 is 1.351154
INFO:root:FL Epoch: 333 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :340
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387922
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195547
INFO:root:FL Epoch: 333 Norm Difference for worker 340 is 1.373044
INFO:root:FL Epoch: 333 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :645
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521104
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382418
INFO:root:FL Epoch: 333 Norm Difference for worker 645 is 1.533403
INFO:root:FL Epoch: 333 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 3 7 5 4], which are global users: [1509, 754, 340, 906, 1785, 557, 684]
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.4355982401791741 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.1645579350491365                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1885, 480, 103, 583, 1552, 1728, 265, 35, 1513, 218]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1885
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595747
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301946
INFO:root:FL Epoch: 334 Norm Difference for worker 1885 is 1.516624
INFO:root:FL Epoch: 334 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :480
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448501
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561630
INFO:root:FL Epoch: 334 Norm Difference for worker 480 is 1.499756
INFO:root:FL Epoch: 334 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :103
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 103 is 1.371702
INFO:root:FL Epoch: 334 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :583
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702120
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266030
INFO:root:FL Epoch: 334 Norm Difference for worker 583 is 1.457349
INFO:root:FL Epoch: 334 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1552
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477013
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221273
INFO:root:FL Epoch: 334 Norm Difference for worker 1552 is 1.556624
INFO:root:FL Epoch: 334 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1728
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436340
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305273
INFO:root:FL Epoch: 334 Norm Difference for worker 1728 is 1.597224
INFO:root:FL Epoch: 334 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :265
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664469
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 265 is 1.571461
INFO:root:FL Epoch: 334 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :35
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 35 is 1.360576
INFO:root:FL Epoch: 334 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1513
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528554
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231677
INFO:root:FL Epoch: 334 Norm Difference for worker 1513 is 1.35778
INFO:root:FL Epoch: 334 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :218
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.374889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.156512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 218 is 1.364969
INFO:root:FL Epoch: 334 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 201 200 201]
INFO:root:Num selected data points: [201 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 8 0], which are global users: [35, 218, 103, 583, 480, 1513, 1885]
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.45708122674156637 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.1887214593589306                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [1862, 981, 783, 483, 92, 332, 409, 1407, 210, 1936]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 335 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :1862
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578160
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260802
INFO:root:FL Epoch: 335 Norm Difference for worker 1862 is 1.478629
INFO:root:FL Epoch: 335 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :981
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648183
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382135
INFO:root:FL Epoch: 335 Norm Difference for worker 981 is 1.553023
INFO:root:FL Epoch: 335 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :783
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459679
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275176
INFO:root:FL Epoch: 335 Norm Difference for worker 783 is 1.471619
INFO:root:FL Epoch: 335 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :483
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286504
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142244
INFO:root:FL Epoch: 335 Norm Difference for worker 483 is 1.333573
INFO:root:FL Epoch: 335 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :92
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 92 is 1.484821
INFO:root:FL Epoch: 335 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :332
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.204505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 332 is 1.459061
INFO:root:FL Epoch: 335 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :409
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336229
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282418
INFO:root:FL Epoch: 335 Norm Difference for worker 409 is 1.545213
INFO:root:FL Epoch: 335 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1407
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561037
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257437
INFO:root:FL Epoch: 335 Norm Difference for worker 1407 is 1.512308
INFO:root:FL Epoch: 335 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :210
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 210 is 1.604281
INFO:root:FL Epoch: 335 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1936
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472587
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234140
INFO:root:FL Epoch: 335 Norm Difference for worker 1936 is 1.484348
INFO:root:FL Epoch: 335 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 201 200 200 201 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 4 5 9 2 0 6], which are global users: [483, 92, 332, 1936, 783, 1862, 409]
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.4705826832967646 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.23294905945658684                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [1219, 607, 222, 931, 772, 1596, 769, 484, 896, 852]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 336 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :1219
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670463
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187290
INFO:root:FL Epoch: 336 Norm Difference for worker 1219 is 1.448737
INFO:root:FL Epoch: 336 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :607
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677843
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391052
INFO:root:FL Epoch: 336 Norm Difference for worker 607 is 1.501894
INFO:root:FL Epoch: 336 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :222
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.194053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 222 is 1.402163
INFO:root:FL Epoch: 336 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :931
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443715
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361642
INFO:root:FL Epoch: 336 Norm Difference for worker 931 is 1.614504
INFO:root:FL Epoch: 336 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :772
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372717
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247910
INFO:root:FL Epoch: 336 Norm Difference for worker 772 is 1.518436
INFO:root:FL Epoch: 336 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1596
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461676
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274677
INFO:root:FL Epoch: 336 Norm Difference for worker 1596 is 1.302911
INFO:root:FL Epoch: 336 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :769
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351427
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267133
INFO:root:FL Epoch: 336 Norm Difference for worker 769 is 1.522707
INFO:root:FL Epoch: 336 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :484
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359260
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512925
INFO:root:FL Epoch: 336 Norm Difference for worker 484 is 1.593875
INFO:root:FL Epoch: 336 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :896
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590579
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356072
INFO:root:FL Epoch: 336 Norm Difference for worker 896 is 1.355146
INFO:root:FL Epoch: 336 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :852
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582678
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375337
INFO:root:FL Epoch: 336 Norm Difference for worker 852 is 1.398803
INFO:root:FL Epoch: 336 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 8 0 4 1], which are global users: [1596, 852, 222, 896, 1219, 772, 607]
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.46443398910410266 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.19988895331819853                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [1915, 136, 1458, 1617, 113, 225, 258, 144, 640, 920]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 337 Num points on workers: [200 201 200 200 201 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :1915
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.861393
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.826961
INFO:root:FL Epoch: 337 Norm Difference for worker 1915 is 1.582255
INFO:root:FL Epoch: 337 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :136
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.151684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 136 is 1.371167
INFO:root:FL Epoch: 337 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1458
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350860
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326315
INFO:root:FL Epoch: 337 Norm Difference for worker 1458 is 1.421729
INFO:root:FL Epoch: 337 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1617
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446816
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315743
INFO:root:FL Epoch: 337 Norm Difference for worker 1617 is 1.392788
INFO:root:FL Epoch: 337 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :113
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252535
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 113 is 1.413684
INFO:root:FL Epoch: 337 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :225
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291311
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 225 is 1.544018
INFO:root:FL Epoch: 337 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :258
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.315362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232130
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 258 is 1.575173
INFO:root:FL Epoch: 337 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :144
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 144 is 1.42807
INFO:root:FL Epoch: 337 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :640
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578026
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397360
INFO:root:FL Epoch: 337 Norm Difference for worker 640 is 1.387359
INFO:root:FL Epoch: 337 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :920
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749597
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229708
INFO:root:FL Epoch: 337 Norm Difference for worker 920 is 1.604684
INFO:root:FL Epoch: 337 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 201 201 201 200 200]
INFO:root:Num selected data points: [201 201 200 200 201 201 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 5 8], which are global users: [144, 113, 1458, 1617, 136, 225, 640]
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.4535123635740841 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.1989762857556343                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [483, 1773, 692, 125, 896, 1694, 899, 1396, 1318, 1791]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :483
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606514
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237946
INFO:root:FL Epoch: 338 Norm Difference for worker 483 is 1.243954
INFO:root:FL Epoch: 338 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1773
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316989
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224190
INFO:root:FL Epoch: 338 Norm Difference for worker 1773 is 1.480181
INFO:root:FL Epoch: 338 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :692
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712020
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292931
INFO:root:FL Epoch: 338 Norm Difference for worker 692 is 1.392924
INFO:root:FL Epoch: 338 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :125
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.218555
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.161176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 125 is 1.372166
INFO:root:FL Epoch: 338 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :896
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304512
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183423
INFO:root:FL Epoch: 338 Norm Difference for worker 896 is 1.262971
INFO:root:FL Epoch: 338 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1694
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554568
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466666
INFO:root:FL Epoch: 338 Norm Difference for worker 1694 is 1.5617
INFO:root:FL Epoch: 338 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :899
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393279
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265838
INFO:root:FL Epoch: 338 Norm Difference for worker 899 is 1.489173
INFO:root:FL Epoch: 338 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1396
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.912580
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349478
INFO:root:FL Epoch: 338 Norm Difference for worker 1396 is 1.450108
INFO:root:FL Epoch: 338 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1318
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273605
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181397
INFO:root:FL Epoch: 338 Norm Difference for worker 1318 is 1.442231
INFO:root:FL Epoch: 338 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1791
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542334
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381488
INFO:root:FL Epoch: 338 Norm Difference for worker 1791 is 1.523136
INFO:root:FL Epoch: 338 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [0 4 3 8 2 7 1], which are global users: [483, 896, 125, 1318, 692, 1396, 1773]
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.4523821210159975 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.1872428593536218                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [1629, 745, 1002, 1359, 619, 1907, 21, 1557, 205, 802]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 339 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :1629
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551210
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389815
INFO:root:FL Epoch: 339 Norm Difference for worker 1629 is 1.618587
INFO:root:FL Epoch: 339 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :745
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486949
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234278
INFO:root:FL Epoch: 339 Norm Difference for worker 745 is 1.592225
INFO:root:FL Epoch: 339 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1002
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630552
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197194
INFO:root:FL Epoch: 339 Norm Difference for worker 1002 is 1.398571
INFO:root:FL Epoch: 339 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1359
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450895
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299778
INFO:root:FL Epoch: 339 Norm Difference for worker 1359 is 1.509626
INFO:root:FL Epoch: 339 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :619
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673112
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268814
INFO:root:FL Epoch: 339 Norm Difference for worker 619 is 1.544879
INFO:root:FL Epoch: 339 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1907
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344519
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173851
INFO:root:FL Epoch: 339 Norm Difference for worker 1907 is 1.439241
INFO:root:FL Epoch: 339 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :21
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.119768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 21 is 1.27846
INFO:root:FL Epoch: 339 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1557
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342458
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284001
INFO:root:FL Epoch: 339 Norm Difference for worker 1557 is 1.568066
INFO:root:FL Epoch: 339 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :205
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.756921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371715
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 205 is 1.598985
INFO:root:FL Epoch: 339 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :802
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422325
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330777
INFO:root:FL Epoch: 339 Norm Difference for worker 802 is 1.54631
INFO:root:FL Epoch: 339 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 6 9 7], which are global users: [1907, 619, 1002, 1359, 21, 802, 1557]
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.44834820838535533 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.1765135650833448                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [871, 60, 930, 1124, 733, 1016, 689, 214, 319, 1111]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 340 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :871
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308885
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.110211
INFO:root:FL Epoch: 340 Norm Difference for worker 871 is 1.406217
INFO:root:FL Epoch: 340 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :60
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.267816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 60 is 1.457844
INFO:root:FL Epoch: 340 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :930
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616267
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254897
INFO:root:FL Epoch: 340 Norm Difference for worker 930 is 1.424336
INFO:root:FL Epoch: 340 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1124
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335597
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338542
INFO:root:FL Epoch: 340 Norm Difference for worker 1124 is 1.481903
INFO:root:FL Epoch: 340 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :733
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326317
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232123
INFO:root:FL Epoch: 340 Norm Difference for worker 733 is 1.5879
INFO:root:FL Epoch: 340 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1016
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576565
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157289
INFO:root:FL Epoch: 340 Norm Difference for worker 1016 is 1.520344
INFO:root:FL Epoch: 340 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :689
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416116
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205356
INFO:root:FL Epoch: 340 Norm Difference for worker 689 is 1.560667
INFO:root:FL Epoch: 340 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :214
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 214 is 1.358087
INFO:root:FL Epoch: 340 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :319
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 319 is 1.360785
INFO:root:FL Epoch: 340 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1111
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450122
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431393
INFO:root:FL Epoch: 340 Norm Difference for worker 1111 is 1.428038
INFO:root:FL Epoch: 340 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 201 201 200]
INFO:root:Num selected data points: [201 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [7 0 8 9 2 1 3], which are global users: [214, 871, 319, 1111, 930, 60, 1124]
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.4565853827139911 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.19352315614620844                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 472, 1059, 560, 655, 898, 1664, 1277]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.173228
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149283
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.12128435696164767 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.12264644801616668 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.215983
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.171394
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.100539
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.12537004550298056 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.12394816130399704 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.209398
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.187237
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113087
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.12817770118514696 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.12566202953457833 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.203433
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :472
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502709
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294115
INFO:root:FL Epoch: 341 Norm Difference for worker 472 is 1.393675
INFO:root:FL Epoch: 341 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1059
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.171476
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182216
INFO:root:FL Epoch: 341 Norm Difference for worker 1059 is 1.289875
INFO:root:FL Epoch: 341 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :560
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776279
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445310
INFO:root:FL Epoch: 341 Norm Difference for worker 560 is 1.509838
INFO:root:FL Epoch: 341 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :655
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504137
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302025
INFO:root:FL Epoch: 341 Norm Difference for worker 655 is 1.552
INFO:root:FL Epoch: 341 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :898
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649188
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304968
INFO:root:FL Epoch: 341 Norm Difference for worker 898 is 1.554876
INFO:root:FL Epoch: 341 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1664
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608927
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378607
INFO:root:FL Epoch: 341 Norm Difference for worker 1664 is 1.311195
INFO:root:FL Epoch: 341 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1277
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508681
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339859
INFO:root:FL Epoch: 341 Norm Difference for worker 1277 is 1.421899
INFO:root:FL Epoch: 341 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 4 8 3 9], which are global users: [1, 0, 2, 1059, 1664, 472, 1277]
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.4700913183829364 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.1568686949710051                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1085, 431, 1019, 17, 671, 163, 1750, 1316, 365, 535]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 342 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1085
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383696
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169426
INFO:root:FL Epoch: 342 Norm Difference for worker 1085 is 1.430608
INFO:root:FL Epoch: 342 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :431
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631020
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300869
INFO:root:FL Epoch: 342 Norm Difference for worker 431 is 1.510984
INFO:root:FL Epoch: 342 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1019
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532553
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484328
INFO:root:FL Epoch: 342 Norm Difference for worker 1019 is 1.491845
INFO:root:FL Epoch: 342 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :17
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.957100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 17 is 1.67871
INFO:root:FL Epoch: 342 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :671
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508756
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254402
INFO:root:FL Epoch: 342 Norm Difference for worker 671 is 1.452109
INFO:root:FL Epoch: 342 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :163
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 1.026851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394844
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 163 is 1.565659
INFO:root:FL Epoch: 342 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1750
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507222
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364770
INFO:root:FL Epoch: 342 Norm Difference for worker 1750 is 1.698306
INFO:root:FL Epoch: 342 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1316
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488932
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461180
INFO:root:FL Epoch: 342 Norm Difference for worker 1316 is 1.409431
INFO:root:FL Epoch: 342 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :365
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295738
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290330
INFO:root:FL Epoch: 342 Norm Difference for worker 365 is 1.419941
INFO:root:FL Epoch: 342 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :535
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320073
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153139
INFO:root:FL Epoch: 342 Norm Difference for worker 535 is 1.442693
INFO:root:FL Epoch: 342 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 0 9 8 2 1], which are global users: [1316, 671, 1085, 535, 365, 1019, 431]
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.4552001400905497 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.14694834624727568                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [807, 1321, 608, 1300, 1732, 245, 865, 1286, 1311, 189]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :807
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495227
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410443
INFO:root:FL Epoch: 343 Norm Difference for worker 807 is 1.540467
INFO:root:FL Epoch: 343 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1321
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366668
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247427
INFO:root:FL Epoch: 343 Norm Difference for worker 1321 is 1.382218
INFO:root:FL Epoch: 343 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :608
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429360
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315768
INFO:root:FL Epoch: 343 Norm Difference for worker 608 is 1.522323
INFO:root:FL Epoch: 343 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1300
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763850
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180244
INFO:root:FL Epoch: 343 Norm Difference for worker 1300 is 1.364543
INFO:root:FL Epoch: 343 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1732
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566968
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389657
INFO:root:FL Epoch: 343 Norm Difference for worker 1732 is 1.531525
INFO:root:FL Epoch: 343 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :245
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626407
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241924
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 245 is 1.61279
INFO:root:FL Epoch: 343 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :865
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516392
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147977
INFO:root:FL Epoch: 343 Norm Difference for worker 865 is 1.384167
INFO:root:FL Epoch: 343 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1286
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561187
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200200
INFO:root:FL Epoch: 343 Norm Difference for worker 1286 is 1.547459
INFO:root:FL Epoch: 343 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1311
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564629
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509309
INFO:root:FL Epoch: 343 Norm Difference for worker 1311 is 1.569571
INFO:root:FL Epoch: 343 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :189
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 189 is 1.479392
INFO:root:FL Epoch: 343 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 2 3 1 4 0], which are global users: [865, 189, 608, 1300, 1321, 1732, 807]
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.4591739808811861 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.15298566843072572                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1045, 1586, 604, 485, 1560, 43, 1653, 8, 197, 1076]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1045
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377300
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405208
INFO:root:FL Epoch: 344 Norm Difference for worker 1045 is 1.426813
INFO:root:FL Epoch: 344 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1586
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606325
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282953
INFO:root:FL Epoch: 344 Norm Difference for worker 1586 is 1.513313
INFO:root:FL Epoch: 344 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :604
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541546
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257110
INFO:root:FL Epoch: 344 Norm Difference for worker 604 is 1.491716
INFO:root:FL Epoch: 344 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :485
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562374
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192362
INFO:root:FL Epoch: 344 Norm Difference for worker 485 is 1.435627
INFO:root:FL Epoch: 344 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1560
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514801
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249439
INFO:root:FL Epoch: 344 Norm Difference for worker 1560 is 1.356722
INFO:root:FL Epoch: 344 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :43
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.847024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 43 is 1.519939
INFO:root:FL Epoch: 344 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1653
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496253
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180710
INFO:root:FL Epoch: 344 Norm Difference for worker 1653 is 1.386608
INFO:root:FL Epoch: 344 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :8
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411990
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 8 is 1.362962
INFO:root:FL Epoch: 344 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :197
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 197 is 1.483558
INFO:root:FL Epoch: 344 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1076
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581437
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223627
INFO:root:FL Epoch: 344 Norm Difference for worker 1076 is 1.478845
INFO:root:FL Epoch: 344 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 201 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 201]
INFO:root:The chosen ones are users: [6 4 7 0 3 9 8], which are global users: [1653, 1560, 8, 1045, 485, 1076, 197]
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.45905833209262176 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.11715150872866313                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [1887, 1618, 192, 1922, 853, 409, 37, 1797, 1173, 354]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 345 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :1887
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475929
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331398
INFO:root:FL Epoch: 345 Norm Difference for worker 1887 is 1.442259
INFO:root:FL Epoch: 345 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1618
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521667
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243351
INFO:root:FL Epoch: 345 Norm Difference for worker 1618 is 1.414716
INFO:root:FL Epoch: 345 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :192
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597523
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 192 is 1.467338
INFO:root:FL Epoch: 345 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1922
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430378
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290157
INFO:root:FL Epoch: 345 Norm Difference for worker 1922 is 1.363981
INFO:root:FL Epoch: 345 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :853
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704718
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269627
INFO:root:FL Epoch: 345 Norm Difference for worker 853 is 1.625398
INFO:root:FL Epoch: 345 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :409
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740313
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204979
INFO:root:FL Epoch: 345 Norm Difference for worker 409 is 1.38387
INFO:root:FL Epoch: 345 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :37
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648982
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 37 is 1.469784
INFO:root:FL Epoch: 345 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1797
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838563
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292955
INFO:root:FL Epoch: 345 Norm Difference for worker 1797 is 1.525694
INFO:root:FL Epoch: 345 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1173
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625074
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387695
INFO:root:FL Epoch: 345 Norm Difference for worker 1173 is 1.523167
INFO:root:FL Epoch: 345 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :354
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411186
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212340
INFO:root:FL Epoch: 345 Norm Difference for worker 354 is 1.46112
INFO:root:FL Epoch: 345 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 3 1 0 8], which are global users: [409, 354, 192, 1922, 1618, 1887, 1173]
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.4561454425839817 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.12291800230741501                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [1581, 1807, 1605, 445, 1804, 852, 67, 1870, 1033, 1199]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :1581
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697913
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292438
INFO:root:FL Epoch: 346 Norm Difference for worker 1581 is 1.615871
INFO:root:FL Epoch: 346 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1807
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.215601
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352746
INFO:root:FL Epoch: 346 Norm Difference for worker 1807 is 1.533385
INFO:root:FL Epoch: 346 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1605
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455495
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231099
INFO:root:FL Epoch: 346 Norm Difference for worker 1605 is 1.468821
INFO:root:FL Epoch: 346 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :445
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463006
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283225
INFO:root:FL Epoch: 346 Norm Difference for worker 445 is 1.484367
INFO:root:FL Epoch: 346 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1804
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492405
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334197
INFO:root:FL Epoch: 346 Norm Difference for worker 1804 is 1.612716
INFO:root:FL Epoch: 346 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :852
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253426
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183695
INFO:root:FL Epoch: 346 Norm Difference for worker 852 is 1.283788
INFO:root:FL Epoch: 346 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :67
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423955
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 67 is 1.573367
INFO:root:FL Epoch: 346 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1870
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556844
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291788
INFO:root:FL Epoch: 346 Norm Difference for worker 1870 is 1.58277
INFO:root:FL Epoch: 346 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1033
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730440
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143400
INFO:root:FL Epoch: 346 Norm Difference for worker 1033 is 1.31414
INFO:root:FL Epoch: 346 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1199
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616199
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232269
INFO:root:FL Epoch: 346 Norm Difference for worker 1199 is 1.435403
INFO:root:FL Epoch: 346 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [9 8 5 3 2 1 6], which are global users: [1199, 1033, 852, 445, 1605, 1807, 67]
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.4497578968020046 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.14511656761169434                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [623, 1667, 1748, 1473, 484, 422, 1584, 1257, 247, 1862]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :623
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649254
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323151
INFO:root:FL Epoch: 347 Norm Difference for worker 623 is 1.423656
INFO:root:FL Epoch: 347 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1667
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717822
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.119794
INFO:root:FL Epoch: 347 Norm Difference for worker 1667 is 1.494162
INFO:root:FL Epoch: 347 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1748
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269510
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313409
INFO:root:FL Epoch: 347 Norm Difference for worker 1748 is 1.653987
INFO:root:FL Epoch: 347 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1473
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286968
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283640
INFO:root:FL Epoch: 347 Norm Difference for worker 1473 is 1.562076
INFO:root:FL Epoch: 347 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :484
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.923850
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300104
INFO:root:FL Epoch: 347 Norm Difference for worker 484 is 1.515819
INFO:root:FL Epoch: 347 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :422
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371573
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314165
INFO:root:FL Epoch: 347 Norm Difference for worker 422 is 1.437623
INFO:root:FL Epoch: 347 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1584
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444314
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354256
INFO:root:FL Epoch: 347 Norm Difference for worker 1584 is 1.408365
INFO:root:FL Epoch: 347 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1257
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538425
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503822
INFO:root:FL Epoch: 347 Norm Difference for worker 1257 is 1.46701
INFO:root:FL Epoch: 347 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :247
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 247 is 1.497533
INFO:root:FL Epoch: 347 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1862
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562052
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213556
INFO:root:FL Epoch: 347 Norm Difference for worker 1862 is 1.340527
INFO:root:FL Epoch: 347 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 9 0 7 5 8 1], which are global users: [1584, 1862, 623, 1257, 422, 247, 1667]
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.4368727049406837 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.13041569913427034                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1637, 1052, 976, 1674, 1323, 573, 1785, 1911, 105, 1649]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1637
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641746
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325905
INFO:root:FL Epoch: 348 Norm Difference for worker 1637 is 1.496358
INFO:root:FL Epoch: 348 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1052
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383919
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228845
INFO:root:FL Epoch: 348 Norm Difference for worker 1052 is 1.33697
INFO:root:FL Epoch: 348 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :976
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339839
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196752
INFO:root:FL Epoch: 348 Norm Difference for worker 976 is 1.429711
INFO:root:FL Epoch: 348 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1674
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740808
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126296
INFO:root:FL Epoch: 348 Norm Difference for worker 1674 is 1.371776
INFO:root:FL Epoch: 348 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1323
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728561
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276606
INFO:root:FL Epoch: 348 Norm Difference for worker 1323 is 1.501007
INFO:root:FL Epoch: 348 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :573
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425984
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206542
INFO:root:FL Epoch: 348 Norm Difference for worker 573 is 1.496672
INFO:root:FL Epoch: 348 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1785
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403448
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340339
INFO:root:FL Epoch: 348 Norm Difference for worker 1785 is 1.396153
INFO:root:FL Epoch: 348 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1911
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308600
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315958
INFO:root:FL Epoch: 348 Norm Difference for worker 1911 is 1.476662
INFO:root:FL Epoch: 348 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :105
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.344034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.268491
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 105 is 1.511212
INFO:root:FL Epoch: 348 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1649
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480004
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361548
INFO:root:FL Epoch: 348 Norm Difference for worker 1649 is 1.462906
INFO:root:FL Epoch: 348 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [1911, 1649, 976, 1674, 1052, 573, 1785]
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.4290819597594878 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.15445434053738913                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [1916, 646, 69, 999, 995, 1098, 338, 1684, 334, 1847]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :1916
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342201
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290316
INFO:root:FL Epoch: 349 Norm Difference for worker 1916 is 1.449703
INFO:root:FL Epoch: 349 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :646
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598885
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241386
INFO:root:FL Epoch: 349 Norm Difference for worker 646 is 1.490798
INFO:root:FL Epoch: 349 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :69
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 69 is 1.539982
INFO:root:FL Epoch: 349 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :999
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415862
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298111
INFO:root:FL Epoch: 349 Norm Difference for worker 999 is 1.324321
INFO:root:FL Epoch: 349 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :995
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904006
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313894
INFO:root:FL Epoch: 349 Norm Difference for worker 995 is 1.534683
INFO:root:FL Epoch: 349 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1098
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281374
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235258
INFO:root:FL Epoch: 349 Norm Difference for worker 1098 is 1.267402
INFO:root:FL Epoch: 349 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :338
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 338 is 1.41434
INFO:root:FL Epoch: 349 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1684
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459135
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413765
INFO:root:FL Epoch: 349 Norm Difference for worker 1684 is 1.470336
INFO:root:FL Epoch: 349 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :334
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 334 is 1.274301
INFO:root:FL Epoch: 349 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1847
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443034
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300745
INFO:root:FL Epoch: 349 Norm Difference for worker 1847 is 1.243673
INFO:root:FL Epoch: 349 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 6 0 1], which are global users: [1098, 1847, 334, 999, 338, 1916, 646]
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.45076722432585326 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.18748150393366814                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1040, 598, 1751, 1280, 1514, 131, 1654, 1021, 35, 475]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 350 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1040
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570255
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213937
INFO:root:FL Epoch: 350 Norm Difference for worker 1040 is 1.420416
INFO:root:FL Epoch: 350 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :598
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700573
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287557
INFO:root:FL Epoch: 350 Norm Difference for worker 598 is 1.542336
INFO:root:FL Epoch: 350 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1751
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630988
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376212
INFO:root:FL Epoch: 350 Norm Difference for worker 1751 is 1.525655
INFO:root:FL Epoch: 350 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1280
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628933
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167495
INFO:root:FL Epoch: 350 Norm Difference for worker 1280 is 1.390709
INFO:root:FL Epoch: 350 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1514
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586273
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.105785
INFO:root:FL Epoch: 350 Norm Difference for worker 1514 is 1.3762
INFO:root:FL Epoch: 350 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :131
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 131 is 1.407103
INFO:root:FL Epoch: 350 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1654
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805566
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336415
INFO:root:FL Epoch: 350 Norm Difference for worker 1654 is 1.551437
INFO:root:FL Epoch: 350 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1021
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663442
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272796
INFO:root:FL Epoch: 350 Norm Difference for worker 1021 is 1.261412
INFO:root:FL Epoch: 350 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :35
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 35 is 1.320014
INFO:root:FL Epoch: 350 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :475
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491876
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133910
INFO:root:FL Epoch: 350 Norm Difference for worker 475 is 1.409396
INFO:root:FL Epoch: 350 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 7 4 0], which are global users: [131, 475, 35, 1280, 1021, 1514, 1040]
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.430888608974569 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.17491521686315536                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 1925, 712, 218, 1646, 399, 1451, 456]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357652
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113018
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.10594209594031175 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.12155071869492531 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.229303
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.156944
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152915
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.10332219737271468 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.12364473417401314 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.220154
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.112454
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176376
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.10487460034588973 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.1238511897623539 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.217421
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1925
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782847
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252813
INFO:root:FL Epoch: 351 Norm Difference for worker 1925 is 1.564726
INFO:root:FL Epoch: 351 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :712
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913662
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250443
INFO:root:FL Epoch: 351 Norm Difference for worker 712 is 1.551993
INFO:root:FL Epoch: 351 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :218
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 218 is 1.427546
INFO:root:FL Epoch: 351 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1646
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349880
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273635
INFO:root:FL Epoch: 351 Norm Difference for worker 1646 is 1.376105
INFO:root:FL Epoch: 351 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :399
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606411
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281349
INFO:root:FL Epoch: 351 Norm Difference for worker 399 is 1.500008
INFO:root:FL Epoch: 351 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1451
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380650
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356026
INFO:root:FL Epoch: 351 Norm Difference for worker 1451 is 1.504299
INFO:root:FL Epoch: 351 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :456
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398491
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221843
INFO:root:FL Epoch: 351 Norm Difference for worker 456 is 1.265117
INFO:root:FL Epoch: 351 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [1 0 2 9 5 6 7], which are global users: [1, 0, 2, 456, 218, 1646, 399]
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.4285449157742893 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.13160264367858568                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [588, 721, 1883, 1861, 358, 1909, 374, 1674, 1237, 72]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :588
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590148
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407429
INFO:root:FL Epoch: 352 Norm Difference for worker 588 is 1.591
INFO:root:FL Epoch: 352 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :721
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699611
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318719
INFO:root:FL Epoch: 352 Norm Difference for worker 721 is 1.501995
INFO:root:FL Epoch: 352 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1883
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384816
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232291
INFO:root:FL Epoch: 352 Norm Difference for worker 1883 is 1.424446
INFO:root:FL Epoch: 352 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1861
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366520
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255540
INFO:root:FL Epoch: 352 Norm Difference for worker 1861 is 1.482376
INFO:root:FL Epoch: 352 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :358
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314157
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210531
INFO:root:FL Epoch: 352 Norm Difference for worker 358 is 1.360783
INFO:root:FL Epoch: 352 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1909
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385157
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170760
INFO:root:FL Epoch: 352 Norm Difference for worker 1909 is 1.424541
INFO:root:FL Epoch: 352 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :374
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630078
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269801
INFO:root:FL Epoch: 352 Norm Difference for worker 374 is 1.418425
INFO:root:FL Epoch: 352 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1674
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487118
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126666
INFO:root:FL Epoch: 352 Norm Difference for worker 1674 is 1.337556
INFO:root:FL Epoch: 352 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1237
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727028
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287305
INFO:root:FL Epoch: 352 Norm Difference for worker 1237 is 1.448514
INFO:root:FL Epoch: 352 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :72
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 72 is 1.326439
INFO:root:FL Epoch: 352 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 4 2 6 5 3], which are global users: [1674, 72, 358, 1883, 374, 1909, 1861]
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.4517700961407493 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.15522541105747223                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1237, 882, 946, 571, 1547, 1187, 1344, 1663, 105, 1843]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1237
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365047
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273498
INFO:root:FL Epoch: 353 Norm Difference for worker 1237 is 1.47422
INFO:root:FL Epoch: 353 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :882
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402528
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182724
INFO:root:FL Epoch: 353 Norm Difference for worker 882 is 1.444014
INFO:root:FL Epoch: 353 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :946
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410182
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209345
INFO:root:FL Epoch: 353 Norm Difference for worker 946 is 1.381151
INFO:root:FL Epoch: 353 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :571
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287783
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154826
INFO:root:FL Epoch: 353 Norm Difference for worker 571 is 1.44375
INFO:root:FL Epoch: 353 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1547
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.222615
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162062
INFO:root:FL Epoch: 353 Norm Difference for worker 1547 is 1.472899
INFO:root:FL Epoch: 353 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1187
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518782
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264620
INFO:root:FL Epoch: 353 Norm Difference for worker 1187 is 1.324159
INFO:root:FL Epoch: 353 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1344
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693585
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319466
INFO:root:FL Epoch: 353 Norm Difference for worker 1344 is 1.351433
INFO:root:FL Epoch: 353 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1663
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360159
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574946
INFO:root:FL Epoch: 353 Norm Difference for worker 1663 is 1.396803
INFO:root:FL Epoch: 353 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :105
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 105 is 1.510211
INFO:root:FL Epoch: 353 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1843
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.205189
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478181
INFO:root:FL Epoch: 353 Norm Difference for worker 1843 is 1.391399
INFO:root:FL Epoch: 353 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [1663, 1843, 946, 571, 882, 1187, 1344]
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.45626942375127005 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.1631288304924965                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [660, 1494, 1242, 1335, 1418, 184, 1837, 178, 10, 14]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 201 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :660
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490891
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364597
INFO:root:FL Epoch: 354 Norm Difference for worker 660 is 1.410673
INFO:root:FL Epoch: 354 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1494
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803567
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370186
INFO:root:FL Epoch: 354 Norm Difference for worker 1494 is 1.338351
INFO:root:FL Epoch: 354 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1242
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772051
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248335
INFO:root:FL Epoch: 354 Norm Difference for worker 1242 is 1.39028
INFO:root:FL Epoch: 354 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1335
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754711
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222619
INFO:root:FL Epoch: 354 Norm Difference for worker 1335 is 1.382746
INFO:root:FL Epoch: 354 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1418
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470158
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179396
INFO:root:FL Epoch: 354 Norm Difference for worker 1418 is 1.342209
INFO:root:FL Epoch: 354 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :184
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.146600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 184 is 1.282325
INFO:root:FL Epoch: 354 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1837
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.192661
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212313
INFO:root:FL Epoch: 354 Norm Difference for worker 1837 is 1.332765
INFO:root:FL Epoch: 354 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :178
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263746
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 178 is 1.351856
INFO:root:FL Epoch: 354 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :10
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 10 is 1.438803
INFO:root:FL Epoch: 354 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :14
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.358856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229916
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 14 is 1.301905
INFO:root:FL Epoch: 354 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 201 201]
INFO:root:Num selected data points: [201 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 9 4 7 6 2 1], which are global users: [184, 14, 1418, 178, 1837, 1242, 1494]
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.44720563292503357 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.14326069131493568                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [196, 1723, 1727, 1583, 929, 174, 1542, 1680, 696, 659]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :196
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222197
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 196 is 1.372853
INFO:root:FL Epoch: 355 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1723
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402696
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299023
INFO:root:FL Epoch: 355 Norm Difference for worker 1723 is 1.269644
INFO:root:FL Epoch: 355 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1727
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320662
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411917
INFO:root:FL Epoch: 355 Norm Difference for worker 1727 is 1.349416
INFO:root:FL Epoch: 355 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1583
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463093
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306312
INFO:root:FL Epoch: 355 Norm Difference for worker 1583 is 1.451519
INFO:root:FL Epoch: 355 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :929
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395694
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374692
INFO:root:FL Epoch: 355 Norm Difference for worker 929 is 1.505403
INFO:root:FL Epoch: 355 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :174
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 174 is 1.469011
INFO:root:FL Epoch: 355 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1542
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555196
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115058
INFO:root:FL Epoch: 355 Norm Difference for worker 1542 is 1.313154
INFO:root:FL Epoch: 355 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1680
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530854
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166991
INFO:root:FL Epoch: 355 Norm Difference for worker 1680 is 1.478001
INFO:root:FL Epoch: 355 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :696
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486662
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337630
INFO:root:FL Epoch: 355 Norm Difference for worker 696 is 1.427555
INFO:root:FL Epoch: 355 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :659
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392937
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235856
INFO:root:FL Epoch: 355 Norm Difference for worker 659 is 1.451671
INFO:root:FL Epoch: 355 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [8 0 2 3 1 5 6], which are global users: [696, 196, 1727, 1583, 1723, 174, 1542]
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.4612281006925246 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.15848089878757796                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [65, 648, 1515, 64, 1041, 823, 1336, 1648, 1233, 54]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 356 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :65
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.301225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 65 is 1.417928
INFO:root:FL Epoch: 356 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362222
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344832
INFO:root:FL Epoch: 356 Norm Difference for worker 648 is 1.340372
INFO:root:FL Epoch: 356 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1515
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535022
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393325
INFO:root:FL Epoch: 356 Norm Difference for worker 1515 is 1.335552
INFO:root:FL Epoch: 356 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :64
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.258462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344844
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 64 is 1.305957
INFO:root:FL Epoch: 356 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1041
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299621
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219682
INFO:root:FL Epoch: 356 Norm Difference for worker 1041 is 1.385939
INFO:root:FL Epoch: 356 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :823
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332810
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404910
INFO:root:FL Epoch: 356 Norm Difference for worker 823 is 1.591434
INFO:root:FL Epoch: 356 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1336
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561174
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271041
INFO:root:FL Epoch: 356 Norm Difference for worker 1336 is 1.439042
INFO:root:FL Epoch: 356 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.979132
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250874
INFO:root:FL Epoch: 356 Norm Difference for worker 1648 is 1.380271
INFO:root:FL Epoch: 356 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1233
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652877
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243413
INFO:root:FL Epoch: 356 Norm Difference for worker 1233 is 1.506778
INFO:root:FL Epoch: 356 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :54
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 54 is 1.350699
INFO:root:FL Epoch: 356 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [1 9 2 3 4 6 7], which are global users: [648, 54, 1515, 64, 1041, 1336, 1648]
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.4648350266849293 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.1547968971232573                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1333, 1745, 1844, 1776, 288, 308, 1198, 441, 1571, 614]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1333
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518474
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300431
INFO:root:FL Epoch: 357 Norm Difference for worker 1333 is 1.39923
INFO:root:FL Epoch: 357 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1745
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396494
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234169
INFO:root:FL Epoch: 357 Norm Difference for worker 1745 is 1.318871
INFO:root:FL Epoch: 357 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1844
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377815
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226842
INFO:root:FL Epoch: 357 Norm Difference for worker 1844 is 1.231302
INFO:root:FL Epoch: 357 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1776
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416199
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250145
INFO:root:FL Epoch: 357 Norm Difference for worker 1776 is 1.353767
INFO:root:FL Epoch: 357 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :288
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 288 is 1.427362
INFO:root:FL Epoch: 357 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :308
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 308 is 1.355852
INFO:root:FL Epoch: 357 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1198
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756772
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318755
INFO:root:FL Epoch: 357 Norm Difference for worker 1198 is 1.296573
INFO:root:FL Epoch: 357 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :441
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474469
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472267
INFO:root:FL Epoch: 357 Norm Difference for worker 441 is 1.467578
INFO:root:FL Epoch: 357 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1571
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444111
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400038
INFO:root:FL Epoch: 357 Norm Difference for worker 1571 is 1.401494
INFO:root:FL Epoch: 357 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :614
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669044
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235300
INFO:root:FL Epoch: 357 Norm Difference for worker 614 is 1.308896
INFO:root:FL Epoch: 357 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 6], which are global users: [1571, 614, 1844, 1776, 1745, 308, 1198]
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.43928848557612477 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.12694303194681802                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1581, 104, 380, 887, 392, 1518, 120, 905, 1181, 65]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1581
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383685
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207889
INFO:root:FL Epoch: 358 Norm Difference for worker 1581 is 1.510107
INFO:root:FL Epoch: 358 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :104
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 104 is 1.366436
INFO:root:FL Epoch: 358 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :380
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357170
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319928
INFO:root:FL Epoch: 358 Norm Difference for worker 380 is 1.390468
INFO:root:FL Epoch: 358 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :887
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631618
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374632
INFO:root:FL Epoch: 358 Norm Difference for worker 887 is 1.47118
INFO:root:FL Epoch: 358 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :392
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310981
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342915
INFO:root:FL Epoch: 358 Norm Difference for worker 392 is 1.369965
INFO:root:FL Epoch: 358 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1518
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336664
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290451
INFO:root:FL Epoch: 358 Norm Difference for worker 1518 is 1.352323
INFO:root:FL Epoch: 358 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :120
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 120 is 1.496192
INFO:root:FL Epoch: 358 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :905
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387458
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350340
INFO:root:FL Epoch: 358 Norm Difference for worker 905 is 1.439252
INFO:root:FL Epoch: 358 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1181
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330305
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193878
INFO:root:FL Epoch: 358 Norm Difference for worker 1181 is 1.28809
INFO:root:FL Epoch: 358 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :65
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 65 is 1.38025
INFO:root:FL Epoch: 358 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [5 4 2 8 1 9 3], which are global users: [1518, 392, 380, 1181, 104, 65, 887]
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.44016077413278465 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.14549319073557854                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [676, 755, 955, 1854, 1219, 281, 1836, 832, 953, 1498]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :676
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766896
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452850
INFO:root:FL Epoch: 359 Norm Difference for worker 676 is 1.512122
INFO:root:FL Epoch: 359 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :755
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365389
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224211
INFO:root:FL Epoch: 359 Norm Difference for worker 755 is 1.235574
INFO:root:FL Epoch: 359 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :955
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686197
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298118
INFO:root:FL Epoch: 359 Norm Difference for worker 955 is 1.428067
INFO:root:FL Epoch: 359 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1854
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556749
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336909
INFO:root:FL Epoch: 359 Norm Difference for worker 1854 is 1.515839
INFO:root:FL Epoch: 359 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1219
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429164
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270397
INFO:root:FL Epoch: 359 Norm Difference for worker 1219 is 1.329851
INFO:root:FL Epoch: 359 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :281
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207627
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 281 is 1.230665
INFO:root:FL Epoch: 359 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1836
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498785
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238554
INFO:root:FL Epoch: 359 Norm Difference for worker 1836 is 1.284418
INFO:root:FL Epoch: 359 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :832
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540954
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283551
INFO:root:FL Epoch: 359 Norm Difference for worker 832 is 1.479714
INFO:root:FL Epoch: 359 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :953
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450263
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286083
INFO:root:FL Epoch: 359 Norm Difference for worker 953 is 1.376692
INFO:root:FL Epoch: 359 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1498
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320703
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261520
INFO:root:FL Epoch: 359 Norm Difference for worker 1498 is 1.393625
INFO:root:FL Epoch: 359 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [1 4 6 5 9 8 2], which are global users: [755, 1219, 1836, 281, 1498, 953, 955]
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.43757044567781334 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.1268489584326744                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [752, 1335, 1381, 1057, 813, 767, 214, 100, 80, 1821]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :752
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537154
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385967
INFO:root:FL Epoch: 360 Norm Difference for worker 752 is 1.501586
INFO:root:FL Epoch: 360 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1335
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600130
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526224
INFO:root:FL Epoch: 360 Norm Difference for worker 1335 is 1.5425
INFO:root:FL Epoch: 360 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1381
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570413
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457680
INFO:root:FL Epoch: 360 Norm Difference for worker 1381 is 1.541882
INFO:root:FL Epoch: 360 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1057
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924489
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395648
INFO:root:FL Epoch: 360 Norm Difference for worker 1057 is 1.462657
INFO:root:FL Epoch: 360 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :813
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353457
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176376
INFO:root:FL Epoch: 360 Norm Difference for worker 813 is 1.435152
INFO:root:FL Epoch: 360 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :767
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736934
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367134
INFO:root:FL Epoch: 360 Norm Difference for worker 767 is 1.561773
INFO:root:FL Epoch: 360 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :214
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.139274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 214 is 1.26497
INFO:root:FL Epoch: 360 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :100
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.147428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 100 is 1.360123
INFO:root:FL Epoch: 360 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :80
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 80 is 1.246792
INFO:root:FL Epoch: 360 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1821
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453028
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355740
INFO:root:FL Epoch: 360 Norm Difference for worker 1821 is 1.527024
INFO:root:FL Epoch: 360 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 201 201 200]
INFO:root:Num selected data points: [201 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 7 0 9], which are global users: [214, 813, 80, 1057, 100, 752, 1821]
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.442449573208304 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.128765399257342                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 1618, 643, 1710, 966, 640, 1848, 1504]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.216449
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167582
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.09085426790018876 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.11918318122625352 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.193328
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241864
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145608
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.09052662613491218 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.11910558044910431 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.199681
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.169212
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147484
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.0932857474933068 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.11984886676073074 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.193724
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1618
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627610
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326095
INFO:root:FL Epoch: 361 Norm Difference for worker 1618 is 1.327764
INFO:root:FL Epoch: 361 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :643
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386599
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253623
INFO:root:FL Epoch: 361 Norm Difference for worker 643 is 1.380662
INFO:root:FL Epoch: 361 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1710
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344824
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155534
INFO:root:FL Epoch: 361 Norm Difference for worker 1710 is 1.387388
INFO:root:FL Epoch: 361 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :966
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532802
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193147
INFO:root:FL Epoch: 361 Norm Difference for worker 966 is 1.453165
INFO:root:FL Epoch: 361 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :640
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389967
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297196
INFO:root:FL Epoch: 361 Norm Difference for worker 640 is 1.37123
INFO:root:FL Epoch: 361 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1848
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415146
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303058
INFO:root:FL Epoch: 361 Norm Difference for worker 1848 is 1.316482
INFO:root:FL Epoch: 361 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1504
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449092
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448709
INFO:root:FL Epoch: 361 Norm Difference for worker 1504 is 1.497021
INFO:root:FL Epoch: 361 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 0 2 3 1 4 5], which are global users: [1848, 0, 2, 1618, 1, 643, 1710]
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.4257834290756899 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.10649935031930606                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [648, 714, 824, 991, 1179, 1599, 585, 1926, 50, 1021]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :648
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491857
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166042
INFO:root:FL Epoch: 362 Norm Difference for worker 648 is 1.321983
INFO:root:FL Epoch: 362 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :714
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693143
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355303
INFO:root:FL Epoch: 362 Norm Difference for worker 714 is 1.563421
INFO:root:FL Epoch: 362 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :824
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330116
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651655
INFO:root:FL Epoch: 362 Norm Difference for worker 824 is 1.425752
INFO:root:FL Epoch: 362 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :991
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.187206
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349032
INFO:root:FL Epoch: 362 Norm Difference for worker 991 is 1.37506
INFO:root:FL Epoch: 362 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1179
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275048
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273028
INFO:root:FL Epoch: 362 Norm Difference for worker 1179 is 1.304731
INFO:root:FL Epoch: 362 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1599
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345855
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156591
INFO:root:FL Epoch: 362 Norm Difference for worker 1599 is 1.320989
INFO:root:FL Epoch: 362 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :585
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655219
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187415
INFO:root:FL Epoch: 362 Norm Difference for worker 585 is 1.374521
INFO:root:FL Epoch: 362 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1926
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438094
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277960
INFO:root:FL Epoch: 362 Norm Difference for worker 1926 is 1.440625
INFO:root:FL Epoch: 362 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :50
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544339
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 50 is 1.457824
INFO:root:FL Epoch: 362 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1021
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558117
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251834
INFO:root:FL Epoch: 362 Norm Difference for worker 1021 is 1.312116
INFO:root:FL Epoch: 362 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 0 9 5 3 6 2], which are global users: [1179, 648, 1021, 1599, 991, 585, 824]
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.4360150230281493 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.10997106942037742                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [1332, 1401, 480, 1193, 838, 313, 1411, 1295, 877, 456]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :1332
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292409
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330413
INFO:root:FL Epoch: 363 Norm Difference for worker 1332 is 1.378042
INFO:root:FL Epoch: 363 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1401
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428629
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189517
INFO:root:FL Epoch: 363 Norm Difference for worker 1401 is 1.467514
INFO:root:FL Epoch: 363 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :480
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456483
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378655
INFO:root:FL Epoch: 363 Norm Difference for worker 480 is 1.508449
INFO:root:FL Epoch: 363 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1193
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304371
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414060
INFO:root:FL Epoch: 363 Norm Difference for worker 1193 is 1.51862
INFO:root:FL Epoch: 363 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :838
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649389
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300630
INFO:root:FL Epoch: 363 Norm Difference for worker 838 is 1.551771
INFO:root:FL Epoch: 363 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :313
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.154963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 313 is 1.313025
INFO:root:FL Epoch: 363 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1411
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518026
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392009
INFO:root:FL Epoch: 363 Norm Difference for worker 1411 is 1.499156
INFO:root:FL Epoch: 363 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1295
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415473
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212708
INFO:root:FL Epoch: 363 Norm Difference for worker 1295 is 1.364454
INFO:root:FL Epoch: 363 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :877
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354349
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262723
INFO:root:FL Epoch: 363 Norm Difference for worker 877 is 1.509225
INFO:root:FL Epoch: 363 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :456
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415158
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241481
INFO:root:FL Epoch: 363 Norm Difference for worker 456 is 1.351646
INFO:root:FL Epoch: 363 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 7 0 8 1 6], which are global users: [313, 456, 1295, 1332, 877, 1401, 1411]
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.45135997498736663 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.12520694235960642                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [161, 1851, 1054, 165, 574, 185, 319, 539, 667, 303]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.10024938 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 364 Num points on workers: [201 200 200 201 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :161
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 161 is 1.353592
INFO:root:FL Epoch: 364 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1851
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675998
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309057
INFO:root:FL Epoch: 364 Norm Difference for worker 1851 is 1.372731
INFO:root:FL Epoch: 364 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1054
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343800
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228974
INFO:root:FL Epoch: 364 Norm Difference for worker 1054 is 1.481499
INFO:root:FL Epoch: 364 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :165
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 165 is 1.452257
INFO:root:FL Epoch: 364 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :574
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287628
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226211
INFO:root:FL Epoch: 364 Norm Difference for worker 574 is 1.452117
INFO:root:FL Epoch: 364 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :185
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.185012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 185 is 1.231799
INFO:root:FL Epoch: 364 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :319
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.206359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.164062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 319 is 1.328691
INFO:root:FL Epoch: 364 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :539
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649670
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311860
INFO:root:FL Epoch: 364 Norm Difference for worker 539 is 1.513478
INFO:root:FL Epoch: 364 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :667
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414984
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265124
INFO:root:FL Epoch: 364 Norm Difference for worker 667 is 1.350751
INFO:root:FL Epoch: 364 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :303
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374496
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 303 is 1.419056
INFO:root:FL Epoch: 364 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 201 201 200 200 201]
INFO:root:Num selected data points: [201 201 200 201 200 200 201]
INFO:root:The chosen ones are users: [5 0 8 6 1 4 9], which are global users: [185, 161, 667, 319, 1851, 574, 303]
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.4650033519548528 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.133640356361866                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [184, 1587, 703, 353, 1442, 1376, 959, 669, 1830, 1102]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 365 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :184
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 184 is 1.231964
INFO:root:FL Epoch: 365 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1587
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483874
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163106
INFO:root:FL Epoch: 365 Norm Difference for worker 1587 is 1.441159
INFO:root:FL Epoch: 365 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :703
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274437
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234917
INFO:root:FL Epoch: 365 Norm Difference for worker 703 is 1.47709
INFO:root:FL Epoch: 365 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :353
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655009
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304831
INFO:root:FL Epoch: 365 Norm Difference for worker 353 is 1.479576
INFO:root:FL Epoch: 365 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1442
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442924
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341612
INFO:root:FL Epoch: 365 Norm Difference for worker 1442 is 1.461019
INFO:root:FL Epoch: 365 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1376
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552026
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219772
INFO:root:FL Epoch: 365 Norm Difference for worker 1376 is 1.385138
INFO:root:FL Epoch: 365 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :959
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611715
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290698
INFO:root:FL Epoch: 365 Norm Difference for worker 959 is 1.407807
INFO:root:FL Epoch: 365 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :669
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373431
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311417
INFO:root:FL Epoch: 365 Norm Difference for worker 669 is 1.437017
INFO:root:FL Epoch: 365 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1830
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583709
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162267
INFO:root:FL Epoch: 365 Norm Difference for worker 1830 is 1.475397
INFO:root:FL Epoch: 365 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1102
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287200
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286978
INFO:root:FL Epoch: 365 Norm Difference for worker 1102 is 1.340882
INFO:root:FL Epoch: 365 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [0 9 6 5 1 7 4], which are global users: [184, 1102, 959, 1376, 1587, 669, 1442]
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.45609355849378247 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.1257425993680954                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1351, 1724, 887, 1192, 624, 1905, 629, 890, 1653, 1794]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1351
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578260
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531058
INFO:root:FL Epoch: 366 Norm Difference for worker 1351 is 1.564503
INFO:root:FL Epoch: 366 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1724
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612875
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333946
INFO:root:FL Epoch: 366 Norm Difference for worker 1724 is 1.464831
INFO:root:FL Epoch: 366 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :887
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432804
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338375
INFO:root:FL Epoch: 366 Norm Difference for worker 887 is 1.387955
INFO:root:FL Epoch: 366 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1192
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420002
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436959
INFO:root:FL Epoch: 366 Norm Difference for worker 1192 is 1.48624
INFO:root:FL Epoch: 366 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :624
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727950
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316072
INFO:root:FL Epoch: 366 Norm Difference for worker 624 is 1.357586
INFO:root:FL Epoch: 366 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1905
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301500
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182720
INFO:root:FL Epoch: 366 Norm Difference for worker 1905 is 1.146238
INFO:root:FL Epoch: 366 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :629
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547512
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242816
INFO:root:FL Epoch: 366 Norm Difference for worker 629 is 1.312229
INFO:root:FL Epoch: 366 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :890
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338148
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336506
INFO:root:FL Epoch: 366 Norm Difference for worker 890 is 1.55213
INFO:root:FL Epoch: 366 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1653
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242099
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197372
INFO:root:FL Epoch: 366 Norm Difference for worker 1653 is 1.287362
INFO:root:FL Epoch: 366 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1794
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393831
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402908
INFO:root:FL Epoch: 366 Norm Difference for worker 1794 is 1.517807
INFO:root:FL Epoch: 366 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 4 2 3 1 5 6], which are global users: [1653, 624, 887, 1192, 1724, 1905, 629]
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.4532453137285569 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.15637695665160814                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [1509, 1066, 558, 1605, 399, 1525, 1148, 677, 1492, 327]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 367 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :1509
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646295
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320853
INFO:root:FL Epoch: 367 Norm Difference for worker 1509 is 1.307757
INFO:root:FL Epoch: 367 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1066
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224530
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381593
INFO:root:FL Epoch: 367 Norm Difference for worker 1066 is 1.523839
INFO:root:FL Epoch: 367 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :558
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468728
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585514
INFO:root:FL Epoch: 367 Norm Difference for worker 558 is 1.591168
INFO:root:FL Epoch: 367 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1605
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252407
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244125
INFO:root:FL Epoch: 367 Norm Difference for worker 1605 is 1.50965
INFO:root:FL Epoch: 367 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :399
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253223
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378733
INFO:root:FL Epoch: 367 Norm Difference for worker 399 is 1.450454
INFO:root:FL Epoch: 367 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1525
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813659
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351076
INFO:root:FL Epoch: 367 Norm Difference for worker 1525 is 1.491755
INFO:root:FL Epoch: 367 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1148
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672630
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261703
INFO:root:FL Epoch: 367 Norm Difference for worker 1148 is 1.550395
INFO:root:FL Epoch: 367 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :677
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466975
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230211
INFO:root:FL Epoch: 367 Norm Difference for worker 677 is 1.57766
INFO:root:FL Epoch: 367 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1492
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762254
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121113
INFO:root:FL Epoch: 367 Norm Difference for worker 1492 is 1.40775
INFO:root:FL Epoch: 367 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :327
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 1.030345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 327 is 1.648549
INFO:root:FL Epoch: 367 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 0 4 1 3 5 6], which are global users: [1492, 1509, 399, 1066, 1605, 1525, 1148]
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.4331016119788675 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.13514080395301184                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [783, 277, 1708, 1063, 169, 1279, 247, 1366, 304, 1678]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 368 Num points on workers: [200 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :783
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858944
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319069
INFO:root:FL Epoch: 368 Norm Difference for worker 783 is 1.384638
INFO:root:FL Epoch: 368 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :277
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372278
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 277 is 1.403937
INFO:root:FL Epoch: 368 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1708
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543595
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266448
INFO:root:FL Epoch: 368 Norm Difference for worker 1708 is 1.474593
INFO:root:FL Epoch: 368 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1063
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311875
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488942
INFO:root:FL Epoch: 368 Norm Difference for worker 1063 is 1.487881
INFO:root:FL Epoch: 368 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :169
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 169 is 1.463806
INFO:root:FL Epoch: 368 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1279
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860760
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382662
INFO:root:FL Epoch: 368 Norm Difference for worker 1279 is 1.392293
INFO:root:FL Epoch: 368 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :247
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.146902
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 247 is 1.46362
INFO:root:FL Epoch: 368 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1366
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299459
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238416
INFO:root:FL Epoch: 368 Norm Difference for worker 1366 is 1.348475
INFO:root:FL Epoch: 368 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :304
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 304 is 1.331169
INFO:root:FL Epoch: 368 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1678
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296452
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222342
INFO:root:FL Epoch: 368 Norm Difference for worker 1678 is 1.34177
INFO:root:FL Epoch: 368 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 201 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 201]
INFO:root:The chosen ones are users: [5 9 8 7 1 0 4], which are global users: [1279, 1678, 304, 1366, 277, 783, 169]
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.4294404615374172 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.14016906544566154                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [897, 768, 199, 1231, 1007, 245, 1031, 439, 680, 841]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :897
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471778
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173592
INFO:root:FL Epoch: 369 Norm Difference for worker 897 is 1.468403
INFO:root:FL Epoch: 369 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :768
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311617
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435826
INFO:root:FL Epoch: 369 Norm Difference for worker 768 is 1.389504
INFO:root:FL Epoch: 369 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :199
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 199 is 1.501221
INFO:root:FL Epoch: 369 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1231
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.183701
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326170
INFO:root:FL Epoch: 369 Norm Difference for worker 1231 is 1.443221
INFO:root:FL Epoch: 369 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1007
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651042
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335860
INFO:root:FL Epoch: 369 Norm Difference for worker 1007 is 1.432647
INFO:root:FL Epoch: 369 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :245
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 245 is 1.528408
INFO:root:FL Epoch: 369 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1031
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612652
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302171
INFO:root:FL Epoch: 369 Norm Difference for worker 1031 is 1.558477
INFO:root:FL Epoch: 369 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :439
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656340
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483762
INFO:root:FL Epoch: 369 Norm Difference for worker 439 is 1.383256
INFO:root:FL Epoch: 369 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :680
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512688
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154859
INFO:root:FL Epoch: 369 Norm Difference for worker 680 is 1.473674
INFO:root:FL Epoch: 369 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :841
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745333
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427681
INFO:root:FL Epoch: 369 Norm Difference for worker 841 is 1.403378
INFO:root:FL Epoch: 369 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 7 3 4 8 0], which are global users: [768, 841, 439, 1231, 1007, 680, 897]
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.44399041288039265 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.15557502085963884                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [78, 158, 1509, 571, 30, 818, 201, 1021, 185, 750]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 370 Num points on workers: [201 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :78
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 78 is 1.346336
INFO:root:FL Epoch: 370 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :158
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.347305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263637
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 158 is 1.328356
INFO:root:FL Epoch: 370 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1509
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406682
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290792
INFO:root:FL Epoch: 370 Norm Difference for worker 1509 is 1.220112
INFO:root:FL Epoch: 370 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :571
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512122
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446102
INFO:root:FL Epoch: 370 Norm Difference for worker 571 is 1.340322
INFO:root:FL Epoch: 370 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :30
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 30 is 1.367689
INFO:root:FL Epoch: 370 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :818
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470942
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368229
INFO:root:FL Epoch: 370 Norm Difference for worker 818 is 1.433343
INFO:root:FL Epoch: 370 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :201
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590911
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 201 is 1.485061
INFO:root:FL Epoch: 370 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1021
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353751
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174450
INFO:root:FL Epoch: 370 Norm Difference for worker 1021 is 1.216287
INFO:root:FL Epoch: 370 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :185
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.221780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.328342
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 185 is 1.156286
INFO:root:FL Epoch: 370 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :750
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492100
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206735
INFO:root:FL Epoch: 370 Norm Difference for worker 750 is 1.453662
INFO:root:FL Epoch: 370 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 201 200 201 200 201 200]
INFO:root:Num selected data points: [200 201 200 200 201 201 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 4], which are global users: [1021, 78, 1509, 571, 158, 185, 30]
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.4702511955710018 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.13183690731724104                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 1061, 1042, 1852, 1271, 1167, 671, 986]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254958
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.106073
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.099142341564099 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.10413204208016395 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.195311
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.128587
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166762
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.10111804989476998 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.10440713837742806 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.194762
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.153599
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194491
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.09695863537490368 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.104556754976511 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.188195
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1061
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538315
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443783
INFO:root:FL Epoch: 371 Norm Difference for worker 1061 is 1.438669
INFO:root:FL Epoch: 371 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1042
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408726
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240914
INFO:root:FL Epoch: 371 Norm Difference for worker 1042 is 1.33613
INFO:root:FL Epoch: 371 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1852
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549776
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453859
INFO:root:FL Epoch: 371 Norm Difference for worker 1852 is 1.380484
INFO:root:FL Epoch: 371 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1271
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638689
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423168
INFO:root:FL Epoch: 371 Norm Difference for worker 1271 is 1.338983
INFO:root:FL Epoch: 371 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1167
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639642
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323513
INFO:root:FL Epoch: 371 Norm Difference for worker 1167 is 1.404854
INFO:root:FL Epoch: 371 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :671
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501431
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193949
INFO:root:FL Epoch: 371 Norm Difference for worker 671 is 1.211463
INFO:root:FL Epoch: 371 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :986
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464744
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304580
INFO:root:FL Epoch: 371 Norm Difference for worker 986 is 1.49803
INFO:root:FL Epoch: 371 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 8 4 6 5], which are global users: [1, 0, 2, 671, 1042, 1271, 1852]
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.4712928270592409 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.13305706282456717                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1304, 439, 523, 1858, 473, 17, 1491, 1571, 364, 119]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1304
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480698
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328101
INFO:root:FL Epoch: 372 Norm Difference for worker 1304 is 1.357895
INFO:root:FL Epoch: 372 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :439
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.210670
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234508
INFO:root:FL Epoch: 372 Norm Difference for worker 439 is 1.267588
INFO:root:FL Epoch: 372 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :523
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601124
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190630
INFO:root:FL Epoch: 372 Norm Difference for worker 523 is 1.523789
INFO:root:FL Epoch: 372 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1858
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525431
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206326
INFO:root:FL Epoch: 372 Norm Difference for worker 1858 is 1.475559
INFO:root:FL Epoch: 372 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :473
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721512
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314417
INFO:root:FL Epoch: 372 Norm Difference for worker 473 is 1.428606
INFO:root:FL Epoch: 372 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :17
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.919731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 17 is 1.539923
INFO:root:FL Epoch: 372 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1491
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711412
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327110
INFO:root:FL Epoch: 372 Norm Difference for worker 1491 is 1.371341
INFO:root:FL Epoch: 372 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1571
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813852
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289184
INFO:root:FL Epoch: 372 Norm Difference for worker 1571 is 1.361385
INFO:root:FL Epoch: 372 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :364
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606817
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204785
INFO:root:FL Epoch: 372 Norm Difference for worker 364 is 1.524536
INFO:root:FL Epoch: 372 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :119
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 119 is 1.480289
INFO:root:FL Epoch: 372 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [1 0 7 6 4 9 3], which are global users: [439, 1304, 1571, 1491, 473, 119, 1858]
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.47877608853227954 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.15953859935204187                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [1519, 1509, 112, 1748, 415, 1017, 782, 1715, 1356, 1342]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :1519
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577634
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474379
INFO:root:FL Epoch: 373 Norm Difference for worker 1519 is 1.375374
INFO:root:FL Epoch: 373 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1509
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383111
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179187
INFO:root:FL Epoch: 373 Norm Difference for worker 1509 is 1.09904
INFO:root:FL Epoch: 373 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :112
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.757547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 112 is 1.400657
INFO:root:FL Epoch: 373 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1748
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499444
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333839
INFO:root:FL Epoch: 373 Norm Difference for worker 1748 is 1.514128
INFO:root:FL Epoch: 373 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :415
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 1.021905
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243134
INFO:root:FL Epoch: 373 Norm Difference for worker 415 is 1.443056
INFO:root:FL Epoch: 373 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1017
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560137
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498969
INFO:root:FL Epoch: 373 Norm Difference for worker 1017 is 1.459311
INFO:root:FL Epoch: 373 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :782
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405304
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229214
INFO:root:FL Epoch: 373 Norm Difference for worker 782 is 1.518994
INFO:root:FL Epoch: 373 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1715
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563695
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219611
INFO:root:FL Epoch: 373 Norm Difference for worker 1715 is 1.395173
INFO:root:FL Epoch: 373 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1356
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454888
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209933
INFO:root:FL Epoch: 373 Norm Difference for worker 1356 is 1.663702
INFO:root:FL Epoch: 373 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1342
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326590
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201756
INFO:root:FL Epoch: 373 Norm Difference for worker 1342 is 1.384822
INFO:root:FL Epoch: 373 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 9 7 4 5], which are global users: [1509, 1519, 112, 1342, 1715, 415, 1017]
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.4693542824071996 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.15228025366862616                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1498, 804, 643, 1075, 1437, 74, 979, 516, 1748, 1798]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1498
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268166
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217874
INFO:root:FL Epoch: 374 Norm Difference for worker 1498 is 1.392194
INFO:root:FL Epoch: 374 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :804
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406066
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346261
INFO:root:FL Epoch: 374 Norm Difference for worker 804 is 1.566461
INFO:root:FL Epoch: 374 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :643
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585062
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225142
INFO:root:FL Epoch: 374 Norm Difference for worker 643 is 1.399549
INFO:root:FL Epoch: 374 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1075
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323888
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173220
INFO:root:FL Epoch: 374 Norm Difference for worker 1075 is 1.35486
INFO:root:FL Epoch: 374 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1437
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858835
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202929
INFO:root:FL Epoch: 374 Norm Difference for worker 1437 is 1.519774
INFO:root:FL Epoch: 374 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :74
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 74 is 1.423267
INFO:root:FL Epoch: 374 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :979
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930672
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406810
INFO:root:FL Epoch: 374 Norm Difference for worker 979 is 1.492863
INFO:root:FL Epoch: 374 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :516
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736825
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202005
INFO:root:FL Epoch: 374 Norm Difference for worker 516 is 1.437043
INFO:root:FL Epoch: 374 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1748
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608303
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372007
INFO:root:FL Epoch: 374 Norm Difference for worker 1748 is 1.472147
INFO:root:FL Epoch: 374 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1798
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677870
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197565
INFO:root:FL Epoch: 374 Norm Difference for worker 1798 is 1.523703
INFO:root:FL Epoch: 374 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 0 2 3 8 5 6], which are global users: [516, 1498, 643, 1075, 1748, 74, 979]
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.45617521159789143 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.1661756212512652                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [317, 105, 1425, 1249, 401, 243, 53, 960, 1525, 1533]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 375 Num points on workers: [201 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :317
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 317 is 1.371638
INFO:root:FL Epoch: 375 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :105
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344899
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 105 is 1.361007
INFO:root:FL Epoch: 375 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1425
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677177
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218290
INFO:root:FL Epoch: 375 Norm Difference for worker 1425 is 1.369922
INFO:root:FL Epoch: 375 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1249
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377266
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410917
INFO:root:FL Epoch: 375 Norm Difference for worker 1249 is 1.333865
INFO:root:FL Epoch: 375 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :401
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598663
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302729
INFO:root:FL Epoch: 375 Norm Difference for worker 401 is 1.457834
INFO:root:FL Epoch: 375 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :243
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 243 is 1.286783
INFO:root:FL Epoch: 375 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :53
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378846
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386979
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 53 is 1.391166
INFO:root:FL Epoch: 375 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :960
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416800
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211860
INFO:root:FL Epoch: 375 Norm Difference for worker 960 is 1.325255
INFO:root:FL Epoch: 375 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1525
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789940
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233690
INFO:root:FL Epoch: 375 Norm Difference for worker 1525 is 1.343542
INFO:root:FL Epoch: 375 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1533
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575205
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286399
INFO:root:FL Epoch: 375 Norm Difference for worker 1533 is 1.342058
INFO:root:FL Epoch: 375 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 9 8 3 7 0 2], which are global users: [243, 1533, 1525, 1249, 960, 317, 1425]
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.4707728098420536 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.154554333537817                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1397, 18, 956, 910, 205, 740, 1557, 1744, 425, 1208]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 376 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1397
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400417
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403779
INFO:root:FL Epoch: 376 Norm Difference for worker 1397 is 1.322181
INFO:root:FL Epoch: 376 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :18
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.294269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 18 is 1.336145
INFO:root:FL Epoch: 376 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :956
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256332
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169020
INFO:root:FL Epoch: 376 Norm Difference for worker 956 is 1.425832
INFO:root:FL Epoch: 376 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :910
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464099
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227408
INFO:root:FL Epoch: 376 Norm Difference for worker 910 is 1.319489
INFO:root:FL Epoch: 376 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :205
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288874
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 205 is 1.395605
INFO:root:FL Epoch: 376 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :740
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610522
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354226
INFO:root:FL Epoch: 376 Norm Difference for worker 740 is 1.36859
INFO:root:FL Epoch: 376 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1557
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304075
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170688
INFO:root:FL Epoch: 376 Norm Difference for worker 1557 is 1.250193
INFO:root:FL Epoch: 376 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1744
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463488
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143644
INFO:root:FL Epoch: 376 Norm Difference for worker 1744 is 1.200045
INFO:root:FL Epoch: 376 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :425
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512092
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322713
INFO:root:FL Epoch: 376 Norm Difference for worker 425 is 1.450535
INFO:root:FL Epoch: 376 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1208
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556853
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229762
INFO:root:FL Epoch: 376 Norm Difference for worker 1208 is 1.350201
INFO:root:FL Epoch: 376 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 0 7 3 1 9 5], which are global users: [1557, 1397, 1744, 910, 18, 1208, 740]
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.47262948576141806 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.15718620643019676                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [1407, 59, 1055, 261, 1932, 581, 1253, 23, 462, 1153]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :1407
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418363
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359691
INFO:root:FL Epoch: 377 Norm Difference for worker 1407 is 1.458621
INFO:root:FL Epoch: 377 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :59
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 59 is 1.237164
INFO:root:FL Epoch: 377 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1055
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496574
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278475
INFO:root:FL Epoch: 377 Norm Difference for worker 1055 is 1.386658
INFO:root:FL Epoch: 377 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :261
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 261 is 1.460184
INFO:root:FL Epoch: 377 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1932
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254631
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107820
INFO:root:FL Epoch: 377 Norm Difference for worker 1932 is 1.345651
INFO:root:FL Epoch: 377 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :581
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595883
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401261
INFO:root:FL Epoch: 377 Norm Difference for worker 581 is 1.610783
INFO:root:FL Epoch: 377 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1253
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419102
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429231
INFO:root:FL Epoch: 377 Norm Difference for worker 1253 is 1.459305
INFO:root:FL Epoch: 377 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :23
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 23 is 1.555966
INFO:root:FL Epoch: 377 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :462
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247751
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233204
INFO:root:FL Epoch: 377 Norm Difference for worker 462 is 1.442735
INFO:root:FL Epoch: 377 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1153
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684383
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337204
INFO:root:FL Epoch: 377 Norm Difference for worker 1153 is 1.450064
INFO:root:FL Epoch: 377 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 201 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 1 8 9], which are global users: [1253, 1932, 1055, 261, 59, 462, 1153]
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.4831460696809432 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.1594395786523819                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1066, 1905, 777, 1310, 1028, 1906, 169, 573, 888, 1462]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1066
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325275
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347203
INFO:root:FL Epoch: 378 Norm Difference for worker 1066 is 1.354461
INFO:root:FL Epoch: 378 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1905
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.159139
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250861
INFO:root:FL Epoch: 378 Norm Difference for worker 1905 is 1.137455
INFO:root:FL Epoch: 378 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :777
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540338
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233765
INFO:root:FL Epoch: 378 Norm Difference for worker 777 is 1.438589
INFO:root:FL Epoch: 378 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1310
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637682
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185463
INFO:root:FL Epoch: 378 Norm Difference for worker 1310 is 1.306008
INFO:root:FL Epoch: 378 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1028
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417979
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321337
INFO:root:FL Epoch: 378 Norm Difference for worker 1028 is 1.315812
INFO:root:FL Epoch: 378 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1906
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363632
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360885
INFO:root:FL Epoch: 378 Norm Difference for worker 1906 is 1.351892
INFO:root:FL Epoch: 378 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :169
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242503
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 169 is 1.357802
INFO:root:FL Epoch: 378 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :573
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521138
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342186
INFO:root:FL Epoch: 378 Norm Difference for worker 573 is 1.39344
INFO:root:FL Epoch: 378 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :888
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532291
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181193
INFO:root:FL Epoch: 378 Norm Difference for worker 888 is 1.286193
INFO:root:FL Epoch: 378 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1462
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421384
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443095
INFO:root:FL Epoch: 378 Norm Difference for worker 1462 is 1.439878
INFO:root:FL Epoch: 378 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 5 0], which are global users: [169, 1028, 888, 1310, 1905, 1906, 1066]
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.47603605599964366 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.15509106839696565                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1554, 794, 1231, 1576, 294, 838, 310, 790, 612, 300]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1554
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395410
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.104901
INFO:root:FL Epoch: 379 Norm Difference for worker 1554 is 1.267567
INFO:root:FL Epoch: 379 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :794
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392605
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311918
INFO:root:FL Epoch: 379 Norm Difference for worker 794 is 1.435546
INFO:root:FL Epoch: 379 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1231
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487677
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416493
INFO:root:FL Epoch: 379 Norm Difference for worker 1231 is 1.409578
INFO:root:FL Epoch: 379 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1576
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529391
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408525
INFO:root:FL Epoch: 379 Norm Difference for worker 1576 is 1.417745
INFO:root:FL Epoch: 379 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :294
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 294 is 1.505829
INFO:root:FL Epoch: 379 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :838
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360483
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276527
INFO:root:FL Epoch: 379 Norm Difference for worker 838 is 1.475002
INFO:root:FL Epoch: 379 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :310
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414067
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 310 is 1.412262
INFO:root:FL Epoch: 379 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :790
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530387
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308770
INFO:root:FL Epoch: 379 Norm Difference for worker 790 is 1.520036
INFO:root:FL Epoch: 379 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :612
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437953
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204497
INFO:root:FL Epoch: 379 Norm Difference for worker 612 is 1.364885
INFO:root:FL Epoch: 379 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :300
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 300 is 1.427275
INFO:root:FL Epoch: 379 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 201 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 0 2 3 1 8 9], which are global users: [310, 1554, 1231, 1576, 794, 612, 300]
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.4773800320485059 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.16411170860131583                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [932, 1259, 1268, 1635, 1840, 651, 1586, 332, 1409, 1110]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :932
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392532
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275682
INFO:root:FL Epoch: 380 Norm Difference for worker 932 is 1.404681
INFO:root:FL Epoch: 380 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1259
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493104
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304513
INFO:root:FL Epoch: 380 Norm Difference for worker 1259 is 1.36433
INFO:root:FL Epoch: 380 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1268
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557874
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204316
INFO:root:FL Epoch: 380 Norm Difference for worker 1268 is 1.397821
INFO:root:FL Epoch: 380 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1635
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.199938
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276548
INFO:root:FL Epoch: 380 Norm Difference for worker 1635 is 1.26925
INFO:root:FL Epoch: 380 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1840
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464250
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237444
INFO:root:FL Epoch: 380 Norm Difference for worker 1840 is 1.366648
INFO:root:FL Epoch: 380 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :651
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565529
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367988
INFO:root:FL Epoch: 380 Norm Difference for worker 651 is 1.393505
INFO:root:FL Epoch: 380 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1586
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584217
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202108
INFO:root:FL Epoch: 380 Norm Difference for worker 1586 is 1.38678
INFO:root:FL Epoch: 380 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :332
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 332 is 1.291036
INFO:root:FL Epoch: 380 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1409
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776885
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272536
INFO:root:FL Epoch: 380 Norm Difference for worker 1409 is 1.346236
INFO:root:FL Epoch: 380 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1110
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567580
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226447
INFO:root:FL Epoch: 380 Norm Difference for worker 1110 is 1.502513
INFO:root:FL Epoch: 380 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 3 8 1 5 4 2], which are global users: [332, 1635, 1409, 1259, 651, 1840, 1268]
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.48380930634105906 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.13671127458413443                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 1679, 116, 928, 1045, 563, 1144, 438]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.156133
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150537
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.08497224375605583 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.1010372944176197 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.185587
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.139365
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.095285
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.08991119389732678 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.10032118484377861 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.171916
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.131756
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166212
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.0881712728490432 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.09945244938135148 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.174909
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1679
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455333
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247887
INFO:root:FL Epoch: 381 Norm Difference for worker 1679 is 1.520551
INFO:root:FL Epoch: 381 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :116
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.128706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 116 is 1.401824
INFO:root:FL Epoch: 381 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :928
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501364
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309512
INFO:root:FL Epoch: 381 Norm Difference for worker 928 is 1.301897
INFO:root:FL Epoch: 381 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1045
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356288
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439569
INFO:root:FL Epoch: 381 Norm Difference for worker 1045 is 1.297172
INFO:root:FL Epoch: 381 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :563
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361975
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226898
INFO:root:FL Epoch: 381 Norm Difference for worker 563 is 1.307107
INFO:root:FL Epoch: 381 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1144
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313075
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158919
INFO:root:FL Epoch: 381 Norm Difference for worker 1144 is 1.375531
INFO:root:FL Epoch: 381 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :438
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505626
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179195
INFO:root:FL Epoch: 381 Norm Difference for worker 438 is 1.436276
INFO:root:FL Epoch: 381 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [563, 0, 2, 1144, 1, 928, 1045]
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.47900373444837685 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.09716433472931385                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [305, 780, 1929, 1520, 481, 1295, 101, 560, 999, 452]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 382 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :305
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 305 is 1.289252
INFO:root:FL Epoch: 382 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :780
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559604
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331194
INFO:root:FL Epoch: 382 Norm Difference for worker 780 is 1.385086
INFO:root:FL Epoch: 382 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1929
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375161
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116675
INFO:root:FL Epoch: 382 Norm Difference for worker 1929 is 1.250698
INFO:root:FL Epoch: 382 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1520
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289301
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141729
INFO:root:FL Epoch: 382 Norm Difference for worker 1520 is 1.281321
INFO:root:FL Epoch: 382 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :481
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350593
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345619
INFO:root:FL Epoch: 382 Norm Difference for worker 481 is 1.464531
INFO:root:FL Epoch: 382 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1295
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440994
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285139
INFO:root:FL Epoch: 382 Norm Difference for worker 1295 is 1.353942
INFO:root:FL Epoch: 382 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :101
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 101 is 1.38382
INFO:root:FL Epoch: 382 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :560
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844701
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500459
INFO:root:FL Epoch: 382 Norm Difference for worker 560 is 1.493611
INFO:root:FL Epoch: 382 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :999
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453514
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252088
INFO:root:FL Epoch: 382 Norm Difference for worker 999 is 1.396893
INFO:root:FL Epoch: 382 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :452
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579447
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154458
INFO:root:FL Epoch: 382 Norm Difference for worker 452 is 1.245911
INFO:root:FL Epoch: 382 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [3 9 2 0 5 1 6], which are global users: [1520, 452, 1929, 305, 1295, 780, 101]
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.466180038802764 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.1082698901494344                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [1594, 712, 1782, 1693, 835, 153, 986, 618, 24, 1431]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :1594
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380220
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324394
INFO:root:FL Epoch: 383 Norm Difference for worker 1594 is 1.481481
INFO:root:FL Epoch: 383 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :712
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348286
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437200
INFO:root:FL Epoch: 383 Norm Difference for worker 712 is 1.461982
INFO:root:FL Epoch: 383 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1782
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397761
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294848
INFO:root:FL Epoch: 383 Norm Difference for worker 1782 is 1.366576
INFO:root:FL Epoch: 383 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1693
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726469
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420579
INFO:root:FL Epoch: 383 Norm Difference for worker 1693 is 1.356298
INFO:root:FL Epoch: 383 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :835
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304613
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245252
INFO:root:FL Epoch: 383 Norm Difference for worker 835 is 1.364472
INFO:root:FL Epoch: 383 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :153
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213459
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 153 is 1.280899
INFO:root:FL Epoch: 383 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :986
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530575
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153808
INFO:root:FL Epoch: 383 Norm Difference for worker 986 is 1.553199
INFO:root:FL Epoch: 383 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :618
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337979
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439234
INFO:root:FL Epoch: 383 Norm Difference for worker 618 is 1.459487
INFO:root:FL Epoch: 383 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :24
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 24 is 1.345788
INFO:root:FL Epoch: 383 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1431
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347206
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506401
INFO:root:FL Epoch: 383 Norm Difference for worker 1431 is 1.454093
INFO:root:FL Epoch: 383 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 201 200]
INFO:root:The chosen ones are users: [7 4 2 3 8 5 9], which are global users: [618, 835, 1782, 1693, 24, 153, 1431]
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.4509333126685199 and Test Accuracy:80.0 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.11424114741384983                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [459, 540, 192, 1368, 424, 223, 444, 1119, 917, 1924]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :459
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380189
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215009
INFO:root:FL Epoch: 384 Norm Difference for worker 459 is 1.318637
INFO:root:FL Epoch: 384 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :540
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388132
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340119
INFO:root:FL Epoch: 384 Norm Difference for worker 540 is 1.451237
INFO:root:FL Epoch: 384 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :192
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588513
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325881
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 192 is 1.334679
INFO:root:FL Epoch: 384 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1368
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544525
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171413
INFO:root:FL Epoch: 384 Norm Difference for worker 1368 is 1.346824
INFO:root:FL Epoch: 384 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :424
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232540
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338376
INFO:root:FL Epoch: 384 Norm Difference for worker 424 is 1.271941
INFO:root:FL Epoch: 384 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :223
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 223 is 1.448365
INFO:root:FL Epoch: 384 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :444
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334176
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442537
INFO:root:FL Epoch: 384 Norm Difference for worker 444 is 1.418212
INFO:root:FL Epoch: 384 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1119
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510311
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196120
INFO:root:FL Epoch: 384 Norm Difference for worker 1119 is 1.34983
INFO:root:FL Epoch: 384 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :917
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281478
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310181
INFO:root:FL Epoch: 384 Norm Difference for worker 917 is 1.534279
INFO:root:FL Epoch: 384 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1924
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503154
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279169
INFO:root:FL Epoch: 384 Norm Difference for worker 1924 is 1.476925
INFO:root:FL Epoch: 384 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 4 2 0 7 1 6], which are global users: [1368, 424, 192, 459, 1119, 540, 444]
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.4683354163871092 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.12845106050372124                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [1334, 1921, 1397, 757, 1041, 1479, 1249, 1807, 357, 1506]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 385 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :1334
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262244
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543734
INFO:root:FL Epoch: 385 Norm Difference for worker 1334 is 1.416163
INFO:root:FL Epoch: 385 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1921
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803109
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196964
INFO:root:FL Epoch: 385 Norm Difference for worker 1921 is 1.386052
INFO:root:FL Epoch: 385 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1397
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448472
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283994
INFO:root:FL Epoch: 385 Norm Difference for worker 1397 is 1.253978
INFO:root:FL Epoch: 385 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :757
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709382
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273267
INFO:root:FL Epoch: 385 Norm Difference for worker 757 is 1.415656
INFO:root:FL Epoch: 385 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1041
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708384
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483918
INFO:root:FL Epoch: 385 Norm Difference for worker 1041 is 1.420444
INFO:root:FL Epoch: 385 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1479
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.911011
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186495
INFO:root:FL Epoch: 385 Norm Difference for worker 1479 is 1.305048
INFO:root:FL Epoch: 385 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1249
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324460
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167981
INFO:root:FL Epoch: 385 Norm Difference for worker 1249 is 1.227262
INFO:root:FL Epoch: 385 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1807
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275678
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232643
INFO:root:FL Epoch: 385 Norm Difference for worker 1807 is 1.346
INFO:root:FL Epoch: 385 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :357
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323806
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206994
INFO:root:FL Epoch: 385 Norm Difference for worker 357 is 1.263376
INFO:root:FL Epoch: 385 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1506
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309755
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201027
INFO:root:FL Epoch: 385 Norm Difference for worker 1506 is 1.198049
INFO:root:FL Epoch: 385 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 8 1 5 6], which are global users: [1807, 1506, 1397, 357, 1921, 1479, 1249]
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.48249928565586314 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.1363017645974954                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [546, 1815, 707, 353, 765, 248, 1947, 1395, 1735, 1729]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :546
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714400
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147215
INFO:root:FL Epoch: 386 Norm Difference for worker 546 is 1.432572
INFO:root:FL Epoch: 386 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1815
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455324
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571586
INFO:root:FL Epoch: 386 Norm Difference for worker 1815 is 1.446205
INFO:root:FL Epoch: 386 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :707
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338451
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313737
INFO:root:FL Epoch: 386 Norm Difference for worker 707 is 1.325889
INFO:root:FL Epoch: 386 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :353
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677213
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225701
INFO:root:FL Epoch: 386 Norm Difference for worker 353 is 1.488363
INFO:root:FL Epoch: 386 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :765
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504848
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289103
INFO:root:FL Epoch: 386 Norm Difference for worker 765 is 1.462633
INFO:root:FL Epoch: 386 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :248
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 248 is 1.38034
INFO:root:FL Epoch: 386 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1947
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654661
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307434
INFO:root:FL Epoch: 386 Norm Difference for worker 1947 is 1.263609
INFO:root:FL Epoch: 386 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1395
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519682
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235048
INFO:root:FL Epoch: 386 Norm Difference for worker 1395 is 1.359644
INFO:root:FL Epoch: 386 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1735
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337320
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381732
INFO:root:FL Epoch: 386 Norm Difference for worker 1735 is 1.382766
INFO:root:FL Epoch: 386 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1729
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654469
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431722
INFO:root:FL Epoch: 386 Norm Difference for worker 1729 is 1.578915
INFO:root:FL Epoch: 386 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [1395, 546, 707, 1735, 1815, 248, 1947]
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.4668002584401299 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.15456117565433183                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [134, 1507, 700, 1293, 1148, 473, 855, 1266, 170, 422]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 387 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :134
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.220140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.147217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 134 is 1.333767
INFO:root:FL Epoch: 387 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1507
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363387
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357312
INFO:root:FL Epoch: 387 Norm Difference for worker 1507 is 1.38706
INFO:root:FL Epoch: 387 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :700
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413256
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320865
INFO:root:FL Epoch: 387 Norm Difference for worker 700 is 1.434346
INFO:root:FL Epoch: 387 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1293
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763325
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226598
INFO:root:FL Epoch: 387 Norm Difference for worker 1293 is 1.276671
INFO:root:FL Epoch: 387 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1148
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416858
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468495
INFO:root:FL Epoch: 387 Norm Difference for worker 1148 is 1.417704
INFO:root:FL Epoch: 387 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :473
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437737
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498764
INFO:root:FL Epoch: 387 Norm Difference for worker 473 is 1.340399
INFO:root:FL Epoch: 387 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :855
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848777
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230351
INFO:root:FL Epoch: 387 Norm Difference for worker 855 is 1.437406
INFO:root:FL Epoch: 387 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1266
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376712
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301113
INFO:root:FL Epoch: 387 Norm Difference for worker 1266 is 1.39357
INFO:root:FL Epoch: 387 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :170
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724141
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 170 is 1.305732
INFO:root:FL Epoch: 387 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :422
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473345
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367497
INFO:root:FL Epoch: 387 Norm Difference for worker 422 is 1.285969
INFO:root:FL Epoch: 387 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [3 9 0 5 8 1 7], which are global users: [1293, 422, 134, 473, 170, 1507, 1266]
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.4509022919570698 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.15124274169405302                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [832, 1256, 1254, 1459, 72, 786, 887, 1099, 1137, 333]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 388 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :832
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509099
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405503
INFO:root:FL Epoch: 388 Norm Difference for worker 832 is 1.412854
INFO:root:FL Epoch: 388 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1256
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361981
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186955
INFO:root:FL Epoch: 388 Norm Difference for worker 1256 is 1.23353
INFO:root:FL Epoch: 388 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1254
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415592
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322144
INFO:root:FL Epoch: 388 Norm Difference for worker 1254 is 1.37446
INFO:root:FL Epoch: 388 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1459
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726695
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247373
INFO:root:FL Epoch: 388 Norm Difference for worker 1459 is 1.478348
INFO:root:FL Epoch: 388 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :72
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285375
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 72 is 1.295723
INFO:root:FL Epoch: 388 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :786
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697081
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360644
INFO:root:FL Epoch: 388 Norm Difference for worker 786 is 1.430938
INFO:root:FL Epoch: 388 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :887
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480268
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185984
INFO:root:FL Epoch: 388 Norm Difference for worker 887 is 1.343522
INFO:root:FL Epoch: 388 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1099
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541052
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231223
INFO:root:FL Epoch: 388 Norm Difference for worker 1099 is 1.368345
INFO:root:FL Epoch: 388 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1137
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707510
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316146
INFO:root:FL Epoch: 388 Norm Difference for worker 1137 is 1.494986
INFO:root:FL Epoch: 388 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :333
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437490
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363161
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 333 is 1.401532
INFO:root:FL Epoch: 388 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 4 2 7 1 0 9], which are global users: [887, 72, 1254, 1099, 1256, 832, 333]
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.4580391592839185 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.1961711806555589                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [1513, 991, 1679, 1102, 716, 905, 546, 26, 1404, 1045]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :1513
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.191379
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188059
INFO:root:FL Epoch: 389 Norm Difference for worker 1513 is 1.282973
INFO:root:FL Epoch: 389 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :991
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398872
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473482
INFO:root:FL Epoch: 389 Norm Difference for worker 991 is 1.305476
INFO:root:FL Epoch: 389 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1679
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396528
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267648
INFO:root:FL Epoch: 389 Norm Difference for worker 1679 is 1.426887
INFO:root:FL Epoch: 389 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1102
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429508
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174546
INFO:root:FL Epoch: 389 Norm Difference for worker 1102 is 1.233793
INFO:root:FL Epoch: 389 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :716
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586428
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169849
INFO:root:FL Epoch: 389 Norm Difference for worker 716 is 1.269525
INFO:root:FL Epoch: 389 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :905
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382002
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469736
INFO:root:FL Epoch: 389 Norm Difference for worker 905 is 1.392894
INFO:root:FL Epoch: 389 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :546
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286136
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291327
INFO:root:FL Epoch: 389 Norm Difference for worker 546 is 1.305779
INFO:root:FL Epoch: 389 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :26
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454489
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 26 is 1.35728
INFO:root:FL Epoch: 389 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1404
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400187
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155583
INFO:root:FL Epoch: 389 Norm Difference for worker 1404 is 1.262502
INFO:root:FL Epoch: 389 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1045
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401346
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423763
INFO:root:FL Epoch: 389 Norm Difference for worker 1045 is 1.212354
INFO:root:FL Epoch: 389 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 8 3 4 6 0], which are global users: [991, 1045, 1404, 1102, 716, 546, 1513]
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.4683753953260534 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.14612605050206184                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [481, 1862, 29, 100, 807, 1488, 787, 447, 839, 251]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 390 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :481
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769396
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310834
INFO:root:FL Epoch: 390 Norm Difference for worker 481 is 1.45281
INFO:root:FL Epoch: 390 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1862
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338524
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200974
INFO:root:FL Epoch: 390 Norm Difference for worker 1862 is 1.297453
INFO:root:FL Epoch: 390 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :29
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 29 is 1.434547
INFO:root:FL Epoch: 390 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :100
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.221743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 100 is 1.360585
INFO:root:FL Epoch: 390 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :807
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482548
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200753
INFO:root:FL Epoch: 390 Norm Difference for worker 807 is 1.426126
INFO:root:FL Epoch: 390 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1488
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367114
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181949
INFO:root:FL Epoch: 390 Norm Difference for worker 1488 is 1.435714
INFO:root:FL Epoch: 390 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :787
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404247
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229452
INFO:root:FL Epoch: 390 Norm Difference for worker 787 is 1.316248
INFO:root:FL Epoch: 390 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :447
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468681
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276781
INFO:root:FL Epoch: 390 Norm Difference for worker 447 is 1.462862
INFO:root:FL Epoch: 390 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :839
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348526
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440537
INFO:root:FL Epoch: 390 Norm Difference for worker 839 is 1.35571
INFO:root:FL Epoch: 390 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :251
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 251 is 1.311923
INFO:root:FL Epoch: 390 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 201 200 200 201]
INFO:root:The chosen ones are users: [6 9 8 3 1 4 2], which are global users: [787, 251, 839, 100, 1862, 807, 29]
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.4993241797475254 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.12860932697852454                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 586, 541, 389, 613, 1869, 1176, 937]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.115575
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116386
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.08411725175877412 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.10274223387241363 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.184679
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.179765
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127090
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.07905098609626293 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.10402128472924232 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.182958
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204124
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149824
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.08163006976246834 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.10312298461794853 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.184609
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :586
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314390
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267697
INFO:root:FL Epoch: 391 Norm Difference for worker 586 is 1.45728
INFO:root:FL Epoch: 391 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :541
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295003
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152750
INFO:root:FL Epoch: 391 Norm Difference for worker 541 is 1.448277
INFO:root:FL Epoch: 391 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :389
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875902
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360544
INFO:root:FL Epoch: 391 Norm Difference for worker 389 is 1.42648
INFO:root:FL Epoch: 391 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :613
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491251
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334282
INFO:root:FL Epoch: 391 Norm Difference for worker 613 is 1.506667
INFO:root:FL Epoch: 391 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1869
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544553
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288580
INFO:root:FL Epoch: 391 Norm Difference for worker 1869 is 1.345276
INFO:root:FL Epoch: 391 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1176
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269341
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258884
INFO:root:FL Epoch: 391 Norm Difference for worker 1176 is 1.293566
INFO:root:FL Epoch: 391 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :937
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436801
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184445
INFO:root:FL Epoch: 391 Norm Difference for worker 937 is 1.336826
INFO:root:FL Epoch: 391 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 9 5], which are global users: [1869, 0, 2, 1176, 1, 937, 389]
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.48054413935717416 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.11811642348766327                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [70, 1309, 1645, 252, 695, 1298, 1816, 1469, 1559, 596]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 392 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :70
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 70 is 1.271119
INFO:root:FL Epoch: 392 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1309
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528633
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216104
INFO:root:FL Epoch: 392 Norm Difference for worker 1309 is 1.401973
INFO:root:FL Epoch: 392 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1645
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326167
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316583
INFO:root:FL Epoch: 392 Norm Difference for worker 1645 is 1.253658
INFO:root:FL Epoch: 392 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :252
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.821248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 252 is 1.459536
INFO:root:FL Epoch: 392 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :695
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719225
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328104
INFO:root:FL Epoch: 392 Norm Difference for worker 695 is 1.322704
INFO:root:FL Epoch: 392 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1298
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572582
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514039
INFO:root:FL Epoch: 392 Norm Difference for worker 1298 is 1.438021
INFO:root:FL Epoch: 392 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1816
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500321
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552158
INFO:root:FL Epoch: 392 Norm Difference for worker 1816 is 1.379618
INFO:root:FL Epoch: 392 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1469
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624352
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397780
INFO:root:FL Epoch: 392 Norm Difference for worker 1469 is 1.454831
INFO:root:FL Epoch: 392 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1559
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288100
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253000
INFO:root:FL Epoch: 392 Norm Difference for worker 1559 is 1.33757
INFO:root:FL Epoch: 392 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :596
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 1.033255
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331360
INFO:root:FL Epoch: 392 Norm Difference for worker 596 is 1.480829
INFO:root:FL Epoch: 392 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [2 0 4 1 8 6 5], which are global users: [1645, 70, 695, 1309, 1559, 1816, 1298]
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.44618239648201885 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.11992450182636578                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [1910, 681, 119, 86, 1536, 40, 1747, 1300, 59, 902]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :1910
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611876
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261317
INFO:root:FL Epoch: 393 Norm Difference for worker 1910 is 1.375157
INFO:root:FL Epoch: 393 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :681
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468830
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382185
INFO:root:FL Epoch: 393 Norm Difference for worker 681 is 1.311793
INFO:root:FL Epoch: 393 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :119
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.253394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 119 is 1.217035
INFO:root:FL Epoch: 393 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :86
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.281118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.174564
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 86 is 1.167237
INFO:root:FL Epoch: 393 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1536
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578022
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252799
INFO:root:FL Epoch: 393 Norm Difference for worker 1536 is 1.359454
INFO:root:FL Epoch: 393 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :40
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 40 is 1.32276
INFO:root:FL Epoch: 393 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1747
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577118
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317553
INFO:root:FL Epoch: 393 Norm Difference for worker 1747 is 1.39807
INFO:root:FL Epoch: 393 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1300
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272352
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305115
INFO:root:FL Epoch: 393 Norm Difference for worker 1300 is 1.26605
INFO:root:FL Epoch: 393 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :59
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 59 is 1.149003
INFO:root:FL Epoch: 393 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :902
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486165
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366628
INFO:root:FL Epoch: 393 Norm Difference for worker 902 is 1.333305
INFO:root:FL Epoch: 393 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 200 201 200 200 201 200]
INFO:root:Num selected data points: [200 200 201 201 200 201 201]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [1300, 902, 119, 86, 681, 40, 59]
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.4469243884086609 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.11962593346834183                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [774, 1926, 1801, 399, 1725, 1837, 123, 912, 1829, 387]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 394 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :774
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477841
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277100
INFO:root:FL Epoch: 394 Norm Difference for worker 774 is 1.35643
INFO:root:FL Epoch: 394 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1926
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413224
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239156
INFO:root:FL Epoch: 394 Norm Difference for worker 1926 is 1.420208
INFO:root:FL Epoch: 394 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1801
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473678
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255150
INFO:root:FL Epoch: 394 Norm Difference for worker 1801 is 1.394957
INFO:root:FL Epoch: 394 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :399
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339191
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210728
INFO:root:FL Epoch: 394 Norm Difference for worker 399 is 1.270533
INFO:root:FL Epoch: 394 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1725
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467859
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345452
INFO:root:FL Epoch: 394 Norm Difference for worker 1725 is 1.409401
INFO:root:FL Epoch: 394 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1837
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365544
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155214
INFO:root:FL Epoch: 394 Norm Difference for worker 1837 is 1.278816
INFO:root:FL Epoch: 394 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :123
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 123 is 1.408557
INFO:root:FL Epoch: 394 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :912
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704753
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257341
INFO:root:FL Epoch: 394 Norm Difference for worker 912 is 1.331854
INFO:root:FL Epoch: 394 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1829
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495286
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127695
INFO:root:FL Epoch: 394 Norm Difference for worker 1829 is 1.389999
INFO:root:FL Epoch: 394 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :387
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633416
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207589
INFO:root:FL Epoch: 394 Norm Difference for worker 387 is 1.567146
INFO:root:FL Epoch: 394 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 3 7 6 0 2 8], which are global users: [1837, 399, 912, 123, 774, 1801, 1829]
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.44936710245469036 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.0990360143284003                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [291, 813, 50, 1335, 830, 653, 483, 1654, 1248, 274]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 395 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :291
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 291 is 1.342214
INFO:root:FL Epoch: 395 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :813
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435580
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319300
INFO:root:FL Epoch: 395 Norm Difference for worker 813 is 1.335295
INFO:root:FL Epoch: 395 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :50
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 50 is 1.297451
INFO:root:FL Epoch: 395 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1335
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271314
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346126
INFO:root:FL Epoch: 395 Norm Difference for worker 1335 is 1.384464
INFO:root:FL Epoch: 395 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :830
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474892
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280125
INFO:root:FL Epoch: 395 Norm Difference for worker 830 is 1.287824
INFO:root:FL Epoch: 395 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :653
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265815
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234283
INFO:root:FL Epoch: 395 Norm Difference for worker 653 is 1.388765
INFO:root:FL Epoch: 395 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :483
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382348
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211127
INFO:root:FL Epoch: 395 Norm Difference for worker 483 is 1.304033
INFO:root:FL Epoch: 395 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1654
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783690
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268035
INFO:root:FL Epoch: 395 Norm Difference for worker 1654 is 1.445662
INFO:root:FL Epoch: 395 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1248
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554644
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190401
INFO:root:FL Epoch: 395 Norm Difference for worker 1248 is 1.433287
INFO:root:FL Epoch: 395 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :274
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 274 is 1.348597
INFO:root:FL Epoch: 395 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [201 200 201 200 200 201 200]
INFO:root:The chosen ones are users: [2 4 9 1 6 0 3], which are global users: [50, 830, 274, 813, 483, 291, 1335]
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.4376225848408306 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.09852612142761548                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [1385, 108, 1824, 1767, 1165, 138, 227, 1226, 114, 486]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 201 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :1385
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565945
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159735
INFO:root:FL Epoch: 396 Norm Difference for worker 1385 is 1.242966
INFO:root:FL Epoch: 396 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :108
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.140315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 108 is 1.279187
INFO:root:FL Epoch: 396 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1824
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606656
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354782
INFO:root:FL Epoch: 396 Norm Difference for worker 1824 is 1.503154
INFO:root:FL Epoch: 396 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1767
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547902
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217974
INFO:root:FL Epoch: 396 Norm Difference for worker 1767 is 1.260657
INFO:root:FL Epoch: 396 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1165
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635860
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213197
INFO:root:FL Epoch: 396 Norm Difference for worker 1165 is 1.406561
INFO:root:FL Epoch: 396 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :138
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438353
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 138 is 1.464406
INFO:root:FL Epoch: 396 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :227
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 227 is 1.359623
INFO:root:FL Epoch: 396 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1226
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775980
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213246
INFO:root:FL Epoch: 396 Norm Difference for worker 1226 is 1.381434
INFO:root:FL Epoch: 396 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :114
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 114 is 1.525643
INFO:root:FL Epoch: 396 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :486
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633721
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437541
INFO:root:FL Epoch: 396 Norm Difference for worker 486 is 1.353939
INFO:root:FL Epoch: 396 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 201 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 0 7 3 1 9 4], which are global users: [227, 1385, 1226, 1767, 108, 486, 1165]
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.4574391771765316 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.14011225601037344                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [337, 1927, 777, 117, 1379, 1198, 527, 1053, 1645, 917]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :337
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 337 is 1.26576
INFO:root:FL Epoch: 397 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1927
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585274
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232917
INFO:root:FL Epoch: 397 Norm Difference for worker 1927 is 1.285491
INFO:root:FL Epoch: 397 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :777
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467145
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234229
INFO:root:FL Epoch: 397 Norm Difference for worker 777 is 1.334823
INFO:root:FL Epoch: 397 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :117
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 117 is 1.23368
INFO:root:FL Epoch: 397 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1379
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292385
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240770
INFO:root:FL Epoch: 397 Norm Difference for worker 1379 is 1.335102
INFO:root:FL Epoch: 397 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1198
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448401
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202133
INFO:root:FL Epoch: 397 Norm Difference for worker 1198 is 1.192605
INFO:root:FL Epoch: 397 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :527
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510395
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364830
INFO:root:FL Epoch: 397 Norm Difference for worker 527 is 1.362873
INFO:root:FL Epoch: 397 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1053
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444460
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369384
INFO:root:FL Epoch: 397 Norm Difference for worker 1053 is 1.338312
INFO:root:FL Epoch: 397 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1645
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419007
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211152
INFO:root:FL Epoch: 397 Norm Difference for worker 1645 is 1.152292
INFO:root:FL Epoch: 397 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :917
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531942
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354505
INFO:root:FL Epoch: 397 Norm Difference for worker 917 is 1.431849
INFO:root:FL Epoch: 397 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 1 4 2], which are global users: [1198, 337, 1645, 117, 1927, 1379, 777]
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.4548155674163033 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.11799632385373116                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1469, 1630, 1186, 1921, 1671, 732, 997, 506, 1188, 398]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 398 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1469
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720570
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187806
INFO:root:FL Epoch: 398 Norm Difference for worker 1469 is 1.434858
INFO:root:FL Epoch: 398 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1630
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875507
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292882
INFO:root:FL Epoch: 398 Norm Difference for worker 1630 is 1.505422
INFO:root:FL Epoch: 398 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1186
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517089
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220638
INFO:root:FL Epoch: 398 Norm Difference for worker 1186 is 1.455519
INFO:root:FL Epoch: 398 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1921
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582730
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252390
INFO:root:FL Epoch: 398 Norm Difference for worker 1921 is 1.300533
INFO:root:FL Epoch: 398 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1671
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550125
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218525
INFO:root:FL Epoch: 398 Norm Difference for worker 1671 is 1.357825
INFO:root:FL Epoch: 398 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :732
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704942
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323506
INFO:root:FL Epoch: 398 Norm Difference for worker 732 is 1.437353
INFO:root:FL Epoch: 398 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :997
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623165
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209803
INFO:root:FL Epoch: 398 Norm Difference for worker 997 is 1.308554
INFO:root:FL Epoch: 398 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :506
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480709
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475057
INFO:root:FL Epoch: 398 Norm Difference for worker 506 is 1.45094
INFO:root:FL Epoch: 398 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1188
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566338
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206621
INFO:root:FL Epoch: 398 Norm Difference for worker 1188 is 1.378529
INFO:root:FL Epoch: 398 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :398
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787018
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442917
INFO:root:FL Epoch: 398 Norm Difference for worker 398 is 1.404994
INFO:root:FL Epoch: 398 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 9 2 0], which are global users: [997, 1671, 1188, 1921, 398, 1186, 1469]
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.4573793937178219 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.13746964434782663                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [33, 656, 758, 379, 1800, 821, 1258, 725, 768, 46]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 399 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :33
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336144
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 33 is 1.378755
INFO:root:FL Epoch: 399 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :656
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599189
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447584
INFO:root:FL Epoch: 399 Norm Difference for worker 656 is 1.295428
INFO:root:FL Epoch: 399 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :758
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382506
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189771
INFO:root:FL Epoch: 399 Norm Difference for worker 758 is 1.312827
INFO:root:FL Epoch: 399 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :379
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201676
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285048
INFO:root:FL Epoch: 399 Norm Difference for worker 379 is 1.411908
INFO:root:FL Epoch: 399 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1800
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411739
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483364
INFO:root:FL Epoch: 399 Norm Difference for worker 1800 is 1.263445
INFO:root:FL Epoch: 399 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :821
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662341
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336381
INFO:root:FL Epoch: 399 Norm Difference for worker 821 is 1.302185
INFO:root:FL Epoch: 399 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1258
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546461
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341282
INFO:root:FL Epoch: 399 Norm Difference for worker 1258 is 1.303845
INFO:root:FL Epoch: 399 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :725
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504841
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204242
INFO:root:FL Epoch: 399 Norm Difference for worker 725 is 1.176088
INFO:root:FL Epoch: 399 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :768
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479489
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.118380
INFO:root:FL Epoch: 399 Norm Difference for worker 768 is 1.209952
INFO:root:FL Epoch: 399 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :46
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521724
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.228712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 46 is 1.252004
INFO:root:FL Epoch: 399 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 8 4 2 1 6], which are global users: [725, 46, 768, 1800, 758, 656, 1258]
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.45305273112128763 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.15001971647143364                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [1374, 653, 800, 738, 1855, 248, 298, 573, 1627, 1083]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :1374
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517366
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143030
INFO:root:FL Epoch: 400 Norm Difference for worker 1374 is 1.192665
INFO:root:FL Epoch: 400 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :653
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522233
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364605
INFO:root:FL Epoch: 400 Norm Difference for worker 653 is 1.244935
INFO:root:FL Epoch: 400 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :800
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441306
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170661
INFO:root:FL Epoch: 400 Norm Difference for worker 800 is 1.129239
INFO:root:FL Epoch: 400 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :738
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288588
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313953
INFO:root:FL Epoch: 400 Norm Difference for worker 738 is 1.35104
INFO:root:FL Epoch: 400 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1855
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747591
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245735
INFO:root:FL Epoch: 400 Norm Difference for worker 1855 is 1.330801
INFO:root:FL Epoch: 400 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :248
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 248 is 1.227084
INFO:root:FL Epoch: 400 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :298
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397572
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.091400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 298 is 1.291296
INFO:root:FL Epoch: 400 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :573
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490570
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331619
INFO:root:FL Epoch: 400 Norm Difference for worker 573 is 1.331014
INFO:root:FL Epoch: 400 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1627
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453650
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315410
INFO:root:FL Epoch: 400 Norm Difference for worker 1627 is 1.379286
INFO:root:FL Epoch: 400 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1083
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352784
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427684
INFO:root:FL Epoch: 400 Norm Difference for worker 1083 is 1.354944
INFO:root:FL Epoch: 400 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 5 4], which are global users: [298, 1374, 800, 573, 653, 248, 1855]
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.4348887801170349 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.12604437954723835                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 163, 138, 1190, 701, 1254, 563, 1004]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196653
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157307
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.08125681181748708 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.1115805223584175 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.184638
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.133067
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133011
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.08854638847211997 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.11206193454563618 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.181909
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.129797
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173534
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.09137691805760066 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.1151357889175415 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.169088
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :163
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 163 is 1.376754
INFO:root:FL Epoch: 401 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :138
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390279
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 138 is 1.431254
INFO:root:FL Epoch: 401 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1190
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369573
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198673
INFO:root:FL Epoch: 401 Norm Difference for worker 1190 is 1.171067
INFO:root:FL Epoch: 401 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :701
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246574
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323131
INFO:root:FL Epoch: 401 Norm Difference for worker 701 is 1.389425
INFO:root:FL Epoch: 401 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1254
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304805
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232919
INFO:root:FL Epoch: 401 Norm Difference for worker 1254 is 1.247036
INFO:root:FL Epoch: 401 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :563
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496925
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200657
INFO:root:FL Epoch: 401 Norm Difference for worker 563 is 1.251208
INFO:root:FL Epoch: 401 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1004
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525532
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333860
INFO:root:FL Epoch: 401 Norm Difference for worker 1004 is 1.434459
INFO:root:FL Epoch: 401 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 8 2 0 1 7 6], which are global users: [1190, 563, 2, 0, 1, 1254, 701]
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.4476091370863073 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.10001250170171261                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [607, 1517, 1264, 1385, 623, 1075, 1805, 731, 742, 1898]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :607
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447306
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239445
INFO:root:FL Epoch: 402 Norm Difference for worker 607 is 1.41601
INFO:root:FL Epoch: 402 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1517
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517175
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208067
INFO:root:FL Epoch: 402 Norm Difference for worker 1517 is 1.409339
INFO:root:FL Epoch: 402 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1264
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718920
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337844
INFO:root:FL Epoch: 402 Norm Difference for worker 1264 is 1.428882
INFO:root:FL Epoch: 402 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1385
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305823
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198375
INFO:root:FL Epoch: 402 Norm Difference for worker 1385 is 1.155051
INFO:root:FL Epoch: 402 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :623
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594177
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329601
INFO:root:FL Epoch: 402 Norm Difference for worker 623 is 1.333722
INFO:root:FL Epoch: 402 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1075
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588828
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215274
INFO:root:FL Epoch: 402 Norm Difference for worker 1075 is 1.285853
INFO:root:FL Epoch: 402 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1805
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 1.187209
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394639
INFO:root:FL Epoch: 402 Norm Difference for worker 1805 is 1.365962
INFO:root:FL Epoch: 402 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :731
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666686
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249639
INFO:root:FL Epoch: 402 Norm Difference for worker 731 is 1.369122
INFO:root:FL Epoch: 402 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :742
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407790
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214480
INFO:root:FL Epoch: 402 Norm Difference for worker 742 is 1.289811
INFO:root:FL Epoch: 402 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1898
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357002
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200293
INFO:root:FL Epoch: 402 Norm Difference for worker 1898 is 1.351848
INFO:root:FL Epoch: 402 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 4 6 7], which are global users: [1075, 1898, 742, 1385, 623, 1805, 731]
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.45864371517125296 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.12384149432182312                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1697, 438, 1000, 1152, 674, 1882, 1176, 1868, 78, 1171]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1697
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255247
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301765
INFO:root:FL Epoch: 403 Norm Difference for worker 1697 is 1.59632
INFO:root:FL Epoch: 403 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :438
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463910
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595223
INFO:root:FL Epoch: 403 Norm Difference for worker 438 is 1.658113
INFO:root:FL Epoch: 403 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1000
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 1.054705
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265418
INFO:root:FL Epoch: 403 Norm Difference for worker 1000 is 1.45668
INFO:root:FL Epoch: 403 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1152
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770423
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155875
INFO:root:FL Epoch: 403 Norm Difference for worker 1152 is 1.53362
INFO:root:FL Epoch: 403 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :674
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392129
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276776
INFO:root:FL Epoch: 403 Norm Difference for worker 674 is 1.31102
INFO:root:FL Epoch: 403 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1882
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384645
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404818
INFO:root:FL Epoch: 403 Norm Difference for worker 1882 is 1.348724
INFO:root:FL Epoch: 403 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1176
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703187
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349309
INFO:root:FL Epoch: 403 Norm Difference for worker 1176 is 1.274018
INFO:root:FL Epoch: 403 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1868
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308432
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277741
INFO:root:FL Epoch: 403 Norm Difference for worker 1868 is 1.492347
INFO:root:FL Epoch: 403 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :78
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255048
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 78 is 1.310982
INFO:root:FL Epoch: 403 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1171
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476442
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131342
INFO:root:FL Epoch: 403 Norm Difference for worker 1171 is 1.236736
INFO:root:FL Epoch: 403 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [9 4 6 5 8 2 7], which are global users: [1171, 674, 1176, 1882, 78, 1000, 1868]
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.47232936235035167 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.11899489785234134                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [42, 1565, 994, 591, 1772, 1731, 767, 1854, 1609, 1682]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 404 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :42
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 42 is 1.370759
INFO:root:FL Epoch: 404 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1565
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472341
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322048
INFO:root:FL Epoch: 404 Norm Difference for worker 1565 is 1.404413
INFO:root:FL Epoch: 404 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :994
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630086
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297248
INFO:root:FL Epoch: 404 Norm Difference for worker 994 is 1.348874
INFO:root:FL Epoch: 404 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :591
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323577
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381520
INFO:root:FL Epoch: 404 Norm Difference for worker 591 is 1.427841
INFO:root:FL Epoch: 404 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1772
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833178
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226698
INFO:root:FL Epoch: 404 Norm Difference for worker 1772 is 1.33163
INFO:root:FL Epoch: 404 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1731
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347225
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217455
INFO:root:FL Epoch: 404 Norm Difference for worker 1731 is 1.291941
INFO:root:FL Epoch: 404 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :767
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401786
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207671
INFO:root:FL Epoch: 404 Norm Difference for worker 767 is 1.435232
INFO:root:FL Epoch: 404 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1854
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318161
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196180
INFO:root:FL Epoch: 404 Norm Difference for worker 1854 is 1.55693
INFO:root:FL Epoch: 404 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1609
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858328
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387444
INFO:root:FL Epoch: 404 Norm Difference for worker 1609 is 1.45015
INFO:root:FL Epoch: 404 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1682
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267914
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258007
INFO:root:FL Epoch: 404 Norm Difference for worker 1682 is 1.289624
INFO:root:FL Epoch: 404 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [5 9 4 8 0 2 1], which are global users: [1731, 1682, 1772, 1609, 42, 994, 1565]
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.4554627572788912 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.12950591246287027                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1229, 1879, 783, 290, 1711, 787, 1366, 1837, 1562, 898]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1229
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584364
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309197
INFO:root:FL Epoch: 405 Norm Difference for worker 1229 is 1.312752
INFO:root:FL Epoch: 405 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1879
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746706
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384449
INFO:root:FL Epoch: 405 Norm Difference for worker 1879 is 1.363387
INFO:root:FL Epoch: 405 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :783
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353145
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199161
INFO:root:FL Epoch: 405 Norm Difference for worker 783 is 1.298693
INFO:root:FL Epoch: 405 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :290
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476067
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 290 is 1.391934
INFO:root:FL Epoch: 405 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1711
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586972
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247802
INFO:root:FL Epoch: 405 Norm Difference for worker 1711 is 1.415848
INFO:root:FL Epoch: 405 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :787
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342557
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319950
INFO:root:FL Epoch: 405 Norm Difference for worker 787 is 1.155229
INFO:root:FL Epoch: 405 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1366
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460006
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253929
INFO:root:FL Epoch: 405 Norm Difference for worker 1366 is 1.302735
INFO:root:FL Epoch: 405 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1837
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714823
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204694
INFO:root:FL Epoch: 405 Norm Difference for worker 1837 is 1.170856
INFO:root:FL Epoch: 405 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1562
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289711
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282159
INFO:root:FL Epoch: 405 Norm Difference for worker 1562 is 1.288476
INFO:root:FL Epoch: 405 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :898
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278597
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263873
INFO:root:FL Epoch: 405 Norm Difference for worker 898 is 1.331797
INFO:root:FL Epoch: 405 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 5 6], which are global users: [1837, 1229, 783, 1562, 1879, 787, 1366]
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.4703038159538718 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.11850732564926147                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [43, 1346, 1944, 1012, 832, 366, 1013, 1230, 475, 495]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 406 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :43
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.834569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 43 is 1.348384
INFO:root:FL Epoch: 406 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1346
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523641
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225743
INFO:root:FL Epoch: 406 Norm Difference for worker 1346 is 1.334407
INFO:root:FL Epoch: 406 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1944
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496878
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205346
INFO:root:FL Epoch: 406 Norm Difference for worker 1944 is 1.190945
INFO:root:FL Epoch: 406 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1012
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505004
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131323
INFO:root:FL Epoch: 406 Norm Difference for worker 1012 is 1.254045
INFO:root:FL Epoch: 406 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :832
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307035
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222383
INFO:root:FL Epoch: 406 Norm Difference for worker 832 is 1.353567
INFO:root:FL Epoch: 406 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :366
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614261
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278652
INFO:root:FL Epoch: 406 Norm Difference for worker 366 is 1.346236
INFO:root:FL Epoch: 406 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1013
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695624
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202504
INFO:root:FL Epoch: 406 Norm Difference for worker 1013 is 1.342085
INFO:root:FL Epoch: 406 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1230
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363943
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.109760
INFO:root:FL Epoch: 406 Norm Difference for worker 1230 is 1.301514
INFO:root:FL Epoch: 406 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :475
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597042
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276217
INFO:root:FL Epoch: 406 Norm Difference for worker 475 is 1.262005
INFO:root:FL Epoch: 406 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :495
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345013
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319193
INFO:root:FL Epoch: 406 Norm Difference for worker 495 is 1.363126
INFO:root:FL Epoch: 406 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 8 6], which are global users: [1230, 832, 1944, 1012, 1346, 475, 1013]
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.4811643449699177 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.11933140208323796                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1183, 943, 1373, 1473, 992, 757, 1475, 680, 491, 1743]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1183
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602124
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186069
INFO:root:FL Epoch: 407 Norm Difference for worker 1183 is 1.243878
INFO:root:FL Epoch: 407 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :943
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356932
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370783
INFO:root:FL Epoch: 407 Norm Difference for worker 943 is 1.324201
INFO:root:FL Epoch: 407 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1373
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584595
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185393
INFO:root:FL Epoch: 407 Norm Difference for worker 1373 is 1.370901
INFO:root:FL Epoch: 407 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1473
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509111
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244398
INFO:root:FL Epoch: 407 Norm Difference for worker 1473 is 1.459205
INFO:root:FL Epoch: 407 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :992
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400640
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304020
INFO:root:FL Epoch: 407 Norm Difference for worker 992 is 1.374675
INFO:root:FL Epoch: 407 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :757
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735519
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364905
INFO:root:FL Epoch: 407 Norm Difference for worker 757 is 1.347962
INFO:root:FL Epoch: 407 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1475
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576747
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266959
INFO:root:FL Epoch: 407 Norm Difference for worker 1475 is 1.292172
INFO:root:FL Epoch: 407 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :680
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583171
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356998
INFO:root:FL Epoch: 407 Norm Difference for worker 680 is 1.260594
INFO:root:FL Epoch: 407 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :491
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482889
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137149
INFO:root:FL Epoch: 407 Norm Difference for worker 491 is 1.12224
INFO:root:FL Epoch: 407 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1743
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741738
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309746
INFO:root:FL Epoch: 407 Norm Difference for worker 1743 is 1.305852
INFO:root:FL Epoch: 407 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 8 9 6 1 5], which are global users: [680, 1183, 491, 1743, 1475, 943, 757]
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.4976333993322709 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.15051711971561113                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [1623, 1108, 1748, 150, 1450, 611, 673, 1016, 676, 1248]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :1623
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597962
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433856
INFO:root:FL Epoch: 408 Norm Difference for worker 1623 is 1.408936
INFO:root:FL Epoch: 408 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1108
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473209
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316042
INFO:root:FL Epoch: 408 Norm Difference for worker 1108 is 1.48673
INFO:root:FL Epoch: 408 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1748
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592947
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277380
INFO:root:FL Epoch: 408 Norm Difference for worker 1748 is 1.342278
INFO:root:FL Epoch: 408 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :150
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.196026
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 150 is 1.416257
INFO:root:FL Epoch: 408 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1450
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463079
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150445
INFO:root:FL Epoch: 408 Norm Difference for worker 1450 is 1.281376
INFO:root:FL Epoch: 408 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :611
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405090
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130558
INFO:root:FL Epoch: 408 Norm Difference for worker 611 is 1.279586
INFO:root:FL Epoch: 408 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :673
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400269
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130514
INFO:root:FL Epoch: 408 Norm Difference for worker 673 is 1.261141
INFO:root:FL Epoch: 408 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1016
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599570
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356913
INFO:root:FL Epoch: 408 Norm Difference for worker 1016 is 1.395914
INFO:root:FL Epoch: 408 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :676
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730516
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294637
INFO:root:FL Epoch: 408 Norm Difference for worker 676 is 1.384771
INFO:root:FL Epoch: 408 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1248
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439540
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280158
INFO:root:FL Epoch: 408 Norm Difference for worker 1248 is 1.365011
INFO:root:FL Epoch: 408 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 6 9 8 7], which are global users: [611, 1450, 1748, 673, 1248, 676, 1016]
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.46199889744029327 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.16055013363560042                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1095, 1034, 884, 1106, 854, 1812, 1365, 1153, 368, 741]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1095
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638421
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366139
INFO:root:FL Epoch: 409 Norm Difference for worker 1095 is 1.339493
INFO:root:FL Epoch: 409 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1034
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355157
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325800
INFO:root:FL Epoch: 409 Norm Difference for worker 1034 is 1.249349
INFO:root:FL Epoch: 409 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :884
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578930
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308223
INFO:root:FL Epoch: 409 Norm Difference for worker 884 is 1.323989
INFO:root:FL Epoch: 409 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1106
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699555
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196908
INFO:root:FL Epoch: 409 Norm Difference for worker 1106 is 1.274153
INFO:root:FL Epoch: 409 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :854
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343189
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229285
INFO:root:FL Epoch: 409 Norm Difference for worker 854 is 1.240481
INFO:root:FL Epoch: 409 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1812
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643358
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226377
INFO:root:FL Epoch: 409 Norm Difference for worker 1812 is 1.278156
INFO:root:FL Epoch: 409 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1365
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238222
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203821
INFO:root:FL Epoch: 409 Norm Difference for worker 1365 is 1.184457
INFO:root:FL Epoch: 409 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1153
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737205
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384505
INFO:root:FL Epoch: 409 Norm Difference for worker 1153 is 1.314867
INFO:root:FL Epoch: 409 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :368
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256912
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265112
INFO:root:FL Epoch: 409 Norm Difference for worker 368 is 1.271314
INFO:root:FL Epoch: 409 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :741
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200654
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241627
INFO:root:FL Epoch: 409 Norm Difference for worker 741 is 1.316154
INFO:root:FL Epoch: 409 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 8 3 1 5 6], which are global users: [1153, 854, 368, 1106, 1034, 1812, 1365]
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.4485074264161727 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.12324465687076251                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [1588, 1566, 1373, 38, 609, 48, 1939, 569, 905, 90]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :1588
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691834
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317443
INFO:root:FL Epoch: 410 Norm Difference for worker 1588 is 1.318665
INFO:root:FL Epoch: 410 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1566
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410492
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204703
INFO:root:FL Epoch: 410 Norm Difference for worker 1566 is 1.228851
INFO:root:FL Epoch: 410 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1373
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445971
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159117
INFO:root:FL Epoch: 410 Norm Difference for worker 1373 is 1.345389
INFO:root:FL Epoch: 410 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :38
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486996
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 38 is 1.268936
INFO:root:FL Epoch: 410 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :609
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761766
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467963
INFO:root:FL Epoch: 410 Norm Difference for worker 609 is 1.368618
INFO:root:FL Epoch: 410 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :48
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 48 is 1.241414
INFO:root:FL Epoch: 410 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1939
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594887
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619577
INFO:root:FL Epoch: 410 Norm Difference for worker 1939 is 1.409291
INFO:root:FL Epoch: 410 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :569
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459778
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327126
INFO:root:FL Epoch: 410 Norm Difference for worker 569 is 1.352903
INFO:root:FL Epoch: 410 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :905
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330055
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279428
INFO:root:FL Epoch: 410 Norm Difference for worker 905 is 1.26559
INFO:root:FL Epoch: 410 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :90
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405995
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 90 is 1.388857
INFO:root:FL Epoch: 410 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 201 200 201 201]
INFO:root:The chosen ones are users: [8 0 2 3 1 5 9], which are global users: [905, 1588, 1373, 38, 1566, 48, 90]
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.4683722187491024 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.13858796656131744                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 1347, 1697, 1523, 1370, 1900, 1837, 1578]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.177074
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216235
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.10001651756465435 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.11492899432778358 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.182541
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.163078
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262382
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.07975471206009388 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.11186887100338935 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.252333
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150914
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145587
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.08354869733254115 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.1153021439909935 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.178842
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1347
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575528
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304919
INFO:root:FL Epoch: 411 Norm Difference for worker 1347 is 1.434095
INFO:root:FL Epoch: 411 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1697
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697137
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 1.687673
INFO:root:FL Epoch: 411 Norm Difference for worker 1697 is 2.436293
INFO:root:FL Epoch: 411 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1523
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428550
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 1.543785
INFO:root:FL Epoch: 411 Norm Difference for worker 1523 is 2.202541
INFO:root:FL Epoch: 411 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1370
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306831
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732507
INFO:root:FL Epoch: 411 Norm Difference for worker 1370 is 1.8126
INFO:root:FL Epoch: 411 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1900
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353129
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185513
INFO:root:FL Epoch: 411 Norm Difference for worker 1900 is 1.250387
INFO:root:FL Epoch: 411 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1837
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252565
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316154
INFO:root:FL Epoch: 411 Norm Difference for worker 1837 is 1.172113
INFO:root:FL Epoch: 411 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1578
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503075
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404043
INFO:root:FL Epoch: 411 Norm Difference for worker 1578 is 1.30404
INFO:root:FL Epoch: 411 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 9 3], which are global users: [1900, 0, 2, 1837, 1, 1578, 1347]
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.4628147623118232 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.13178448813656965                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1440, 141, 1453, 738, 655, 1904, 396, 1209, 903, 881]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 412 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1440
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296413
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237516
INFO:root:FL Epoch: 412 Norm Difference for worker 1440 is 1.314394
INFO:root:FL Epoch: 412 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :141
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 141 is 1.157998
INFO:root:FL Epoch: 412 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1453
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453094
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200123
INFO:root:FL Epoch: 412 Norm Difference for worker 1453 is 1.290372
INFO:root:FL Epoch: 412 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :738
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691093
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266815
INFO:root:FL Epoch: 412 Norm Difference for worker 738 is 1.256556
INFO:root:FL Epoch: 412 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :655
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511460
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383336
INFO:root:FL Epoch: 412 Norm Difference for worker 655 is 1.230271
INFO:root:FL Epoch: 412 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1904
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389144
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391210
INFO:root:FL Epoch: 412 Norm Difference for worker 1904 is 1.300595
INFO:root:FL Epoch: 412 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :396
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445484
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124691
INFO:root:FL Epoch: 412 Norm Difference for worker 396 is 1.22753
INFO:root:FL Epoch: 412 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1209
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613778
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319007
INFO:root:FL Epoch: 412 Norm Difference for worker 1209 is 1.301931
INFO:root:FL Epoch: 412 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :903
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503127
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203683
INFO:root:FL Epoch: 412 Norm Difference for worker 903 is 1.291324
INFO:root:FL Epoch: 412 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :881
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399401
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204325
INFO:root:FL Epoch: 412 Norm Difference for worker 881 is 1.097309
INFO:root:FL Epoch: 412 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 6 4 8 3 2], which are global users: [141, 881, 396, 655, 903, 738, 1453]
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.4475250384386848 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.09102766712506612                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [459, 6, 1260, 1890, 606, 1654, 276, 718, 1641, 1195]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 413 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :459
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340766
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243679
INFO:root:FL Epoch: 413 Norm Difference for worker 459 is 1.238207
INFO:root:FL Epoch: 413 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :6
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.274158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 6 is 1.267511
INFO:root:FL Epoch: 413 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1260
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601645
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380222
INFO:root:FL Epoch: 413 Norm Difference for worker 1260 is 1.305388
INFO:root:FL Epoch: 413 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1890
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592288
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269661
INFO:root:FL Epoch: 413 Norm Difference for worker 1890 is 1.287679
INFO:root:FL Epoch: 413 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :606
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382228
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432538
INFO:root:FL Epoch: 413 Norm Difference for worker 606 is 1.163843
INFO:root:FL Epoch: 413 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1654
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491985
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278056
INFO:root:FL Epoch: 413 Norm Difference for worker 1654 is 1.408464
INFO:root:FL Epoch: 413 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :276
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 276 is 1.361453
INFO:root:FL Epoch: 413 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :718
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412444
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420765
INFO:root:FL Epoch: 413 Norm Difference for worker 718 is 1.374077
INFO:root:FL Epoch: 413 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1641
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383713
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254418
INFO:root:FL Epoch: 413 Norm Difference for worker 1641 is 1.353576
INFO:root:FL Epoch: 413 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1195
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328741
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288072
INFO:root:FL Epoch: 413 Norm Difference for worker 1195 is 1.271919
INFO:root:FL Epoch: 413 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 201]
INFO:root:The chosen ones are users: [4 0 8 9 1 3 6], which are global users: [606, 459, 1641, 1195, 6, 1890, 276]
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.4455447442391339 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.12000750253597896                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [1250, 1532, 1790, 1295, 290, 1589, 1759, 1893, 1747, 1008]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :1250
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704830
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294126
INFO:root:FL Epoch: 414 Norm Difference for worker 1250 is 1.262679
INFO:root:FL Epoch: 414 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1532
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452734
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151048
INFO:root:FL Epoch: 414 Norm Difference for worker 1532 is 1.173198
INFO:root:FL Epoch: 414 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1790
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271084
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297709
INFO:root:FL Epoch: 414 Norm Difference for worker 1790 is 1.257707
INFO:root:FL Epoch: 414 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1295
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389863
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212703
INFO:root:FL Epoch: 414 Norm Difference for worker 1295 is 1.149149
INFO:root:FL Epoch: 414 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :290
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 290 is 1.336098
INFO:root:FL Epoch: 414 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1589
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.222588
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344978
INFO:root:FL Epoch: 414 Norm Difference for worker 1589 is 1.333159
INFO:root:FL Epoch: 414 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1759
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507972
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260333
INFO:root:FL Epoch: 414 Norm Difference for worker 1759 is 1.247848
INFO:root:FL Epoch: 414 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1893
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780305
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386270
INFO:root:FL Epoch: 414 Norm Difference for worker 1893 is 1.404183
INFO:root:FL Epoch: 414 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1747
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385791
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532721
INFO:root:FL Epoch: 414 Norm Difference for worker 1747 is 1.289967
INFO:root:FL Epoch: 414 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1008
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470703
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483997
INFO:root:FL Epoch: 414 Norm Difference for worker 1008 is 1.370032
INFO:root:FL Epoch: 414 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 0 2 3 1 8 4], which are global users: [1759, 1250, 1790, 1295, 1532, 1747, 290]
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.45304543831769156 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.14631778001785278                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [1413, 172, 86, 370, 1824, 1386, 472, 1000, 637, 1934]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 415 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :1413
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206678
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393859
INFO:root:FL Epoch: 415 Norm Difference for worker 1413 is 1.163229
INFO:root:FL Epoch: 415 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :172
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299338
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 172 is 1.227694
INFO:root:FL Epoch: 415 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :86
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.289886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 86 is 1.121928
INFO:root:FL Epoch: 415 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :370
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789643
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245706
INFO:root:FL Epoch: 415 Norm Difference for worker 370 is 1.247826
INFO:root:FL Epoch: 415 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1824
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700141
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299846
INFO:root:FL Epoch: 415 Norm Difference for worker 1824 is 1.352373
INFO:root:FL Epoch: 415 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1386
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588335
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167668
INFO:root:FL Epoch: 415 Norm Difference for worker 1386 is 1.155332
INFO:root:FL Epoch: 415 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :472
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684460
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172034
INFO:root:FL Epoch: 415 Norm Difference for worker 472 is 1.233797
INFO:root:FL Epoch: 415 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1000
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360368
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413034
INFO:root:FL Epoch: 415 Norm Difference for worker 1000 is 1.434972
INFO:root:FL Epoch: 415 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :637
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869149
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375217
INFO:root:FL Epoch: 415 Norm Difference for worker 637 is 1.465522
INFO:root:FL Epoch: 415 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1934
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622823
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381833
INFO:root:FL Epoch: 415 Norm Difference for worker 1934 is 1.321295
INFO:root:FL Epoch: 415 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 5 4], which are global users: [472, 1413, 86, 370, 172, 1386, 1824]
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.45048728234627666 and Test Accuracy:80.0 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.12019614068170388                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [337, 431, 1785, 716, 52, 758, 1794, 162, 1203, 898]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 416 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :337
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 337 is 1.195227
INFO:root:FL Epoch: 416 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :431
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621460
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373902
INFO:root:FL Epoch: 416 Norm Difference for worker 431 is 1.400635
INFO:root:FL Epoch: 416 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1785
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420808
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321022
INFO:root:FL Epoch: 416 Norm Difference for worker 1785 is 1.234498
INFO:root:FL Epoch: 416 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :716
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606253
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139787
INFO:root:FL Epoch: 416 Norm Difference for worker 716 is 1.143522
INFO:root:FL Epoch: 416 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :52
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.358761
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 52 is 1.342957
INFO:root:FL Epoch: 416 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :758
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532630
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414114
INFO:root:FL Epoch: 416 Norm Difference for worker 758 is 1.221943
INFO:root:FL Epoch: 416 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1794
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465123
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385740
INFO:root:FL Epoch: 416 Norm Difference for worker 1794 is 1.427014
INFO:root:FL Epoch: 416 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :162
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 162 is 1.227568
INFO:root:FL Epoch: 416 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1203
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870804
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376702
INFO:root:FL Epoch: 416 Norm Difference for worker 1203 is 1.334792
INFO:root:FL Epoch: 416 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :898
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363472
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383036
INFO:root:FL Epoch: 416 Norm Difference for worker 898 is 1.39938
INFO:root:FL Epoch: 416 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [201 201 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 0 2 3 8 5 4], which are global users: [162, 337, 1785, 716, 1203, 758, 52]
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.4441615500870873 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.128596822420756                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1578, 1877, 1722, 1440, 1829, 671, 994, 651, 1136, 1386]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1578
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428209
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156129
INFO:root:FL Epoch: 417 Norm Difference for worker 1578 is 1.153771
INFO:root:FL Epoch: 417 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1877
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543827
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409200
INFO:root:FL Epoch: 417 Norm Difference for worker 1877 is 1.191301
INFO:root:FL Epoch: 417 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1722
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474580
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230782
INFO:root:FL Epoch: 417 Norm Difference for worker 1722 is 1.230659
INFO:root:FL Epoch: 417 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1440
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655576
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266152
INFO:root:FL Epoch: 417 Norm Difference for worker 1440 is 1.320687
INFO:root:FL Epoch: 417 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1829
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329579
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228550
INFO:root:FL Epoch: 417 Norm Difference for worker 1829 is 1.252344
INFO:root:FL Epoch: 417 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :671
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749177
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150667
INFO:root:FL Epoch: 417 Norm Difference for worker 671 is 1.228193
INFO:root:FL Epoch: 417 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :994
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677975
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244224
INFO:root:FL Epoch: 417 Norm Difference for worker 994 is 1.212777
INFO:root:FL Epoch: 417 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :651
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312113
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151429
INFO:root:FL Epoch: 417 Norm Difference for worker 651 is 1.21227
INFO:root:FL Epoch: 417 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1136
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262803
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258936
INFO:root:FL Epoch: 417 Norm Difference for worker 1136 is 1.340682
INFO:root:FL Epoch: 417 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1386
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339364
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328081
INFO:root:FL Epoch: 417 Norm Difference for worker 1386 is 1.207002
INFO:root:FL Epoch: 417 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 9 7 6 5 2], which are global users: [1877, 1578, 1386, 651, 994, 671, 1722]
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.4539999996914583 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.15522907674312592                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [1394, 446, 1001, 597, 430, 98, 478, 1158, 171, 285]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :1394
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633926
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144149
INFO:root:FL Epoch: 418 Norm Difference for worker 1394 is 1.362112
INFO:root:FL Epoch: 418 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :446
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537735
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318512
INFO:root:FL Epoch: 418 Norm Difference for worker 446 is 1.410436
INFO:root:FL Epoch: 418 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1001
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505953
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479276
INFO:root:FL Epoch: 418 Norm Difference for worker 1001 is 1.353601
INFO:root:FL Epoch: 418 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :597
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578510
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244606
INFO:root:FL Epoch: 418 Norm Difference for worker 597 is 1.296789
INFO:root:FL Epoch: 418 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :430
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391795
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415501
INFO:root:FL Epoch: 418 Norm Difference for worker 430 is 1.347119
INFO:root:FL Epoch: 418 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :98
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.301270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 98 is 1.302735
INFO:root:FL Epoch: 418 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :478
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345908
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298757
INFO:root:FL Epoch: 418 Norm Difference for worker 478 is 1.31445
INFO:root:FL Epoch: 418 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1158
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579150
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246260
INFO:root:FL Epoch: 418 Norm Difference for worker 1158 is 1.340748
INFO:root:FL Epoch: 418 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :171
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 171 is 1.261021
INFO:root:FL Epoch: 418 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :285
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 285 is 1.25682
INFO:root:FL Epoch: 418 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 201 201]
INFO:root:Num selected data points: [201 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 8 3 6 4 0], which are global users: [98, 285, 171, 597, 478, 430, 1394]
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.46257421023705425 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.1389635168015957                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [1565, 1770, 855, 807, 185, 421, 1904, 1529, 162, 1104]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :1565
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404276
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227706
INFO:root:FL Epoch: 419 Norm Difference for worker 1565 is 1.303252
INFO:root:FL Epoch: 419 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1770
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360719
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242096
INFO:root:FL Epoch: 419 Norm Difference for worker 1770 is 1.187583
INFO:root:FL Epoch: 419 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :855
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404038
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308290
INFO:root:FL Epoch: 419 Norm Difference for worker 855 is 1.340993
INFO:root:FL Epoch: 419 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :807
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406035
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286941
INFO:root:FL Epoch: 419 Norm Difference for worker 807 is 1.291688
INFO:root:FL Epoch: 419 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :185
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.263337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.191009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 185 is 1.088118
INFO:root:FL Epoch: 419 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :421
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713764
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304724
INFO:root:FL Epoch: 419 Norm Difference for worker 421 is 1.419503
INFO:root:FL Epoch: 419 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1904
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368825
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318350
INFO:root:FL Epoch: 419 Norm Difference for worker 1904 is 1.307833
INFO:root:FL Epoch: 419 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1529
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561083
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246909
INFO:root:FL Epoch: 419 Norm Difference for worker 1529 is 1.263399
INFO:root:FL Epoch: 419 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :162
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370040
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 162 is 1.20122
INFO:root:FL Epoch: 419 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1104
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443697
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278015
INFO:root:FL Epoch: 419 Norm Difference for worker 1104 is 1.340742
INFO:root:FL Epoch: 419 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 8 3 1 7 0], which are global users: [1904, 185, 162, 807, 1770, 1529, 1565]
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.4636329938383663 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.14645051211118698                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1780, 132, 501, 1727, 1308, 1584, 1596, 1485, 854, 363]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 420 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1780
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406793
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261540
INFO:root:FL Epoch: 420 Norm Difference for worker 1780 is 1.170371
INFO:root:FL Epoch: 420 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :132
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 132 is 1.178463
INFO:root:FL Epoch: 420 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :501
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567100
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178487
INFO:root:FL Epoch: 420 Norm Difference for worker 501 is 1.252623
INFO:root:FL Epoch: 420 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1727
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892083
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296233
INFO:root:FL Epoch: 420 Norm Difference for worker 1727 is 1.207222
INFO:root:FL Epoch: 420 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1308
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763336
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190547
INFO:root:FL Epoch: 420 Norm Difference for worker 1308 is 1.335539
INFO:root:FL Epoch: 420 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1584
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421605
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165020
INFO:root:FL Epoch: 420 Norm Difference for worker 1584 is 1.189216
INFO:root:FL Epoch: 420 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1596
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340765
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203661
INFO:root:FL Epoch: 420 Norm Difference for worker 1596 is 1.238748
INFO:root:FL Epoch: 420 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1485
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383689
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180418
INFO:root:FL Epoch: 420 Norm Difference for worker 1485 is 1.247026
INFO:root:FL Epoch: 420 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :854
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414887
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297943
INFO:root:FL Epoch: 420 Norm Difference for worker 854 is 1.194172
INFO:root:FL Epoch: 420 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :363
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551908
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336693
INFO:root:FL Epoch: 420 Norm Difference for worker 363 is 1.469587
INFO:root:FL Epoch: 420 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [5 3 6 0 1 7 2], which are global users: [1584, 1727, 1596, 1780, 132, 1485, 501]
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.45244553597534404 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.1133885346353054                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 331, 252, 1598, 852, 1672, 738, 1413]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.157419
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168187
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.08439802192151546 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.10004020184278488 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.171255
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.138980
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.096235
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.08823809027671814 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.0997889518737793 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.173465
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.115451
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138036
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.0873638770232598 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.10045919343829154 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.170656
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :331
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 331 is 1.50198
INFO:root:FL Epoch: 421 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :252
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621425
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383782
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 252 is 1.442042
INFO:root:FL Epoch: 421 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1598
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486686
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310856
INFO:root:FL Epoch: 421 Norm Difference for worker 1598 is 1.267618
INFO:root:FL Epoch: 421 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :852
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282959
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193642
INFO:root:FL Epoch: 421 Norm Difference for worker 852 is 1.187812
INFO:root:FL Epoch: 421 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1672
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503751
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211878
INFO:root:FL Epoch: 421 Norm Difference for worker 1672 is 1.339734
INFO:root:FL Epoch: 421 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :738
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564888
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185920
INFO:root:FL Epoch: 421 Norm Difference for worker 738 is 1.282961
INFO:root:FL Epoch: 421 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1413
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241371
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234500
INFO:root:FL Epoch: 421 Norm Difference for worker 1413 is 1.21201
INFO:root:FL Epoch: 421 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 6 9 8 5], which are global users: [1, 0, 2, 852, 1413, 738, 1598]
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.46616924860898185 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.1008894784996907                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [265, 1432, 207, 1520, 890, 723, 1096, 1450, 440, 1471]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 422 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :265
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 265 is 1.526751
INFO:root:FL Epoch: 422 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1432
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366992
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163056
INFO:root:FL Epoch: 422 Norm Difference for worker 1432 is 1.267583
INFO:root:FL Epoch: 422 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :207
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 207 is 1.410266
INFO:root:FL Epoch: 422 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1520
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302514
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107716
INFO:root:FL Epoch: 422 Norm Difference for worker 1520 is 1.186985
INFO:root:FL Epoch: 422 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :890
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703032
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265588
INFO:root:FL Epoch: 422 Norm Difference for worker 890 is 1.408152
INFO:root:FL Epoch: 422 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :723
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422168
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231337
INFO:root:FL Epoch: 422 Norm Difference for worker 723 is 1.357957
INFO:root:FL Epoch: 422 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1096
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323913
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513107
INFO:root:FL Epoch: 422 Norm Difference for worker 1096 is 1.364777
INFO:root:FL Epoch: 422 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1450
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839056
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159224
INFO:root:FL Epoch: 422 Norm Difference for worker 1450 is 1.257334
INFO:root:FL Epoch: 422 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :440
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461921
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246043
INFO:root:FL Epoch: 422 Norm Difference for worker 440 is 1.403035
INFO:root:FL Epoch: 422 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1471
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443790
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179733
INFO:root:FL Epoch: 422 Norm Difference for worker 1471 is 1.371715
INFO:root:FL Epoch: 422 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [1450, 1471, 207, 1520, 1432, 723, 1096]
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.45981379817513857 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.1387260121603807                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [1477, 1688, 190, 1382, 1904, 742, 1629, 178, 1346, 1406]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 423 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :1477
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321443
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267940
INFO:root:FL Epoch: 423 Norm Difference for worker 1477 is 1.37441
INFO:root:FL Epoch: 423 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1688
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681381
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269235
INFO:root:FL Epoch: 423 Norm Difference for worker 1688 is 1.251985
INFO:root:FL Epoch: 423 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :190
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521706
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327812
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 190 is 1.414161
INFO:root:FL Epoch: 423 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1382
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496955
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282448
INFO:root:FL Epoch: 423 Norm Difference for worker 1382 is 1.36238
INFO:root:FL Epoch: 423 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1904
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351304
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163623
INFO:root:FL Epoch: 423 Norm Difference for worker 1904 is 1.251313
INFO:root:FL Epoch: 423 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :742
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346022
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184528
INFO:root:FL Epoch: 423 Norm Difference for worker 742 is 1.195307
INFO:root:FL Epoch: 423 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1629
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776922
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223001
INFO:root:FL Epoch: 423 Norm Difference for worker 1629 is 1.383256
INFO:root:FL Epoch: 423 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :178
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 178 is 1.240342
INFO:root:FL Epoch: 423 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1346
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646101
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205415
INFO:root:FL Epoch: 423 Norm Difference for worker 1346 is 1.326398
INFO:root:FL Epoch: 423 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1406
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481739
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204257
INFO:root:FL Epoch: 423 Norm Difference for worker 1406 is 1.281007
INFO:root:FL Epoch: 423 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [1 4 7 5 9 8 0], which are global users: [1688, 1904, 178, 742, 1406, 1346, 1477]
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.46116723207866445 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.11983054627974828                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [1005, 998, 1599, 1223, 719, 279, 1149, 66, 805, 1920]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :1005
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583506
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218737
INFO:root:FL Epoch: 424 Norm Difference for worker 1005 is 1.282814
INFO:root:FL Epoch: 424 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :998
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667859
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235281
INFO:root:FL Epoch: 424 Norm Difference for worker 998 is 1.333128
INFO:root:FL Epoch: 424 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1599
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292356
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178768
INFO:root:FL Epoch: 424 Norm Difference for worker 1599 is 1.259116
INFO:root:FL Epoch: 424 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1223
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658468
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370688
INFO:root:FL Epoch: 424 Norm Difference for worker 1223 is 1.452188
INFO:root:FL Epoch: 424 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :719
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261883
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381651
INFO:root:FL Epoch: 424 Norm Difference for worker 719 is 1.295148
INFO:root:FL Epoch: 424 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :279
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 279 is 1.282192
INFO:root:FL Epoch: 424 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1149
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616392
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476455
INFO:root:FL Epoch: 424 Norm Difference for worker 1149 is 1.395764
INFO:root:FL Epoch: 424 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :66
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.112786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 66 is 1.361345
INFO:root:FL Epoch: 424 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :805
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556193
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186455
INFO:root:FL Epoch: 424 Norm Difference for worker 805 is 1.301978
INFO:root:FL Epoch: 424 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1920
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371952
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315552
INFO:root:FL Epoch: 424 Norm Difference for worker 1920 is 1.357428
INFO:root:FL Epoch: 424 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 4 8 1 9], which are global users: [279, 1005, 1599, 719, 805, 998, 1920]
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.4458048992297229 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.1411434014638265                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [125, 315, 593, 250, 1008, 1364, 824, 487, 695, 198]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 425 Num points on workers: [201 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :125
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.389084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 125 is 1.299418
INFO:root:FL Epoch: 425 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :315
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 315 is 1.340437
INFO:root:FL Epoch: 425 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :593
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374104
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532766
INFO:root:FL Epoch: 425 Norm Difference for worker 593 is 1.433658
INFO:root:FL Epoch: 425 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :250
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.164707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 250 is 1.289234
INFO:root:FL Epoch: 425 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1008
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794742
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253688
INFO:root:FL Epoch: 425 Norm Difference for worker 1008 is 1.405532
INFO:root:FL Epoch: 425 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1364
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498204
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259039
INFO:root:FL Epoch: 425 Norm Difference for worker 1364 is 1.334349
INFO:root:FL Epoch: 425 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :824
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651239
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272777
INFO:root:FL Epoch: 425 Norm Difference for worker 824 is 1.201906
INFO:root:FL Epoch: 425 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :487
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315933
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313584
INFO:root:FL Epoch: 425 Norm Difference for worker 487 is 1.271854
INFO:root:FL Epoch: 425 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :695
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320786
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284671
INFO:root:FL Epoch: 425 Norm Difference for worker 695 is 1.22686
INFO:root:FL Epoch: 425 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :198
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294944
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 198 is 1.397426
INFO:root:FL Epoch: 425 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 201 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 201 201 200 200]
INFO:root:The chosen ones are users: [7 0 8 3 1 5 6], which are global users: [487, 125, 695, 250, 315, 1364, 824]
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.4226796591983122 and Test Accuracy:80.0 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.14376775672038397                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [1053, 684, 410, 840, 477, 530, 660, 1267, 513, 296]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 426 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :1053
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537244
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284665
INFO:root:FL Epoch: 426 Norm Difference for worker 1053 is 1.322654
INFO:root:FL Epoch: 426 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :684
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581105
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410199
INFO:root:FL Epoch: 426 Norm Difference for worker 684 is 1.280063
INFO:root:FL Epoch: 426 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :410
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379019
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292884
INFO:root:FL Epoch: 426 Norm Difference for worker 410 is 1.252921
INFO:root:FL Epoch: 426 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :840
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537765
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346415
INFO:root:FL Epoch: 426 Norm Difference for worker 840 is 1.371448
INFO:root:FL Epoch: 426 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :477
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574048
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351333
INFO:root:FL Epoch: 426 Norm Difference for worker 477 is 1.330322
INFO:root:FL Epoch: 426 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :530
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359857
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426702
INFO:root:FL Epoch: 426 Norm Difference for worker 530 is 1.282349
INFO:root:FL Epoch: 426 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :660
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693012
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263623
INFO:root:FL Epoch: 426 Norm Difference for worker 660 is 1.339004
INFO:root:FL Epoch: 426 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1267
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361235
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342489
INFO:root:FL Epoch: 426 Norm Difference for worker 1267 is 1.267332
INFO:root:FL Epoch: 426 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :513
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397591
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168728
INFO:root:FL Epoch: 426 Norm Difference for worker 513 is 1.37077
INFO:root:FL Epoch: 426 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :296
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 296 is 1.278454
INFO:root:FL Epoch: 426 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 9 2 7 1 0 4], which are global users: [530, 296, 410, 1267, 684, 1053, 477]
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.43207816867267385 and Test Accuracy:80.0 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.16079278414448103                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [358, 1702, 890, 850, 371, 1285, 1450, 49, 1623, 1502]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :358
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.192940
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355314
INFO:root:FL Epoch: 427 Norm Difference for worker 358 is 1.160314
INFO:root:FL Epoch: 427 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1702
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254765
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248712
INFO:root:FL Epoch: 427 Norm Difference for worker 1702 is 1.245601
INFO:root:FL Epoch: 427 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :890
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665103
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297726
INFO:root:FL Epoch: 427 Norm Difference for worker 890 is 1.266773
INFO:root:FL Epoch: 427 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :850
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359653
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296182
INFO:root:FL Epoch: 427 Norm Difference for worker 850 is 1.209025
INFO:root:FL Epoch: 427 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :371
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451513
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200068
INFO:root:FL Epoch: 427 Norm Difference for worker 371 is 1.19411
INFO:root:FL Epoch: 427 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1285
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431161
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279928
INFO:root:FL Epoch: 427 Norm Difference for worker 1285 is 1.215785
INFO:root:FL Epoch: 427 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1450
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343033
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328452
INFO:root:FL Epoch: 427 Norm Difference for worker 1450 is 1.164656
INFO:root:FL Epoch: 427 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :49
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 49 is 1.331594
INFO:root:FL Epoch: 427 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1623
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448037
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237438
INFO:root:FL Epoch: 427 Norm Difference for worker 1623 is 1.268722
INFO:root:FL Epoch: 427 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1502
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381503
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275843
INFO:root:FL Epoch: 427 Norm Difference for worker 1502 is 1.223068
INFO:root:FL Epoch: 427 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 4 5 9 3 1], which are global users: [1450, 358, 371, 1285, 1502, 850, 1702]
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.4392405397751752 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.18351823712388673                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [1496, 1175, 188, 1530, 250, 1880, 417, 73, 781, 931]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 428 Num points on workers: [200 200 201 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :1496
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448083
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173340
INFO:root:FL Epoch: 428 Norm Difference for worker 1496 is 1.201759
INFO:root:FL Epoch: 428 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1175
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559928
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127943
INFO:root:FL Epoch: 428 Norm Difference for worker 1175 is 1.195905
INFO:root:FL Epoch: 428 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :188
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.245381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 188 is 1.235551
INFO:root:FL Epoch: 428 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1530
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736281
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238540
INFO:root:FL Epoch: 428 Norm Difference for worker 1530 is 1.388514
INFO:root:FL Epoch: 428 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :250
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 250 is 1.148875
INFO:root:FL Epoch: 428 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1880
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411807
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382381
INFO:root:FL Epoch: 428 Norm Difference for worker 1880 is 1.424785
INFO:root:FL Epoch: 428 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :417
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609174
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242654
INFO:root:FL Epoch: 428 Norm Difference for worker 417 is 1.393409
INFO:root:FL Epoch: 428 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :73
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.188205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 73 is 1.270804
INFO:root:FL Epoch: 428 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :781
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595529
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173136
INFO:root:FL Epoch: 428 Norm Difference for worker 781 is 1.256655
INFO:root:FL Epoch: 428 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :931
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675719
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222052
INFO:root:FL Epoch: 428 Norm Difference for worker 931 is 1.381891
INFO:root:FL Epoch: 428 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [200 201 200 201 200 200 201]
INFO:root:The chosen ones are users: [1 4 0 7 6 8 2], which are global users: [1175, 250, 1496, 73, 417, 781, 188]
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.4275109540013706 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.17597094550728798                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [573, 1218, 1481, 1222, 962, 866, 753, 639, 467, 1324]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :573
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693359
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365754
INFO:root:FL Epoch: 429 Norm Difference for worker 573 is 1.226469
INFO:root:FL Epoch: 429 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1218
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456348
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353116
INFO:root:FL Epoch: 429 Norm Difference for worker 1218 is 1.315664
INFO:root:FL Epoch: 429 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1481
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696874
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497829
INFO:root:FL Epoch: 429 Norm Difference for worker 1481 is 1.428223
INFO:root:FL Epoch: 429 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1222
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347270
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415258
INFO:root:FL Epoch: 429 Norm Difference for worker 1222 is 1.331882
INFO:root:FL Epoch: 429 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :962
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.185202
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291953
INFO:root:FL Epoch: 429 Norm Difference for worker 962 is 1.279028
INFO:root:FL Epoch: 429 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :866
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464692
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152438
INFO:root:FL Epoch: 429 Norm Difference for worker 866 is 1.400854
INFO:root:FL Epoch: 429 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :753
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492630
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505480
INFO:root:FL Epoch: 429 Norm Difference for worker 753 is 1.293993
INFO:root:FL Epoch: 429 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :639
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457284
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340010
INFO:root:FL Epoch: 429 Norm Difference for worker 639 is 1.291181
INFO:root:FL Epoch: 429 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :467
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274462
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309592
INFO:root:FL Epoch: 429 Norm Difference for worker 467 is 1.200476
INFO:root:FL Epoch: 429 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1324
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509208
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318511
INFO:root:FL Epoch: 429 Norm Difference for worker 1324 is 1.234378
INFO:root:FL Epoch: 429 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 0 9 6 4 7 3], which are global users: [467, 573, 1324, 753, 962, 639, 1222]
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.44348810174885916 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.1660580188035965                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [510, 1930, 1874, 1305, 567, 1866, 16, 1329, 1868, 483]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 430 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :510
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585878
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259626
INFO:root:FL Epoch: 430 Norm Difference for worker 510 is 1.244968
INFO:root:FL Epoch: 430 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1930
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561404
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215971
INFO:root:FL Epoch: 430 Norm Difference for worker 1930 is 1.368864
INFO:root:FL Epoch: 430 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1874
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355390
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208773
INFO:root:FL Epoch: 430 Norm Difference for worker 1874 is 1.203042
INFO:root:FL Epoch: 430 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1305
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748443
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153105
INFO:root:FL Epoch: 430 Norm Difference for worker 1305 is 1.309321
INFO:root:FL Epoch: 430 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :567
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576164
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341180
INFO:root:FL Epoch: 430 Norm Difference for worker 567 is 1.207397
INFO:root:FL Epoch: 430 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1866
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660333
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343905
INFO:root:FL Epoch: 430 Norm Difference for worker 1866 is 1.344406
INFO:root:FL Epoch: 430 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :16
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 16 is 1.417677
INFO:root:FL Epoch: 430 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1329
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334156
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355197
INFO:root:FL Epoch: 430 Norm Difference for worker 1329 is 1.306054
INFO:root:FL Epoch: 430 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1868
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465358
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432802
INFO:root:FL Epoch: 430 Norm Difference for worker 1868 is 1.349481
INFO:root:FL Epoch: 430 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :483
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411440
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238066
INFO:root:FL Epoch: 430 Norm Difference for worker 483 is 1.170485
INFO:root:FL Epoch: 430 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [9 4 2 0 3 5 7], which are global users: [483, 567, 1874, 510, 1305, 1866, 1329]
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.43343545408809886 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.14117775236566862                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 1386, 1380, 347, 1315, 1866, 1628, 201]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.152154
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163603
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.09588978998363018 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.0986762635409832 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.161495
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.158726
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157449
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.09485371348758538 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.09827724322676659 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.16473
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.140133
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141352
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.08859819049636523 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.09972982183098793 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.163111
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1386
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316928
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220930
INFO:root:FL Epoch: 431 Norm Difference for worker 1386 is 1.146176
INFO:root:FL Epoch: 431 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1380
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552526
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247646
INFO:root:FL Epoch: 431 Norm Difference for worker 1380 is 1.365215
INFO:root:FL Epoch: 431 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :347
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453076
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276100
INFO:root:FL Epoch: 431 Norm Difference for worker 347 is 1.35654
INFO:root:FL Epoch: 431 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1315
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564935
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269366
INFO:root:FL Epoch: 431 Norm Difference for worker 1315 is 1.323786
INFO:root:FL Epoch: 431 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1866
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384039
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221729
INFO:root:FL Epoch: 431 Norm Difference for worker 1866 is 1.216177
INFO:root:FL Epoch: 431 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1628
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442753
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265794
INFO:root:FL Epoch: 431 Norm Difference for worker 1628 is 1.303423
INFO:root:FL Epoch: 431 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :201
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.187993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 201 is 1.540383
INFO:root:FL Epoch: 431 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 3 2 0 7 8 6], which are global users: [1, 1386, 2, 0, 1866, 1628, 1315]
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.4442790203234729 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.09313341602683067                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1163, 172, 1453, 1739, 840, 1608, 371, 1040, 702, 1686]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 432 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1163
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488399
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403708
INFO:root:FL Epoch: 432 Norm Difference for worker 1163 is 1.303352
INFO:root:FL Epoch: 432 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :172
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.224205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 172 is 1.288148
INFO:root:FL Epoch: 432 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1453
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340747
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126333
INFO:root:FL Epoch: 432 Norm Difference for worker 1453 is 1.289648
INFO:root:FL Epoch: 432 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1739
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564510
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164875
INFO:root:FL Epoch: 432 Norm Difference for worker 1739 is 1.315749
INFO:root:FL Epoch: 432 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :840
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444028
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323284
INFO:root:FL Epoch: 432 Norm Difference for worker 840 is 1.35921
INFO:root:FL Epoch: 432 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1608
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425318
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282785
INFO:root:FL Epoch: 432 Norm Difference for worker 1608 is 1.353277
INFO:root:FL Epoch: 432 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :371
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461360
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195094
INFO:root:FL Epoch: 432 Norm Difference for worker 371 is 1.234018
INFO:root:FL Epoch: 432 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1040
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402098
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278709
INFO:root:FL Epoch: 432 Norm Difference for worker 1040 is 1.334906
INFO:root:FL Epoch: 432 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :702
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461104
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338039
INFO:root:FL Epoch: 432 Norm Difference for worker 702 is 1.373668
INFO:root:FL Epoch: 432 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1686
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343255
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432197
INFO:root:FL Epoch: 432 Norm Difference for worker 1686 is 1.239268
INFO:root:FL Epoch: 432 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 9 2 6 0 3 7], which are global users: [172, 1686, 1453, 371, 1163, 1739, 1040]
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.42848994977333965 and Test Accuracy:81.47058823529412 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.11472352221608162                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [936, 1529, 428, 1022, 1797, 133, 96, 1201, 1407, 422]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :936
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.199440
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300834
INFO:root:FL Epoch: 433 Norm Difference for worker 936 is 1.317161
INFO:root:FL Epoch: 433 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1529
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303953
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389428
INFO:root:FL Epoch: 433 Norm Difference for worker 1529 is 1.236505
INFO:root:FL Epoch: 433 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :428
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821944
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322868
INFO:root:FL Epoch: 433 Norm Difference for worker 428 is 1.204927
INFO:root:FL Epoch: 433 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1022
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336275
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398301
INFO:root:FL Epoch: 433 Norm Difference for worker 1022 is 1.242509
INFO:root:FL Epoch: 433 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1797
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 1.005753
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172197
INFO:root:FL Epoch: 433 Norm Difference for worker 1797 is 1.398704
INFO:root:FL Epoch: 433 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :133
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.172530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 133 is 1.284871
INFO:root:FL Epoch: 433 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :96
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 96 is 1.39963
INFO:root:FL Epoch: 433 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1201
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469349
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280294
INFO:root:FL Epoch: 433 Norm Difference for worker 1201 is 1.287347
INFO:root:FL Epoch: 433 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1407
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579073
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393960
INFO:root:FL Epoch: 433 Norm Difference for worker 1407 is 1.336558
INFO:root:FL Epoch: 433 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :422
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455409
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324024
INFO:root:FL Epoch: 433 Norm Difference for worker 422 is 1.216939
INFO:root:FL Epoch: 433 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 0], which are global users: [1201, 422, 428, 1022, 1529, 133, 936]
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.43269288452232585 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.10265089757740498                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1767, 1620, 569, 55, 953, 253, 598, 295, 1199, 545]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1767
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387446
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174722
INFO:root:FL Epoch: 434 Norm Difference for worker 1767 is 1.227133
INFO:root:FL Epoch: 434 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1620
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398587
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361481
INFO:root:FL Epoch: 434 Norm Difference for worker 1620 is 1.707869
INFO:root:FL Epoch: 434 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :569
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367650
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440069
INFO:root:FL Epoch: 434 Norm Difference for worker 569 is 1.411332
INFO:root:FL Epoch: 434 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :55
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370875
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 55 is 1.241393
INFO:root:FL Epoch: 434 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :953
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272054
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166263
INFO:root:FL Epoch: 434 Norm Difference for worker 953 is 1.973051
INFO:root:FL Epoch: 434 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :253
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.184898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.161154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 253 is 1.23701
INFO:root:FL Epoch: 434 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :598
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462260
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310712
INFO:root:FL Epoch: 434 Norm Difference for worker 598 is 1.409071
INFO:root:FL Epoch: 434 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :295
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 295 is 1.522877
INFO:root:FL Epoch: 434 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1199
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265928
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278903
INFO:root:FL Epoch: 434 Norm Difference for worker 1199 is 1.500759
INFO:root:FL Epoch: 434 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :545
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299360
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290769
INFO:root:FL Epoch: 434 Norm Difference for worker 545 is 1.35659
INFO:root:FL Epoch: 434 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 201 200 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [3 0 5 9 2 6 8], which are global users: [55, 1767, 253, 545, 569, 598, 1199]
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.43444211079793815 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.10635204737385114                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [444, 1452, 461, 140, 1000, 1210, 747, 33, 1773, 375]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :444
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330528
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345524
INFO:root:FL Epoch: 435 Norm Difference for worker 444 is 1.278234
INFO:root:FL Epoch: 435 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1452
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570826
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376215
INFO:root:FL Epoch: 435 Norm Difference for worker 1452 is 1.341445
INFO:root:FL Epoch: 435 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :461
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449688
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301072
INFO:root:FL Epoch: 435 Norm Difference for worker 461 is 1.343062
INFO:root:FL Epoch: 435 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :140
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.276809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 140 is 1.315633
INFO:root:FL Epoch: 435 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1000
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703247
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429541
INFO:root:FL Epoch: 435 Norm Difference for worker 1000 is 1.37455
INFO:root:FL Epoch: 435 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1210
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342641
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424704
INFO:root:FL Epoch: 435 Norm Difference for worker 1210 is 1.330327
INFO:root:FL Epoch: 435 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :747
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408144
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332840
INFO:root:FL Epoch: 435 Norm Difference for worker 747 is 1.198979
INFO:root:FL Epoch: 435 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :33
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355231
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 33 is 1.337948
INFO:root:FL Epoch: 435 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1773
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436398
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285034
INFO:root:FL Epoch: 435 Norm Difference for worker 1773 is 1.270815
INFO:root:FL Epoch: 435 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :375
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385457
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312224
INFO:root:FL Epoch: 435 Norm Difference for worker 375 is 1.256176
INFO:root:FL Epoch: 435 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 3 0 2 1], which are global users: [747, 375, 1773, 140, 444, 461, 1452]
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.4502325916991514 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.14702904845277467                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1596, 104, 1138, 367, 1834, 289, 475, 1888, 1798, 51]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 436 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1596
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428402
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165136
INFO:root:FL Epoch: 436 Norm Difference for worker 1596 is 1.127825
INFO:root:FL Epoch: 436 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :104
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.321398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.139038
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 104 is 1.242305
INFO:root:FL Epoch: 436 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1138
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717001
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342727
INFO:root:FL Epoch: 436 Norm Difference for worker 1138 is 1.350397
INFO:root:FL Epoch: 436 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :367
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562622
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341648
INFO:root:FL Epoch: 436 Norm Difference for worker 367 is 1.212844
INFO:root:FL Epoch: 436 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1834
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.948901
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434014
INFO:root:FL Epoch: 436 Norm Difference for worker 1834 is 1.177521
INFO:root:FL Epoch: 436 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :289
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432594
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.156934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 289 is 1.116796
INFO:root:FL Epoch: 436 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :475
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348216
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175945
INFO:root:FL Epoch: 436 Norm Difference for worker 475 is 1.150189
INFO:root:FL Epoch: 436 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1888
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583031
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371710
INFO:root:FL Epoch: 436 Norm Difference for worker 1888 is 1.247696
INFO:root:FL Epoch: 436 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1798
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298345
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365658
INFO:root:FL Epoch: 436 Norm Difference for worker 1798 is 1.413415
INFO:root:FL Epoch: 436 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :51
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 51 is 1.241634
INFO:root:FL Epoch: 436 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 0 6 4 7 1 3], which are global users: [289, 1596, 475, 1834, 1888, 104, 367]
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.453819462481667 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.13568205883105597                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [945, 15, 304, 957, 1361, 1848, 1090, 284, 1715, 208]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 437 Num points on workers: [200 201 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :945
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241008
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224198
INFO:root:FL Epoch: 437 Norm Difference for worker 945 is 1.141265
INFO:root:FL Epoch: 437 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :15
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 15 is 1.237247
INFO:root:FL Epoch: 437 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :304
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 304 is 1.269406
INFO:root:FL Epoch: 437 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :957
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566702
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287839
INFO:root:FL Epoch: 437 Norm Difference for worker 957 is 1.246725
INFO:root:FL Epoch: 437 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1361
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348722
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358038
INFO:root:FL Epoch: 437 Norm Difference for worker 1361 is 1.289238
INFO:root:FL Epoch: 437 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1848
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.166877
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304546
INFO:root:FL Epoch: 437 Norm Difference for worker 1848 is 1.347726
INFO:root:FL Epoch: 437 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1090
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385266
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151280
INFO:root:FL Epoch: 437 Norm Difference for worker 1090 is 1.221771
INFO:root:FL Epoch: 437 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :284
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.891603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 284 is 1.478965
INFO:root:FL Epoch: 437 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1715
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329737
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319629
INFO:root:FL Epoch: 437 Norm Difference for worker 1715 is 1.250064
INFO:root:FL Epoch: 437 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :208
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565443
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.228373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 208 is 1.388778
INFO:root:FL Epoch: 437 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [200 200 201 200 201 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 8 4], which are global users: [1090, 945, 304, 957, 15, 1715, 1361]
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.4608661900548374 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.1168981771916151                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [421, 1169, 907, 1176, 1511, 288, 1524, 1826, 1157, 919]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :421
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771797
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215447
INFO:root:FL Epoch: 438 Norm Difference for worker 421 is 1.322729
INFO:root:FL Epoch: 438 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1169
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.160920
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186137
INFO:root:FL Epoch: 438 Norm Difference for worker 1169 is 1.147743
INFO:root:FL Epoch: 438 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :907
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579364
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345657
INFO:root:FL Epoch: 438 Norm Difference for worker 907 is 1.249016
INFO:root:FL Epoch: 438 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1176
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645179
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197769
INFO:root:FL Epoch: 438 Norm Difference for worker 1176 is 1.147443
INFO:root:FL Epoch: 438 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1511
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432015
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221874
INFO:root:FL Epoch: 438 Norm Difference for worker 1511 is 1.358354
INFO:root:FL Epoch: 438 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :288
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.749211
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 288 is 1.296679
INFO:root:FL Epoch: 438 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1524
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831613
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433012
INFO:root:FL Epoch: 438 Norm Difference for worker 1524 is 1.3771
INFO:root:FL Epoch: 438 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1826
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324284
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288581
INFO:root:FL Epoch: 438 Norm Difference for worker 1826 is 1.164373
INFO:root:FL Epoch: 438 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1157
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619912
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419243
INFO:root:FL Epoch: 438 Norm Difference for worker 1157 is 1.292198
INFO:root:FL Epoch: 438 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :919
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689996
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496836
INFO:root:FL Epoch: 438 Norm Difference for worker 919 is 1.310119
INFO:root:FL Epoch: 438 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [1826, 919, 907, 1176, 1169, 288, 1157]
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.4615083599791807 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.1175681749979655                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1124, 583, 333, 158, 126, 459, 786, 991, 1294, 367]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1124
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456510
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262016
INFO:root:FL Epoch: 439 Norm Difference for worker 1124 is 1.242512
INFO:root:FL Epoch: 439 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :583
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469719
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366438
INFO:root:FL Epoch: 439 Norm Difference for worker 583 is 1.20593
INFO:root:FL Epoch: 439 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :333
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438093
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383738
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 333 is 1.208834
INFO:root:FL Epoch: 439 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :158
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297305
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 158 is 1.197269
INFO:root:FL Epoch: 439 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :126
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435278
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 126 is 1.202462
INFO:root:FL Epoch: 439 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :459
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570444
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309036
INFO:root:FL Epoch: 439 Norm Difference for worker 459 is 1.150533
INFO:root:FL Epoch: 439 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :786
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655803
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483314
INFO:root:FL Epoch: 439 Norm Difference for worker 786 is 1.3059
INFO:root:FL Epoch: 439 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :991
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448769
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142916
INFO:root:FL Epoch: 439 Norm Difference for worker 991 is 1.080515
INFO:root:FL Epoch: 439 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1294
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437936
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310294
INFO:root:FL Epoch: 439 Norm Difference for worker 1294 is 1.275473
INFO:root:FL Epoch: 439 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :367
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307276
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298150
INFO:root:FL Epoch: 439 Norm Difference for worker 367 is 1.068376
INFO:root:FL Epoch: 439 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 201 201 200]
INFO:root:The chosen ones are users: [5 9 7 3 4 2 1], which are global users: [459, 367, 991, 158, 126, 333, 583]
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.46908430842792287 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.12839418028791746                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1829, 1217, 584, 1479, 451, 1313, 1673, 401, 885, 1525]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1829
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407779
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364132
INFO:root:FL Epoch: 440 Norm Difference for worker 1829 is 1.27441
INFO:root:FL Epoch: 440 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1217
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452103
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292249
INFO:root:FL Epoch: 440 Norm Difference for worker 1217 is 1.350403
INFO:root:FL Epoch: 440 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :584
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547456
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332864
INFO:root:FL Epoch: 440 Norm Difference for worker 584 is 1.345684
INFO:root:FL Epoch: 440 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1479
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452514
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272493
INFO:root:FL Epoch: 440 Norm Difference for worker 1479 is 1.159791
INFO:root:FL Epoch: 440 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :451
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411049
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359539
INFO:root:FL Epoch: 440 Norm Difference for worker 451 is 1.286942
INFO:root:FL Epoch: 440 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1313
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564945
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266374
INFO:root:FL Epoch: 440 Norm Difference for worker 1313 is 1.170699
INFO:root:FL Epoch: 440 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1673
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661322
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313237
INFO:root:FL Epoch: 440 Norm Difference for worker 1673 is 1.288948
INFO:root:FL Epoch: 440 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :401
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832333
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596346
INFO:root:FL Epoch: 440 Norm Difference for worker 401 is 1.314945
INFO:root:FL Epoch: 440 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :885
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589686
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206987
INFO:root:FL Epoch: 440 Norm Difference for worker 885 is 1.193924
INFO:root:FL Epoch: 440 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1525
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528484
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193100
INFO:root:FL Epoch: 440 Norm Difference for worker 1525 is 1.331289
INFO:root:FL Epoch: 440 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 6 4 7], which are global users: [1313, 1829, 885, 1479, 1673, 451, 401]
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.4368079918272355 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.12306506000459194                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 1644, 1050, 1137, 72, 1710, 325, 74]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201475
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182344
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.07579638808965683 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.11285052001476288 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.190732
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278282
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.099390
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.08322402462363243 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.11436711065471172 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.181907
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.128698
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170251
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.08157625794410706 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.11366887763142586 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.181689
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1644
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394411
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322681
INFO:root:FL Epoch: 441 Norm Difference for worker 1644 is 1.286165
INFO:root:FL Epoch: 441 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1050
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438627
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458666
INFO:root:FL Epoch: 441 Norm Difference for worker 1050 is 1.314167
INFO:root:FL Epoch: 441 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1137
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722752
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440902
INFO:root:FL Epoch: 441 Norm Difference for worker 1137 is 1.439544
INFO:root:FL Epoch: 441 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :72
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 72 is 1.178983
INFO:root:FL Epoch: 441 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1710
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263971
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205765
INFO:root:FL Epoch: 441 Norm Difference for worker 1710 is 1.252151
INFO:root:FL Epoch: 441 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :325
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.111078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 325 is 1.176216
INFO:root:FL Epoch: 441 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :74
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 74 is 1.268811
INFO:root:FL Epoch: 441 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 201 201]
INFO:root:Num selected data points: [200 200 200 200 200 201 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 6], which are global users: [1710, 0, 2, 1644, 1, 325, 72]
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.43959029106532826 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.11138814315199852                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1904, 830, 1706, 724, 105, 669, 1838, 1426, 1525, 348]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1904
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566780
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320548
INFO:root:FL Epoch: 442 Norm Difference for worker 1904 is 1.268922
INFO:root:FL Epoch: 442 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :830
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395979
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460860
INFO:root:FL Epoch: 442 Norm Difference for worker 830 is 1.109748
INFO:root:FL Epoch: 442 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1706
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566867
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408041
INFO:root:FL Epoch: 442 Norm Difference for worker 1706 is 1.328982
INFO:root:FL Epoch: 442 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :724
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235442
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429198
INFO:root:FL Epoch: 442 Norm Difference for worker 724 is 1.360101
INFO:root:FL Epoch: 442 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :105
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 105 is 1.289501
INFO:root:FL Epoch: 442 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :669
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501781
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.120391
INFO:root:FL Epoch: 442 Norm Difference for worker 669 is 1.167717
INFO:root:FL Epoch: 442 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1838
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392869
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466545
INFO:root:FL Epoch: 442 Norm Difference for worker 1838 is 1.36219
INFO:root:FL Epoch: 442 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1426
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616096
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325803
INFO:root:FL Epoch: 442 Norm Difference for worker 1426 is 1.410466
INFO:root:FL Epoch: 442 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1525
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709827
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450043
INFO:root:FL Epoch: 442 Norm Difference for worker 1525 is 1.351532
INFO:root:FL Epoch: 442 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :348
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619232
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376708
INFO:root:FL Epoch: 442 Norm Difference for worker 348 is 1.237972
INFO:root:FL Epoch: 442 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [1 9 5 0 8 4 2], which are global users: [830, 348, 669, 1904, 1525, 105, 1706]
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.4604390807011548 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.1024714025358359                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1577, 779, 512, 235, 243, 191, 1671, 634, 443, 1020]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1577
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432930
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383332
INFO:root:FL Epoch: 443 Norm Difference for worker 1577 is 1.263641
INFO:root:FL Epoch: 443 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :779
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528012
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165376
INFO:root:FL Epoch: 443 Norm Difference for worker 779 is 1.300752
INFO:root:FL Epoch: 443 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :512
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488779
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280674
INFO:root:FL Epoch: 443 Norm Difference for worker 512 is 1.336043
INFO:root:FL Epoch: 443 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :235
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.211444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 235 is 1.368057
INFO:root:FL Epoch: 443 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :243
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591195
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 243 is 1.146675
INFO:root:FL Epoch: 443 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :191
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456289
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.109046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 191 is 1.302026
INFO:root:FL Epoch: 443 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1671
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354013
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444223
INFO:root:FL Epoch: 443 Norm Difference for worker 1671 is 1.226725
INFO:root:FL Epoch: 443 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :634
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567378
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357067
INFO:root:FL Epoch: 443 Norm Difference for worker 634 is 1.227649
INFO:root:FL Epoch: 443 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :443
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815061
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514307
INFO:root:FL Epoch: 443 Norm Difference for worker 443 is 1.285665
INFO:root:FL Epoch: 443 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1020
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492310
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252079
INFO:root:FL Epoch: 443 Norm Difference for worker 1020 is 1.258056
INFO:root:FL Epoch: 443 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 201 201 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 7 9 8 1 0], which are global users: [1671, 243, 634, 1020, 443, 779, 1577]
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.47957346018622904 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.15845595176021257                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [563, 1407, 1882, 1071, 1689, 574, 1118, 399, 1608, 1747]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :563
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311647
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146914
INFO:root:FL Epoch: 444 Norm Difference for worker 563 is 1.057834
INFO:root:FL Epoch: 444 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1407
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506571
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368552
INFO:root:FL Epoch: 444 Norm Difference for worker 1407 is 1.358309
INFO:root:FL Epoch: 444 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1882
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487243
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335474
INFO:root:FL Epoch: 444 Norm Difference for worker 1882 is 1.247673
INFO:root:FL Epoch: 444 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1071
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707190
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323629
INFO:root:FL Epoch: 444 Norm Difference for worker 1071 is 1.231266
INFO:root:FL Epoch: 444 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1689
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538099
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236956
INFO:root:FL Epoch: 444 Norm Difference for worker 1689 is 1.339025
INFO:root:FL Epoch: 444 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :574
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515617
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370830
INFO:root:FL Epoch: 444 Norm Difference for worker 574 is 1.260256
INFO:root:FL Epoch: 444 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1118
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751236
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260963
INFO:root:FL Epoch: 444 Norm Difference for worker 1118 is 1.291697
INFO:root:FL Epoch: 444 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :399
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497909
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326503
INFO:root:FL Epoch: 444 Norm Difference for worker 399 is 1.176666
INFO:root:FL Epoch: 444 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1608
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592887
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195364
INFO:root:FL Epoch: 444 Norm Difference for worker 1608 is 1.356079
INFO:root:FL Epoch: 444 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1747
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354557
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332548
INFO:root:FL Epoch: 444 Norm Difference for worker 1747 is 1.287259
INFO:root:FL Epoch: 444 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 9 6 5], which are global users: [399, 563, 1882, 1071, 1747, 1118, 574]
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.4550636235405417 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.11405819281935692                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [1111, 1878, 1505, 1084, 1040, 1173, 1446, 805, 871, 453]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 445 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :1111
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528230
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248264
INFO:root:FL Epoch: 445 Norm Difference for worker 1111 is 1.325084
INFO:root:FL Epoch: 445 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1878
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537145
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340710
INFO:root:FL Epoch: 445 Norm Difference for worker 1878 is 1.382559
INFO:root:FL Epoch: 445 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1505
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746061
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337014
INFO:root:FL Epoch: 445 Norm Difference for worker 1505 is 1.29288
INFO:root:FL Epoch: 445 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1084
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469997
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209115
INFO:root:FL Epoch: 445 Norm Difference for worker 1084 is 1.349945
INFO:root:FL Epoch: 445 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1040
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603088
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221514
INFO:root:FL Epoch: 445 Norm Difference for worker 1040 is 1.239618
INFO:root:FL Epoch: 445 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1173
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522313
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303320
INFO:root:FL Epoch: 445 Norm Difference for worker 1173 is 1.188909
INFO:root:FL Epoch: 445 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1446
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547980
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280137
INFO:root:FL Epoch: 445 Norm Difference for worker 1446 is 1.285259
INFO:root:FL Epoch: 445 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :805
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376028
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290543
INFO:root:FL Epoch: 445 Norm Difference for worker 805 is 1.382221
INFO:root:FL Epoch: 445 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :871
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489471
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228851
INFO:root:FL Epoch: 445 Norm Difference for worker 871 is 1.195962
INFO:root:FL Epoch: 445 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :453
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664854
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290022
INFO:root:FL Epoch: 445 Norm Difference for worker 453 is 1.331202
INFO:root:FL Epoch: 445 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 8 6 0 9], which are global users: [1173, 1040, 1505, 871, 1446, 1111, 453]
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.44066886165562796 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.12498722225427628                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [1056, 1824, 1566, 228, 917, 527, 169, 279, 1402, 1605]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :1056
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554766
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205001
INFO:root:FL Epoch: 446 Norm Difference for worker 1056 is 1.224931
INFO:root:FL Epoch: 446 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1824
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788215
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534148
INFO:root:FL Epoch: 446 Norm Difference for worker 1824 is 1.272299
INFO:root:FL Epoch: 446 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1566
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522114
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442268
INFO:root:FL Epoch: 446 Norm Difference for worker 1566 is 1.203694
INFO:root:FL Epoch: 446 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :228
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594255
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 228 is 1.234004
INFO:root:FL Epoch: 446 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :917
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622362
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400748
INFO:root:FL Epoch: 446 Norm Difference for worker 917 is 1.431456
INFO:root:FL Epoch: 446 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :527
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416400
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287488
INFO:root:FL Epoch: 446 Norm Difference for worker 527 is 1.236928
INFO:root:FL Epoch: 446 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :169
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 169 is 1.200307
INFO:root:FL Epoch: 446 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :279
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 279 is 1.237533
INFO:root:FL Epoch: 446 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1402
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455591
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470230
INFO:root:FL Epoch: 446 Norm Difference for worker 1402 is 1.317346
INFO:root:FL Epoch: 446 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1605
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414154
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477486
INFO:root:FL Epoch: 446 Norm Difference for worker 1605 is 1.265167
INFO:root:FL Epoch: 446 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 201 201 200 200]
INFO:root:Num selected data points: [201 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 6], which are global users: [279, 1056, 1566, 228, 1824, 527, 169]
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.455779468311983 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.1155711052318414                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [4, 146, 1929, 1862, 226, 1490, 914, 1000, 1175, 116]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 447 Num points on workers: [201 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :4
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490725
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 4 is 1.209189
INFO:root:FL Epoch: 447 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :146
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555731
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 146 is 1.401403
INFO:root:FL Epoch: 447 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1929
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.223195
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158788
INFO:root:FL Epoch: 447 Norm Difference for worker 1929 is 1.142588
INFO:root:FL Epoch: 447 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1862
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.227013
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228307
INFO:root:FL Epoch: 447 Norm Difference for worker 1862 is 1.216188
INFO:root:FL Epoch: 447 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :226
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.271151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.268445
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 226 is 1.277458
INFO:root:FL Epoch: 447 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1490
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585173
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296998
INFO:root:FL Epoch: 447 Norm Difference for worker 1490 is 1.275912
INFO:root:FL Epoch: 447 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :914
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512336
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309702
INFO:root:FL Epoch: 447 Norm Difference for worker 914 is 1.356445
INFO:root:FL Epoch: 447 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1000
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661671
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210677
INFO:root:FL Epoch: 447 Norm Difference for worker 1000 is 1.406239
INFO:root:FL Epoch: 447 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1175
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306677
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334743
INFO:root:FL Epoch: 447 Norm Difference for worker 1175 is 1.116586
INFO:root:FL Epoch: 447 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :116
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209668
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 116 is 1.338586
INFO:root:FL Epoch: 447 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 201 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 201 200 201]
INFO:root:The chosen ones are users: [8 0 2 3 4 5 9], which are global users: [1175, 4, 1929, 1862, 226, 1490, 116]
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.48484095229822044 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.12293037834266822                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [949, 1443, 890, 852, 689, 1895, 1574, 607, 277, 950]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :949
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428963
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499503
INFO:root:FL Epoch: 448 Norm Difference for worker 949 is 1.477342
INFO:root:FL Epoch: 448 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1443
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349105
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390113
INFO:root:FL Epoch: 448 Norm Difference for worker 1443 is 1.332368
INFO:root:FL Epoch: 448 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :890
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596441
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265840
INFO:root:FL Epoch: 448 Norm Difference for worker 890 is 1.36033
INFO:root:FL Epoch: 448 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :852
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535631
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190119
INFO:root:FL Epoch: 448 Norm Difference for worker 852 is 1.23607
INFO:root:FL Epoch: 448 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :689
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472980
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167514
INFO:root:FL Epoch: 448 Norm Difference for worker 689 is 2.042868
INFO:root:FL Epoch: 448 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1895
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387343
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213134
INFO:root:FL Epoch: 448 Norm Difference for worker 1895 is 1.444985
INFO:root:FL Epoch: 448 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1574
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281121
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356104
INFO:root:FL Epoch: 448 Norm Difference for worker 1574 is 1.542076
INFO:root:FL Epoch: 448 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :607
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747586
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200004
INFO:root:FL Epoch: 448 Norm Difference for worker 607 is 1.354414
INFO:root:FL Epoch: 448 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :277
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 277 is 1.313971
INFO:root:FL Epoch: 448 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :950
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.231848
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173255
INFO:root:FL Epoch: 448 Norm Difference for worker 950 is 1.173829
INFO:root:FL Epoch: 448 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 8], which are global users: [607, 950, 890, 852, 1443, 1895, 277]
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.46320972898427176 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.11017448641359806                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [1522, 782, 758, 912, 1379, 1210, 1104, 1023, 1212, 1352]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :1522
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592856
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229661
INFO:root:FL Epoch: 449 Norm Difference for worker 1522 is 1.21853
INFO:root:FL Epoch: 449 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :782
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527302
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339536
INFO:root:FL Epoch: 449 Norm Difference for worker 782 is 1.388815
INFO:root:FL Epoch: 449 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :758
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463016
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389120
INFO:root:FL Epoch: 449 Norm Difference for worker 758 is 1.16651
INFO:root:FL Epoch: 449 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :912
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560808
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208611
INFO:root:FL Epoch: 449 Norm Difference for worker 912 is 1.141887
INFO:root:FL Epoch: 449 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1379
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357377
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193639
INFO:root:FL Epoch: 449 Norm Difference for worker 1379 is 1.208571
INFO:root:FL Epoch: 449 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1210
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286810
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238991
INFO:root:FL Epoch: 449 Norm Difference for worker 1210 is 1.356813
INFO:root:FL Epoch: 449 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1104
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320714
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470984
INFO:root:FL Epoch: 449 Norm Difference for worker 1104 is 1.361192
INFO:root:FL Epoch: 449 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1023
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442015
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214267
INFO:root:FL Epoch: 449 Norm Difference for worker 1023 is 1.135232
INFO:root:FL Epoch: 449 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1212
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242546
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191604
INFO:root:FL Epoch: 449 Norm Difference for worker 1212 is 1.287243
INFO:root:FL Epoch: 449 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1352
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431743
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444461
INFO:root:FL Epoch: 449 Norm Difference for worker 1352 is 1.217349
INFO:root:FL Epoch: 449 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 0 4 8], which are global users: [1023, 1352, 758, 912, 1522, 1379, 1212]
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.45577724102665396 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.10827603501578172                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [389, 411, 375, 1747, 319, 522, 1311, 1796, 76, 1590]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :389
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416849
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333105
INFO:root:FL Epoch: 450 Norm Difference for worker 389 is 1.295398
INFO:root:FL Epoch: 450 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :411
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224741
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340954
INFO:root:FL Epoch: 450 Norm Difference for worker 411 is 1.462342
INFO:root:FL Epoch: 450 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :375
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422060
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386141
INFO:root:FL Epoch: 450 Norm Difference for worker 375 is 1.261691
INFO:root:FL Epoch: 450 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1747
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305765
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334200
INFO:root:FL Epoch: 450 Norm Difference for worker 1747 is 1.272085
INFO:root:FL Epoch: 450 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :319
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 319 is 1.2519
INFO:root:FL Epoch: 450 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :522
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541391
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175764
INFO:root:FL Epoch: 450 Norm Difference for worker 522 is 1.177146
INFO:root:FL Epoch: 450 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1311
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548223
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291105
INFO:root:FL Epoch: 450 Norm Difference for worker 1311 is 1.39852
INFO:root:FL Epoch: 450 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1796
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326914
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343584
INFO:root:FL Epoch: 450 Norm Difference for worker 1796 is 1.278613
INFO:root:FL Epoch: 450 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :76
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 76 is 1.395239
INFO:root:FL Epoch: 450 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1590
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454059
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236060
INFO:root:FL Epoch: 450 Norm Difference for worker 1590 is 1.301961
INFO:root:FL Epoch: 450 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 3 7 9 0], which are global users: [522, 319, 375, 1747, 1796, 1590, 389]
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.43990300508106456 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.11249846716721852                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 1108, 1097, 1433, 1247, 1404, 1313, 684]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150066
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.109572
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.07445294534166653 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.10052023157477379 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.156259
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.165528
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144072
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.07590810830394427 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.09917801916599274 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.164148
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.215358
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.111841
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.07832386468847592 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.09843441918492317 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.164014
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1108
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713616
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261239
INFO:root:FL Epoch: 451 Norm Difference for worker 1108 is 1.414447
INFO:root:FL Epoch: 451 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1097
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412552
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228081
INFO:root:FL Epoch: 451 Norm Difference for worker 1097 is 1.353833
INFO:root:FL Epoch: 451 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1433
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411161
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270551
INFO:root:FL Epoch: 451 Norm Difference for worker 1433 is 1.267461
INFO:root:FL Epoch: 451 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1247
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565095
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206625
INFO:root:FL Epoch: 451 Norm Difference for worker 1247 is 1.184499
INFO:root:FL Epoch: 451 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1404
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406888
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316730
INFO:root:FL Epoch: 451 Norm Difference for worker 1404 is 1.141621
INFO:root:FL Epoch: 451 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1313
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653301
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157346
INFO:root:FL Epoch: 451 Norm Difference for worker 1313 is 1.124678
INFO:root:FL Epoch: 451 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :684
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385422
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265585
INFO:root:FL Epoch: 451 Norm Difference for worker 684 is 1.157872
INFO:root:FL Epoch: 451 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 8 1 9 6], which are global users: [1404, 0, 2, 1313, 1, 684, 1247]
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.4500470687361324 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.0936770321180423                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1459, 1133, 1333, 1274, 6, 1294, 853, 1204, 312, 111]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1459
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446178
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372057
INFO:root:FL Epoch: 452 Norm Difference for worker 1459 is 1.308079
INFO:root:FL Epoch: 452 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1133
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389563
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370789
INFO:root:FL Epoch: 452 Norm Difference for worker 1133 is 1.406004
INFO:root:FL Epoch: 452 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1333
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578472
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196046
INFO:root:FL Epoch: 452 Norm Difference for worker 1333 is 1.458969
INFO:root:FL Epoch: 452 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1274
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333009
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304326
INFO:root:FL Epoch: 452 Norm Difference for worker 1274 is 1.334569
INFO:root:FL Epoch: 452 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :6
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 6 is 1.171141
INFO:root:FL Epoch: 452 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1294
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803151
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184284
INFO:root:FL Epoch: 452 Norm Difference for worker 1294 is 1.363819
INFO:root:FL Epoch: 452 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :853
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424127
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505231
INFO:root:FL Epoch: 452 Norm Difference for worker 853 is 1.531608
INFO:root:FL Epoch: 452 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1204
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570659
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158388
INFO:root:FL Epoch: 452 Norm Difference for worker 1204 is 1.38397
INFO:root:FL Epoch: 452 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :312
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.316142
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 312 is 1.286457
INFO:root:FL Epoch: 452 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :111
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248980
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 111 is 1.310273
INFO:root:FL Epoch: 452 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 201 201]
INFO:root:Num selected data points: [201 201 200 201 200 200 200]
INFO:root:The chosen ones are users: [8 4 0 9 3 5 7], which are global users: [312, 6, 1459, 111, 1274, 1294, 1204]
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.43044448950711417 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.09028539930780728                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1448, 287, 1140, 793, 1896, 421, 213, 1873, 1936, 764]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 453 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1448
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519794
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183607
INFO:root:FL Epoch: 453 Norm Difference for worker 1448 is 1.233547
INFO:root:FL Epoch: 453 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :287
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 287 is 1.241445
INFO:root:FL Epoch: 453 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1140
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659974
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353254
INFO:root:FL Epoch: 453 Norm Difference for worker 1140 is 1.221402
INFO:root:FL Epoch: 453 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :793
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893286
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179859
INFO:root:FL Epoch: 453 Norm Difference for worker 793 is 1.279547
INFO:root:FL Epoch: 453 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1896
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434322
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168186
INFO:root:FL Epoch: 453 Norm Difference for worker 1896 is 1.218186
INFO:root:FL Epoch: 453 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :421
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504970
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442114
INFO:root:FL Epoch: 453 Norm Difference for worker 421 is 1.311182
INFO:root:FL Epoch: 453 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :213
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 213 is 1.297
INFO:root:FL Epoch: 453 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1873
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479278
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183233
INFO:root:FL Epoch: 453 Norm Difference for worker 1873 is 1.177237
INFO:root:FL Epoch: 453 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1936
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.223436
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183058
INFO:root:FL Epoch: 453 Norm Difference for worker 1936 is 1.209267
INFO:root:FL Epoch: 453 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :764
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503480
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165809
INFO:root:FL Epoch: 453 Norm Difference for worker 764 is 1.187073
INFO:root:FL Epoch: 453 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 9 8 4 2 0 1], which are global users: [1873, 764, 1936, 1896, 1140, 1448, 287]
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.4410520984846003 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.12422081207235654                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [20, 53, 1915, 859, 1637, 1037, 375, 528, 1448, 1070]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 454 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :20
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429694
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 20 is 1.194327
INFO:root:FL Epoch: 454 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :53
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604073
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 53 is 1.252449
INFO:root:FL Epoch: 454 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1915
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608375
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288116
INFO:root:FL Epoch: 454 Norm Difference for worker 1915 is 1.315745
INFO:root:FL Epoch: 454 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :859
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414493
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200976
INFO:root:FL Epoch: 454 Norm Difference for worker 859 is 1.255733
INFO:root:FL Epoch: 454 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1637
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509787
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483292
INFO:root:FL Epoch: 454 Norm Difference for worker 1637 is 1.350078
INFO:root:FL Epoch: 454 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1037
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321748
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313816
INFO:root:FL Epoch: 454 Norm Difference for worker 1037 is 1.260774
INFO:root:FL Epoch: 454 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :375
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493336
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306831
INFO:root:FL Epoch: 454 Norm Difference for worker 375 is 1.093452
INFO:root:FL Epoch: 454 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :528
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453125
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149972
INFO:root:FL Epoch: 454 Norm Difference for worker 528 is 1.325935
INFO:root:FL Epoch: 454 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1448
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422137
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310259
INFO:root:FL Epoch: 454 Norm Difference for worker 1448 is 1.184151
INFO:root:FL Epoch: 454 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1070
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774617
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214775
INFO:root:FL Epoch: 454 Norm Difference for worker 1070 is 1.356337
INFO:root:FL Epoch: 454 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [8 0 2 3 1 5 6], which are global users: [1448, 20, 1915, 859, 53, 1037, 375]
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.4510085354833042 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.11274556443095207                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [248, 1827, 377, 1118, 1287, 306, 1415, 336, 1237, 1124]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 455 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :248
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.283931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 248 is 1.162806
INFO:root:FL Epoch: 455 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1827
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499669
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425122
INFO:root:FL Epoch: 455 Norm Difference for worker 1827 is 1.282014
INFO:root:FL Epoch: 455 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :377
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445236
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649851
INFO:root:FL Epoch: 455 Norm Difference for worker 377 is 1.382577
INFO:root:FL Epoch: 455 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1118
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291151
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284827
INFO:root:FL Epoch: 455 Norm Difference for worker 1118 is 1.189545
INFO:root:FL Epoch: 455 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1287
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557524
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328996
INFO:root:FL Epoch: 455 Norm Difference for worker 1287 is 1.230474
INFO:root:FL Epoch: 455 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :306
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384742
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.190474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 306 is 1.130468
INFO:root:FL Epoch: 455 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1415
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392579
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390094
INFO:root:FL Epoch: 455 Norm Difference for worker 1415 is 1.332845
INFO:root:FL Epoch: 455 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :336
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.157586
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 336 is 1.215807
INFO:root:FL Epoch: 455 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1237
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661278
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344659
INFO:root:FL Epoch: 455 Norm Difference for worker 1237 is 1.327077
INFO:root:FL Epoch: 455 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1124
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568741
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303276
INFO:root:FL Epoch: 455 Norm Difference for worker 1124 is 1.251965
INFO:root:FL Epoch: 455 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 200 201 200 200]
INFO:root:Num selected data points: [201 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 7 3 9 4 1], which are global users: [306, 248, 336, 1118, 1124, 1287, 1827]
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.43997128921396594 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.12295022855202357                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1208, 847, 1418, 97, 558, 674, 1098, 1624, 983, 1079]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1208
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633286
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246805
INFO:root:FL Epoch: 456 Norm Difference for worker 1208 is 1.195684
INFO:root:FL Epoch: 456 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :847
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710716
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316244
INFO:root:FL Epoch: 456 Norm Difference for worker 847 is 1.206968
INFO:root:FL Epoch: 456 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1418
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569478
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326564
INFO:root:FL Epoch: 456 Norm Difference for worker 1418 is 1.270772
INFO:root:FL Epoch: 456 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :97
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.220806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 97 is 1.241094
INFO:root:FL Epoch: 456 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :558
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554301
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249196
INFO:root:FL Epoch: 456 Norm Difference for worker 558 is 1.335246
INFO:root:FL Epoch: 456 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :674
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428565
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247351
INFO:root:FL Epoch: 456 Norm Difference for worker 674 is 1.13254
INFO:root:FL Epoch: 456 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1098
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508899
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246824
INFO:root:FL Epoch: 456 Norm Difference for worker 1098 is 1.138958
INFO:root:FL Epoch: 456 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1624
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415287
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453205
INFO:root:FL Epoch: 456 Norm Difference for worker 1624 is 1.191609
INFO:root:FL Epoch: 456 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :983
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447568
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296917
INFO:root:FL Epoch: 456 Norm Difference for worker 983 is 1.355326
INFO:root:FL Epoch: 456 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1079
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334856
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334571
INFO:root:FL Epoch: 456 Norm Difference for worker 1079 is 1.297227
INFO:root:FL Epoch: 456 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 1 5 6], which are global users: [1624, 1208, 1418, 97, 847, 674, 1098]
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.4625954470213722 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.14099817847212157                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [301, 892, 1357, 946, 1812, 217, 198, 160, 97, 78]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.0997009 0.1001994 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 457 Num points on workers: [201 200 200 200 200 201 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :301
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 301 is 1.205816
INFO:root:FL Epoch: 457 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :892
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271737
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318522
INFO:root:FL Epoch: 457 Norm Difference for worker 892 is 1.13281
INFO:root:FL Epoch: 457 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1357
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534018
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254901
INFO:root:FL Epoch: 457 Norm Difference for worker 1357 is 1.298128
INFO:root:FL Epoch: 457 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :946
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409723
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455561
INFO:root:FL Epoch: 457 Norm Difference for worker 946 is 1.236908
INFO:root:FL Epoch: 457 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1812
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266371
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249477
INFO:root:FL Epoch: 457 Norm Difference for worker 1812 is 1.254774
INFO:root:FL Epoch: 457 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :217
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205356
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 217 is 1.214514
INFO:root:FL Epoch: 457 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :198
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628714
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 198 is 1.309783
INFO:root:FL Epoch: 457 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :160
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 1.050630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 160 is 1.290922
INFO:root:FL Epoch: 457 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :97
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217144
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 97 is 1.078875
INFO:root:FL Epoch: 457 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :78
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.248385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414818
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 78 is 1.117315
INFO:root:FL Epoch: 457 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 201 201 201 201 201]
INFO:root:Num selected data points: [200 201 201 201 201 200 201]
INFO:root:The chosen ones are users: [1 9 8 0 7 3 5], which are global users: [892, 78, 97, 301, 160, 946, 217]
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.4546740545946009 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.12586033095916113                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [993, 92, 497, 26, 364, 1508, 1296, 1117, 1009, 867]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 458 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :993
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352849
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258545
INFO:root:FL Epoch: 458 Norm Difference for worker 993 is 1.278362
INFO:root:FL Epoch: 458 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :92
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 92 is 1.236183
INFO:root:FL Epoch: 458 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :497
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628530
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260460
INFO:root:FL Epoch: 458 Norm Difference for worker 497 is 1.133247
INFO:root:FL Epoch: 458 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :26
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321899
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 26 is 1.143722
INFO:root:FL Epoch: 458 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :364
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435975
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240411
INFO:root:FL Epoch: 458 Norm Difference for worker 364 is 1.202116
INFO:root:FL Epoch: 458 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1508
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516385
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193610
INFO:root:FL Epoch: 458 Norm Difference for worker 1508 is 1.142746
INFO:root:FL Epoch: 458 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1296
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549672
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190269
INFO:root:FL Epoch: 458 Norm Difference for worker 1296 is 1.224752
INFO:root:FL Epoch: 458 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1117
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738573
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231450
INFO:root:FL Epoch: 458 Norm Difference for worker 1117 is 1.162991
INFO:root:FL Epoch: 458 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1009
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547670
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574440
INFO:root:FL Epoch: 458 Norm Difference for worker 1009 is 1.341696
INFO:root:FL Epoch: 458 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :867
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327859
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169411
INFO:root:FL Epoch: 458 Norm Difference for worker 867 is 1.137351
INFO:root:FL Epoch: 458 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 201]
INFO:root:The chosen ones are users: [5 9 2 3 7 4 1], which are global users: [1508, 867, 497, 26, 1117, 364, 92]
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.4828248620033264 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.1622194411853949                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [1706, 1346, 133, 699, 374, 827, 367, 1408, 741, 952]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 459 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :1706
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327677
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240758
INFO:root:FL Epoch: 459 Norm Difference for worker 1706 is 1.163904
INFO:root:FL Epoch: 459 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1346
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201177
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225789
INFO:root:FL Epoch: 459 Norm Difference for worker 1346 is 1.240494
INFO:root:FL Epoch: 459 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :133
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 133 is 1.126797
INFO:root:FL Epoch: 459 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :699
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599813
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177481
INFO:root:FL Epoch: 459 Norm Difference for worker 699 is 1.28117
INFO:root:FL Epoch: 459 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :374
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454850
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219095
INFO:root:FL Epoch: 459 Norm Difference for worker 374 is 1.18717
INFO:root:FL Epoch: 459 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :827
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675474
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247692
INFO:root:FL Epoch: 459 Norm Difference for worker 827 is 1.296472
INFO:root:FL Epoch: 459 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :367
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491594
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176884
INFO:root:FL Epoch: 459 Norm Difference for worker 367 is 1.13585
INFO:root:FL Epoch: 459 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1408
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466147
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319110
INFO:root:FL Epoch: 459 Norm Difference for worker 1408 is 1.195497
INFO:root:FL Epoch: 459 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :741
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416597
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524146
INFO:root:FL Epoch: 459 Norm Difference for worker 741 is 1.289755
INFO:root:FL Epoch: 459 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :952
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419493
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361365
INFO:root:FL Epoch: 459 Norm Difference for worker 952 is 1.33592
INFO:root:FL Epoch: 459 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 0 7 1 8], which are global users: [367, 374, 133, 1706, 1408, 1346, 741]
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.4510185455574709 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.1174443947772185                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [580, 445, 1191, 908, 25, 749, 812, 244, 593, 618]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :580
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479493
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318527
INFO:root:FL Epoch: 460 Norm Difference for worker 580 is 1.259089
INFO:root:FL Epoch: 460 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :445
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622251
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191575
INFO:root:FL Epoch: 460 Norm Difference for worker 445 is 1.215457
INFO:root:FL Epoch: 460 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1191
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742694
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290817
INFO:root:FL Epoch: 460 Norm Difference for worker 1191 is 1.26378
INFO:root:FL Epoch: 460 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :908
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436293
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241621
INFO:root:FL Epoch: 460 Norm Difference for worker 908 is 1.189788
INFO:root:FL Epoch: 460 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :25
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.331630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 25 is 1.181234
INFO:root:FL Epoch: 460 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :749
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312406
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133372
INFO:root:FL Epoch: 460 Norm Difference for worker 749 is 1.206417
INFO:root:FL Epoch: 460 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :812
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530241
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411105
INFO:root:FL Epoch: 460 Norm Difference for worker 812 is 1.281817
INFO:root:FL Epoch: 460 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :244
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.185143
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 244 is 1.164638
INFO:root:FL Epoch: 460 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :593
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654399
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312230
INFO:root:FL Epoch: 460 Norm Difference for worker 593 is 1.356525
INFO:root:FL Epoch: 460 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :618
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374032
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178696
INFO:root:FL Epoch: 460 Norm Difference for worker 618 is 1.280119
INFO:root:FL Epoch: 460 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 201 200 200]
INFO:root:Num selected data points: [200 201 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 7 3 1 0 9], which are global users: [749, 25, 244, 908, 445, 580, 618]
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.4583291551646064 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.1215117114285628                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 607, 837, 17, 896, 1404, 909, 1212]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.188875
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165319
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.07842687144875526 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.10651358515024185 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.162635
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213605
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133971
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.07915601568917434 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.10634118169546128 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.160189
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.126474
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113109
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.08508037527402242 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.10934722609817982 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.146964
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :607
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677502
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223086
INFO:root:FL Epoch: 461 Norm Difference for worker 607 is 1.207007
INFO:root:FL Epoch: 461 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :837
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634759
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264719
INFO:root:FL Epoch: 461 Norm Difference for worker 837 is 1.227513
INFO:root:FL Epoch: 461 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :17
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 17 is 1.231241
INFO:root:FL Epoch: 461 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :896
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510251
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.099158
INFO:root:FL Epoch: 461 Norm Difference for worker 896 is 1.086323
INFO:root:FL Epoch: 461 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1404
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577298
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243553
INFO:root:FL Epoch: 461 Norm Difference for worker 1404 is 1.073164
INFO:root:FL Epoch: 461 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :909
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455370
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199246
INFO:root:FL Epoch: 461 Norm Difference for worker 909 is 1.178488
INFO:root:FL Epoch: 461 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1212
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476990
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244472
INFO:root:FL Epoch: 461 Norm Difference for worker 1212 is 1.12645
INFO:root:FL Epoch: 461 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 7 1 9 8], which are global users: [896, 0, 2, 1404, 1, 1212, 909]
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.46080874257227955 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.1001904687533776                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [1587, 831, 1744, 981, 535, 1490, 1495, 634, 1243, 571]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :1587
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465526
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260210
INFO:root:FL Epoch: 462 Norm Difference for worker 1587 is 1.231426
INFO:root:FL Epoch: 462 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :831
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333694
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148254
INFO:root:FL Epoch: 462 Norm Difference for worker 831 is 1.128816
INFO:root:FL Epoch: 462 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1744
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473939
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296436
INFO:root:FL Epoch: 462 Norm Difference for worker 1744 is 1.155325
INFO:root:FL Epoch: 462 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :981
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394347
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257713
INFO:root:FL Epoch: 462 Norm Difference for worker 981 is 1.365811
INFO:root:FL Epoch: 462 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :535
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492757
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176475
INFO:root:FL Epoch: 462 Norm Difference for worker 535 is 1.237329
INFO:root:FL Epoch: 462 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1490
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348634
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261365
INFO:root:FL Epoch: 462 Norm Difference for worker 1490 is 1.254139
INFO:root:FL Epoch: 462 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1495
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 1.013412
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353248
INFO:root:FL Epoch: 462 Norm Difference for worker 1495 is 1.495666
INFO:root:FL Epoch: 462 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :634
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526064
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337673
INFO:root:FL Epoch: 462 Norm Difference for worker 634 is 1.199058
INFO:root:FL Epoch: 462 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1243
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785163
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176115
INFO:root:FL Epoch: 462 Norm Difference for worker 1243 is 1.28483
INFO:root:FL Epoch: 462 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :571
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264652
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243755
INFO:root:FL Epoch: 462 Norm Difference for worker 571 is 1.251112
INFO:root:FL Epoch: 462 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 7 4 9 5], which are global users: [831, 1587, 1744, 634, 535, 571, 1490]
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.48982396020608787 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.122452932720383                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [335, 1320, 78, 417, 3, 371, 1139, 1410, 1867, 738]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 463 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :335
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.234760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 335 is 1.219911
INFO:root:FL Epoch: 463 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1320
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735431
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254016
INFO:root:FL Epoch: 463 Norm Difference for worker 1320 is 1.229297
INFO:root:FL Epoch: 463 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :78
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 78 is 1.13438
INFO:root:FL Epoch: 463 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :417
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533302
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242385
INFO:root:FL Epoch: 463 Norm Difference for worker 417 is 1.244759
INFO:root:FL Epoch: 463 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :3
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.879033
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 3 is 1.266308
INFO:root:FL Epoch: 463 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :371
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335495
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184225
INFO:root:FL Epoch: 463 Norm Difference for worker 371 is 1.102833
INFO:root:FL Epoch: 463 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1139
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508859
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367972
INFO:root:FL Epoch: 463 Norm Difference for worker 1139 is 1.251099
INFO:root:FL Epoch: 463 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1410
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415916
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137522
INFO:root:FL Epoch: 463 Norm Difference for worker 1410 is 1.230278
INFO:root:FL Epoch: 463 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1867
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459859
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338692
INFO:root:FL Epoch: 463 Norm Difference for worker 1867 is 1.352044
INFO:root:FL Epoch: 463 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :738
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352904
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156004
INFO:root:FL Epoch: 463 Norm Difference for worker 738 is 1.186209
INFO:root:FL Epoch: 463 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 201 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 1 5 6], which are global users: [1410, 738, 78, 417, 1320, 371, 1139]
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.4743523492532618 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.12098986282944679                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [740, 258, 895, 807, 468, 1002, 239, 675, 1571, 1007]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 464 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :740
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615680
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423418
INFO:root:FL Epoch: 464 Norm Difference for worker 740 is 1.214193
INFO:root:FL Epoch: 464 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :258
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619657
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 258 is 1.377495
INFO:root:FL Epoch: 464 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :895
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512036
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246054
INFO:root:FL Epoch: 464 Norm Difference for worker 895 is 1.231684
INFO:root:FL Epoch: 464 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :807
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248296
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360768
INFO:root:FL Epoch: 464 Norm Difference for worker 807 is 1.273592
INFO:root:FL Epoch: 464 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :468
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470401
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215088
INFO:root:FL Epoch: 464 Norm Difference for worker 468 is 1.217063
INFO:root:FL Epoch: 464 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1002
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344147
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217931
INFO:root:FL Epoch: 464 Norm Difference for worker 1002 is 1.197213
INFO:root:FL Epoch: 464 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :239
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386820
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 239 is 1.45318
INFO:root:FL Epoch: 464 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :675
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579531
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254853
INFO:root:FL Epoch: 464 Norm Difference for worker 675 is 1.340707
INFO:root:FL Epoch: 464 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1571
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271743
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445959
INFO:root:FL Epoch: 464 Norm Difference for worker 1571 is 1.213738
INFO:root:FL Epoch: 464 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1007
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292770
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397644
INFO:root:FL Epoch: 464 Norm Difference for worker 1007 is 1.207799
INFO:root:FL Epoch: 464 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 2 8 9 3 0], which are global users: [1002, 468, 895, 1571, 1007, 807, 740]
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.4687112166601069 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.110730005428195                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [81, 351, 1764, 1030, 751, 1163, 582, 323, 1265, 143]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 465 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :81
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481634
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 81 is 1.334209
INFO:root:FL Epoch: 465 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :351
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448733
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221701
INFO:root:FL Epoch: 465 Norm Difference for worker 351 is 1.227775
INFO:root:FL Epoch: 465 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1764
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711393
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390853
INFO:root:FL Epoch: 465 Norm Difference for worker 1764 is 1.424706
INFO:root:FL Epoch: 465 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1030
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745491
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243113
INFO:root:FL Epoch: 465 Norm Difference for worker 1030 is 1.473472
INFO:root:FL Epoch: 465 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :751
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511825
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216251
INFO:root:FL Epoch: 465 Norm Difference for worker 751 is 1.242214
INFO:root:FL Epoch: 465 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1163
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365156
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272101
INFO:root:FL Epoch: 465 Norm Difference for worker 1163 is 1.200424
INFO:root:FL Epoch: 465 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :582
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662096
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387383
INFO:root:FL Epoch: 465 Norm Difference for worker 582 is 1.459755
INFO:root:FL Epoch: 465 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :323
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 323 is 1.332713
INFO:root:FL Epoch: 465 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1265
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364004
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248890
INFO:root:FL Epoch: 465 Norm Difference for worker 1265 is 1.250346
INFO:root:FL Epoch: 465 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :143
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376321
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.199982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 143 is 1.248984
INFO:root:FL Epoch: 465 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [200 200 200 200 201 201 201]
INFO:root:The chosen ones are users: [1 4 8 5 9 7 0], which are global users: [351, 751, 1265, 1163, 143, 323, 81]
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.4675729169565089 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.12059012738366921                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1824, 1524, 512, 513, 1770, 173, 1460, 639, 1261, 1732]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1824
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433393
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386171
INFO:root:FL Epoch: 466 Norm Difference for worker 1824 is 1.279291
INFO:root:FL Epoch: 466 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1524
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628944
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206156
INFO:root:FL Epoch: 466 Norm Difference for worker 1524 is 1.351219
INFO:root:FL Epoch: 466 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :512
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643393
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370831
INFO:root:FL Epoch: 466 Norm Difference for worker 512 is 1.254474
INFO:root:FL Epoch: 466 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :513
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334689
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437664
INFO:root:FL Epoch: 466 Norm Difference for worker 513 is 1.435705
INFO:root:FL Epoch: 466 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1770
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339812
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325289
INFO:root:FL Epoch: 466 Norm Difference for worker 1770 is 1.113078
INFO:root:FL Epoch: 466 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :173
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 173 is 1.285668
INFO:root:FL Epoch: 466 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1460
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282348
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156150
INFO:root:FL Epoch: 466 Norm Difference for worker 1460 is 1.128863
INFO:root:FL Epoch: 466 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :639
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555721
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252476
INFO:root:FL Epoch: 466 Norm Difference for worker 639 is 1.209951
INFO:root:FL Epoch: 466 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1261
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572176
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395012
INFO:root:FL Epoch: 466 Norm Difference for worker 1261 is 1.313024
INFO:root:FL Epoch: 466 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1732
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572434
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387165
INFO:root:FL Epoch: 466 Norm Difference for worker 1732 is 1.202201
INFO:root:FL Epoch: 466 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 4 9 7 0 5 2], which are global users: [1460, 1770, 1732, 639, 1824, 173, 512]
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.46717001234783845 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.1323355920612812                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1773, 938, 657, 1319, 1905, 21, 745, 488, 408, 1595]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 467 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1773
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571803
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235845
INFO:root:FL Epoch: 467 Norm Difference for worker 1773 is 1.241069
INFO:root:FL Epoch: 467 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :938
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623381
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502344
INFO:root:FL Epoch: 467 Norm Difference for worker 938 is 1.362475
INFO:root:FL Epoch: 467 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :657
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 1.002980
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303933
INFO:root:FL Epoch: 467 Norm Difference for worker 657 is 1.309474
INFO:root:FL Epoch: 467 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1319
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480806
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392555
INFO:root:FL Epoch: 467 Norm Difference for worker 1319 is 1.378146
INFO:root:FL Epoch: 467 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1905
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262666
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162810
INFO:root:FL Epoch: 467 Norm Difference for worker 1905 is 1.100792
INFO:root:FL Epoch: 467 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :21
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 21 is 1.111951
INFO:root:FL Epoch: 467 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :745
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456875
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331212
INFO:root:FL Epoch: 467 Norm Difference for worker 745 is 1.260822
INFO:root:FL Epoch: 467 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :488
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336057
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262802
INFO:root:FL Epoch: 467 Norm Difference for worker 488 is 1.189234
INFO:root:FL Epoch: 467 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :408
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522787
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212547
INFO:root:FL Epoch: 467 Norm Difference for worker 408 is 1.241459
INFO:root:FL Epoch: 467 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1595
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259049
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278567
INFO:root:FL Epoch: 467 Norm Difference for worker 1595 is 1.207245
INFO:root:FL Epoch: 467 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 4 7 9 8 6 0], which are global users: [21, 1905, 488, 1595, 408, 745, 1773]
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.47618255720419045 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.18059713393449783                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1586, 1317, 626, 1406, 854, 1493, 724, 1905, 1504, 843]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1586
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735522
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224937
INFO:root:FL Epoch: 468 Norm Difference for worker 1586 is 1.339693
INFO:root:FL Epoch: 468 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1317
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424312
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325080
INFO:root:FL Epoch: 468 Norm Difference for worker 1317 is 1.206173
INFO:root:FL Epoch: 468 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :626
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.130187
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251226
INFO:root:FL Epoch: 468 Norm Difference for worker 626 is 1.151503
INFO:root:FL Epoch: 468 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1406
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513951
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344277
INFO:root:FL Epoch: 468 Norm Difference for worker 1406 is 1.184206
INFO:root:FL Epoch: 468 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :854
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434078
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371270
INFO:root:FL Epoch: 468 Norm Difference for worker 854 is 1.196034
INFO:root:FL Epoch: 468 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1493
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327157
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274536
INFO:root:FL Epoch: 468 Norm Difference for worker 1493 is 1.252796
INFO:root:FL Epoch: 468 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :724
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561389
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306483
INFO:root:FL Epoch: 468 Norm Difference for worker 724 is 1.238301
INFO:root:FL Epoch: 468 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1905
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295545
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.091896
INFO:root:FL Epoch: 468 Norm Difference for worker 1905 is 0.906055
INFO:root:FL Epoch: 468 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1504
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682221
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177158
INFO:root:FL Epoch: 468 Norm Difference for worker 1504 is 1.355485
INFO:root:FL Epoch: 468 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :843
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551987
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369542
INFO:root:FL Epoch: 468 Norm Difference for worker 843 is 1.299903
INFO:root:FL Epoch: 468 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 5 6], which are global users: [1905, 854, 626, 1406, 1317, 1493, 724]
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.4546004148090587 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.13532781973481178                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [554, 1448, 934, 1333, 217, 1698, 1453, 379, 1803, 488]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :554
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454144
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305597
INFO:root:FL Epoch: 469 Norm Difference for worker 554 is 1.284721
INFO:root:FL Epoch: 469 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1448
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413666
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348061
INFO:root:FL Epoch: 469 Norm Difference for worker 1448 is 1.179574
INFO:root:FL Epoch: 469 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :934
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597260
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339536
INFO:root:FL Epoch: 469 Norm Difference for worker 934 is 1.337893
INFO:root:FL Epoch: 469 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1333
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840581
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410695
INFO:root:FL Epoch: 469 Norm Difference for worker 1333 is 1.418121
INFO:root:FL Epoch: 469 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :217
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 217 is 1.108794
INFO:root:FL Epoch: 469 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1698
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519293
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320333
INFO:root:FL Epoch: 469 Norm Difference for worker 1698 is 1.355971
INFO:root:FL Epoch: 469 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1453
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372912
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272810
INFO:root:FL Epoch: 469 Norm Difference for worker 1453 is 1.163761
INFO:root:FL Epoch: 469 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :379
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636294
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220217
INFO:root:FL Epoch: 469 Norm Difference for worker 379 is 1.314497
INFO:root:FL Epoch: 469 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1803
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735986
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289017
INFO:root:FL Epoch: 469 Norm Difference for worker 1803 is 1.239432
INFO:root:FL Epoch: 469 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :488
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433241
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233123
INFO:root:FL Epoch: 469 Norm Difference for worker 488 is 1.140383
INFO:root:FL Epoch: 469 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 201 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [4 9 7 0 1 8 6], which are global users: [217, 488, 379, 554, 1448, 1803, 1453]
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.43787429876187267 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.10608264369269212                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [709, 1445, 1569, 618, 1559, 1202, 1010, 484, 1465, 613]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :709
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447493
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462740
INFO:root:FL Epoch: 470 Norm Difference for worker 709 is 1.301789
INFO:root:FL Epoch: 470 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1445
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788515
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369441
INFO:root:FL Epoch: 470 Norm Difference for worker 1445 is 1.301333
INFO:root:FL Epoch: 470 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1569
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454685
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292541
INFO:root:FL Epoch: 470 Norm Difference for worker 1569 is 1.349982
INFO:root:FL Epoch: 470 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :618
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527988
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136690
INFO:root:FL Epoch: 470 Norm Difference for worker 618 is 1.160821
INFO:root:FL Epoch: 470 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1559
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275661
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217150
INFO:root:FL Epoch: 470 Norm Difference for worker 1559 is 1.198003
INFO:root:FL Epoch: 470 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1202
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502228
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162842
INFO:root:FL Epoch: 470 Norm Difference for worker 1202 is 1.312098
INFO:root:FL Epoch: 470 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1010
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467633
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358749
INFO:root:FL Epoch: 470 Norm Difference for worker 1010 is 1.31089
INFO:root:FL Epoch: 470 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :484
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689277
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256675
INFO:root:FL Epoch: 470 Norm Difference for worker 484 is 1.378555
INFO:root:FL Epoch: 470 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1465
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398798
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481328
INFO:root:FL Epoch: 470 Norm Difference for worker 1465 is 1.284811
INFO:root:FL Epoch: 470 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :613
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606918
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319639
INFO:root:FL Epoch: 470 Norm Difference for worker 613 is 1.413114
INFO:root:FL Epoch: 470 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [3 4 8 0 5 1 6], which are global users: [618, 1559, 1465, 709, 1202, 1445, 1010]
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.43758853568750267 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.09362369465331237                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 151, 1654, 1080, 91, 1467, 1247, 1165]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.104315
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.094794
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.07818151699999969 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.09423461109399796 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.137662
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.086752
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.117288
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.07710535327593486 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.09392993487417697 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.140218
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.096519
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134715
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.07885278947651386 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.09258869737386703 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.145956
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :151
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 151 is 1.272797
INFO:root:FL Epoch: 471 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1654
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921454
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187171
INFO:root:FL Epoch: 471 Norm Difference for worker 1654 is 1.316575
INFO:root:FL Epoch: 471 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1080
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.989077
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450799
INFO:root:FL Epoch: 471 Norm Difference for worker 1080 is 1.316627
INFO:root:FL Epoch: 471 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :91
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 91 is 1.309791
INFO:root:FL Epoch: 471 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1467
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519597
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161445
INFO:root:FL Epoch: 471 Norm Difference for worker 1467 is 1.175535
INFO:root:FL Epoch: 471 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1247
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533103
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238140
INFO:root:FL Epoch: 471 Norm Difference for worker 1247 is 1.191729
INFO:root:FL Epoch: 471 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1165
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.162400
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325901
INFO:root:FL Epoch: 471 Norm Difference for worker 1165 is 1.230613
INFO:root:FL Epoch: 471 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 200 201 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [7 0 2 8 1 9 3], which are global users: [1467, 0, 2, 1247, 1, 1165, 151]
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.44561159084824953 and Test Accuracy:80.0 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.09659385246535142                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [55, 1275, 894, 1719, 433, 1880, 1000, 1374, 879, 853]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 472 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :55
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.225871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.180413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 55 is 1.113461
INFO:root:FL Epoch: 472 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1275
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343417
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268799
INFO:root:FL Epoch: 472 Norm Difference for worker 1275 is 1.301473
INFO:root:FL Epoch: 472 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :894
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213638
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223640
INFO:root:FL Epoch: 472 Norm Difference for worker 894 is 1.161487
INFO:root:FL Epoch: 472 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1719
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333755
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404199
INFO:root:FL Epoch: 472 Norm Difference for worker 1719 is 1.178291
INFO:root:FL Epoch: 472 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :433
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336878
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306723
INFO:root:FL Epoch: 472 Norm Difference for worker 433 is 1.252715
INFO:root:FL Epoch: 472 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1880
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675733
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412579
INFO:root:FL Epoch: 472 Norm Difference for worker 1880 is 1.317874
INFO:root:FL Epoch: 472 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1000
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517589
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165404
INFO:root:FL Epoch: 472 Norm Difference for worker 1000 is 1.406659
INFO:root:FL Epoch: 472 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1374
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425811
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219525
INFO:root:FL Epoch: 472 Norm Difference for worker 1374 is 1.109546
INFO:root:FL Epoch: 472 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :879
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473797
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564029
INFO:root:FL Epoch: 472 Norm Difference for worker 879 is 1.333213
INFO:root:FL Epoch: 472 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :853
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431978
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352868
INFO:root:FL Epoch: 472 Norm Difference for worker 853 is 1.438904
INFO:root:FL Epoch: 472 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 0 2 3 4 1 5], which are global users: [1374, 55, 894, 1719, 433, 1275, 1880]
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.4440340610111461 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.1084550569454829                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [548, 1156, 785, 1590, 1674, 880, 1577, 662, 1528, 386]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :548
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494483
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424270
INFO:root:FL Epoch: 473 Norm Difference for worker 548 is 1.34713
INFO:root:FL Epoch: 473 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1156
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479022
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235760
INFO:root:FL Epoch: 473 Norm Difference for worker 1156 is 1.179139
INFO:root:FL Epoch: 473 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :785
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396145
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288112
INFO:root:FL Epoch: 473 Norm Difference for worker 785 is 1.207053
INFO:root:FL Epoch: 473 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1590
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641808
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274966
INFO:root:FL Epoch: 473 Norm Difference for worker 1590 is 1.254087
INFO:root:FL Epoch: 473 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1674
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489523
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265706
INFO:root:FL Epoch: 473 Norm Difference for worker 1674 is 1.345843
INFO:root:FL Epoch: 473 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :880
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551420
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422130
INFO:root:FL Epoch: 473 Norm Difference for worker 880 is 1.269452
INFO:root:FL Epoch: 473 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1577
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591141
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256991
INFO:root:FL Epoch: 473 Norm Difference for worker 1577 is 1.249719
INFO:root:FL Epoch: 473 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :662
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816986
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277498
INFO:root:FL Epoch: 473 Norm Difference for worker 662 is 1.62806
INFO:root:FL Epoch: 473 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1528
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378623
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234835
INFO:root:FL Epoch: 473 Norm Difference for worker 1528 is 1.087833
INFO:root:FL Epoch: 473 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :386
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329412
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122416
INFO:root:FL Epoch: 473 Norm Difference for worker 386 is 1.06382
INFO:root:FL Epoch: 473 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 9 2 3 1 5 6], which are global users: [1528, 386, 785, 1590, 1156, 880, 1577]
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.454781397300608 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.13085481151938438                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1866, 1598, 830, 460, 382, 1338, 838, 193, 457, 1938]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1866
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366201
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157319
INFO:root:FL Epoch: 474 Norm Difference for worker 1866 is 1.324425
INFO:root:FL Epoch: 474 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1598
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277407
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235322
INFO:root:FL Epoch: 474 Norm Difference for worker 1598 is 1.111338
INFO:root:FL Epoch: 474 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :830
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362804
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165327
INFO:root:FL Epoch: 474 Norm Difference for worker 830 is 1.081643
INFO:root:FL Epoch: 474 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :460
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440456
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321773
INFO:root:FL Epoch: 474 Norm Difference for worker 460 is 1.327199
INFO:root:FL Epoch: 474 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :382
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615839
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303890
INFO:root:FL Epoch: 474 Norm Difference for worker 382 is 1.349305
INFO:root:FL Epoch: 474 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1338
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808060
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425471
INFO:root:FL Epoch: 474 Norm Difference for worker 1338 is 1.189328
INFO:root:FL Epoch: 474 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :838
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302058
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381801
INFO:root:FL Epoch: 474 Norm Difference for worker 838 is 1.299782
INFO:root:FL Epoch: 474 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :193
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 1.210577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 193 is 1.350624
INFO:root:FL Epoch: 474 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :457
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519356
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297666
INFO:root:FL Epoch: 474 Norm Difference for worker 457 is 1.365251
INFO:root:FL Epoch: 474 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1938
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398961
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370536
INFO:root:FL Epoch: 474 Norm Difference for worker 1938 is 1.300129
INFO:root:FL Epoch: 474 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 6 1 9 3], which are global users: [1338, 1866, 830, 838, 1598, 1938, 460]
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.4530406489091761 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.10891871526837349                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1290, 213, 1351, 1815, 282, 152, 1723, 1823, 752, 1239]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 475 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1290
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442090
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308051
INFO:root:FL Epoch: 475 Norm Difference for worker 1290 is 1.22611
INFO:root:FL Epoch: 475 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :213
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 213 is 1.385178
INFO:root:FL Epoch: 475 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1351
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333010
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409065
INFO:root:FL Epoch: 475 Norm Difference for worker 1351 is 1.296831
INFO:root:FL Epoch: 475 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1815
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720025
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219912
INFO:root:FL Epoch: 475 Norm Difference for worker 1815 is 1.209865
INFO:root:FL Epoch: 475 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :282
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.320476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370880
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 282 is 1.354674
INFO:root:FL Epoch: 475 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :152
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 152 is 1.265556
INFO:root:FL Epoch: 475 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1723
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630291
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221886
INFO:root:FL Epoch: 475 Norm Difference for worker 1723 is 1.197338
INFO:root:FL Epoch: 475 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1823
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292562
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251879
INFO:root:FL Epoch: 475 Norm Difference for worker 1823 is 1.332536
INFO:root:FL Epoch: 475 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :752
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492512
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557434
INFO:root:FL Epoch: 475 Norm Difference for worker 752 is 1.235752
INFO:root:FL Epoch: 475 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1239
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353748
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242624
INFO:root:FL Epoch: 475 Norm Difference for worker 1239 is 1.277609
INFO:root:FL Epoch: 475 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 201 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 8 3 6 9 2], which are global users: [152, 1290, 752, 1815, 1723, 1239, 1351]
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.4487881152068867 and Test Accuracy:80.0 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.11128728464245796                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [1494, 1738, 1857, 453, 1466, 1132, 1586, 1646, 1059, 419]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 476 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :1494
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247403
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223017
INFO:root:FL Epoch: 476 Norm Difference for worker 1494 is 1.124061
INFO:root:FL Epoch: 476 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1738
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295354
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369446
INFO:root:FL Epoch: 476 Norm Difference for worker 1738 is 1.193677
INFO:root:FL Epoch: 476 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1857
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436186
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285352
INFO:root:FL Epoch: 476 Norm Difference for worker 1857 is 1.224488
INFO:root:FL Epoch: 476 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :453
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304277
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206620
INFO:root:FL Epoch: 476 Norm Difference for worker 453 is 1.254221
INFO:root:FL Epoch: 476 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1466
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547984
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525922
INFO:root:FL Epoch: 476 Norm Difference for worker 1466 is 1.200386
INFO:root:FL Epoch: 476 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1132
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447097
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316565
INFO:root:FL Epoch: 476 Norm Difference for worker 1132 is 1.195036
INFO:root:FL Epoch: 476 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1586
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670545
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297187
INFO:root:FL Epoch: 476 Norm Difference for worker 1586 is 1.210373
INFO:root:FL Epoch: 476 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1646
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286116
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376498
INFO:root:FL Epoch: 476 Norm Difference for worker 1646 is 1.166206
INFO:root:FL Epoch: 476 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1059
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289583
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272034
INFO:root:FL Epoch: 476 Norm Difference for worker 1059 is 1.068127
INFO:root:FL Epoch: 476 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :419
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200322
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244650
INFO:root:FL Epoch: 476 Norm Difference for worker 419 is 1.103542
INFO:root:FL Epoch: 476 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [8 9 0 7 4 5 1], which are global users: [1059, 419, 1494, 1646, 1466, 1132, 1738]
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.4552505033857682 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.13408131524920464                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [952, 411, 415, 1448, 552, 1943, 679, 1277, 1416, 35]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 477 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :952
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737000
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405322
INFO:root:FL Epoch: 477 Norm Difference for worker 952 is 1.234753
INFO:root:FL Epoch: 477 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :411
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854950
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376219
INFO:root:FL Epoch: 477 Norm Difference for worker 411 is 1.35342
INFO:root:FL Epoch: 477 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :415
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594572
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257924
INFO:root:FL Epoch: 477 Norm Difference for worker 415 is 1.130911
INFO:root:FL Epoch: 477 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1448
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428627
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198937
INFO:root:FL Epoch: 477 Norm Difference for worker 1448 is 1.129365
INFO:root:FL Epoch: 477 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :552
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504488
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439895
INFO:root:FL Epoch: 477 Norm Difference for worker 552 is 1.287775
INFO:root:FL Epoch: 477 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1943
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624959
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365530
INFO:root:FL Epoch: 477 Norm Difference for worker 1943 is 1.345633
INFO:root:FL Epoch: 477 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :679
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436167
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440808
INFO:root:FL Epoch: 477 Norm Difference for worker 679 is 1.230772
INFO:root:FL Epoch: 477 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1277
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230578
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174647
INFO:root:FL Epoch: 477 Norm Difference for worker 1277 is 1.135831
INFO:root:FL Epoch: 477 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1416
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504464
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158969
INFO:root:FL Epoch: 477 Norm Difference for worker 1416 is 1.179257
INFO:root:FL Epoch: 477 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :35
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232055
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 35 is 1.080255
INFO:root:FL Epoch: 477 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [7 9 2 3 8 0 6], which are global users: [1277, 35, 415, 1448, 1416, 952, 679]
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.4472293029813206 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.10460388660430908                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [1457, 196, 409, 1243, 850, 1688, 1945, 529, 1824, 301]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 478 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :1457
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644904
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292650
INFO:root:FL Epoch: 478 Norm Difference for worker 1457 is 1.248972
INFO:root:FL Epoch: 478 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :196
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 196 is 1.230358
INFO:root:FL Epoch: 478 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :409
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571237
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270598
INFO:root:FL Epoch: 478 Norm Difference for worker 409 is 1.213753
INFO:root:FL Epoch: 478 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1243
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741211
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203650
INFO:root:FL Epoch: 478 Norm Difference for worker 1243 is 1.217009
INFO:root:FL Epoch: 478 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :850
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261189
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235262
INFO:root:FL Epoch: 478 Norm Difference for worker 850 is 1.153382
INFO:root:FL Epoch: 478 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1688
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305424
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199396
INFO:root:FL Epoch: 478 Norm Difference for worker 1688 is 1.145269
INFO:root:FL Epoch: 478 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1945
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347513
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134413
INFO:root:FL Epoch: 478 Norm Difference for worker 1945 is 1.100536
INFO:root:FL Epoch: 478 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :529
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500936
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187271
INFO:root:FL Epoch: 478 Norm Difference for worker 529 is 1.191198
INFO:root:FL Epoch: 478 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1824
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710781
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256206
INFO:root:FL Epoch: 478 Norm Difference for worker 1824 is 1.173607
INFO:root:FL Epoch: 478 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :301
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 301 is 1.161126
INFO:root:FL Epoch: 478 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [5 4 8 7 6 9 3], which are global users: [1688, 850, 1824, 529, 1945, 301, 1243]
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.46901711383286643 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.12193319884439309                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [1556, 1805, 396, 462, 693, 700, 492, 688, 164, 1734]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :1556
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461707
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334735
INFO:root:FL Epoch: 479 Norm Difference for worker 1556 is 1.177939
INFO:root:FL Epoch: 479 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1805
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325594
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133530
INFO:root:FL Epoch: 479 Norm Difference for worker 1805 is 1.167936
INFO:root:FL Epoch: 479 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :396
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577736
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.086815
INFO:root:FL Epoch: 479 Norm Difference for worker 396 is 1.151489
INFO:root:FL Epoch: 479 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :462
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513951
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299063
INFO:root:FL Epoch: 479 Norm Difference for worker 462 is 1.332492
INFO:root:FL Epoch: 479 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :693
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402187
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314812
INFO:root:FL Epoch: 479 Norm Difference for worker 693 is 1.252144
INFO:root:FL Epoch: 479 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :700
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546052
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240942
INFO:root:FL Epoch: 479 Norm Difference for worker 700 is 1.215965
INFO:root:FL Epoch: 479 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :492
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606039
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133530
INFO:root:FL Epoch: 479 Norm Difference for worker 492 is 1.181428
INFO:root:FL Epoch: 479 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :688
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566212
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234008
INFO:root:FL Epoch: 479 Norm Difference for worker 688 is 1.2029
INFO:root:FL Epoch: 479 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :164
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186556
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 164 is 1.320758
INFO:root:FL Epoch: 479 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1734
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.155006
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195349
INFO:root:FL Epoch: 479 Norm Difference for worker 1734 is 1.212767
INFO:root:FL Epoch: 479 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 0 2 9 7 6 5], which are global users: [1805, 1556, 396, 1734, 688, 492, 700]
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.467869560508167 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.08981107547879219                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [616, 1015, 305, 191, 1119, 1854, 1670, 983, 1569, 980]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :616
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808672
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255365
INFO:root:FL Epoch: 480 Norm Difference for worker 616 is 1.370733
INFO:root:FL Epoch: 480 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1015
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567265
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253425
INFO:root:FL Epoch: 480 Norm Difference for worker 1015 is 1.30049
INFO:root:FL Epoch: 480 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :305
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484843
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 305 is 1.200059
INFO:root:FL Epoch: 480 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :191
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300874
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 191 is 1.295737
INFO:root:FL Epoch: 480 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1119
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418547
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237604
INFO:root:FL Epoch: 480 Norm Difference for worker 1119 is 1.145732
INFO:root:FL Epoch: 480 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1854
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762730
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324561
INFO:root:FL Epoch: 480 Norm Difference for worker 1854 is 1.484796
INFO:root:FL Epoch: 480 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1670
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700544
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174559
INFO:root:FL Epoch: 480 Norm Difference for worker 1670 is 1.237677
INFO:root:FL Epoch: 480 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :983
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737761
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261585
INFO:root:FL Epoch: 480 Norm Difference for worker 983 is 1.406696
INFO:root:FL Epoch: 480 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1569
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557200
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200527
INFO:root:FL Epoch: 480 Norm Difference for worker 1569 is 1.364682
INFO:root:FL Epoch: 480 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :980
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558963
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217214
INFO:root:FL Epoch: 480 Norm Difference for worker 980 is 1.286622
INFO:root:FL Epoch: 480 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 201 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 201 201 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 9 1 0], which are global users: [1670, 1119, 305, 191, 980, 1015, 616]
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.47929198601666617 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.12589562187592188                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 561, 481, 321, 674, 79, 14, 483]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.124670
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.074206
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.09391984529793262 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.10004473999142646 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.157421
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.158043
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218102
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.08330425185461839 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.09727339819073677 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.166147
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.092639
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153114
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.08399179702003796 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.09922366105020046 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.158954
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :561
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421962
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364573
INFO:root:FL Epoch: 481 Norm Difference for worker 561 is 1.316471
INFO:root:FL Epoch: 481 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :481
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591555
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235877
INFO:root:FL Epoch: 481 Norm Difference for worker 481 is 1.223441
INFO:root:FL Epoch: 481 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :321
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 321 is 1.257378
INFO:root:FL Epoch: 481 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :674
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544585
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179103
INFO:root:FL Epoch: 481 Norm Difference for worker 674 is 1.046016
INFO:root:FL Epoch: 481 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :79
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347773
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 79 is 1.165849
INFO:root:FL Epoch: 481 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :14
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265700
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 14 is 1.077102
INFO:root:FL Epoch: 481 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :483
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249254
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211519
INFO:root:FL Epoch: 481 Norm Difference for worker 483 is 1.023287
INFO:root:FL Epoch: 481 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 201 200 201 201 200]
INFO:root:Num selected data points: [200 200 200 200 201 200 201]
INFO:root:The chosen ones are users: [1 0 2 9 7 6 8], which are global users: [1, 0, 2, 483, 79, 674, 14]
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.47533177978852215 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.09663580171763897                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [949, 863, 340, 58, 1181, 242, 1945, 1451, 1473, 477]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :949
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434967
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403163
INFO:root:FL Epoch: 482 Norm Difference for worker 949 is 1.414315
INFO:root:FL Epoch: 482 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :863
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715338
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370034
INFO:root:FL Epoch: 482 Norm Difference for worker 863 is 1.296314
INFO:root:FL Epoch: 482 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :340
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304053
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233790
INFO:root:FL Epoch: 482 Norm Difference for worker 340 is 1.344074
INFO:root:FL Epoch: 482 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :58
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424759
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 58 is 1.374889
INFO:root:FL Epoch: 482 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1181
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399589
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248919
INFO:root:FL Epoch: 482 Norm Difference for worker 1181 is 1.18877
INFO:root:FL Epoch: 482 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :242
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.346128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 242 is 1.272614
INFO:root:FL Epoch: 482 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1945
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482594
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138485
INFO:root:FL Epoch: 482 Norm Difference for worker 1945 is 1.103339
INFO:root:FL Epoch: 482 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1451
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693253
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194286
INFO:root:FL Epoch: 482 Norm Difference for worker 1451 is 1.268104
INFO:root:FL Epoch: 482 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1473
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507732
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347367
INFO:root:FL Epoch: 482 Norm Difference for worker 1473 is 1.448805
INFO:root:FL Epoch: 482 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :477
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475273
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267560
INFO:root:FL Epoch: 482 Norm Difference for worker 477 is 1.251468
INFO:root:FL Epoch: 482 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [6 4 9 7 2 5 1], which are global users: [1945, 1181, 477, 1451, 340, 242, 863]
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.4602178633213043 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.11784485603372256                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [849, 1204, 1327, 924, 1031, 409, 912, 401, 117, 1136]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 483 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :849
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745720
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272520
INFO:root:FL Epoch: 483 Norm Difference for worker 849 is 1.233984
INFO:root:FL Epoch: 483 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1204
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305655
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211688
INFO:root:FL Epoch: 483 Norm Difference for worker 1204 is 1.22789
INFO:root:FL Epoch: 483 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1327
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432513
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357678
INFO:root:FL Epoch: 483 Norm Difference for worker 1327 is 1.083108
INFO:root:FL Epoch: 483 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :924
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360276
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267370
INFO:root:FL Epoch: 483 Norm Difference for worker 924 is 1.16499
INFO:root:FL Epoch: 483 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1031
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371481
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325923
INFO:root:FL Epoch: 483 Norm Difference for worker 1031 is 1.321802
INFO:root:FL Epoch: 483 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :409
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808765
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375555
INFO:root:FL Epoch: 483 Norm Difference for worker 409 is 1.15132
INFO:root:FL Epoch: 483 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :912
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429370
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286206
INFO:root:FL Epoch: 483 Norm Difference for worker 912 is 1.112927
INFO:root:FL Epoch: 483 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :401
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300937
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404905
INFO:root:FL Epoch: 483 Norm Difference for worker 401 is 1.144742
INFO:root:FL Epoch: 483 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :117
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.294437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 117 is 1.139423
INFO:root:FL Epoch: 483 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1136
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830764
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283976
INFO:root:FL Epoch: 483 Norm Difference for worker 1136 is 1.257285
INFO:root:FL Epoch: 483 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 201 200 200 200 200 200]
INFO:root:The chosen ones are users: [5 8 2 6 7 3 1], which are global users: [409, 117, 1327, 912, 401, 924, 1204]
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.460998312515371 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.11557433630029361                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [528, 141, 406, 1149, 639, 932, 865, 1944, 1827, 1174]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 484 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :528
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.954474
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239238
INFO:root:FL Epoch: 484 Norm Difference for worker 528 is 1.316591
INFO:root:FL Epoch: 484 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :141
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.113302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 141 is 1.115523
INFO:root:FL Epoch: 484 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :406
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680017
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525221
INFO:root:FL Epoch: 484 Norm Difference for worker 406 is 1.290636
INFO:root:FL Epoch: 484 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1149
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444382
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316025
INFO:root:FL Epoch: 484 Norm Difference for worker 1149 is 1.256295
INFO:root:FL Epoch: 484 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :639
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318111
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214055
INFO:root:FL Epoch: 484 Norm Difference for worker 639 is 1.161662
INFO:root:FL Epoch: 484 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :932
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482809
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216119
INFO:root:FL Epoch: 484 Norm Difference for worker 932 is 1.308606
INFO:root:FL Epoch: 484 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :865
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454591
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192592
INFO:root:FL Epoch: 484 Norm Difference for worker 865 is 1.157247
INFO:root:FL Epoch: 484 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1944
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458697
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168499
INFO:root:FL Epoch: 484 Norm Difference for worker 1944 is 1.102917
INFO:root:FL Epoch: 484 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1827
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706695
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406503
INFO:root:FL Epoch: 484 Norm Difference for worker 1827 is 1.265086
INFO:root:FL Epoch: 484 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1174
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730495
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165382
INFO:root:FL Epoch: 484 Norm Difference for worker 1174 is 1.37956
INFO:root:FL Epoch: 484 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [1 7 6 4 8 2 3], which are global users: [141, 1944, 865, 639, 1827, 406, 1149]
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.44836503793211546 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.11983456586798032                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [496, 203, 42, 22, 915, 382, 62, 1040, 29, 779]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 485 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :496
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386098
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182240
INFO:root:FL Epoch: 485 Norm Difference for worker 496 is 1.1831
INFO:root:FL Epoch: 485 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :203
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415392
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 203 is 1.247126
INFO:root:FL Epoch: 485 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :42
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.304711
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 42 is 1.121343
INFO:root:FL Epoch: 485 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :22
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.168169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 22 is 1.280806
INFO:root:FL Epoch: 485 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :915
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523560
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393977
INFO:root:FL Epoch: 485 Norm Difference for worker 915 is 1.218447
INFO:root:FL Epoch: 485 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :382
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370470
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615049
INFO:root:FL Epoch: 485 Norm Difference for worker 382 is 1.210901
INFO:root:FL Epoch: 485 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :62
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302806
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 62 is 1.2106
INFO:root:FL Epoch: 485 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1040
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367970
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290086
INFO:root:FL Epoch: 485 Norm Difference for worker 1040 is 1.207865
INFO:root:FL Epoch: 485 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :29
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483436
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 29 is 1.293502
INFO:root:FL Epoch: 485 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :779
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407678
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277504
INFO:root:FL Epoch: 485 Norm Difference for worker 779 is 1.082104
INFO:root:FL Epoch: 485 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 201 201 200 200 201 200 201 200]
INFO:root:Num selected data points: [201 200 200 200 201 200 200]
INFO:root:The chosen ones are users: [2 9 0 7 6 5 4], which are global users: [42, 779, 496, 1040, 62, 382, 915]
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.4570331047562992 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.09643861961861451                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1637, 577, 971, 1234, 1712, 1120, 733, 1188, 1270, 393]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1637
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639879
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527756
INFO:root:FL Epoch: 486 Norm Difference for worker 1637 is 1.354823
INFO:root:FL Epoch: 486 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :577
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537597
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278544
INFO:root:FL Epoch: 486 Norm Difference for worker 577 is 1.344128
INFO:root:FL Epoch: 486 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :971
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556573
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270108
INFO:root:FL Epoch: 486 Norm Difference for worker 971 is 1.286254
INFO:root:FL Epoch: 486 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1234
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 1.060324
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227794
INFO:root:FL Epoch: 486 Norm Difference for worker 1234 is 1.316377
INFO:root:FL Epoch: 486 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1712
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477088
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261593
INFO:root:FL Epoch: 486 Norm Difference for worker 1712 is 1.169499
INFO:root:FL Epoch: 486 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1120
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800051
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245790
INFO:root:FL Epoch: 486 Norm Difference for worker 1120 is 1.277521
INFO:root:FL Epoch: 486 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :733
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681136
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207727
INFO:root:FL Epoch: 486 Norm Difference for worker 733 is 1.272289
INFO:root:FL Epoch: 486 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1188
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445202
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269340
INFO:root:FL Epoch: 486 Norm Difference for worker 1188 is 1.348657
INFO:root:FL Epoch: 486 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1270
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515394
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154680
INFO:root:FL Epoch: 486 Norm Difference for worker 1270 is 1.060129
INFO:root:FL Epoch: 486 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :393
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484938
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467648
INFO:root:FL Epoch: 486 Norm Difference for worker 393 is 1.325218
INFO:root:FL Epoch: 486 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 8 5 0], which are global users: [733, 1712, 971, 1234, 1270, 1120, 1637]
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.47653529223273783 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.12297897910078366                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1318, 1307, 1255, 86, 1583, 73, 1774, 1361, 1191, 72]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1318
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565648
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210450
INFO:root:FL Epoch: 487 Norm Difference for worker 1318 is 1.052303
INFO:root:FL Epoch: 487 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1307
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526388
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146834
INFO:root:FL Epoch: 487 Norm Difference for worker 1307 is 1.150396
INFO:root:FL Epoch: 487 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1255
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682795
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295222
INFO:root:FL Epoch: 487 Norm Difference for worker 1255 is 1.289205
INFO:root:FL Epoch: 487 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :86
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297396
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 86 is 1.083544
INFO:root:FL Epoch: 487 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1583
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471477
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291642
INFO:root:FL Epoch: 487 Norm Difference for worker 1583 is 1.178282
INFO:root:FL Epoch: 487 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :73
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404496
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 73 is 1.114365
INFO:root:FL Epoch: 487 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1774
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440877
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445960
INFO:root:FL Epoch: 487 Norm Difference for worker 1774 is 1.068468
INFO:root:FL Epoch: 487 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1361
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409017
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346294
INFO:root:FL Epoch: 487 Norm Difference for worker 1361 is 1.184621
INFO:root:FL Epoch: 487 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1191
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578243
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318805
INFO:root:FL Epoch: 487 Norm Difference for worker 1191 is 1.157741
INFO:root:FL Epoch: 487 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :72
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.339584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214398
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 72 is 1.108166
INFO:root:FL Epoch: 487 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 201 200 201 200 200 200 201]
INFO:root:Num selected data points: [201 200 200 201 201 200 200]
INFO:root:The chosen ones are users: [5 0 6 3 9 8 1], which are global users: [73, 1318, 1774, 86, 72, 1191, 1307]
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.45919108741423664 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.10619444275895755                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [1497, 860, 1140, 427, 1056, 1259, 134, 1401, 937, 1377]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 488 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :1497
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462252
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325411
INFO:root:FL Epoch: 488 Norm Difference for worker 1497 is 1.123373
INFO:root:FL Epoch: 488 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :860
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889907
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400112
INFO:root:FL Epoch: 488 Norm Difference for worker 860 is 1.261644
INFO:root:FL Epoch: 488 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1140
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.202259
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241694
INFO:root:FL Epoch: 488 Norm Difference for worker 1140 is 1.144591
INFO:root:FL Epoch: 488 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :427
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453868
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262574
INFO:root:FL Epoch: 488 Norm Difference for worker 427 is 1.14198
INFO:root:FL Epoch: 488 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1056
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461110
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.117968
INFO:root:FL Epoch: 488 Norm Difference for worker 1056 is 1.154638
INFO:root:FL Epoch: 488 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1259
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403896
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429191
INFO:root:FL Epoch: 488 Norm Difference for worker 1259 is 1.229959
INFO:root:FL Epoch: 488 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :134
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.331538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.145376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 134 is 1.085607
INFO:root:FL Epoch: 488 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1401
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492509
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253323
INFO:root:FL Epoch: 488 Norm Difference for worker 1401 is 1.280411
INFO:root:FL Epoch: 488 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :937
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535131
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204597
INFO:root:FL Epoch: 488 Norm Difference for worker 937 is 1.138421
INFO:root:FL Epoch: 488 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1377
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546844
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386083
INFO:root:FL Epoch: 488 Norm Difference for worker 1377 is 1.235184
INFO:root:FL Epoch: 488 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 4 2 3 8 0 5], which are global users: [134, 1056, 1140, 427, 937, 1497, 1259]
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.45184920114629407 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.09520854863027732                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [858, 1611, 442, 1751, 1626, 1430, 557, 6, 1406, 1934]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :858
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550908
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139496
INFO:root:FL Epoch: 489 Norm Difference for worker 858 is 1.222846
INFO:root:FL Epoch: 489 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1611
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323076
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206480
INFO:root:FL Epoch: 489 Norm Difference for worker 1611 is 1.168198
INFO:root:FL Epoch: 489 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :442
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509414
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308817
INFO:root:FL Epoch: 489 Norm Difference for worker 442 is 1.84485
INFO:root:FL Epoch: 489 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1751
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595560
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274339
INFO:root:FL Epoch: 489 Norm Difference for worker 1751 is 1.356909
INFO:root:FL Epoch: 489 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1626
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588808
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341832
INFO:root:FL Epoch: 489 Norm Difference for worker 1626 is 1.394704
INFO:root:FL Epoch: 489 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1430
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482845
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406007
INFO:root:FL Epoch: 489 Norm Difference for worker 1430 is 1.26813
INFO:root:FL Epoch: 489 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :557
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246867
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431733
INFO:root:FL Epoch: 489 Norm Difference for worker 557 is 1.276262
INFO:root:FL Epoch: 489 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :6
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431978
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.120044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 6 is 1.076293
INFO:root:FL Epoch: 489 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1406
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485332
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378065
INFO:root:FL Epoch: 489 Norm Difference for worker 1406 is 1.121992
INFO:root:FL Epoch: 489 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1934
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551918
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178193
INFO:root:FL Epoch: 489 Norm Difference for worker 1934 is 1.270016
INFO:root:FL Epoch: 489 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [6 0 8 7 1 5 9], which are global users: [557, 858, 1406, 6, 1611, 1430, 1934]
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.467420393929762 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.09389721664289634                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [406, 1256, 1544, 894, 738, 923, 1701, 1105, 182, 95]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 490 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :406
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289375
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277038
INFO:root:FL Epoch: 490 Norm Difference for worker 406 is 1.215018
INFO:root:FL Epoch: 490 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1256
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297866
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229041
INFO:root:FL Epoch: 490 Norm Difference for worker 1256 is 1.042726
INFO:root:FL Epoch: 490 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1544
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593145
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238879
INFO:root:FL Epoch: 490 Norm Difference for worker 1544 is 1.32908
INFO:root:FL Epoch: 490 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :894
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356872
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247759
INFO:root:FL Epoch: 490 Norm Difference for worker 894 is 1.087762
INFO:root:FL Epoch: 490 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :738
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619365
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233007
INFO:root:FL Epoch: 490 Norm Difference for worker 738 is 1.074078
INFO:root:FL Epoch: 490 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :923
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621925
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277942
INFO:root:FL Epoch: 490 Norm Difference for worker 923 is 1.292882
INFO:root:FL Epoch: 490 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1701
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460515
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434168
INFO:root:FL Epoch: 490 Norm Difference for worker 1701 is 1.231024
INFO:root:FL Epoch: 490 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1105
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476032
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205523
INFO:root:FL Epoch: 490 Norm Difference for worker 1105 is 1.133576
INFO:root:FL Epoch: 490 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :182
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 182 is 1.254032
INFO:root:FL Epoch: 490 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :95
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435733
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 95 is 1.233285
INFO:root:FL Epoch: 490 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 201]
INFO:root:Num selected data points: [200 200 200 200 200 201 201]
INFO:root:The chosen ones are users: [1 4 7 3 0 8 9], which are global users: [1256, 738, 1105, 894, 406, 182, 95]
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.4603885622585521 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.10434781139095624                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 1088, 523, 382, 1677, 98, 89, 290]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.172417
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123420
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.07688910079499085 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.08551217541098595 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.130094
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.090426
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141429
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.07884645151595275 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.0849154032766819 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.13388
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.133498
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.081946
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.08028303645551205 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.08495029471814633 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.134107
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1088
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415055
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192537
INFO:root:FL Epoch: 491 Norm Difference for worker 1088 is 1.136212
INFO:root:FL Epoch: 491 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :523
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817548
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369954
INFO:root:FL Epoch: 491 Norm Difference for worker 523 is 1.343791
INFO:root:FL Epoch: 491 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :382
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425978
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400114
INFO:root:FL Epoch: 491 Norm Difference for worker 382 is 1.320532
INFO:root:FL Epoch: 491 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1677
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694781
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417828
INFO:root:FL Epoch: 491 Norm Difference for worker 1677 is 1.324044
INFO:root:FL Epoch: 491 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :98
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.195979
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 98 is 1.189388
INFO:root:FL Epoch: 491 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :89
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 89 is 1.235386
INFO:root:FL Epoch: 491 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :290
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 290 is 1.241984
INFO:root:FL Epoch: 491 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 201 201 201]
INFO:root:Num selected data points: [201 200 200 200 200 201 201]
INFO:root:The chosen ones are users: [7 0 2 3 1 8 9], which are global users: [98, 0, 2, 1088, 1, 89, 290]
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.4580339070628671 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.09705236926674843                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [331, 1080, 1356, 698, 1944, 796, 259, 384, 392, 19]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 492 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :331
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.820398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 331 is 1.390833
INFO:root:FL Epoch: 492 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1080
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448587
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175325
INFO:root:FL Epoch: 492 Norm Difference for worker 1080 is 1.3179
INFO:root:FL Epoch: 492 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1356
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 1.222106
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406903
INFO:root:FL Epoch: 492 Norm Difference for worker 1356 is 1.439942
INFO:root:FL Epoch: 492 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :698
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.932931
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320015
INFO:root:FL Epoch: 492 Norm Difference for worker 698 is 1.38531
INFO:root:FL Epoch: 492 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1944
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330945
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156232
INFO:root:FL Epoch: 492 Norm Difference for worker 1944 is 1.062944
INFO:root:FL Epoch: 492 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :796
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340969
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150104
INFO:root:FL Epoch: 492 Norm Difference for worker 796 is 1.175247
INFO:root:FL Epoch: 492 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :259
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.200004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444445
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 259 is 1.299409
INFO:root:FL Epoch: 492 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :384
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493876
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291621
INFO:root:FL Epoch: 492 Norm Difference for worker 384 is 1.309089
INFO:root:FL Epoch: 492 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :392
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211027
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.105839
INFO:root:FL Epoch: 492 Norm Difference for worker 392 is 1.160187
INFO:root:FL Epoch: 492 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :19
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.755465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 19 is 1.335832
INFO:root:FL Epoch: 492 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 201 200 200 201]
INFO:root:Num selected data points: [201 200 200 200 200 200 201]
INFO:root:The chosen ones are users: [6 4 8 7 1 5 9], which are global users: [259, 1944, 392, 384, 1080, 796, 19]
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.44560199099428516 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.10584444490571816                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [1392, 707, 927, 1825, 923, 1449, 169, 1319, 496, 681]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :1392
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529890
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294849
INFO:root:FL Epoch: 493 Norm Difference for worker 1392 is 1.272516
INFO:root:FL Epoch: 493 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :707
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 1.138390
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165973
INFO:root:FL Epoch: 493 Norm Difference for worker 707 is 1.212623
INFO:root:FL Epoch: 493 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :927
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420398
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223962
INFO:root:FL Epoch: 493 Norm Difference for worker 927 is 1.051597
INFO:root:FL Epoch: 493 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1825
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309618
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367447
INFO:root:FL Epoch: 493 Norm Difference for worker 1825 is 1.173584
INFO:root:FL Epoch: 493 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :923
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435362
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374116
INFO:root:FL Epoch: 493 Norm Difference for worker 923 is 1.374151
INFO:root:FL Epoch: 493 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1449
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883790
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.132268
INFO:root:FL Epoch: 493 Norm Difference for worker 1449 is 1.337947
INFO:root:FL Epoch: 493 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :169
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.210026
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 169 is 1.119737
INFO:root:FL Epoch: 493 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1319
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492270
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291443
INFO:root:FL Epoch: 493 Norm Difference for worker 1319 is 1.281655
INFO:root:FL Epoch: 493 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :496
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206495
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252218
INFO:root:FL Epoch: 493 Norm Difference for worker 496 is 1.020147
INFO:root:FL Epoch: 493 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :681
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518434
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203454
INFO:root:FL Epoch: 493 Norm Difference for worker 681 is 1.24952
INFO:root:FL Epoch: 493 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 201 200 200 200]
INFO:root:Num selected data points: [201 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 0 2 3 1 8 9], which are global users: [169, 1392, 927, 1825, 707, 496, 681]
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.44136913909631614 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.09822906305392583                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [999, 311, 1767, 1021, 1187, 1460, 822, 1804, 711, 228]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 494 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :999
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599859
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363618
INFO:root:FL Epoch: 494 Norm Difference for worker 999 is 1.185109
INFO:root:FL Epoch: 494 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :311
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311843
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 311 is 1.176872
INFO:root:FL Epoch: 494 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1767
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437426
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259226
INFO:root:FL Epoch: 494 Norm Difference for worker 1767 is 1.125384
INFO:root:FL Epoch: 494 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1021
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341103
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208528
INFO:root:FL Epoch: 494 Norm Difference for worker 1021 is 1.105981
INFO:root:FL Epoch: 494 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1187
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503624
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348396
INFO:root:FL Epoch: 494 Norm Difference for worker 1187 is 1.152707
INFO:root:FL Epoch: 494 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1460
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693190
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255215
INFO:root:FL Epoch: 494 Norm Difference for worker 1460 is 1.11927
INFO:root:FL Epoch: 494 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :822
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514159
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178661
INFO:root:FL Epoch: 494 Norm Difference for worker 822 is 1.246693
INFO:root:FL Epoch: 494 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1804
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517458
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429927
INFO:root:FL Epoch: 494 Norm Difference for worker 1804 is 1.287327
INFO:root:FL Epoch: 494 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :711
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327579
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349305
INFO:root:FL Epoch: 494 Norm Difference for worker 711 is 1.156368
INFO:root:FL Epoch: 494 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :228
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.270192
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 228 is 1.139916
INFO:root:FL Epoch: 494 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 200 200 200 200 201]
INFO:root:Num selected data points: [200 201 200 200 200 201 200]
INFO:root:The chosen ones are users: [3 9 2 4 8 1 5], which are global users: [1021, 228, 1767, 1187, 711, 311, 1460]
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.45731693856856404 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.10460676749547322                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [780, 63, 1298, 1777, 1947, 227, 1603, 1502, 1894, 1344]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 495 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :780
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507817
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304039
INFO:root:FL Epoch: 495 Norm Difference for worker 780 is 1.084267
INFO:root:FL Epoch: 495 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :63
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 63 is 1.36928
INFO:root:FL Epoch: 495 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1298
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537631
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258750
INFO:root:FL Epoch: 495 Norm Difference for worker 1298 is 1.150595
INFO:root:FL Epoch: 495 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1777
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212583
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290024
INFO:root:FL Epoch: 495 Norm Difference for worker 1777 is 1.383512
INFO:root:FL Epoch: 495 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1947
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511962
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373064
INFO:root:FL Epoch: 495 Norm Difference for worker 1947 is 1.037855
INFO:root:FL Epoch: 495 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :227
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 227 is 1.186359
INFO:root:FL Epoch: 495 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1603
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466447
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220302
INFO:root:FL Epoch: 495 Norm Difference for worker 1603 is 1.216336
INFO:root:FL Epoch: 495 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1502
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444691
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281503
INFO:root:FL Epoch: 495 Norm Difference for worker 1502 is 1.211496
INFO:root:FL Epoch: 495 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1894
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634960
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242420
INFO:root:FL Epoch: 495 Norm Difference for worker 1894 is 1.266832
INFO:root:FL Epoch: 495 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1344
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352043
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314650
INFO:root:FL Epoch: 495 Norm Difference for worker 1344 is 1.286571
INFO:root:FL Epoch: 495 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 201 200 200 200]
INFO:root:The chosen ones are users: [4 0 2 5 7 6 8], which are global users: [1947, 780, 1298, 227, 1502, 1603, 1894]
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.4492350448580349 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.12246831382314365                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [83, 593, 676, 1241, 405, 1473, 912, 335, 726, 15]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 496 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :83
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557449
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 83 is 1.367425
INFO:root:FL Epoch: 496 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :593
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761997
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304475
INFO:root:FL Epoch: 496 Norm Difference for worker 593 is 1.301732
INFO:root:FL Epoch: 496 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :676
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429689
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253025
INFO:root:FL Epoch: 496 Norm Difference for worker 676 is 1.302542
INFO:root:FL Epoch: 496 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1241
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563877
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387410
INFO:root:FL Epoch: 496 Norm Difference for worker 1241 is 1.254061
INFO:root:FL Epoch: 496 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :405
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463031
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122281
INFO:root:FL Epoch: 496 Norm Difference for worker 405 is 1.203232
INFO:root:FL Epoch: 496 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1473
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561691
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424319
INFO:root:FL Epoch: 496 Norm Difference for worker 1473 is 1.387954
INFO:root:FL Epoch: 496 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :912
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263751
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295682
INFO:root:FL Epoch: 496 Norm Difference for worker 912 is 1.097819
INFO:root:FL Epoch: 496 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :335
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 335 is 1.293391
INFO:root:FL Epoch: 496 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :726
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349705
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.100744
INFO:root:FL Epoch: 496 Norm Difference for worker 726 is 1.193163
INFO:root:FL Epoch: 496 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :15
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451744
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 15 is 1.196736
INFO:root:FL Epoch: 496 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [201 200 200 200 200 200 200 201 200 201]
INFO:root:Num selected data points: [200 201 200 200 201 200 200]
INFO:root:The chosen ones are users: [6 9 8 4 7 3 1], which are global users: [912, 15, 726, 405, 335, 1241, 593]
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.4443061369306901 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.13769220312436423                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [733, 220, 907, 1530, 605, 307, 873, 1496, 391, 607]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 497 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :733
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244099
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379871
INFO:root:FL Epoch: 497 Norm Difference for worker 733 is 1.167215
INFO:root:FL Epoch: 497 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :220
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 220 is 1.251361
INFO:root:FL Epoch: 497 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :907
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316343
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343310
INFO:root:FL Epoch: 497 Norm Difference for worker 907 is 1.237614
INFO:root:FL Epoch: 497 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1530
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969378
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297162
INFO:root:FL Epoch: 497 Norm Difference for worker 1530 is 1.301673
INFO:root:FL Epoch: 497 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :605
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679840
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248367
INFO:root:FL Epoch: 497 Norm Difference for worker 605 is 1.201391
INFO:root:FL Epoch: 497 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :307
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 307 is 1.250069
INFO:root:FL Epoch: 497 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :873
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299159
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342405
INFO:root:FL Epoch: 497 Norm Difference for worker 873 is 1.243497
INFO:root:FL Epoch: 497 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1496
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306097
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375899
INFO:root:FL Epoch: 497 Norm Difference for worker 1496 is 1.123285
INFO:root:FL Epoch: 497 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :391
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705231
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391417
INFO:root:FL Epoch: 497 Norm Difference for worker 391 is 1.336602
INFO:root:FL Epoch: 497 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :607
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496072
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247226
INFO:root:FL Epoch: 497 Norm Difference for worker 607 is 1.171525
INFO:root:FL Epoch: 497 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 201 200 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 0 9 6 4 1 2], which are global users: [1496, 733, 607, 873, 605, 220, 907]
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.4645146131515503 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.16696763038635254                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [1400, 441, 67, 585, 632, 280, 890, 1637, 897, 1319]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :1400
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304434
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352223
INFO:root:FL Epoch: 498 Norm Difference for worker 1400 is 1.17502
INFO:root:FL Epoch: 498 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :441
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.972326
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263167
INFO:root:FL Epoch: 498 Norm Difference for worker 441 is 1.317812
INFO:root:FL Epoch: 498 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :67
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381703
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 67 is 1.134354
INFO:root:FL Epoch: 498 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :585
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558975
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397445
INFO:root:FL Epoch: 498 Norm Difference for worker 585 is 1.186319
INFO:root:FL Epoch: 498 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :632
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449371
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410055
INFO:root:FL Epoch: 498 Norm Difference for worker 632 is 1.172759
INFO:root:FL Epoch: 498 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :280
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.328371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 280 is 1.138342
INFO:root:FL Epoch: 498 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :890
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617769
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243000
INFO:root:FL Epoch: 498 Norm Difference for worker 890 is 1.202531
INFO:root:FL Epoch: 498 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1637
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578850
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264038
INFO:root:FL Epoch: 498 Norm Difference for worker 1637 is 1.276332
INFO:root:FL Epoch: 498 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :897
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611552
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348467
INFO:root:FL Epoch: 498 Norm Difference for worker 897 is 1.275539
INFO:root:FL Epoch: 498 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1319
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336332
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198082
INFO:root:FL Epoch: 498 Norm Difference for worker 1319 is 1.239024
INFO:root:FL Epoch: 498 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 201 200 200 201 200 200 200 200]
INFO:root:Num selected data points: [201 200 201 200 200 200 200]
INFO:root:The chosen ones are users: [5 0 2 4 3 6 9], which are global users: [280, 1400, 67, 632, 585, 890, 1319]
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.44348671331125145 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.13193797320127487                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1014, 1779, 1466, 1440, 1234, 808, 479, 1215, 188, 1752]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1014
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641887
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375153
INFO:root:FL Epoch: 499 Norm Difference for worker 1014 is 1.265451
INFO:root:FL Epoch: 499 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1779
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336639
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261489
INFO:root:FL Epoch: 499 Norm Difference for worker 1779 is 1.149134
INFO:root:FL Epoch: 499 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1466
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406616
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491448
INFO:root:FL Epoch: 499 Norm Difference for worker 1466 is 1.157926
INFO:root:FL Epoch: 499 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1440
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661590
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361563
INFO:root:FL Epoch: 499 Norm Difference for worker 1440 is 1.186377
INFO:root:FL Epoch: 499 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1234
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516352
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176095
INFO:root:FL Epoch: 499 Norm Difference for worker 1234 is 1.130438
INFO:root:FL Epoch: 499 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :808
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635130
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321368
INFO:root:FL Epoch: 499 Norm Difference for worker 808 is 1.220476
INFO:root:FL Epoch: 499 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :479
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502416
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448387
INFO:root:FL Epoch: 499 Norm Difference for worker 479 is 1.294137
INFO:root:FL Epoch: 499 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1215
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849432
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383504
INFO:root:FL Epoch: 499 Norm Difference for worker 1215 is 1.145799
INFO:root:FL Epoch: 499 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :188
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 188 is 1.048946
INFO:root:FL Epoch: 499 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1752
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448410
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217413
INFO:root:FL Epoch: 499 Norm Difference for worker 1752 is 1.201723
INFO:root:FL Epoch: 499 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 201 200]
INFO:root:Num selected data points: [200 200 200 200 200 201 200]
INFO:root:The chosen ones are users: [7 4 2 3 1 8 9], which are global users: [1215, 1234, 1466, 1440, 1779, 188, 1752]
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.44418029925402475 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.12777816007534662                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [465, 1676, 1137, 1286, 1292, 469, 679, 551, 1025, 1649]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :465
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254183
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416330
INFO:root:FL Epoch: 500 Norm Difference for worker 465 is 1.227501
INFO:root:FL Epoch: 500 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1676
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381910
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274537
INFO:root:FL Epoch: 500 Norm Difference for worker 1676 is 1.316339
INFO:root:FL Epoch: 500 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1137
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516399
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560422
INFO:root:FL Epoch: 500 Norm Difference for worker 1137 is 1.373529
INFO:root:FL Epoch: 500 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1286
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460264
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223200
INFO:root:FL Epoch: 500 Norm Difference for worker 1286 is 1.27056
INFO:root:FL Epoch: 500 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1292
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568716
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195196
INFO:root:FL Epoch: 500 Norm Difference for worker 1292 is 1.290651
INFO:root:FL Epoch: 500 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :469
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242517
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183551
INFO:root:FL Epoch: 500 Norm Difference for worker 469 is 1.096458
INFO:root:FL Epoch: 500 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :679
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.234447
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279162
INFO:root:FL Epoch: 500 Norm Difference for worker 679 is 1.171558
INFO:root:FL Epoch: 500 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :551
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412989
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145267
INFO:root:FL Epoch: 500 Norm Difference for worker 551 is 1.167514
INFO:root:FL Epoch: 500 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1025
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513893
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338937
INFO:root:FL Epoch: 500 Norm Difference for worker 1025 is 1.196054
INFO:root:FL Epoch: 500 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1649
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575711
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273234
INFO:root:FL Epoch: 500 Norm Difference for worker 1649 is 1.183642
INFO:root:FL Epoch: 500 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Num data points: [200 200 200 200 200 200 200 200 200 200]
INFO:root:Num selected data points: [200 200 200 200 200 200 200]
INFO:root:The chosen ones are users: [6 9 8 3 7 5 0], which are global users: [679, 1649, 1025, 1286, 551, 469, 465]
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.4584430158138275 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.14586172749598822                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/report/1b/stats.csv ******
