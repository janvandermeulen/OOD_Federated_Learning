INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [595, 500, 859, 383, 1838, 1939, 1125, 353, 1260, 1834]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :595
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688655
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678628
INFO:root:FL Epoch: 1 Norm Difference for worker 595 is 0.309219
INFO:root:FL Epoch: 1 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :500
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687979
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695450
INFO:root:FL Epoch: 1 Norm Difference for worker 500 is 0.312871
INFO:root:FL Epoch: 1 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :859
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688206
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692797
INFO:root:FL Epoch: 1 Norm Difference for worker 859 is 0.339252
INFO:root:FL Epoch: 1 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :383
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695146
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691239
INFO:root:FL Epoch: 1 Norm Difference for worker 383 is 0.294267
INFO:root:FL Epoch: 1 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1838
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693395
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685373
INFO:root:FL Epoch: 1 Norm Difference for worker 1838 is 0.288625
INFO:root:FL Epoch: 1 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1939
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689367
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690727
INFO:root:FL Epoch: 1 Norm Difference for worker 1939 is 0.282308
INFO:root:FL Epoch: 1 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1125
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693816
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691197
INFO:root:FL Epoch: 1 Norm Difference for worker 1125 is 0.309659
INFO:root:FL Epoch: 1 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :353
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698617
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688889
INFO:root:FL Epoch: 1 Norm Difference for worker 353 is 0.281798
INFO:root:FL Epoch: 1 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1260
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694889
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697892
INFO:root:FL Epoch: 1 Norm Difference for worker 1260 is 0.342221
INFO:root:FL Epoch: 1 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1834
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689608
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693329
INFO:root:FL Epoch: 1 Norm Difference for worker 1834 is 0.292841
INFO:root:FL Epoch: 1 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.2792493916864265, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.2791191780864857
INFO:root:#### Oracle Cals: 3, Objective Val: 0.2791168824960179
INFO:root:#### Oracle Cals: 4, Objective Val: 0.27911675310979334
INFO:root:#### Oracle Cals: 5, Objective Val: 0.27911675086424137
INFO:root:Aggregating After Defense
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.689855719313902 and Test Accuracy:58.23529411764706 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6985084215799967                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1016
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690537
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672649
INFO:root:FL Epoch: 2 Norm Difference for worker 1016 is 0.401151
INFO:root:FL Epoch: 2 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :543
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695043
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675524
INFO:root:FL Epoch: 2 Norm Difference for worker 543 is 0.334771
INFO:root:FL Epoch: 2 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1103
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693313
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692799
INFO:root:FL Epoch: 2 Norm Difference for worker 1103 is 0.286856
INFO:root:FL Epoch: 2 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1820
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693212
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689014
INFO:root:FL Epoch: 2 Norm Difference for worker 1820 is 0.308909
INFO:root:FL Epoch: 2 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :768
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691156
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669267
INFO:root:FL Epoch: 2 Norm Difference for worker 768 is 0.369202
INFO:root:FL Epoch: 2 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1316
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686002
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695165
INFO:root:FL Epoch: 2 Norm Difference for worker 1316 is 0.283315
INFO:root:FL Epoch: 2 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697367
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700590
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.370279
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :276
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697181
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 276 is 0.313678
INFO:root:FL Epoch: 2 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :207
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693808
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 207 is 0.299959
INFO:root:FL Epoch: 2 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :159
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 159 is 0.302264
INFO:root:FL Epoch: 2 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.29406932071730224, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.29391998270225206
INFO:root:#### Oracle Cals: 3, Objective Val: 0.2939177336652202
INFO:root:#### Oracle Cals: 4, Objective Val: 0.293917633795614
INFO:root:#### Oracle Cals: 5, Objective Val: 0.29391762484915196
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6882094881113838 and Test Accuracy:54.705882352941174 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.6685447792212168                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 3 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :263
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702104
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 263 is 0.315264
INFO:root:FL Epoch: 3 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1554
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693727
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671711
INFO:root:FL Epoch: 3 Norm Difference for worker 1554 is 0.474043
INFO:root:FL Epoch: 3 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1266
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698282
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695114
INFO:root:FL Epoch: 3 Norm Difference for worker 1266 is 0.28073
INFO:root:FL Epoch: 3 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :982
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694334
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684141
INFO:root:FL Epoch: 3 Norm Difference for worker 982 is 0.323408
INFO:root:FL Epoch: 3 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700211
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664572
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.322759
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :475
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703420
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686119
INFO:root:FL Epoch: 3 Norm Difference for worker 475 is 0.316551
INFO:root:FL Epoch: 3 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1357
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683670
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668075
INFO:root:FL Epoch: 3 Norm Difference for worker 1357 is 0.309285
INFO:root:FL Epoch: 3 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :684
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690124
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685159
INFO:root:FL Epoch: 3 Norm Difference for worker 684 is 0.316183
INFO:root:FL Epoch: 3 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1506
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679959
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697303
INFO:root:FL Epoch: 3 Norm Difference for worker 1506 is 0.325087
INFO:root:FL Epoch: 3 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1238
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695293
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681565
INFO:root:FL Epoch: 3 Norm Difference for worker 1238 is 0.314996
INFO:root:FL Epoch: 3 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.29576382100261145, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.29514278276714595
INFO:root:#### Oracle Cals: 3, Objective Val: 0.2951318585963792
INFO:root:#### Oracle Cals: 4, Objective Val: 0.2951315148571938
INFO:root:#### Oracle Cals: 5, Objective Val: 0.2951316976708671
INFO:root:#### Oracle Cals: 6, Objective Val: 0.29513162196659115
INFO:root:#### Oracle Cals: 7, Objective Val: 0.2951315155295564
INFO:root:#### Oracle Cals: 8, Objective Val: 0.29513158837637504
INFO:root:#### Oracle Cals: 9, Objective Val: 0.2951316670294293
INFO:root:#### Oracle Cals: 10, Objective Val: 0.2951316108869295
INFO:root:#### Oracle Cals: 11, Objective Val: 0.29513150431663604
INFO:root:#### Oracle Cals: 12, Objective Val: 0.295131543073538
INFO:root:#### Oracle Cals: 13, Objective Val: 0.2951315540409555
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6849225899752449 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.6882846355438232                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :979
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686827
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716666
INFO:root:FL Epoch: 4 Norm Difference for worker 979 is 0.346787
INFO:root:FL Epoch: 4 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :915
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686496
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685953
INFO:root:FL Epoch: 4 Norm Difference for worker 915 is 0.450169
INFO:root:FL Epoch: 4 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1324
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710347
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710337
INFO:root:FL Epoch: 4 Norm Difference for worker 1324 is 0.339585
INFO:root:FL Epoch: 4 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1034
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683074
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678367
INFO:root:FL Epoch: 4 Norm Difference for worker 1034 is 0.377498
INFO:root:FL Epoch: 4 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :360
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670929
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679272
INFO:root:FL Epoch: 4 Norm Difference for worker 360 is 0.388931
INFO:root:FL Epoch: 4 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1751
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687088
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683596
INFO:root:FL Epoch: 4 Norm Difference for worker 1751 is 0.321581
INFO:root:FL Epoch: 4 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1025
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678253
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679607
INFO:root:FL Epoch: 4 Norm Difference for worker 1025 is 0.32298
INFO:root:FL Epoch: 4 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :153
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677098
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.711971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 153 is 0.42947
INFO:root:FL Epoch: 4 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1482
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677382
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682513
INFO:root:FL Epoch: 4 Norm Difference for worker 1482 is 0.356592
INFO:root:FL Epoch: 4 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :274
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 274 is 0.327989
INFO:root:FL Epoch: 4 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.32915173535320347, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.3289486594444811
INFO:root:#### Oracle Cals: 3, Objective Val: 0.328947054490239
INFO:root:#### Oracle Cals: 4, Objective Val: 0.32894688934093014
INFO:root:#### Oracle Cals: 5, Objective Val: 0.3289469440002812
INFO:root:#### Oracle Cals: 6, Objective Val: 0.328946888942257
INFO:root:#### Oracle Cals: 7, Objective Val: 0.32894703310494966
INFO:root:#### Oracle Cals: 8, Objective Val: 0.3289471423207671
INFO:root:#### Oracle Cals: 9, Objective Val: 0.3289468866476274
INFO:root:#### Oracle Cals: 10, Objective Val: 0.32894688893545343
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6830138143371133 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.6606027781963348                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 5 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :786
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674787
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683408
INFO:root:FL Epoch: 5 Norm Difference for worker 786 is 0.358231
INFO:root:FL Epoch: 5 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :115
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654445
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 115 is 0.401438
INFO:root:FL Epoch: 5 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :329
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682995
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 329 is 0.367236
INFO:root:FL Epoch: 5 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :440
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663024
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682958
INFO:root:FL Epoch: 5 Norm Difference for worker 440 is 0.343309
INFO:root:FL Epoch: 5 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1220
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677026
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685048
INFO:root:FL Epoch: 5 Norm Difference for worker 1220 is 0.351797
INFO:root:FL Epoch: 5 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :622
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667794
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674601
INFO:root:FL Epoch: 5 Norm Difference for worker 622 is 0.469444
INFO:root:FL Epoch: 5 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1865
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688827
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688716
INFO:root:FL Epoch: 5 Norm Difference for worker 1865 is 0.386898
INFO:root:FL Epoch: 5 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1868
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730536
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680581
INFO:root:FL Epoch: 5 Norm Difference for worker 1868 is 0.414421
INFO:root:FL Epoch: 5 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1776
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658527
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645339
INFO:root:FL Epoch: 5 Norm Difference for worker 1776 is 0.379128
INFO:root:FL Epoch: 5 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1316
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695847
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663907
INFO:root:FL Epoch: 5 Norm Difference for worker 1316 is 0.34452
INFO:root:FL Epoch: 5 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.34419486990280157, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.3440101343252383
INFO:root:#### Oracle Cals: 3, Objective Val: 0.3440087450974754
INFO:root:#### Oracle Cals: 4, Objective Val: 0.3440085719771905
INFO:root:#### Oracle Cals: 5, Objective Val: 0.3440084649598302
INFO:root:#### Oracle Cals: 6, Objective Val: 0.34400843010460813
INFO:root:#### Oracle Cals: 7, Objective Val: 0.34400846493793624
INFO:root:#### Oracle Cals: 8, Objective Val: 0.34400844534699865
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6793361902236938 and Test Accuracy:58.23529411764706 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.6788946986198425                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 6 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :1197
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654267
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628632
INFO:root:FL Epoch: 6 Norm Difference for worker 1197 is 0.571989
INFO:root:FL Epoch: 6 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1507
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667471
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686894
INFO:root:FL Epoch: 6 Norm Difference for worker 1507 is 0.496116
INFO:root:FL Epoch: 6 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1435
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674580
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681459
INFO:root:FL Epoch: 6 Norm Difference for worker 1435 is 0.410766
INFO:root:FL Epoch: 6 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1040
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665917
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686582
INFO:root:FL Epoch: 6 Norm Difference for worker 1040 is 0.40561
INFO:root:FL Epoch: 6 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1420
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683865
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628996
INFO:root:FL Epoch: 6 Norm Difference for worker 1420 is 0.576087
INFO:root:FL Epoch: 6 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :361
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713416
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663893
INFO:root:FL Epoch: 6 Norm Difference for worker 361 is 0.409197
INFO:root:FL Epoch: 6 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1002
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655191
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656377
INFO:root:FL Epoch: 6 Norm Difference for worker 1002 is 0.476325
INFO:root:FL Epoch: 6 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :327
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 327 is 0.408356
INFO:root:FL Epoch: 6 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :674
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681523
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676346
INFO:root:FL Epoch: 6 Norm Difference for worker 674 is 0.507437
INFO:root:FL Epoch: 6 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1021
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664745
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674268
INFO:root:FL Epoch: 6 Norm Difference for worker 1021 is 0.465304
INFO:root:FL Epoch: 6 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.4202451130573487, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.41980956263282204
INFO:root:#### Oracle Cals: 3, Objective Val: 0.41980545417312476
INFO:root:#### Oracle Cals: 4, Objective Val: 0.4198052894688985
INFO:root:#### Oracle Cals: 5, Objective Val: 0.4198052802431943
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6748246164882884 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7534851133823395                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 7 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :1809
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688747
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713325
INFO:root:FL Epoch: 7 Norm Difference for worker 1809 is 0.434799
INFO:root:FL Epoch: 7 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :835
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671367
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687279
INFO:root:FL Epoch: 7 Norm Difference for worker 835 is 0.458059
INFO:root:FL Epoch: 7 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :972
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704894
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642390
INFO:root:FL Epoch: 7 Norm Difference for worker 972 is 0.491689
INFO:root:FL Epoch: 7 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1512
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741600
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658657
INFO:root:FL Epoch: 7 Norm Difference for worker 1512 is 0.458037
INFO:root:FL Epoch: 7 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1161
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657643
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667137
INFO:root:FL Epoch: 7 Norm Difference for worker 1161 is 0.444269
INFO:root:FL Epoch: 7 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1280
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676945
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644147
INFO:root:FL Epoch: 7 Norm Difference for worker 1280 is 0.510022
INFO:root:FL Epoch: 7 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1341
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664006
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627947
INFO:root:FL Epoch: 7 Norm Difference for worker 1341 is 0.550842
INFO:root:FL Epoch: 7 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :243
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 243 is 0.471379
INFO:root:FL Epoch: 7 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1257
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735117
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665026
INFO:root:FL Epoch: 7 Norm Difference for worker 1257 is 0.472026
INFO:root:FL Epoch: 7 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :863
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618499
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659861
INFO:root:FL Epoch: 7 Norm Difference for worker 863 is 0.472876
INFO:root:FL Epoch: 7 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.4251914890248386, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.4251614125903003
INFO:root:#### Oracle Cals: 3, Objective Val: 0.4251609329523071
INFO:root:#### Oracle Cals: 4, Objective Val: 0.42516102339950995
INFO:root:#### Oracle Cals: 5, Objective Val: 0.4251609397013746
INFO:root:#### Oracle Cals: 6, Objective Val: 0.42516097455271745
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6712432749131146 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.7029741505781809                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1434
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654160
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684008
INFO:root:FL Epoch: 8 Norm Difference for worker 1434 is 0.523666
INFO:root:FL Epoch: 8 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :721
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684798
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705156
INFO:root:FL Epoch: 8 Norm Difference for worker 721 is 0.502111
INFO:root:FL Epoch: 8 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :363
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685763
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661803
INFO:root:FL Epoch: 8 Norm Difference for worker 363 is 0.605946
INFO:root:FL Epoch: 8 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :467
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676352
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665160
INFO:root:FL Epoch: 8 Norm Difference for worker 467 is 0.540489
INFO:root:FL Epoch: 8 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1443
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706950
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632196
INFO:root:FL Epoch: 8 Norm Difference for worker 1443 is 0.559603
INFO:root:FL Epoch: 8 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1573
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685582
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671789
INFO:root:FL Epoch: 8 Norm Difference for worker 1573 is 0.565631
INFO:root:FL Epoch: 8 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.500573
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :475
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598364
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682710
INFO:root:FL Epoch: 8 Norm Difference for worker 475 is 0.513778
INFO:root:FL Epoch: 8 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1216
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648349
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696609
INFO:root:FL Epoch: 8 Norm Difference for worker 1216 is 0.510719
INFO:root:FL Epoch: 8 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :521
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656531
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704751
INFO:root:FL Epoch: 8 Norm Difference for worker 521 is 0.504283
INFO:root:FL Epoch: 8 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.49287262907634716, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.4927464117672565
INFO:root:#### Oracle Cals: 3, Objective Val: 0.4927453129487484
INFO:root:#### Oracle Cals: 4, Objective Val: 0.49274531848260517
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6681583138073192 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7334437668323517                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1154
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660843
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643312
INFO:root:FL Epoch: 9 Norm Difference for worker 1154 is 0.516574
INFO:root:FL Epoch: 9 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :257
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.743978
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 257 is 0.545615
INFO:root:FL Epoch: 9 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1894
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670463
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707152
INFO:root:FL Epoch: 9 Norm Difference for worker 1894 is 0.607931
INFO:root:FL Epoch: 9 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :729
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672507
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630679
INFO:root:FL Epoch: 9 Norm Difference for worker 729 is 0.551797
INFO:root:FL Epoch: 9 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1361
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651563
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653342
INFO:root:FL Epoch: 9 Norm Difference for worker 1361 is 0.575237
INFO:root:FL Epoch: 9 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :634
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688455
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727140
INFO:root:FL Epoch: 9 Norm Difference for worker 634 is 0.582032
INFO:root:FL Epoch: 9 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671322
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651866
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.576604
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :657
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623412
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658141
INFO:root:FL Epoch: 9 Norm Difference for worker 657 is 0.584539
INFO:root:FL Epoch: 9 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :28
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672728
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.718683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 28 is 0.558106
INFO:root:FL Epoch: 9 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :344
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662429
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650727
INFO:root:FL Epoch: 9 Norm Difference for worker 344 is 0.508729
INFO:root:FL Epoch: 9 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.5116493599566381, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.5116057906935765
INFO:root:#### Oracle Cals: 3, Objective Val: 0.5116053477928301
INFO:root:#### Oracle Cals: 4, Objective Val: 0.5116053127394364
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6668043837827795 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.8017139136791229                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :322
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 322 is 0.636412
INFO:root:FL Epoch: 10 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1069
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781753
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737474
INFO:root:FL Epoch: 10 Norm Difference for worker 1069 is 0.650382
INFO:root:FL Epoch: 10 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645937
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656598
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.605667
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :716
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659450
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654913
INFO:root:FL Epoch: 10 Norm Difference for worker 716 is 0.618422
INFO:root:FL Epoch: 10 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1613
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646480
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674549
INFO:root:FL Epoch: 10 Norm Difference for worker 1613 is 0.648675
INFO:root:FL Epoch: 10 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1184
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658319
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715313
INFO:root:FL Epoch: 10 Norm Difference for worker 1184 is 0.567611
INFO:root:FL Epoch: 10 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1191
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648720
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674994
INFO:root:FL Epoch: 10 Norm Difference for worker 1191 is 0.701146
INFO:root:FL Epoch: 10 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :27
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 27 is 0.61689
INFO:root:FL Epoch: 10 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1904
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676768
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646386
INFO:root:FL Epoch: 10 Norm Difference for worker 1904 is 0.717403
INFO:root:FL Epoch: 10 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :291
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 291 is 0.616758
INFO:root:FL Epoch: 10 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.5711207057147502, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.5710785665601985
INFO:root:#### Oracle Cals: 3, Objective Val: 0.5710779986309952
INFO:root:#### Oracle Cals: 4, Objective Val: 0.571078014660232
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6631779565530664 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.7921967307726542                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [1409, 1122, 467, 247, 1802, 1801, 1139, 1528, 498, 594]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :1409
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656292
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641751
INFO:root:FL Epoch: 11 Norm Difference for worker 1409 is 0.678417
INFO:root:FL Epoch: 11 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1122
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682177
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570210
INFO:root:FL Epoch: 11 Norm Difference for worker 1122 is 0.758886
INFO:root:FL Epoch: 11 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :467
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657640
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591396
INFO:root:FL Epoch: 11 Norm Difference for worker 467 is 0.702025
INFO:root:FL Epoch: 11 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :247
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640909
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 247 is 0.728661
INFO:root:FL Epoch: 11 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1802
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677782
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624426
INFO:root:FL Epoch: 11 Norm Difference for worker 1802 is 0.703245
INFO:root:FL Epoch: 11 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1801
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693073
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565159
INFO:root:FL Epoch: 11 Norm Difference for worker 1801 is 0.719713
INFO:root:FL Epoch: 11 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1139
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702179
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633660
INFO:root:FL Epoch: 11 Norm Difference for worker 1139 is 0.683374
INFO:root:FL Epoch: 11 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1528
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712896
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560807
INFO:root:FL Epoch: 11 Norm Difference for worker 1528 is 0.800477
INFO:root:FL Epoch: 11 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :498
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618064
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627236
INFO:root:FL Epoch: 11 Norm Difference for worker 498 is 0.698732
INFO:root:FL Epoch: 11 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :594
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625083
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639888
INFO:root:FL Epoch: 11 Norm Difference for worker 594 is 0.716262
INFO:root:FL Epoch: 11 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.6333342257140369, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.6332986200046254
INFO:root:#### Oracle Cals: 3, Objective Val: 0.6332982242809019
INFO:root:#### Oracle Cals: 4, Objective Val: 0.6332982053122842
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.657785457723281 and Test Accuracy:61.76470588235294 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.8754657308260599                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1405
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630587
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619428
INFO:root:FL Epoch: 12 Norm Difference for worker 1405 is 0.842711
INFO:root:FL Epoch: 12 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1244
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630813
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639080
INFO:root:FL Epoch: 12 Norm Difference for worker 1244 is 0.873169
INFO:root:FL Epoch: 12 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :380
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691568
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675300
INFO:root:FL Epoch: 12 Norm Difference for worker 380 is 0.798165
INFO:root:FL Epoch: 12 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :125
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 125 is 0.849024
INFO:root:FL Epoch: 12 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :802
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599759
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587631
INFO:root:FL Epoch: 12 Norm Difference for worker 802 is 0.827708
INFO:root:FL Epoch: 12 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :840
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660977
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623698
INFO:root:FL Epoch: 12 Norm Difference for worker 840 is 0.861696
INFO:root:FL Epoch: 12 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1334
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658021
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518603
INFO:root:FL Epoch: 12 Norm Difference for worker 1334 is 0.892561
INFO:root:FL Epoch: 12 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659361
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619139
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.838004
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :689
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604946
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638869
INFO:root:FL Epoch: 12 Norm Difference for worker 689 is 0.794641
INFO:root:FL Epoch: 12 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1036
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675442
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692967
INFO:root:FL Epoch: 12 Norm Difference for worker 1036 is 0.842738
INFO:root:FL Epoch: 12 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.7707971301702512, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.7707566005498775
INFO:root:#### Oracle Cals: 3, Objective Val: 0.7707560546631506
INFO:root:#### Oracle Cals: 4, Objective Val: 0.7707560397292901
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6536539196968079 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.9107179840405782                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1930
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594465
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502014
INFO:root:FL Epoch: 13 Norm Difference for worker 1930 is 1.012917
INFO:root:FL Epoch: 13 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1474
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608444
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535921
INFO:root:FL Epoch: 13 Norm Difference for worker 1474 is 0.926825
INFO:root:FL Epoch: 13 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :442
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699441
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734408
INFO:root:FL Epoch: 13 Norm Difference for worker 442 is 0.872913
INFO:root:FL Epoch: 13 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :232
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.711374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 232 is 0.981768
INFO:root:FL Epoch: 13 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :116
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.745984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 116 is 0.956118
INFO:root:FL Epoch: 13 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :202
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 202 is 0.909177
INFO:root:FL Epoch: 13 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1081
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704232
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594678
INFO:root:FL Epoch: 13 Norm Difference for worker 1081 is 0.981291
INFO:root:FL Epoch: 13 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :606
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625321
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543573
INFO:root:FL Epoch: 13 Norm Difference for worker 606 is 0.951475
INFO:root:FL Epoch: 13 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1303
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643841
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655067
INFO:root:FL Epoch: 13 Norm Difference for worker 1303 is 0.964305
INFO:root:FL Epoch: 13 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :945
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692120
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609936
INFO:root:FL Epoch: 13 Norm Difference for worker 945 is 0.983275
INFO:root:FL Epoch: 13 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.8794044850514479, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.8792976440006637
INFO:root:#### Oracle Cals: 3, Objective Val: 0.879296319212042
INFO:root:#### Oracle Cals: 4, Objective Val: 0.8792963730775795
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6468789051560795 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:1.0268016854921977                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1163
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588697
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568480
INFO:root:FL Epoch: 14 Norm Difference for worker 1163 is 1.07214
INFO:root:FL Epoch: 14 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1460
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598796
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626110
INFO:root:FL Epoch: 14 Norm Difference for worker 1460 is 1.04299
INFO:root:FL Epoch: 14 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :409
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585790
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600412
INFO:root:FL Epoch: 14 Norm Difference for worker 409 is 1.166012
INFO:root:FL Epoch: 14 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1123
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558280
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663642
INFO:root:FL Epoch: 14 Norm Difference for worker 1123 is 1.056348
INFO:root:FL Epoch: 14 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :604
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642106
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505744
INFO:root:FL Epoch: 14 Norm Difference for worker 604 is 1.124773
INFO:root:FL Epoch: 14 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :200
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 200 is 1.024533
INFO:root:FL Epoch: 14 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :551
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580993
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519105
INFO:root:FL Epoch: 14 Norm Difference for worker 551 is 1.021913
INFO:root:FL Epoch: 14 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1222
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689733
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527605
INFO:root:FL Epoch: 14 Norm Difference for worker 1222 is 1.089523
INFO:root:FL Epoch: 14 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1589
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621268
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559834
INFO:root:FL Epoch: 14 Norm Difference for worker 1589 is 1.044967
INFO:root:FL Epoch: 14 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :746
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633725
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589201
INFO:root:FL Epoch: 14 Norm Difference for worker 746 is 1.013846
INFO:root:FL Epoch: 14 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9864933835973886, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9863692181308077
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9863676195779283
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9863676059425446
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6439871051732231 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:1.1682996948560078                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 15 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :1506
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567194
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543032
INFO:root:FL Epoch: 15 Norm Difference for worker 1506 is 1.242405
INFO:root:FL Epoch: 15 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :196
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 196 is 1.258245
INFO:root:FL Epoch: 15 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1478
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598844
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586720
INFO:root:FL Epoch: 15 Norm Difference for worker 1478 is 1.205961
INFO:root:FL Epoch: 15 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612985
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445822
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 1.274835
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1923
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629475
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634738
INFO:root:FL Epoch: 15 Norm Difference for worker 1923 is 1.222857
INFO:root:FL Epoch: 15 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :91
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 91 is 1.209282
INFO:root:FL Epoch: 15 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :242
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660061
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604405
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 242 is 1.174309
INFO:root:FL Epoch: 15 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1709
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564274
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631298
INFO:root:FL Epoch: 15 Norm Difference for worker 1709 is 1.235865
INFO:root:FL Epoch: 15 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1297
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746140
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662228
INFO:root:FL Epoch: 15 Norm Difference for worker 1297 is 1.232754
INFO:root:FL Epoch: 15 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1000
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574330
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601799
INFO:root:FL Epoch: 15 Norm Difference for worker 1000 is 1.26417
INFO:root:FL Epoch: 15 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.15556740218668, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1555059947569146
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1555050225237848
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1555049925712755
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6334868792225333 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:1.197700321674347                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :639
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590789
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446761
INFO:root:FL Epoch: 16 Norm Difference for worker 639 is 1.326916
INFO:root:FL Epoch: 16 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :327
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 327 is 1.368036
INFO:root:FL Epoch: 16 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :503
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667019
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624068
INFO:root:FL Epoch: 16 Norm Difference for worker 503 is 1.33742
INFO:root:FL Epoch: 16 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1110
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602085
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559803
INFO:root:FL Epoch: 16 Norm Difference for worker 1110 is 1.315717
INFO:root:FL Epoch: 16 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :839
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602191
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531773
INFO:root:FL Epoch: 16 Norm Difference for worker 839 is 1.348221
INFO:root:FL Epoch: 16 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :472
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697730
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478340
INFO:root:FL Epoch: 16 Norm Difference for worker 472 is 1.355207
INFO:root:FL Epoch: 16 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :274
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697477
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 274 is 1.335001
INFO:root:FL Epoch: 16 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :481
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506300
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601601
INFO:root:FL Epoch: 16 Norm Difference for worker 481 is 1.375088
INFO:root:FL Epoch: 16 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :805
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689355
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681747
INFO:root:FL Epoch: 16 Norm Difference for worker 805 is 1.354651
INFO:root:FL Epoch: 16 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1606
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580616
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613725
INFO:root:FL Epoch: 16 Norm Difference for worker 1606 is 1.335678
INFO:root:FL Epoch: 16 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2644830952735413, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2644665245265316
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2644663425545315
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2644663543665262
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6262518728480619 and Test Accuracy:62.94117647058823 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.3193352023760478                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :116
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563776
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 116 is 1.48535
INFO:root:FL Epoch: 17 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1658
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510989
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553146
INFO:root:FL Epoch: 17 Norm Difference for worker 1658 is 1.491999
INFO:root:FL Epoch: 17 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :988
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558296
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364289
INFO:root:FL Epoch: 17 Norm Difference for worker 988 is 1.515205
INFO:root:FL Epoch: 17 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1655
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628911
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504234
INFO:root:FL Epoch: 17 Norm Difference for worker 1655 is 1.515552
INFO:root:FL Epoch: 17 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :62
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537572
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 62 is 1.461041
INFO:root:FL Epoch: 17 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :870
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617246
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635228
INFO:root:FL Epoch: 17 Norm Difference for worker 870 is 1.490456
INFO:root:FL Epoch: 17 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :955
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663698
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491208
INFO:root:FL Epoch: 17 Norm Difference for worker 955 is 1.51396
INFO:root:FL Epoch: 17 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :304
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 304 is 1.441364
INFO:root:FL Epoch: 17 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1427
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657529
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614919
INFO:root:FL Epoch: 17 Norm Difference for worker 1427 is 1.430444
INFO:root:FL Epoch: 17 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :652
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558703
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560121
INFO:root:FL Epoch: 17 Norm Difference for worker 652 is 1.464813
INFO:root:FL Epoch: 17 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3949948719247416, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3949572744901861
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3949569087977602
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3949568690590466
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6141067234908834 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:1.1022984584172566                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1037
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633254
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591368
INFO:root:FL Epoch: 18 Norm Difference for worker 1037 is 1.446227
INFO:root:FL Epoch: 18 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1375
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736798
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435397
INFO:root:FL Epoch: 18 Norm Difference for worker 1375 is 1.468779
INFO:root:FL Epoch: 18 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :637
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668878
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435640
INFO:root:FL Epoch: 18 Norm Difference for worker 637 is 1.567205
INFO:root:FL Epoch: 18 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :293
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 293 is 1.455874
INFO:root:FL Epoch: 18 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1435
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688780
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575543
INFO:root:FL Epoch: 18 Norm Difference for worker 1435 is 1.520697
INFO:root:FL Epoch: 18 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1294
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728336
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519884
INFO:root:FL Epoch: 18 Norm Difference for worker 1294 is 1.472107
INFO:root:FL Epoch: 18 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :712
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802198
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512186
INFO:root:FL Epoch: 18 Norm Difference for worker 712 is 1.577874
INFO:root:FL Epoch: 18 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :440
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606347
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657226
INFO:root:FL Epoch: 18 Norm Difference for worker 440 is 1.396032
INFO:root:FL Epoch: 18 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1768
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659359
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553059
INFO:root:FL Epoch: 18 Norm Difference for worker 1768 is 1.415202
INFO:root:FL Epoch: 18 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1805
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606471
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605891
INFO:root:FL Epoch: 18 Norm Difference for worker 1805 is 1.497448
INFO:root:FL Epoch: 18 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3989729584745614, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3988882159186482
INFO:root:#### Oracle Cals: 3, Objective Val: 1.398887056215315
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3988870375488882
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6114268004894257 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.3278586864471436                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 19 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :772
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750519
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339781
INFO:root:FL Epoch: 19 Norm Difference for worker 772 is 1.475239
INFO:root:FL Epoch: 19 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :212
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491327
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 212 is 1.545484
INFO:root:FL Epoch: 19 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :407
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472486
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508036
INFO:root:FL Epoch: 19 Norm Difference for worker 407 is 1.506913
INFO:root:FL Epoch: 19 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :782
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646621
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629214
INFO:root:FL Epoch: 19 Norm Difference for worker 782 is 1.636008
INFO:root:FL Epoch: 19 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1093
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581493
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535219
INFO:root:FL Epoch: 19 Norm Difference for worker 1093 is 1.530306
INFO:root:FL Epoch: 19 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1764
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706358
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506105
INFO:root:FL Epoch: 19 Norm Difference for worker 1764 is 1.654802
INFO:root:FL Epoch: 19 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618726
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 1.576088
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :351
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630428
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450109
INFO:root:FL Epoch: 19 Norm Difference for worker 351 is 1.478065
INFO:root:FL Epoch: 19 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1391
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714471
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545019
INFO:root:FL Epoch: 19 Norm Difference for worker 1391 is 1.565346
INFO:root:FL Epoch: 19 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :334
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425288
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 334 is 1.626679
INFO:root:FL Epoch: 19 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4589680623248622, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4588399645225607
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4588382214600206
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4588382023165158
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6262724119074204 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.2528076966603596                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :697
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672888
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465675
INFO:root:FL Epoch: 20 Norm Difference for worker 697 is 1.692767
INFO:root:FL Epoch: 20 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1059
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632957
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519033
INFO:root:FL Epoch: 20 Norm Difference for worker 1059 is 1.539412
INFO:root:FL Epoch: 20 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :940
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698963
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466262
INFO:root:FL Epoch: 20 Norm Difference for worker 940 is 1.593732
INFO:root:FL Epoch: 20 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1796
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566990
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626048
INFO:root:FL Epoch: 20 Norm Difference for worker 1796 is 1.631726
INFO:root:FL Epoch: 20 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1162
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551015
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539666
INFO:root:FL Epoch: 20 Norm Difference for worker 1162 is 1.661966
INFO:root:FL Epoch: 20 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1765
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620432
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636661
INFO:root:FL Epoch: 20 Norm Difference for worker 1765 is 1.546838
INFO:root:FL Epoch: 20 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :469
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627963
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484727
INFO:root:FL Epoch: 20 Norm Difference for worker 469 is 1.586653
INFO:root:FL Epoch: 20 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1470
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542780
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442732
INFO:root:FL Epoch: 20 Norm Difference for worker 1470 is 1.513008
INFO:root:FL Epoch: 20 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :442
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764531
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541810
INFO:root:FL Epoch: 20 Norm Difference for worker 442 is 1.545654
INFO:root:FL Epoch: 20 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1373
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681658
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429978
INFO:root:FL Epoch: 20 Norm Difference for worker 1373 is 1.592345
INFO:root:FL Epoch: 20 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.488189717422877, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4881347099105489
INFO:root:#### Oracle Cals: 3, Objective Val: 1.488134060662375
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4881340400844056
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6021165076424094 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.1735300620396931                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [188, 485, 797, 1233, 876, 159, 811, 1592, 1089, 1895]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :188
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 188 is 1.554181
INFO:root:FL Epoch: 21 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :485
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658502
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496076
INFO:root:FL Epoch: 21 Norm Difference for worker 485 is 1.653861
INFO:root:FL Epoch: 21 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :797
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673075
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579654
INFO:root:FL Epoch: 21 Norm Difference for worker 797 is 1.585775
INFO:root:FL Epoch: 21 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1233
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697957
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496278
INFO:root:FL Epoch: 21 Norm Difference for worker 1233 is 1.67869
INFO:root:FL Epoch: 21 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :876
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657437
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590605
INFO:root:FL Epoch: 21 Norm Difference for worker 876 is 1.573754
INFO:root:FL Epoch: 21 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :159
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 159 is 1.506337
INFO:root:FL Epoch: 21 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :811
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818272
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460997
INFO:root:FL Epoch: 21 Norm Difference for worker 811 is 1.564563
INFO:root:FL Epoch: 21 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1592
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630641
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505883
INFO:root:FL Epoch: 21 Norm Difference for worker 1592 is 1.575269
INFO:root:FL Epoch: 21 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1089
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653346
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532535
INFO:root:FL Epoch: 21 Norm Difference for worker 1089 is 1.529148
INFO:root:FL Epoch: 21 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1895
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787068
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586371
INFO:root:FL Epoch: 21 Norm Difference for worker 1895 is 1.61716
INFO:root:FL Epoch: 21 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4885063685849764, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4884307223390605
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4884297509255213
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4884297380845122
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.616862169083427 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:1.2006428440411885                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 22 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :1716
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542757
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496984
INFO:root:FL Epoch: 22 Norm Difference for worker 1716 is 1.499606
INFO:root:FL Epoch: 22 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :910
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531622
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513838
INFO:root:FL Epoch: 22 Norm Difference for worker 910 is 1.59582
INFO:root:FL Epoch: 22 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1098
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499583
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329062
INFO:root:FL Epoch: 22 Norm Difference for worker 1098 is 1.581474
INFO:root:FL Epoch: 22 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1721
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467659
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552135
INFO:root:FL Epoch: 22 Norm Difference for worker 1721 is 1.574989
INFO:root:FL Epoch: 22 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :576
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459688
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443301
INFO:root:FL Epoch: 22 Norm Difference for worker 576 is 1.477745
INFO:root:FL Epoch: 22 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :104
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.800464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560940
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 104 is 1.514857
INFO:root:FL Epoch: 22 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1834
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580056
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565788
INFO:root:FL Epoch: 22 Norm Difference for worker 1834 is 1.599805
INFO:root:FL Epoch: 22 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1178
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642729
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396814
INFO:root:FL Epoch: 22 Norm Difference for worker 1178 is 1.545748
INFO:root:FL Epoch: 22 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :810
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637519
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447013
INFO:root:FL Epoch: 22 Norm Difference for worker 810 is 1.568462
INFO:root:FL Epoch: 22 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1047
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545274
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486606
INFO:root:FL Epoch: 22 Norm Difference for worker 1047 is 1.567881
INFO:root:FL Epoch: 22 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4522795289286135, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4522256532876403
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4522249712222461
INFO:root:#### Oracle Cals: 4, Objective Val: 1.452224901718641
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6191368032904232 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:1.4074002106984456                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1150
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549117
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436684
INFO:root:FL Epoch: 23 Norm Difference for worker 1150 is 1.582833
INFO:root:FL Epoch: 23 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :703
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573716
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550748
INFO:root:FL Epoch: 23 Norm Difference for worker 703 is 1.660087
INFO:root:FL Epoch: 23 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1942
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524068
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661772
INFO:root:FL Epoch: 23 Norm Difference for worker 1942 is 1.741081
INFO:root:FL Epoch: 23 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :362
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643945
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640104
INFO:root:FL Epoch: 23 Norm Difference for worker 362 is 1.743209
INFO:root:FL Epoch: 23 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1475
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584337
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430703
INFO:root:FL Epoch: 23 Norm Difference for worker 1475 is 1.693735
INFO:root:FL Epoch: 23 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :742
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541819
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436756
INFO:root:FL Epoch: 23 Norm Difference for worker 742 is 1.706279
INFO:root:FL Epoch: 23 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635369
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577794
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 1.592416
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :355
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569585
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547175
INFO:root:FL Epoch: 23 Norm Difference for worker 355 is 1.754301
INFO:root:FL Epoch: 23 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :747
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597971
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429268
INFO:root:FL Epoch: 23 Norm Difference for worker 747 is 1.714801
INFO:root:FL Epoch: 23 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :802
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641646
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569090
INFO:root:FL Epoch: 23 Norm Difference for worker 802 is 1.757967
INFO:root:FL Epoch: 23 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.587456280231345, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5872679995130017
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5872653942579396
INFO:root:#### Oracle Cals: 4, Objective Val: 1.587265350892149
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6143211950274075 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:1.503695785999298                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489353
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410477
INFO:root:FL Epoch: 24 Norm Difference for worker 858 is 1.703861
INFO:root:FL Epoch: 24 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :699
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586955
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492942
INFO:root:FL Epoch: 24 Norm Difference for worker 699 is 1.772474
INFO:root:FL Epoch: 24 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :206
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647547
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 206 is 1.610263
INFO:root:FL Epoch: 24 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1820
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644434
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491528
INFO:root:FL Epoch: 24 Norm Difference for worker 1820 is 1.756613
INFO:root:FL Epoch: 24 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1414
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641091
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483479
INFO:root:FL Epoch: 24 Norm Difference for worker 1414 is 1.700185
INFO:root:FL Epoch: 24 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :474
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608475
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579960
INFO:root:FL Epoch: 24 Norm Difference for worker 474 is 1.696096
INFO:root:FL Epoch: 24 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :7
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 7 is 1.647965
INFO:root:FL Epoch: 24 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1914
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582506
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613741
INFO:root:FL Epoch: 24 Norm Difference for worker 1914 is 1.682883
INFO:root:FL Epoch: 24 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :865
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748448
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423426
INFO:root:FL Epoch: 24 Norm Difference for worker 865 is 1.704857
INFO:root:FL Epoch: 24 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :249
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 249 is 1.604073
INFO:root:FL Epoch: 24 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5823537980690472, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5822739571823878
INFO:root:#### Oracle Cals: 3, Objective Val: 1.582272855256114
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5822728400268118
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6158298779936398 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:1.4493550856908162                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1399
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605597
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413868
INFO:root:FL Epoch: 25 Norm Difference for worker 1399 is 1.695255
INFO:root:FL Epoch: 25 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :693
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482665
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520545
INFO:root:FL Epoch: 25 Norm Difference for worker 693 is 1.729592
INFO:root:FL Epoch: 25 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1217
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569440
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449533
INFO:root:FL Epoch: 25 Norm Difference for worker 1217 is 1.771004
INFO:root:FL Epoch: 25 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :70
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 70 is 1.613831
INFO:root:FL Epoch: 25 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :496
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720783
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490284
INFO:root:FL Epoch: 25 Norm Difference for worker 496 is 1.675495
INFO:root:FL Epoch: 25 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :407
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664354
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298564
INFO:root:FL Epoch: 25 Norm Difference for worker 407 is 1.614426
INFO:root:FL Epoch: 25 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :317
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729909
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 317 is 1.682504
INFO:root:FL Epoch: 25 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :98
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 98 is 1.731225
INFO:root:FL Epoch: 25 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1286
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643757
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451856
INFO:root:FL Epoch: 25 Norm Difference for worker 1286 is 1.682838
INFO:root:FL Epoch: 25 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1251
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556817
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377511
INFO:root:FL Epoch: 25 Norm Difference for worker 1251 is 1.834788
INFO:root:FL Epoch: 25 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6096811266522701, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6095834699033693
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6095822231042984
INFO:root:#### Oracle Cals: 4, Objective Val: 1.609582199155853
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6168856533134685 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.5958098371823628                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 26 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :1748
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644712
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401215
INFO:root:FL Epoch: 26 Norm Difference for worker 1748 is 1.739889
INFO:root:FL Epoch: 26 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1403
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717791
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433323
INFO:root:FL Epoch: 26 Norm Difference for worker 1403 is 1.753439
INFO:root:FL Epoch: 26 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1456
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671618
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464341
INFO:root:FL Epoch: 26 Norm Difference for worker 1456 is 1.735378
INFO:root:FL Epoch: 26 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1021
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524174
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392854
INFO:root:FL Epoch: 26 Norm Difference for worker 1021 is 1.615869
INFO:root:FL Epoch: 26 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1824
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496510
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654894
INFO:root:FL Epoch: 26 Norm Difference for worker 1824 is 1.829493
INFO:root:FL Epoch: 26 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :311
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 311 is 1.706549
INFO:root:FL Epoch: 26 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :906
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555659
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483010
INFO:root:FL Epoch: 26 Norm Difference for worker 906 is 1.753196
INFO:root:FL Epoch: 26 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1618
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747944
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597397
INFO:root:FL Epoch: 26 Norm Difference for worker 1618 is 1.66069
INFO:root:FL Epoch: 26 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :900
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616398
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526516
INFO:root:FL Epoch: 26 Norm Difference for worker 900 is 1.908143
INFO:root:FL Epoch: 26 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1277
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558316
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590562
INFO:root:FL Epoch: 26 Norm Difference for worker 1277 is 1.731789
INFO:root:FL Epoch: 26 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6397171660280911, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.639572127063798
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6395703526777512
INFO:root:#### Oracle Cals: 4, Objective Val: 1.639570305173579
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.595853880924337 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:1.5240661303202312                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 27 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1930
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588503
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303184
INFO:root:FL Epoch: 27 Norm Difference for worker 1930 is 1.768892
INFO:root:FL Epoch: 27 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1641
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700747
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552615
INFO:root:FL Epoch: 27 Norm Difference for worker 1641 is 1.774282
INFO:root:FL Epoch: 27 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :786
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643321
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503908
INFO:root:FL Epoch: 27 Norm Difference for worker 786 is 1.759546
INFO:root:FL Epoch: 27 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1944
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715751
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354823
INFO:root:FL Epoch: 27 Norm Difference for worker 1944 is 1.647076
INFO:root:FL Epoch: 27 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :949
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605606
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642055
INFO:root:FL Epoch: 27 Norm Difference for worker 949 is 1.846959
INFO:root:FL Epoch: 27 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400285
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 1.66511
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1024
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681447
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418295
INFO:root:FL Epoch: 27 Norm Difference for worker 1024 is 1.732008
INFO:root:FL Epoch: 27 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :860
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752473
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458863
INFO:root:FL Epoch: 27 Norm Difference for worker 860 is 1.851925
INFO:root:FL Epoch: 27 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :79
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 79 is 1.745051
INFO:root:FL Epoch: 27 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1497
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551085
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513636
INFO:root:FL Epoch: 27 Norm Difference for worker 1497 is 1.726793
INFO:root:FL Epoch: 27 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6478730076651502, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6477604724340928
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6477591260865012
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6477590819719976
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6142730029190288 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:1.050221820672353                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :533
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581254
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631964
INFO:root:FL Epoch: 28 Norm Difference for worker 533 is 1.740599
INFO:root:FL Epoch: 28 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1370
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608476
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432020
INFO:root:FL Epoch: 28 Norm Difference for worker 1370 is 1.71592
INFO:root:FL Epoch: 28 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1778
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405638
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380829
INFO:root:FL Epoch: 28 Norm Difference for worker 1778 is 1.681268
INFO:root:FL Epoch: 28 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :376
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579778
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439952
INFO:root:FL Epoch: 28 Norm Difference for worker 376 is 1.704633
INFO:root:FL Epoch: 28 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1688
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657695
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541433
INFO:root:FL Epoch: 28 Norm Difference for worker 1688 is 1.661104
INFO:root:FL Epoch: 28 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1791
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745422
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548521
INFO:root:FL Epoch: 28 Norm Difference for worker 1791 is 1.664315
INFO:root:FL Epoch: 28 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :744
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534733
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498390
INFO:root:FL Epoch: 28 Norm Difference for worker 744 is 1.701265
INFO:root:FL Epoch: 28 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :605
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637295
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517618
INFO:root:FL Epoch: 28 Norm Difference for worker 605 is 1.856601
INFO:root:FL Epoch: 28 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1458
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660639
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558768
INFO:root:FL Epoch: 28 Norm Difference for worker 1458 is 1.70643
INFO:root:FL Epoch: 28 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :452
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801047
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496540
INFO:root:FL Epoch: 28 Norm Difference for worker 452 is 1.693818
INFO:root:FL Epoch: 28 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.615514623234054, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6154186654149845
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6154174654360565
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6154174453413062
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6146971916451174 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.3803152640660603                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :173
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 173 is 1.781641
INFO:root:FL Epoch: 29 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1917
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636595
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464730
INFO:root:FL Epoch: 29 Norm Difference for worker 1917 is 1.682258
INFO:root:FL Epoch: 29 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1341
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568929
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414086
INFO:root:FL Epoch: 29 Norm Difference for worker 1341 is 1.661888
INFO:root:FL Epoch: 29 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :789
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698729
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494800
INFO:root:FL Epoch: 29 Norm Difference for worker 789 is 1.756182
INFO:root:FL Epoch: 29 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :961
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667041
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402641
INFO:root:FL Epoch: 29 Norm Difference for worker 961 is 1.729565
INFO:root:FL Epoch: 29 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1601
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583973
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385021
INFO:root:FL Epoch: 29 Norm Difference for worker 1601 is 1.775993
INFO:root:FL Epoch: 29 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1755
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692334
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429746
INFO:root:FL Epoch: 29 Norm Difference for worker 1755 is 1.724138
INFO:root:FL Epoch: 29 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1597
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526109
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503420
INFO:root:FL Epoch: 29 Norm Difference for worker 1597 is 1.78218
INFO:root:FL Epoch: 29 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1906
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562274
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525992
INFO:root:FL Epoch: 29 Norm Difference for worker 1906 is 1.786537
INFO:root:FL Epoch: 29 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :545
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513740
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430239
INFO:root:FL Epoch: 29 Norm Difference for worker 545 is 1.626477
INFO:root:FL Epoch: 29 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6259622228057546, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6258435959894102
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6258419812847347
INFO:root:#### Oracle Cals: 4, Objective Val: 1.62584196842594
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6147499400026658 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:1.5882299145062764                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :97
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456255
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537314
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 97 is 1.910671
INFO:root:FL Epoch: 30 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622129
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525771
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 1.891472
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1598
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447850
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372637
INFO:root:FL Epoch: 30 Norm Difference for worker 1598 is 1.845916
INFO:root:FL Epoch: 30 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1172
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617885
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555634
INFO:root:FL Epoch: 30 Norm Difference for worker 1172 is 1.917752
INFO:root:FL Epoch: 30 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :189
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456812
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402417
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 189 is 1.798059
INFO:root:FL Epoch: 30 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1585
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816407
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353296
INFO:root:FL Epoch: 30 Norm Difference for worker 1585 is 1.93953
INFO:root:FL Epoch: 30 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1215
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684312
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406245
INFO:root:FL Epoch: 30 Norm Difference for worker 1215 is 1.824603
INFO:root:FL Epoch: 30 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :439
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573378
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402565
INFO:root:FL Epoch: 30 Norm Difference for worker 439 is 1.865505
INFO:root:FL Epoch: 30 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :573
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517641
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417131
INFO:root:FL Epoch: 30 Norm Difference for worker 573 is 1.960819
INFO:root:FL Epoch: 30 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1311
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467375
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320279
INFO:root:FL Epoch: 30 Norm Difference for worker 1311 is 1.985161
INFO:root:FL Epoch: 30 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.78443451774328, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7843058402666754
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7843039717014832
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7843039904560039
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.5960014041732339 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:1.5843435327212017                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [1693, 599, 1613, 1374, 698, 1310, 1539, 786, 1330, 1413]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 31 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :1693
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606023
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481463
INFO:root:FL Epoch: 31 Norm Difference for worker 1693 is 1.776947
INFO:root:FL Epoch: 31 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :599
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639403
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306867
INFO:root:FL Epoch: 31 Norm Difference for worker 599 is 1.771006
INFO:root:FL Epoch: 31 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1613
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673951
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419742
INFO:root:FL Epoch: 31 Norm Difference for worker 1613 is 1.847925
INFO:root:FL Epoch: 31 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1374
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483317
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488921
INFO:root:FL Epoch: 31 Norm Difference for worker 1374 is 1.781894
INFO:root:FL Epoch: 31 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :698
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639494
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361418
INFO:root:FL Epoch: 31 Norm Difference for worker 698 is 1.779074
INFO:root:FL Epoch: 31 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1310
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518800
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344829
INFO:root:FL Epoch: 31 Norm Difference for worker 1310 is 1.821304
INFO:root:FL Epoch: 31 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1539
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482944
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415974
INFO:root:FL Epoch: 31 Norm Difference for worker 1539 is 1.78419
INFO:root:FL Epoch: 31 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :786
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598539
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381782
INFO:root:FL Epoch: 31 Norm Difference for worker 786 is 1.831172
INFO:root:FL Epoch: 31 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1330
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511873
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460895
INFO:root:FL Epoch: 31 Norm Difference for worker 1330 is 1.94591
INFO:root:FL Epoch: 31 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1413
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580356
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425805
INFO:root:FL Epoch: 31 Norm Difference for worker 1413 is 1.873486
INFO:root:FL Epoch: 31 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.71991945153541, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7198619716756618
INFO:root:#### Oracle Cals: 3, Objective Val: 1.719861358028144
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7198613840820034
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.5820021068348604 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:1.6522923111915588                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :1528
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588751
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301537
INFO:root:FL Epoch: 32 Norm Difference for worker 1528 is 1.788444
INFO:root:FL Epoch: 32 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :546
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574876
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326290
INFO:root:FL Epoch: 32 Norm Difference for worker 546 is 1.850459
INFO:root:FL Epoch: 32 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1315
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524931
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411424
INFO:root:FL Epoch: 32 Norm Difference for worker 1315 is 1.894068
INFO:root:FL Epoch: 32 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 1.812385
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :504
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483199
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381213
INFO:root:FL Epoch: 32 Norm Difference for worker 504 is 1.86796
INFO:root:FL Epoch: 32 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :250
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 250 is 1.817712
INFO:root:FL Epoch: 32 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :655
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611094
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387255
INFO:root:FL Epoch: 32 Norm Difference for worker 655 is 1.841229
INFO:root:FL Epoch: 32 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1640
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630592
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469921
INFO:root:FL Epoch: 32 Norm Difference for worker 1640 is 1.934674
INFO:root:FL Epoch: 32 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1386
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558442
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402509
INFO:root:FL Epoch: 32 Norm Difference for worker 1386 is 1.778813
INFO:root:FL Epoch: 32 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :46
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386257
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 46 is 1.835733
INFO:root:FL Epoch: 32 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7327770450730162, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7327490453770225
INFO:root:#### Oracle Cals: 3, Objective Val: 1.732748720118268
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7327487145726823
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.5834804037038017 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.8457367618878682                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1149
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456062
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491156
INFO:root:FL Epoch: 33 Norm Difference for worker 1149 is 2.011729
INFO:root:FL Epoch: 33 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :529
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522320
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361631
INFO:root:FL Epoch: 33 Norm Difference for worker 529 is 1.98544
INFO:root:FL Epoch: 33 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :986
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697851
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373201
INFO:root:FL Epoch: 33 Norm Difference for worker 986 is 2.142902
INFO:root:FL Epoch: 33 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :911
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575664
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576908
INFO:root:FL Epoch: 33 Norm Difference for worker 911 is 2.088431
INFO:root:FL Epoch: 33 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :260
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 260 is 1.982141
INFO:root:FL Epoch: 33 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :855
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448235
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469602
INFO:root:FL Epoch: 33 Norm Difference for worker 855 is 2.059831
INFO:root:FL Epoch: 33 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :478
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504291
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377747
INFO:root:FL Epoch: 33 Norm Difference for worker 478 is 1.991992
INFO:root:FL Epoch: 33 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1001
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480865
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364335
INFO:root:FL Epoch: 33 Norm Difference for worker 1001 is 1.84513
INFO:root:FL Epoch: 33 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :407
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522590
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312165
INFO:root:FL Epoch: 33 Norm Difference for worker 407 is 1.799346
INFO:root:FL Epoch: 33 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1886
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647477
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427537
INFO:root:FL Epoch: 33 Norm Difference for worker 1886 is 2.091705
INFO:root:FL Epoch: 33 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8785727731513098, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8784135167392908
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8784116407164342
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8784116475660975
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.5703312000807594 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:1.7964610854784648                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1640
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508679
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501409
INFO:root:FL Epoch: 34 Norm Difference for worker 1640 is 1.813759
INFO:root:FL Epoch: 34 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :942
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564134
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405808
INFO:root:FL Epoch: 34 Norm Difference for worker 942 is 1.806968
INFO:root:FL Epoch: 34 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :389
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635829
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449092
INFO:root:FL Epoch: 34 Norm Difference for worker 389 is 1.838207
INFO:root:FL Epoch: 34 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :907
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528709
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364710
INFO:root:FL Epoch: 34 Norm Difference for worker 907 is 1.831963
INFO:root:FL Epoch: 34 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1081
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534040
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381192
INFO:root:FL Epoch: 34 Norm Difference for worker 1081 is 1.835249
INFO:root:FL Epoch: 34 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1797
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614351
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411715
INFO:root:FL Epoch: 34 Norm Difference for worker 1797 is 1.883176
INFO:root:FL Epoch: 34 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1890
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771451
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432216
INFO:root:FL Epoch: 34 Norm Difference for worker 1890 is 1.857532
INFO:root:FL Epoch: 34 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :922
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814871
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477987
INFO:root:FL Epoch: 34 Norm Difference for worker 922 is 1.917598
INFO:root:FL Epoch: 34 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1593
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658391
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530638
INFO:root:FL Epoch: 34 Norm Difference for worker 1593 is 1.81196
INFO:root:FL Epoch: 34 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1411
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624271
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566938
INFO:root:FL Epoch: 34 Norm Difference for worker 1411 is 1.838946
INFO:root:FL Epoch: 34 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.732374922870996, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7323090078852126
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7323081741003807
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7323081512319356
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.5804576049832737 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.6029833753903706                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1678
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778756
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556818
INFO:root:FL Epoch: 35 Norm Difference for worker 1678 is 1.767525
INFO:root:FL Epoch: 35 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1654
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533756
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577662
INFO:root:FL Epoch: 35 Norm Difference for worker 1654 is 1.949805
INFO:root:FL Epoch: 35 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1413
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462472
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476308
INFO:root:FL Epoch: 35 Norm Difference for worker 1413 is 1.855946
INFO:root:FL Epoch: 35 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :547
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561769
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469468
INFO:root:FL Epoch: 35 Norm Difference for worker 547 is 1.871804
INFO:root:FL Epoch: 35 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1443
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721897
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355244
INFO:root:FL Epoch: 35 Norm Difference for worker 1443 is 1.879858
INFO:root:FL Epoch: 35 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :144
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 144 is 1.86869
INFO:root:FL Epoch: 35 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :892
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624112
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258432
INFO:root:FL Epoch: 35 Norm Difference for worker 892 is 1.833466
INFO:root:FL Epoch: 35 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :191
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502585
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 191 is 1.951616
INFO:root:FL Epoch: 35 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :340
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704015
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384897
INFO:root:FL Epoch: 35 Norm Difference for worker 340 is 1.881672
INFO:root:FL Epoch: 35 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1558
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560925
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471779
INFO:root:FL Epoch: 35 Norm Difference for worker 1558 is 1.904748
INFO:root:FL Epoch: 35 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7607209469032974, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7606408817773964
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7606398306989408
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7606398287382927
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.5634599047548631 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.4885713855425518                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1323
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703049
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445936
INFO:root:FL Epoch: 36 Norm Difference for worker 1323 is 1.962602
INFO:root:FL Epoch: 36 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1216
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693793
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334236
INFO:root:FL Epoch: 36 Norm Difference for worker 1216 is 1.851715
INFO:root:FL Epoch: 36 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527135
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425374
INFO:root:FL Epoch: 36 Norm Difference for worker 1937 is 1.945246
INFO:root:FL Epoch: 36 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :432
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587333
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409144
INFO:root:FL Epoch: 36 Norm Difference for worker 432 is 1.762267
INFO:root:FL Epoch: 36 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1511
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573204
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628705
INFO:root:FL Epoch: 36 Norm Difference for worker 1511 is 2.045097
INFO:root:FL Epoch: 36 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :669
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678931
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461003
INFO:root:FL Epoch: 36 Norm Difference for worker 669 is 1.990498
INFO:root:FL Epoch: 36 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1891
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816144
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511699
INFO:root:FL Epoch: 36 Norm Difference for worker 1891 is 1.871981
INFO:root:FL Epoch: 36 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1824
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425983
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559088
INFO:root:FL Epoch: 36 Norm Difference for worker 1824 is 2.016126
INFO:root:FL Epoch: 36 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :228
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 228 is 1.898159
INFO:root:FL Epoch: 36 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :447
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739041
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456393
INFO:root:FL Epoch: 36 Norm Difference for worker 447 is 1.986592
INFO:root:FL Epoch: 36 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8183627488225345, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8181797728265343
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8181771321051867
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8181771034599925
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.5501356528085821 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.5448945959409077                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 37 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :400
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660989
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496978
INFO:root:FL Epoch: 37 Norm Difference for worker 400 is 1.892788
INFO:root:FL Epoch: 37 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :3
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 3 is 1.936744
INFO:root:FL Epoch: 37 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1265
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722678
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352937
INFO:root:FL Epoch: 37 Norm Difference for worker 1265 is 1.940885
INFO:root:FL Epoch: 37 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :532
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494361
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578854
INFO:root:FL Epoch: 37 Norm Difference for worker 532 is 1.948418
INFO:root:FL Epoch: 37 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1836
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644385
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408842
INFO:root:FL Epoch: 37 Norm Difference for worker 1836 is 1.830803
INFO:root:FL Epoch: 37 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :270
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361227
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 270 is 1.838444
INFO:root:FL Epoch: 37 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1792
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570231
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413110
INFO:root:FL Epoch: 37 Norm Difference for worker 1792 is 1.742291
INFO:root:FL Epoch: 37 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1318
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550318
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402620
INFO:root:FL Epoch: 37 Norm Difference for worker 1318 is 1.839469
INFO:root:FL Epoch: 37 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :159
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 159 is 1.834661
INFO:root:FL Epoch: 37 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :894
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612024
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406325
INFO:root:FL Epoch: 37 Norm Difference for worker 894 is 1.903659
INFO:root:FL Epoch: 37 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7529875949344687, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7528731566132416
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7528715627355969
INFO:root:#### Oracle Cals: 4, Objective Val: 1.75287153705523
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.5633890330791473 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.6731167435646057                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 38 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :91
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 91 is 1.938632
INFO:root:FL Epoch: 38 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :406
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521363
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677024
INFO:root:FL Epoch: 38 Norm Difference for worker 406 is 2.023234
INFO:root:FL Epoch: 38 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1341
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437630
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385210
INFO:root:FL Epoch: 38 Norm Difference for worker 1341 is 1.846159
INFO:root:FL Epoch: 38 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1142
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704924
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289319
INFO:root:FL Epoch: 38 Norm Difference for worker 1142 is 1.928831
INFO:root:FL Epoch: 38 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :961
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555885
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469876
INFO:root:FL Epoch: 38 Norm Difference for worker 961 is 1.920947
INFO:root:FL Epoch: 38 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1634
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664640
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501770
INFO:root:FL Epoch: 38 Norm Difference for worker 1634 is 2.040323
INFO:root:FL Epoch: 38 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :278
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 278 is 2.006669
INFO:root:FL Epoch: 38 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1725
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600001
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418388
INFO:root:FL Epoch: 38 Norm Difference for worker 1725 is 2.017421
INFO:root:FL Epoch: 38 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1426
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780102
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313546
INFO:root:FL Epoch: 38 Norm Difference for worker 1426 is 2.032854
INFO:root:FL Epoch: 38 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :171
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407128
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 171 is 1.979105
INFO:root:FL Epoch: 38 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8493029566331616, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8491902293711693
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8491888746229717
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8491888558597585
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.562157392501831 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:1.4637425343195598                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :793
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826167
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399640
INFO:root:FL Epoch: 39 Norm Difference for worker 793 is 1.915556
INFO:root:FL Epoch: 39 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1430
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559836
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304956
INFO:root:FL Epoch: 39 Norm Difference for worker 1430 is 1.918506
INFO:root:FL Epoch: 39 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1259
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645567
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523688
INFO:root:FL Epoch: 39 Norm Difference for worker 1259 is 1.966853
INFO:root:FL Epoch: 39 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :83
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 83 is 1.986714
INFO:root:FL Epoch: 39 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :963
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757535
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426664
INFO:root:FL Epoch: 39 Norm Difference for worker 963 is 2.045191
INFO:root:FL Epoch: 39 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :727
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635814
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498839
INFO:root:FL Epoch: 39 Norm Difference for worker 727 is 1.948115
INFO:root:FL Epoch: 39 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1798
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724953
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427158
INFO:root:FL Epoch: 39 Norm Difference for worker 1798 is 1.928873
INFO:root:FL Epoch: 39 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1045
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430445
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440704
INFO:root:FL Epoch: 39 Norm Difference for worker 1045 is 1.88768
INFO:root:FL Epoch: 39 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :795
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562743
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469778
INFO:root:FL Epoch: 39 Norm Difference for worker 795 is 1.938514
INFO:root:FL Epoch: 39 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570052
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530302
INFO:root:FL Epoch: 39 Norm Difference for worker 1544 is 1.982316
INFO:root:FL Epoch: 39 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.837036478713738, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.836991765998276
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8369911767815412
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8369911609517438
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.5679832854691673 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:1.5333865483601887                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :1876
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746356
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354489
INFO:root:FL Epoch: 40 Norm Difference for worker 1876 is 2.060707
INFO:root:FL Epoch: 40 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1511
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698046
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334417
INFO:root:FL Epoch: 40 Norm Difference for worker 1511 is 1.998374
INFO:root:FL Epoch: 40 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1817
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597441
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253703
INFO:root:FL Epoch: 40 Norm Difference for worker 1817 is 2.019883
INFO:root:FL Epoch: 40 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :696
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676085
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555693
INFO:root:FL Epoch: 40 Norm Difference for worker 696 is 1.988332
INFO:root:FL Epoch: 40 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :514
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633279
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388738
INFO:root:FL Epoch: 40 Norm Difference for worker 514 is 1.881109
INFO:root:FL Epoch: 40 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :724
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628681
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560244
INFO:root:FL Epoch: 40 Norm Difference for worker 724 is 1.988456
INFO:root:FL Epoch: 40 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :71
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434600
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 71 is 1.829448
INFO:root:FL Epoch: 40 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1627
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460113
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489878
INFO:root:FL Epoch: 40 Norm Difference for worker 1627 is 1.96072
INFO:root:FL Epoch: 40 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1036
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513033
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262051
INFO:root:FL Epoch: 40 Norm Difference for worker 1036 is 1.95213
INFO:root:FL Epoch: 40 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1139
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525006
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411600
INFO:root:FL Epoch: 40 Norm Difference for worker 1139 is 1.968744
INFO:root:FL Epoch: 40 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8289901204660268, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8288764609287607
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8288749234221673
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8288748988810055
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.5641829073429108 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.4973317583401997                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [431, 1920, 659, 855, 1679, 48, 359, 1794, 466, 1659]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :431
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595047
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431717
INFO:root:FL Epoch: 41 Norm Difference for worker 431 is 1.943856
INFO:root:FL Epoch: 41 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1920
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593742
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427781
INFO:root:FL Epoch: 41 Norm Difference for worker 1920 is 2.017502
INFO:root:FL Epoch: 41 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670782
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486519
INFO:root:FL Epoch: 41 Norm Difference for worker 659 is 2.031179
INFO:root:FL Epoch: 41 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :855
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653706
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481607
INFO:root:FL Epoch: 41 Norm Difference for worker 855 is 1.9349
INFO:root:FL Epoch: 41 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1679
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660553
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368086
INFO:root:FL Epoch: 41 Norm Difference for worker 1679 is 2.086363
INFO:root:FL Epoch: 41 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :48
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 48 is 1.950838
INFO:root:FL Epoch: 41 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :359
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403031
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425484
INFO:root:FL Epoch: 41 Norm Difference for worker 359 is 1.937524
INFO:root:FL Epoch: 41 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1794
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504898
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449393
INFO:root:FL Epoch: 41 Norm Difference for worker 1794 is 2.128464
INFO:root:FL Epoch: 41 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :466
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430765
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438346
INFO:root:FL Epoch: 41 Norm Difference for worker 466 is 1.91844
INFO:root:FL Epoch: 41 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768307
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349826
INFO:root:FL Epoch: 41 Norm Difference for worker 1659 is 1.983073
INFO:root:FL Epoch: 41 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8638441325478416, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8637409572645374
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8637396630614573
INFO:root:#### Oracle Cals: 4, Objective Val: 1.863739620616913
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.5402244802783517 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:1.221642275651296                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1016
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521960
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318421
INFO:root:FL Epoch: 42 Norm Difference for worker 1016 is 2.059223
INFO:root:FL Epoch: 42 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :758
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547004
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572439
INFO:root:FL Epoch: 42 Norm Difference for worker 758 is 1.859377
INFO:root:FL Epoch: 42 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1919
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494212
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625921
INFO:root:FL Epoch: 42 Norm Difference for worker 1919 is 2.038736
INFO:root:FL Epoch: 42 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1693
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607049
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369237
INFO:root:FL Epoch: 42 Norm Difference for worker 1693 is 1.887036
INFO:root:FL Epoch: 42 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1465
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610143
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382118
INFO:root:FL Epoch: 42 Norm Difference for worker 1465 is 1.952735
INFO:root:FL Epoch: 42 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :882
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670988
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463409
INFO:root:FL Epoch: 42 Norm Difference for worker 882 is 1.947367
INFO:root:FL Epoch: 42 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :176
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 176 is 1.980903
INFO:root:FL Epoch: 42 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1854
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501076
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409107
INFO:root:FL Epoch: 42 Norm Difference for worker 1854 is 2.074367
INFO:root:FL Epoch: 42 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :107
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 107 is 1.999989
INFO:root:FL Epoch: 42 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :77
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 77 is 1.955363
INFO:root:FL Epoch: 42 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8379108834227629, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8377876145577836
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8377859388910038
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8377858557774083
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.5465682113871855 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:1.1407113273938496                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 43 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :301
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 301 is 1.991666
INFO:root:FL Epoch: 43 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :961
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690844
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315216
INFO:root:FL Epoch: 43 Norm Difference for worker 961 is 1.919314
INFO:root:FL Epoch: 43 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1081
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724845
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486223
INFO:root:FL Epoch: 43 Norm Difference for worker 1081 is 1.96627
INFO:root:FL Epoch: 43 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :165
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 165 is 1.96557
INFO:root:FL Epoch: 43 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1765
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518053
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551557
INFO:root:FL Epoch: 43 Norm Difference for worker 1765 is 1.801376
INFO:root:FL Epoch: 43 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.859655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 2.013775
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :21
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 21 is 1.879515
INFO:root:FL Epoch: 43 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :425
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611226
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457637
INFO:root:FL Epoch: 43 Norm Difference for worker 425 is 1.92712
INFO:root:FL Epoch: 43 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1827
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696508
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456205
INFO:root:FL Epoch: 43 Norm Difference for worker 1827 is 1.942948
INFO:root:FL Epoch: 43 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1721
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399151
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347246
INFO:root:FL Epoch: 43 Norm Difference for worker 1721 is 1.915041
INFO:root:FL Epoch: 43 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8118588480158513, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.811780481838189
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8117795480655186
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8117795056980222
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.5262184143066406 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:1.2682069341341655                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :617
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291715
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318211
INFO:root:FL Epoch: 44 Norm Difference for worker 617 is 1.974102
INFO:root:FL Epoch: 44 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :842
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551366
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518347
INFO:root:FL Epoch: 44 Norm Difference for worker 842 is 1.972099
INFO:root:FL Epoch: 44 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :851
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545527
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257315
INFO:root:FL Epoch: 44 Norm Difference for worker 851 is 1.794005
INFO:root:FL Epoch: 44 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :604
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437092
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229096
INFO:root:FL Epoch: 44 Norm Difference for worker 604 is 2.061562
INFO:root:FL Epoch: 44 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1478
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448928
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221983
INFO:root:FL Epoch: 44 Norm Difference for worker 1478 is 1.852923
INFO:root:FL Epoch: 44 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1239
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596562
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428963
INFO:root:FL Epoch: 44 Norm Difference for worker 1239 is 2.079337
INFO:root:FL Epoch: 44 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1744
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759531
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487413
INFO:root:FL Epoch: 44 Norm Difference for worker 1744 is 2.040346
INFO:root:FL Epoch: 44 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1946
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731175
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530553
INFO:root:FL Epoch: 44 Norm Difference for worker 1946 is 2.038746
INFO:root:FL Epoch: 44 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1499
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539186
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337004
INFO:root:FL Epoch: 44 Norm Difference for worker 1499 is 1.974918
INFO:root:FL Epoch: 44 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1072
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505805
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401477
INFO:root:FL Epoch: 44 Norm Difference for worker 1072 is 1.923609
INFO:root:FL Epoch: 44 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8404496049068577, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8401922441126752
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8401889492295833
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8401888396321875
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.5455580634229323 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:1.4398355682690938                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :284
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 284 is 2.092899
INFO:root:FL Epoch: 45 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :629
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471948
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332788
INFO:root:FL Epoch: 45 Norm Difference for worker 629 is 1.962066
INFO:root:FL Epoch: 45 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1483
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510129
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257554
INFO:root:FL Epoch: 45 Norm Difference for worker 1483 is 1.955887
INFO:root:FL Epoch: 45 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :496
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850447
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277954
INFO:root:FL Epoch: 45 Norm Difference for worker 496 is 1.949298
INFO:root:FL Epoch: 45 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1902
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376860
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347412
INFO:root:FL Epoch: 45 Norm Difference for worker 1902 is 2.0415
INFO:root:FL Epoch: 45 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :261
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 261 is 2.118767
INFO:root:FL Epoch: 45 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1691
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756523
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367428
INFO:root:FL Epoch: 45 Norm Difference for worker 1691 is 2.042065
INFO:root:FL Epoch: 45 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :309
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 309 is 2.003788
INFO:root:FL Epoch: 45 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :195
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 195 is 2.044041
INFO:root:FL Epoch: 45 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :346
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516440
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382400
INFO:root:FL Epoch: 45 Norm Difference for worker 346 is 2.067894
INFO:root:FL Epoch: 45 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9028430286624838, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9027677408651757
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9027668342124207
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9027667822393712
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.5493063944227555 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:1.592856228351593                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1012
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630583
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479451
INFO:root:FL Epoch: 46 Norm Difference for worker 1012 is 2.013458
INFO:root:FL Epoch: 46 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1287
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491919
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405855
INFO:root:FL Epoch: 46 Norm Difference for worker 1287 is 2.111527
INFO:root:FL Epoch: 46 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1772
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577142
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533001
INFO:root:FL Epoch: 46 Norm Difference for worker 1772 is 2.141448
INFO:root:FL Epoch: 46 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :973
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604403
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387401
INFO:root:FL Epoch: 46 Norm Difference for worker 973 is 2.096553
INFO:root:FL Epoch: 46 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :355
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767433
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534677
INFO:root:FL Epoch: 46 Norm Difference for worker 355 is 2.170164
INFO:root:FL Epoch: 46 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :15
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 15 is 2.021985
INFO:root:FL Epoch: 46 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1335
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517264
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492046
INFO:root:FL Epoch: 46 Norm Difference for worker 1335 is 2.02581
INFO:root:FL Epoch: 46 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :859
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439636
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421336
INFO:root:FL Epoch: 46 Norm Difference for worker 859 is 2.073119
INFO:root:FL Epoch: 46 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1060
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371750
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625444
INFO:root:FL Epoch: 46 Norm Difference for worker 1060 is 2.272999
INFO:root:FL Epoch: 46 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1175
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768830
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382081
INFO:root:FL Epoch: 46 Norm Difference for worker 1175 is 2.10278
INFO:root:FL Epoch: 46 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9698363604650417, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9697092367413276
INFO:root:#### Oracle Cals: 3, Objective Val: 1.969707699452725
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9697076891885392
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.542116782244514 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:1.313535471757253                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1026
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656619
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247483
INFO:root:FL Epoch: 47 Norm Difference for worker 1026 is 1.91937
INFO:root:FL Epoch: 47 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1386
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505222
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250577
INFO:root:FL Epoch: 47 Norm Difference for worker 1386 is 1.858126
INFO:root:FL Epoch: 47 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :370
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595607
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395828
INFO:root:FL Epoch: 47 Norm Difference for worker 370 is 1.906628
INFO:root:FL Epoch: 47 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1316
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543116
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531530
INFO:root:FL Epoch: 47 Norm Difference for worker 1316 is 1.920679
INFO:root:FL Epoch: 47 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1423
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707038
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342575
INFO:root:FL Epoch: 47 Norm Difference for worker 1423 is 1.910135
INFO:root:FL Epoch: 47 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1323
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484196
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388301
INFO:root:FL Epoch: 47 Norm Difference for worker 1323 is 2.047567
INFO:root:FL Epoch: 47 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1440
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522832
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441947
INFO:root:FL Epoch: 47 Norm Difference for worker 1440 is 1.92586
INFO:root:FL Epoch: 47 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :374
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622454
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570821
INFO:root:FL Epoch: 47 Norm Difference for worker 374 is 1.944808
INFO:root:FL Epoch: 47 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :641
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535493
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415539
INFO:root:FL Epoch: 47 Norm Difference for worker 641 is 1.935729
INFO:root:FL Epoch: 47 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :685
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512668
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416562
INFO:root:FL Epoch: 47 Norm Difference for worker 685 is 1.876731
INFO:root:FL Epoch: 47 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8054405672449243, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8053766533158833
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8053758345860473
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8053758610308877
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.556371914989808 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:1.7460434834162395                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :742
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531301
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258498
INFO:root:FL Epoch: 48 Norm Difference for worker 742 is 2.00815
INFO:root:FL Epoch: 48 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :885
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691599
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297569
INFO:root:FL Epoch: 48 Norm Difference for worker 885 is 2.093991
INFO:root:FL Epoch: 48 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :169
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 169 is 2.095421
INFO:root:FL Epoch: 48 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622960
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346870
INFO:root:FL Epoch: 48 Norm Difference for worker 1527 is 1.900223
INFO:root:FL Epoch: 48 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :884
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411837
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319915
INFO:root:FL Epoch: 48 Norm Difference for worker 884 is 2.108603
INFO:root:FL Epoch: 48 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1072
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483935
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356928
INFO:root:FL Epoch: 48 Norm Difference for worker 1072 is 1.964309
INFO:root:FL Epoch: 48 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :458
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501942
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517474
INFO:root:FL Epoch: 48 Norm Difference for worker 458 is 1.974618
INFO:root:FL Epoch: 48 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1623
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522885
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379522
INFO:root:FL Epoch: 48 Norm Difference for worker 1623 is 1.991314
INFO:root:FL Epoch: 48 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1318
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561355
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395960
INFO:root:FL Epoch: 48 Norm Difference for worker 1318 is 2.031054
INFO:root:FL Epoch: 48 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1808
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471995
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349456
INFO:root:FL Epoch: 48 Norm Difference for worker 1808 is 2.136323
INFO:root:FL Epoch: 48 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.909682260564548, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.909592666162757
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9095915597389015
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9095915154747876
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.5541301755344167 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.6403386394182842                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :1089
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675297
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282195
INFO:root:FL Epoch: 49 Norm Difference for worker 1089 is 1.966135
INFO:root:FL Epoch: 49 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1220
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460430
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501114
INFO:root:FL Epoch: 49 Norm Difference for worker 1220 is 2.106603
INFO:root:FL Epoch: 49 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :832
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505371
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516853
INFO:root:FL Epoch: 49 Norm Difference for worker 832 is 2.141899
INFO:root:FL Epoch: 49 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :348
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674991
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601718
INFO:root:FL Epoch: 49 Norm Difference for worker 348 is 2.055967
INFO:root:FL Epoch: 49 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1483
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594138
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298410
INFO:root:FL Epoch: 49 Norm Difference for worker 1483 is 1.951851
INFO:root:FL Epoch: 49 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1709
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421224
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277102
INFO:root:FL Epoch: 49 Norm Difference for worker 1709 is 2.171173
INFO:root:FL Epoch: 49 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :170
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 170 is 2.074872
INFO:root:FL Epoch: 49 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665064
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346406
INFO:root:FL Epoch: 49 Norm Difference for worker 862 is 2.137649
INFO:root:FL Epoch: 49 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1619
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610974
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401819
INFO:root:FL Epoch: 49 Norm Difference for worker 1619 is 2.061396
INFO:root:FL Epoch: 49 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :52
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 52 is 2.183335
INFO:root:FL Epoch: 49 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9643909758975109, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9642517512624553
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9642501671664931
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9642501250493014
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.5716226994991302 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:1.5140670537948608                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :1159
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832702
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364092
INFO:root:FL Epoch: 50 Norm Difference for worker 1159 is 2.011388
INFO:root:FL Epoch: 50 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :973
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600171
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344524
INFO:root:FL Epoch: 50 Norm Difference for worker 973 is 1.939131
INFO:root:FL Epoch: 50 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :918
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467121
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455205
INFO:root:FL Epoch: 50 Norm Difference for worker 918 is 2.074279
INFO:root:FL Epoch: 50 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :978
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746347
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316363
INFO:root:FL Epoch: 50 Norm Difference for worker 978 is 1.978515
INFO:root:FL Epoch: 50 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1454
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558607
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453748
INFO:root:FL Epoch: 50 Norm Difference for worker 1454 is 1.885393
INFO:root:FL Epoch: 50 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1102
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575786
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298787
INFO:root:FL Epoch: 50 Norm Difference for worker 1102 is 2.082955
INFO:root:FL Epoch: 50 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :762
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641883
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471868
INFO:root:FL Epoch: 50 Norm Difference for worker 762 is 1.999196
INFO:root:FL Epoch: 50 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :302
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 302 is 1.985926
INFO:root:FL Epoch: 50 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1871
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443426
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325632
INFO:root:FL Epoch: 50 Norm Difference for worker 1871 is 2.085835
INFO:root:FL Epoch: 50 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :580
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612443
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360116
INFO:root:FL Epoch: 50 Norm Difference for worker 580 is 2.002867
INFO:root:FL Epoch: 50 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8788882174887445, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8787931780303218
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8787919002958373
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8787919033415994
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.5740130070377799 and Test Accuracy:70.0 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.8307401339213054                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [1942, 848, 888, 1807, 655, 164, 302, 119, 1277, 1553]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :1942
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474871
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399903
INFO:root:FL Epoch: 51 Norm Difference for worker 1942 is 2.112384
INFO:root:FL Epoch: 51 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :848
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780047
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399936
INFO:root:FL Epoch: 51 Norm Difference for worker 848 is 2.120005
INFO:root:FL Epoch: 51 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :888
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706753
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483839
INFO:root:FL Epoch: 51 Norm Difference for worker 888 is 2.099959
INFO:root:FL Epoch: 51 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1807
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850466
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348550
INFO:root:FL Epoch: 51 Norm Difference for worker 1807 is 2.050411
INFO:root:FL Epoch: 51 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :655
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594509
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337243
INFO:root:FL Epoch: 51 Norm Difference for worker 655 is 1.932492
INFO:root:FL Epoch: 51 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :164
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 164 is 2.086006
INFO:root:FL Epoch: 51 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :302
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 302 is 1.921651
INFO:root:FL Epoch: 51 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :119
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.358712
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 119 is 2.162292
INFO:root:FL Epoch: 51 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1277
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710090
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236341
INFO:root:FL Epoch: 51 Norm Difference for worker 1277 is 2.090866
INFO:root:FL Epoch: 51 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1553
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750433
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308929
INFO:root:FL Epoch: 51 Norm Difference for worker 1553 is 2.083049
INFO:root:FL Epoch: 51 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9487465920177551, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9486133709016829
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9486113544593535
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9486113516607393
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.5556620955467224 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:1.4952370127042134                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :410
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416038
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286740
INFO:root:FL Epoch: 52 Norm Difference for worker 410 is 2.063557
INFO:root:FL Epoch: 52 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :710
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692057
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431815
INFO:root:FL Epoch: 52 Norm Difference for worker 710 is 2.121496
INFO:root:FL Epoch: 52 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1013
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526327
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427494
INFO:root:FL Epoch: 52 Norm Difference for worker 1013 is 2.140819
INFO:root:FL Epoch: 52 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :60
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 60 is 2.039906
INFO:root:FL Epoch: 52 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :109
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626261
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454952
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 109 is 2.216198
INFO:root:FL Epoch: 52 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1576
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573380
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308129
INFO:root:FL Epoch: 52 Norm Difference for worker 1576 is 2.07154
INFO:root:FL Epoch: 52 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :931
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696203
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251252
INFO:root:FL Epoch: 52 Norm Difference for worker 931 is 2.185806
INFO:root:FL Epoch: 52 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :407
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758500
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327251
INFO:root:FL Epoch: 52 Norm Difference for worker 407 is 1.923486
INFO:root:FL Epoch: 52 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :697
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621576
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243661
INFO:root:FL Epoch: 52 Norm Difference for worker 697 is 2.16584
INFO:root:FL Epoch: 52 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1217
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440815
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494678
INFO:root:FL Epoch: 52 Norm Difference for worker 1217 is 2.14374
INFO:root:FL Epoch: 52 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9826077429417273, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9824399301262612
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9824375225170625
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9824374826342095
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.5547374416800106 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:1.7516385316848755                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1299
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592418
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390630
INFO:root:FL Epoch: 53 Norm Difference for worker 1299 is 2.020184
INFO:root:FL Epoch: 53 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :593
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776748
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482627
INFO:root:FL Epoch: 53 Norm Difference for worker 593 is 2.080757
INFO:root:FL Epoch: 53 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1438
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737517
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340230
INFO:root:FL Epoch: 53 Norm Difference for worker 1438 is 2.07205
INFO:root:FL Epoch: 53 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1891
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613703
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429888
INFO:root:FL Epoch: 53 Norm Difference for worker 1891 is 2.000154
INFO:root:FL Epoch: 53 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1705
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432215
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289214
INFO:root:FL Epoch: 53 Norm Difference for worker 1705 is 2.113807
INFO:root:FL Epoch: 53 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1052
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668853
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298513
INFO:root:FL Epoch: 53 Norm Difference for worker 1052 is 2.050227
INFO:root:FL Epoch: 53 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1474
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741330
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293733
INFO:root:FL Epoch: 53 Norm Difference for worker 1474 is 2.046119
INFO:root:FL Epoch: 53 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :550
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683038
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311425
INFO:root:FL Epoch: 53 Norm Difference for worker 550 is 2.05735
INFO:root:FL Epoch: 53 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :475
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562017
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371408
INFO:root:FL Epoch: 53 Norm Difference for worker 475 is 2.009859
INFO:root:FL Epoch: 53 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1925
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627509
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330126
INFO:root:FL Epoch: 53 Norm Difference for worker 1925 is 2.090344
INFO:root:FL Epoch: 53 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9384507046648736, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9384328598266138
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9384326295216887
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9384326577856064
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.5484471443821403 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.6138648589452107                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 54 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :1628
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608272
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304991
INFO:root:FL Epoch: 54 Norm Difference for worker 1628 is 1.927338
INFO:root:FL Epoch: 54 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :165
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704735
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 165 is 2.080403
INFO:root:FL Epoch: 54 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :671
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487063
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327786
INFO:root:FL Epoch: 54 Norm Difference for worker 671 is 1.99621
INFO:root:FL Epoch: 54 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :216
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431070
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 216 is 1.995833
INFO:root:FL Epoch: 54 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :620
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706429
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323583
INFO:root:FL Epoch: 54 Norm Difference for worker 620 is 1.879051
INFO:root:FL Epoch: 54 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :465
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462684
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361174
INFO:root:FL Epoch: 54 Norm Difference for worker 465 is 2.040863
INFO:root:FL Epoch: 54 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :72
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350715
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 72 is 2.020772
INFO:root:FL Epoch: 54 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :559
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771365
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323366
INFO:root:FL Epoch: 54 Norm Difference for worker 559 is 1.979978
INFO:root:FL Epoch: 54 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :886
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561878
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331124
INFO:root:FL Epoch: 54 Norm Difference for worker 886 is 1.967247
INFO:root:FL Epoch: 54 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1530
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629862
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339390
INFO:root:FL Epoch: 54 Norm Difference for worker 1530 is 2.042215
INFO:root:FL Epoch: 54 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.878064297605694, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8779446926270347
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8779429013047029
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8779428825947624
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.5371732361176434 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:1.801067630449931                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1536
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583232
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426228
INFO:root:FL Epoch: 55 Norm Difference for worker 1536 is 1.970168
INFO:root:FL Epoch: 55 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1204
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611981
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439668
INFO:root:FL Epoch: 55 Norm Difference for worker 1204 is 2.077809
INFO:root:FL Epoch: 55 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1550
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591925
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397270
INFO:root:FL Epoch: 55 Norm Difference for worker 1550 is 2.059564
INFO:root:FL Epoch: 55 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1139
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453664
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300627
INFO:root:FL Epoch: 55 Norm Difference for worker 1139 is 1.981969
INFO:root:FL Epoch: 55 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :735
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589044
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396588
INFO:root:FL Epoch: 55 Norm Difference for worker 735 is 2.145755
INFO:root:FL Epoch: 55 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1804
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513688
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520477
INFO:root:FL Epoch: 55 Norm Difference for worker 1804 is 2.054473
INFO:root:FL Epoch: 55 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1303
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536075
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425741
INFO:root:FL Epoch: 55 Norm Difference for worker 1303 is 2.023756
INFO:root:FL Epoch: 55 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :856
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974036
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398288
INFO:root:FL Epoch: 55 Norm Difference for worker 856 is 2.224563
INFO:root:FL Epoch: 55 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1587
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506512
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345072
INFO:root:FL Epoch: 55 Norm Difference for worker 1587 is 2.030657
INFO:root:FL Epoch: 55 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :124
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 124 is 2.155011
INFO:root:FL Epoch: 55 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.954214117844218, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9541267292844284
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9541254655223166
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9541254289972574
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.5280048514113707 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:1.6994393467903137                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 56 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :103
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 103 is 1.958665
INFO:root:FL Epoch: 56 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :47
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 47 is 1.894427
INFO:root:FL Epoch: 56 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1805
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522812
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434126
INFO:root:FL Epoch: 56 Norm Difference for worker 1805 is 2.076397
INFO:root:FL Epoch: 56 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1280
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583344
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348983
INFO:root:FL Epoch: 56 Norm Difference for worker 1280 is 1.968975
INFO:root:FL Epoch: 56 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1599
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587946
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387625
INFO:root:FL Epoch: 56 Norm Difference for worker 1599 is 2.01543
INFO:root:FL Epoch: 56 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1088
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472754
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226042
INFO:root:FL Epoch: 56 Norm Difference for worker 1088 is 1.919836
INFO:root:FL Epoch: 56 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1092
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506105
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410371
INFO:root:FL Epoch: 56 Norm Difference for worker 1092 is 2.135667
INFO:root:FL Epoch: 56 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1468
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806194
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536481
INFO:root:FL Epoch: 56 Norm Difference for worker 1468 is 2.090866
INFO:root:FL Epoch: 56 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :962
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377914
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463688
INFO:root:FL Epoch: 56 Norm Difference for worker 962 is 1.976615
INFO:root:FL Epoch: 56 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1742
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476653
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331715
INFO:root:FL Epoch: 56 Norm Difference for worker 1742 is 2.060207
INFO:root:FL Epoch: 56 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8958454276191914, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8956704623101868
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8956682045536268
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8956681761986136
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.5168848388335284 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.574941615263621                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :1087
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478727
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426897
INFO:root:FL Epoch: 57 Norm Difference for worker 1087 is 1.997912
INFO:root:FL Epoch: 57 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :51
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.799980
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336630
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 51 is 1.996057
INFO:root:FL Epoch: 57 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :352
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625543
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341319
INFO:root:FL Epoch: 57 Norm Difference for worker 352 is 2.033673
INFO:root:FL Epoch: 57 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1760
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974793
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335363
INFO:root:FL Epoch: 57 Norm Difference for worker 1760 is 2.242765
INFO:root:FL Epoch: 57 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1518
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707549
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213899
INFO:root:FL Epoch: 57 Norm Difference for worker 1518 is 2.101107
INFO:root:FL Epoch: 57 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1886
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532183
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368703
INFO:root:FL Epoch: 57 Norm Difference for worker 1886 is 2.062167
INFO:root:FL Epoch: 57 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1418
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600015
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384680
INFO:root:FL Epoch: 57 Norm Difference for worker 1418 is 1.981293
INFO:root:FL Epoch: 57 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :593
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670197
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326201
INFO:root:FL Epoch: 57 Norm Difference for worker 593 is 2.067526
INFO:root:FL Epoch: 57 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :803
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408000
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329076
INFO:root:FL Epoch: 57 Norm Difference for worker 803 is 2.037837
INFO:root:FL Epoch: 57 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1360
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515639
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372630
INFO:root:FL Epoch: 57 Norm Difference for worker 1360 is 2.015822
INFO:root:FL Epoch: 57 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9341121533713106, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9339396402306417
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9339375385405626
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9339374995568546
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.545857276986627 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:2.003492812315623                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1472
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590630
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433812
INFO:root:FL Epoch: 58 Norm Difference for worker 1472 is 2.173756
INFO:root:FL Epoch: 58 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :142
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 142 is 2.08119
INFO:root:FL Epoch: 58 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :686
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645072
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434092
INFO:root:FL Epoch: 58 Norm Difference for worker 686 is 2.136657
INFO:root:FL Epoch: 58 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1238
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423190
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345805
INFO:root:FL Epoch: 58 Norm Difference for worker 1238 is 2.078011
INFO:root:FL Epoch: 58 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :610
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846833
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340170
INFO:root:FL Epoch: 58 Norm Difference for worker 610 is 2.035999
INFO:root:FL Epoch: 58 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :438
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576328
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390967
INFO:root:FL Epoch: 58 Norm Difference for worker 438 is 2.108944
INFO:root:FL Epoch: 58 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1853
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555565
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275708
INFO:root:FL Epoch: 58 Norm Difference for worker 1853 is 2.184474
INFO:root:FL Epoch: 58 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1371
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605758
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361455
INFO:root:FL Epoch: 58 Norm Difference for worker 1371 is 2.118246
INFO:root:FL Epoch: 58 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :839
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586429
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281246
INFO:root:FL Epoch: 58 Norm Difference for worker 839 is 2.126086
INFO:root:FL Epoch: 58 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1439
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699075
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343576
INFO:root:FL Epoch: 58 Norm Difference for worker 1439 is 2.206258
INFO:root:FL Epoch: 58 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9904954107077102, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.990386309785724
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9903848282483203
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9903848145460237
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.5322217467953178 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:1.4128817319869995                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1354
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785164
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375646
INFO:root:FL Epoch: 59 Norm Difference for worker 1354 is 2.068986
INFO:root:FL Epoch: 59 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :228
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409007
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 228 is 1.906787
INFO:root:FL Epoch: 59 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :462
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732901
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466944
INFO:root:FL Epoch: 59 Norm Difference for worker 462 is 2.019861
INFO:root:FL Epoch: 59 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1636
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568768
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255510
INFO:root:FL Epoch: 59 Norm Difference for worker 1636 is 2.00304
INFO:root:FL Epoch: 59 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1046
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473830
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380566
INFO:root:FL Epoch: 59 Norm Difference for worker 1046 is 1.993623
INFO:root:FL Epoch: 59 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1188
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421169
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653334
INFO:root:FL Epoch: 59 Norm Difference for worker 1188 is 2.125957
INFO:root:FL Epoch: 59 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1882
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624924
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297477
INFO:root:FL Epoch: 59 Norm Difference for worker 1882 is 2.025447
INFO:root:FL Epoch: 59 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1003
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579536
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425755
INFO:root:FL Epoch: 59 Norm Difference for worker 1003 is 1.994076
INFO:root:FL Epoch: 59 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1658
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410109
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447660
INFO:root:FL Epoch: 59 Norm Difference for worker 1658 is 1.865332
INFO:root:FL Epoch: 59 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1075
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581684
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430595
INFO:root:FL Epoch: 59 Norm Difference for worker 1075 is 2.01721
INFO:root:FL Epoch: 59 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.878361332398454, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8782450197079334
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8782435521267709
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8782435235643224
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.5378544102696812 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.939517895380656                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :160
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350556
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 160 is 2.259939
INFO:root:FL Epoch: 60 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1460
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362042
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278894
INFO:root:FL Epoch: 60 Norm Difference for worker 1460 is 2.004337
INFO:root:FL Epoch: 60 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1369
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506175
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314822
INFO:root:FL Epoch: 60 Norm Difference for worker 1369 is 2.139335
INFO:root:FL Epoch: 60 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1465
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736233
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480453
INFO:root:FL Epoch: 60 Norm Difference for worker 1465 is 2.139731
INFO:root:FL Epoch: 60 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :920
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417014
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309669
INFO:root:FL Epoch: 60 Norm Difference for worker 920 is 2.130797
INFO:root:FL Epoch: 60 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :167
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.251526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 167 is 2.174148
INFO:root:FL Epoch: 60 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :434
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481979
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277497
INFO:root:FL Epoch: 60 Norm Difference for worker 434 is 2.10639
INFO:root:FL Epoch: 60 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :908
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599418
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271060
INFO:root:FL Epoch: 60 Norm Difference for worker 908 is 2.056178
INFO:root:FL Epoch: 60 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1014
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924780
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280337
INFO:root:FL Epoch: 60 Norm Difference for worker 1014 is 2.029977
INFO:root:FL Epoch: 60 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1614
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386878
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403388
INFO:root:FL Epoch: 60 Norm Difference for worker 1614 is 2.297888
INFO:root:FL Epoch: 60 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 2.0069248199663408, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 2.0067997994136477
INFO:root:#### Oracle Cals: 3, Objective Val: 2.0067983534129175
INFO:root:#### Oracle Cals: 4, Objective Val: 2.006798363133327
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.5164190250284532 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:1.4773868123690288                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [1377, 126, 1194, 362, 1279, 1826, 1404, 1802, 128, 1290]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 61 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :1377
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528299
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330587
INFO:root:FL Epoch: 61 Norm Difference for worker 1377 is 1.978528
INFO:root:FL Epoch: 61 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :126
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 126 is 1.936491
INFO:root:FL Epoch: 61 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1194
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572921
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298857
INFO:root:FL Epoch: 61 Norm Difference for worker 1194 is 1.987681
INFO:root:FL Epoch: 61 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :362
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584931
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376992
INFO:root:FL Epoch: 61 Norm Difference for worker 362 is 1.943381
INFO:root:FL Epoch: 61 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1279
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665755
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335330
INFO:root:FL Epoch: 61 Norm Difference for worker 1279 is 1.848858
INFO:root:FL Epoch: 61 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1826
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317855
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480454
INFO:root:FL Epoch: 61 Norm Difference for worker 1826 is 1.844505
INFO:root:FL Epoch: 61 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1404
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355269
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345079
INFO:root:FL Epoch: 61 Norm Difference for worker 1404 is 1.771731
INFO:root:FL Epoch: 61 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1802
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494873
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287416
INFO:root:FL Epoch: 61 Norm Difference for worker 1802 is 1.867021
INFO:root:FL Epoch: 61 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :128
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 128 is 1.996552
INFO:root:FL Epoch: 61 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1290
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471174
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573842
INFO:root:FL Epoch: 61 Norm Difference for worker 1290 is 2.144432
INFO:root:FL Epoch: 61 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8225020065644304, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8222658641540659
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8222623326983356
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8222622775927935
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.5319655467482174 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.8773635427157085                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :228
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 228 is 1.869941
INFO:root:FL Epoch: 62 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :380
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645766
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354089
INFO:root:FL Epoch: 62 Norm Difference for worker 380 is 2.036871
INFO:root:FL Epoch: 62 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1593
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406370
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273519
INFO:root:FL Epoch: 62 Norm Difference for worker 1593 is 1.845516
INFO:root:FL Epoch: 62 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1340
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569183
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350979
INFO:root:FL Epoch: 62 Norm Difference for worker 1340 is 2.089429
INFO:root:FL Epoch: 62 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :838
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467217
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354471
INFO:root:FL Epoch: 62 Norm Difference for worker 838 is 1.992986
INFO:root:FL Epoch: 62 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :117
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 117 is 1.933834
INFO:root:FL Epoch: 62 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :48
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362001
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 48 is 2.014304
INFO:root:FL Epoch: 62 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :793
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655778
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536477
INFO:root:FL Epoch: 62 Norm Difference for worker 793 is 2.032389
INFO:root:FL Epoch: 62 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1118
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655648
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410343
INFO:root:FL Epoch: 62 Norm Difference for worker 1118 is 1.972538
INFO:root:FL Epoch: 62 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1657
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612157
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409270
INFO:root:FL Epoch: 62 Norm Difference for worker 1657 is 2.116957
INFO:root:FL Epoch: 62 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.876960402883702, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.876801217202861
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8767991606544399
INFO:root:#### Oracle Cals: 4, Objective Val: 1.876799151423597
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.5464495753540712 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.7483279307683308                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1234
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470110
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279962
INFO:root:FL Epoch: 63 Norm Difference for worker 1234 is 2.130818
INFO:root:FL Epoch: 63 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :729
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364073
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202621
INFO:root:FL Epoch: 63 Norm Difference for worker 729 is 2.030315
INFO:root:FL Epoch: 63 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :469
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466199
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176813
INFO:root:FL Epoch: 63 Norm Difference for worker 469 is 2.050036
INFO:root:FL Epoch: 63 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :846
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729664
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332983
INFO:root:FL Epoch: 63 Norm Difference for worker 846 is 2.124286
INFO:root:FL Epoch: 63 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1600
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726560
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278482
INFO:root:FL Epoch: 63 Norm Difference for worker 1600 is 2.118585
INFO:root:FL Epoch: 63 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :157
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 157 is 2.086976
INFO:root:FL Epoch: 63 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1182
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492375
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339270
INFO:root:FL Epoch: 63 Norm Difference for worker 1182 is 1.986139
INFO:root:FL Epoch: 63 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1061
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687044
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367450
INFO:root:FL Epoch: 63 Norm Difference for worker 1061 is 2.03239
INFO:root:FL Epoch: 63 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1408
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491396
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401957
INFO:root:FL Epoch: 63 Norm Difference for worker 1408 is 2.170494
INFO:root:FL Epoch: 63 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :650
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481728
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607365
INFO:root:FL Epoch: 63 Norm Difference for worker 650 is 2.240877
INFO:root:FL Epoch: 63 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9900779908862352, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9899503833205636
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9899487468984078
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9899487123568806
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.5428453438422259 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.954300085703532                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :207
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 207 is 2.142394
INFO:root:FL Epoch: 64 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :542
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610848
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359056
INFO:root:FL Epoch: 64 Norm Difference for worker 542 is 2.029938
INFO:root:FL Epoch: 64 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1793
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644181
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341255
INFO:root:FL Epoch: 64 Norm Difference for worker 1793 is 2.098973
INFO:root:FL Epoch: 64 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1161
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834348
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379846
INFO:root:FL Epoch: 64 Norm Difference for worker 1161 is 2.158825
INFO:root:FL Epoch: 64 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1832
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704764
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491217
INFO:root:FL Epoch: 64 Norm Difference for worker 1832 is 2.083703
INFO:root:FL Epoch: 64 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1180
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479166
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391156
INFO:root:FL Epoch: 64 Norm Difference for worker 1180 is 2.004425
INFO:root:FL Epoch: 64 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1370
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537562
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354994
INFO:root:FL Epoch: 64 Norm Difference for worker 1370 is 2.060202
INFO:root:FL Epoch: 64 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :679
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521565
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303521
INFO:root:FL Epoch: 64 Norm Difference for worker 679 is 1.986833
INFO:root:FL Epoch: 64 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1235
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339303
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334922
INFO:root:FL Epoch: 64 Norm Difference for worker 1235 is 2.039632
INFO:root:FL Epoch: 64 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :562
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745434
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370792
INFO:root:FL Epoch: 64 Norm Difference for worker 562 is 2.079233
INFO:root:FL Epoch: 64 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.925429903901918, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9253904557261676
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9253900036498655
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9253900008724814
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5364993074361015 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:1.8139688968658447                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 65 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :7
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 7 is 2.101171
INFO:root:FL Epoch: 65 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :806
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702431
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437788
INFO:root:FL Epoch: 65 Norm Difference for worker 806 is 2.214425
INFO:root:FL Epoch: 65 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :172
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433449
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 172 is 1.980125
INFO:root:FL Epoch: 65 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :751
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554218
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249478
INFO:root:FL Epoch: 65 Norm Difference for worker 751 is 1.87592
INFO:root:FL Epoch: 65 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :922
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521357
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288188
INFO:root:FL Epoch: 65 Norm Difference for worker 922 is 2.027507
INFO:root:FL Epoch: 65 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1606
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622220
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296452
INFO:root:FL Epoch: 65 Norm Difference for worker 1606 is 2.061312
INFO:root:FL Epoch: 65 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :904
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417939
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256283
INFO:root:FL Epoch: 65 Norm Difference for worker 904 is 1.902544
INFO:root:FL Epoch: 65 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1023
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653669
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384242
INFO:root:FL Epoch: 65 Norm Difference for worker 1023 is 2.00369
INFO:root:FL Epoch: 65 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :451
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505735
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449774
INFO:root:FL Epoch: 65 Norm Difference for worker 451 is 2.16767
INFO:root:FL Epoch: 65 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :871
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500749
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366172
INFO:root:FL Epoch: 65 Norm Difference for worker 871 is 1.96956
INFO:root:FL Epoch: 65 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9227942882813407, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.922496728520642
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9224927447234175
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9224926893278642
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.5089013348607456 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.6878147919972737                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1824
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643868
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307656
INFO:root:FL Epoch: 66 Norm Difference for worker 1824 is 2.220532
INFO:root:FL Epoch: 66 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :776
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562932
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403631
INFO:root:FL Epoch: 66 Norm Difference for worker 776 is 2.000742
INFO:root:FL Epoch: 66 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :679
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525260
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307317
INFO:root:FL Epoch: 66 Norm Difference for worker 679 is 1.983504
INFO:root:FL Epoch: 66 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1263
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664940
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285299
INFO:root:FL Epoch: 66 Norm Difference for worker 1263 is 2.037279
INFO:root:FL Epoch: 66 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1658
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632919
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293172
INFO:root:FL Epoch: 66 Norm Difference for worker 1658 is 1.996913
INFO:root:FL Epoch: 66 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :161
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286812
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 161 is 2.019042
INFO:root:FL Epoch: 66 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :623
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462524
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326602
INFO:root:FL Epoch: 66 Norm Difference for worker 623 is 2.134181
INFO:root:FL Epoch: 66 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1308
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763668
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491778
INFO:root:FL Epoch: 66 Norm Difference for worker 1308 is 2.117728
INFO:root:FL Epoch: 66 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :248
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 248 is 2.063866
INFO:root:FL Epoch: 66 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :692
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464356
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371764
INFO:root:FL Epoch: 66 Norm Difference for worker 692 is 2.149834
INFO:root:FL Epoch: 66 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.961272149203312, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9611383302662078
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9611365228713817
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9611364785369476
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.5059534872279448 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:2.0577575961748757                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :1855
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572185
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315818
INFO:root:FL Epoch: 67 Norm Difference for worker 1855 is 2.048006
INFO:root:FL Epoch: 67 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :447
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610113
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409070
INFO:root:FL Epoch: 67 Norm Difference for worker 447 is 2.107165
INFO:root:FL Epoch: 67 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :860
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599560
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279016
INFO:root:FL Epoch: 67 Norm Difference for worker 860 is 2.213062
INFO:root:FL Epoch: 67 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435224
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425252
INFO:root:FL Epoch: 67 Norm Difference for worker 1575 is 2.103998
INFO:root:FL Epoch: 67 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :818
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544334
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314902
INFO:root:FL Epoch: 67 Norm Difference for worker 818 is 2.133904
INFO:root:FL Epoch: 67 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1745
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480700
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300428
INFO:root:FL Epoch: 67 Norm Difference for worker 1745 is 1.99977
INFO:root:FL Epoch: 67 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :201
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345074
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 201 is 2.095324
INFO:root:FL Epoch: 67 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :82
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 82 is 2.037928
INFO:root:FL Epoch: 67 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :907
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478730
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308810
INFO:root:FL Epoch: 67 Norm Difference for worker 907 is 2.111383
INFO:root:FL Epoch: 67 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1068
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577385
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282002
INFO:root:FL Epoch: 67 Norm Difference for worker 1068 is 2.005108
INFO:root:FL Epoch: 67 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9667581693455023, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9666683788075354
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9666672713357678
INFO:root:#### Oracle Cals: 4, Objective Val: 1.966667266298684
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5234652775175431 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.5598500768343608                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1385
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340318
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515769
INFO:root:FL Epoch: 68 Norm Difference for worker 1385 is 2.054063
INFO:root:FL Epoch: 68 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1108
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943257
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380738
INFO:root:FL Epoch: 68 Norm Difference for worker 1108 is 2.085505
INFO:root:FL Epoch: 68 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1575
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560828
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201973
INFO:root:FL Epoch: 68 Norm Difference for worker 1575 is 1.888548
INFO:root:FL Epoch: 68 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :567
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515991
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225694
INFO:root:FL Epoch: 68 Norm Difference for worker 567 is 1.925815
INFO:root:FL Epoch: 68 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1334
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502348
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235344
INFO:root:FL Epoch: 68 Norm Difference for worker 1334 is 2.085108
INFO:root:FL Epoch: 68 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :186
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 186 is 2.06723
INFO:root:FL Epoch: 68 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :589
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715004
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470655
INFO:root:FL Epoch: 68 Norm Difference for worker 589 is 2.149851
INFO:root:FL Epoch: 68 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :861
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770700
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356752
INFO:root:FL Epoch: 68 Norm Difference for worker 861 is 2.16323
INFO:root:FL Epoch: 68 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :249
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 249 is 2.024565
INFO:root:FL Epoch: 68 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :363
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642456
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378190
INFO:root:FL Epoch: 68 Norm Difference for worker 363 is 2.174008
INFO:root:FL Epoch: 68 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.924419063174293, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9242763422139806
INFO:root:#### Oracle Cals: 3, Objective Val: 1.924274608127017
INFO:root:#### Oracle Cals: 4, Objective Val: 1.924274585218614
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5125678725102368 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.6600794990857441                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :1792
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371968
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265505
INFO:root:FL Epoch: 69 Norm Difference for worker 1792 is 1.949973
INFO:root:FL Epoch: 69 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1931
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477437
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360061
INFO:root:FL Epoch: 69 Norm Difference for worker 1931 is 2.103106
INFO:root:FL Epoch: 69 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1446
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541316
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386211
INFO:root:FL Epoch: 69 Norm Difference for worker 1446 is 2.006074
INFO:root:FL Epoch: 69 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1658
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391196
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260782
INFO:root:FL Epoch: 69 Norm Difference for worker 1658 is 1.884266
INFO:root:FL Epoch: 69 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1501
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500171
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312882
INFO:root:FL Epoch: 69 Norm Difference for worker 1501 is 2.152408
INFO:root:FL Epoch: 69 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :633
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495000
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197824
INFO:root:FL Epoch: 69 Norm Difference for worker 633 is 2.023123
INFO:root:FL Epoch: 69 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :191
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 191 is 2.139365
INFO:root:FL Epoch: 69 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :365
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453648
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390896
INFO:root:FL Epoch: 69 Norm Difference for worker 365 is 2.071857
INFO:root:FL Epoch: 69 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :539
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765424
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327550
INFO:root:FL Epoch: 69 Norm Difference for worker 539 is 2.153505
INFO:root:FL Epoch: 69 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1151
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609005
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375357
INFO:root:FL Epoch: 69 Norm Difference for worker 1151 is 2.000702
INFO:root:FL Epoch: 69 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9166720247862654, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9165196108553362
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9165175282203553
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9165174987260056
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5252592107828926 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.6146787603696187                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1947
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556132
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227214
INFO:root:FL Epoch: 70 Norm Difference for worker 1947 is 2.02674
INFO:root:FL Epoch: 70 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :708
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595154
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336760
INFO:root:FL Epoch: 70 Norm Difference for worker 708 is 1.946283
INFO:root:FL Epoch: 70 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1032
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521122
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321836
INFO:root:FL Epoch: 70 Norm Difference for worker 1032 is 2.026502
INFO:root:FL Epoch: 70 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1835
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812109
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378747
INFO:root:FL Epoch: 70 Norm Difference for worker 1835 is 2.197565
INFO:root:FL Epoch: 70 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1097
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557911
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414012
INFO:root:FL Epoch: 70 Norm Difference for worker 1097 is 2.122774
INFO:root:FL Epoch: 70 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1636
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599419
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422595
INFO:root:FL Epoch: 70 Norm Difference for worker 1636 is 2.152087
INFO:root:FL Epoch: 70 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :104
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 104 is 2.045798
INFO:root:FL Epoch: 70 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1018
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486498
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402484
INFO:root:FL Epoch: 70 Norm Difference for worker 1018 is 2.003403
INFO:root:FL Epoch: 70 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :783
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692837
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537064
INFO:root:FL Epoch: 70 Norm Difference for worker 783 is 2.089863
INFO:root:FL Epoch: 70 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1165
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475992
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397555
INFO:root:FL Epoch: 70 Norm Difference for worker 1165 is 2.095562
INFO:root:FL Epoch: 70 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9449698635610084, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.944843284932237
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9448416684252852
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9448416152333403
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.5211582814945894 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.9184362292289734                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [62, 1637, 492, 467, 439, 1788, 1531, 1101, 1372, 1289]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :62
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316994
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 62 is 2.027962
INFO:root:FL Epoch: 71 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1637
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729045
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308347
INFO:root:FL Epoch: 71 Norm Difference for worker 1637 is 2.050073
INFO:root:FL Epoch: 71 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :492
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502539
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248588
INFO:root:FL Epoch: 71 Norm Difference for worker 492 is 1.902425
INFO:root:FL Epoch: 71 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :467
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457410
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331200
INFO:root:FL Epoch: 71 Norm Difference for worker 467 is 1.909628
INFO:root:FL Epoch: 71 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :439
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504354
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336038
INFO:root:FL Epoch: 71 Norm Difference for worker 439 is 2.110717
INFO:root:FL Epoch: 71 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1788
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611804
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429137
INFO:root:FL Epoch: 71 Norm Difference for worker 1788 is 2.055933
INFO:root:FL Epoch: 71 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1531
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447611
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509346
INFO:root:FL Epoch: 71 Norm Difference for worker 1531 is 2.108021
INFO:root:FL Epoch: 71 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1101
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321743
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400047
INFO:root:FL Epoch: 71 Norm Difference for worker 1101 is 2.105811
INFO:root:FL Epoch: 71 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1372
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411258
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365952
INFO:root:FL Epoch: 71 Norm Difference for worker 1372 is 2.034606
INFO:root:FL Epoch: 71 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1289
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459100
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404529
INFO:root:FL Epoch: 71 Norm Difference for worker 1289 is 1.933958
INFO:root:FL Epoch: 71 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9071240041338604, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.906961394486106
INFO:root:#### Oracle Cals: 3, Objective Val: 1.906959365949805
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9069593314519173
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.5531624906203326 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.9797368844350178                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1808
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399631
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251041
INFO:root:FL Epoch: 72 Norm Difference for worker 1808 is 2.084305
INFO:root:FL Epoch: 72 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :988
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503665
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184114
INFO:root:FL Epoch: 72 Norm Difference for worker 988 is 1.897218
INFO:root:FL Epoch: 72 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1871
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603125
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197234
INFO:root:FL Epoch: 72 Norm Difference for worker 1871 is 2.150124
INFO:root:FL Epoch: 72 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :246
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517811
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362221
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 246 is 2.050542
INFO:root:FL Epoch: 72 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :578
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519889
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214469
INFO:root:FL Epoch: 72 Norm Difference for worker 578 is 1.997354
INFO:root:FL Epoch: 72 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1167
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502417
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343066
INFO:root:FL Epoch: 72 Norm Difference for worker 1167 is 2.015632
INFO:root:FL Epoch: 72 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1905
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578668
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251265
INFO:root:FL Epoch: 72 Norm Difference for worker 1905 is 1.946165
INFO:root:FL Epoch: 72 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :161
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 161 is 1.937653
INFO:root:FL Epoch: 72 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :115
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 115 is 1.970014
INFO:root:FL Epoch: 72 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :918
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589971
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424191
INFO:root:FL Epoch: 72 Norm Difference for worker 918 is 2.188431
INFO:root:FL Epoch: 72 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9062511816492096, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.90608174898182
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9060794172352844
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9060793894747223
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5234037988326129 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:2.0523756941159568                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 73 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1190
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664843
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224470
INFO:root:FL Epoch: 73 Norm Difference for worker 1190 is 1.98558
INFO:root:FL Epoch: 73 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :534
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620870
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390356
INFO:root:FL Epoch: 73 Norm Difference for worker 534 is 2.231373
INFO:root:FL Epoch: 73 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1482
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622950
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266463
INFO:root:FL Epoch: 73 Norm Difference for worker 1482 is 2.069824
INFO:root:FL Epoch: 73 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :854
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741098
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257536
INFO:root:FL Epoch: 73 Norm Difference for worker 854 is 2.04535
INFO:root:FL Epoch: 73 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1711
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700494
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201191
INFO:root:FL Epoch: 73 Norm Difference for worker 1711 is 2.215361
INFO:root:FL Epoch: 73 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :834
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601232
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473605
INFO:root:FL Epoch: 73 Norm Difference for worker 834 is 2.40834
INFO:root:FL Epoch: 73 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :816
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606714
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307167
INFO:root:FL Epoch: 73 Norm Difference for worker 816 is 2.189771
INFO:root:FL Epoch: 73 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1421
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352426
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271798
INFO:root:FL Epoch: 73 Norm Difference for worker 1421 is 1.998866
INFO:root:FL Epoch: 73 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1353
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362223
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341011
INFO:root:FL Epoch: 73 Norm Difference for worker 1353 is 2.072095
INFO:root:FL Epoch: 73 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :991
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.914955
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307184
INFO:root:FL Epoch: 73 Norm Difference for worker 991 is 2.288579
INFO:root:FL Epoch: 73 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 2.034482994396788, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 2.0340458847319716
INFO:root:#### Oracle Cals: 3, Objective Val: 2.0340402551375765
INFO:root:#### Oracle Cals: 4, Objective Val: 2.0340401604024185
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.5280850617324605 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:1.837274173895518                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :906
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286224
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355913
INFO:root:FL Epoch: 74 Norm Difference for worker 906 is 2.152901
INFO:root:FL Epoch: 74 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :572
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532135
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356642
INFO:root:FL Epoch: 74 Norm Difference for worker 572 is 2.032934
INFO:root:FL Epoch: 74 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1804
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627860
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411709
INFO:root:FL Epoch: 74 Norm Difference for worker 1804 is 1.959673
INFO:root:FL Epoch: 74 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :98
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 98 is 2.053075
INFO:root:FL Epoch: 74 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1645
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635142
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316804
INFO:root:FL Epoch: 74 Norm Difference for worker 1645 is 2.066451
INFO:root:FL Epoch: 74 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :583
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502816
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358968
INFO:root:FL Epoch: 74 Norm Difference for worker 583 is 2.06301
INFO:root:FL Epoch: 74 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :100
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.389451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 100 is 2.110279
INFO:root:FL Epoch: 74 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1709
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507404
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383517
INFO:root:FL Epoch: 74 Norm Difference for worker 1709 is 2.059254
INFO:root:FL Epoch: 74 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :278
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.634541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 278 is 2.186186
INFO:root:FL Epoch: 74 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :942
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691672
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423901
INFO:root:FL Epoch: 74 Norm Difference for worker 942 is 1.971254
INFO:root:FL Epoch: 74 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9411947048308609, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.941052586056178
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9410507658876317
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9410507422610799
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.54143224568928 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.7832425634066265                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :978
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524622
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307734
INFO:root:FL Epoch: 75 Norm Difference for worker 978 is 2.075669
INFO:root:FL Epoch: 75 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :410
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572383
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238633
INFO:root:FL Epoch: 75 Norm Difference for worker 410 is 1.954229
INFO:root:FL Epoch: 75 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :848
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367743
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553133
INFO:root:FL Epoch: 75 Norm Difference for worker 848 is 2.098238
INFO:root:FL Epoch: 75 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1023
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347065
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412593
INFO:root:FL Epoch: 75 Norm Difference for worker 1023 is 1.99233
INFO:root:FL Epoch: 75 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :197
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549983
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 197 is 2.117124
INFO:root:FL Epoch: 75 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1535
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514371
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238379
INFO:root:FL Epoch: 75 Norm Difference for worker 1535 is 2.046631
INFO:root:FL Epoch: 75 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :786
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599002
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458282
INFO:root:FL Epoch: 75 Norm Difference for worker 786 is 2.170924
INFO:root:FL Epoch: 75 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1486
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716384
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493731
INFO:root:FL Epoch: 75 Norm Difference for worker 1486 is 2.137761
INFO:root:FL Epoch: 75 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1128
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621543
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251873
INFO:root:FL Epoch: 75 Norm Difference for worker 1128 is 1.988408
INFO:root:FL Epoch: 75 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1761
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429649
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366128
INFO:root:FL Epoch: 75 Norm Difference for worker 1761 is 2.05431
INFO:root:FL Epoch: 75 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9380511964552793, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.937905715078182
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9379036866921118
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9379036610089329
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.495248300187728 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:1.7773057421048482                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 76 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1548
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 1.014223
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504492
INFO:root:FL Epoch: 76 Norm Difference for worker 1548 is 2.185189
INFO:root:FL Epoch: 76 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1417
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597140
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374608
INFO:root:FL Epoch: 76 Norm Difference for worker 1417 is 1.98322
INFO:root:FL Epoch: 76 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :840
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474662
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527178
INFO:root:FL Epoch: 76 Norm Difference for worker 840 is 2.065581
INFO:root:FL Epoch: 76 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :570
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670806
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476168
INFO:root:FL Epoch: 76 Norm Difference for worker 570 is 1.938265
INFO:root:FL Epoch: 76 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1300
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559889
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315261
INFO:root:FL Epoch: 76 Norm Difference for worker 1300 is 2.133875
INFO:root:FL Epoch: 76 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1440
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757268
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176252
INFO:root:FL Epoch: 76 Norm Difference for worker 1440 is 1.963601
INFO:root:FL Epoch: 76 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :716
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669004
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199591
INFO:root:FL Epoch: 76 Norm Difference for worker 716 is 1.946368
INFO:root:FL Epoch: 76 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1434
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607504
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316080
INFO:root:FL Epoch: 76 Norm Difference for worker 1434 is 1.980634
INFO:root:FL Epoch: 76 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1090
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508332
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298806
INFO:root:FL Epoch: 76 Norm Difference for worker 1090 is 1.980321
INFO:root:FL Epoch: 76 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :170
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 170 is 2.040458
INFO:root:FL Epoch: 76 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9020141489639193, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.901842835942252
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9018407151549708
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9018406917623019
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5071239313658547 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.4816533923149109                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :975
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603444
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291404
INFO:root:FL Epoch: 77 Norm Difference for worker 975 is 2.267981
INFO:root:FL Epoch: 77 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :926
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523821
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397329
INFO:root:FL Epoch: 77 Norm Difference for worker 926 is 1.999259
INFO:root:FL Epoch: 77 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445792
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290378
INFO:root:FL Epoch: 77 Norm Difference for worker 1128 is 1.929581
INFO:root:FL Epoch: 77 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.244303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 303 is 2.072423
INFO:root:FL Epoch: 77 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1274
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527737
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282703
INFO:root:FL Epoch: 77 Norm Difference for worker 1274 is 2.093878
INFO:root:FL Epoch: 77 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :483
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522233
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289133
INFO:root:FL Epoch: 77 Norm Difference for worker 483 is 2.150571
INFO:root:FL Epoch: 77 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :944
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733968
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414879
INFO:root:FL Epoch: 77 Norm Difference for worker 944 is 2.152259
INFO:root:FL Epoch: 77 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :904
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639433
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367330
INFO:root:FL Epoch: 77 Norm Difference for worker 904 is 1.845919
INFO:root:FL Epoch: 77 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :394
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587502
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272678
INFO:root:FL Epoch: 77 Norm Difference for worker 394 is 2.178311
INFO:root:FL Epoch: 77 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1282
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586515
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499561
INFO:root:FL Epoch: 77 Norm Difference for worker 1282 is 2.250402
INFO:root:FL Epoch: 77 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9611452076792346, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9608287725374054
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9608241687085197
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9608240972532718
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5377097585622002 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.845119873682658                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :1205
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507624
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180046
INFO:root:FL Epoch: 78 Norm Difference for worker 1205 is 2.038167
INFO:root:FL Epoch: 78 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :886
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594453
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320883
INFO:root:FL Epoch: 78 Norm Difference for worker 886 is 2.017496
INFO:root:FL Epoch: 78 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :835
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636064
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331188
INFO:root:FL Epoch: 78 Norm Difference for worker 835 is 1.9976
INFO:root:FL Epoch: 78 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1830
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559460
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274541
INFO:root:FL Epoch: 78 Norm Difference for worker 1830 is 1.962405
INFO:root:FL Epoch: 78 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :482
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357626
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354745
INFO:root:FL Epoch: 78 Norm Difference for worker 482 is 2.093908
INFO:root:FL Epoch: 78 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1179
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494962
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353392
INFO:root:FL Epoch: 78 Norm Difference for worker 1179 is 1.977799
INFO:root:FL Epoch: 78 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1312
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581680
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359529
INFO:root:FL Epoch: 78 Norm Difference for worker 1312 is 1.979222
INFO:root:FL Epoch: 78 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1592
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462622
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456781
INFO:root:FL Epoch: 78 Norm Difference for worker 1592 is 2.145844
INFO:root:FL Epoch: 78 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :45
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 45 is 2.110485
INFO:root:FL Epoch: 78 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1934
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574743
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430947
INFO:root:FL Epoch: 78 Norm Difference for worker 1934 is 2.128474
INFO:root:FL Epoch: 78 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9323392229794345, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.932191412556549
INFO:root:#### Oracle Cals: 3, Objective Val: 1.932189714993694
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9321897011211195
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.5091343031210058 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.769520143667857                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1712
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689535
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235764
INFO:root:FL Epoch: 79 Norm Difference for worker 1712 is 2.074369
INFO:root:FL Epoch: 79 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :194
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 194 is 2.038133
INFO:root:FL Epoch: 79 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :814
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426285
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322760
INFO:root:FL Epoch: 79 Norm Difference for worker 814 is 2.048725
INFO:root:FL Epoch: 79 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :277
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 277 is 2.039289
INFO:root:FL Epoch: 79 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1810
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301689
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305079
INFO:root:FL Epoch: 79 Norm Difference for worker 1810 is 1.931482
INFO:root:FL Epoch: 79 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :235
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562235
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 235 is 2.0108
INFO:root:FL Epoch: 79 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :487
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416683
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340307
INFO:root:FL Epoch: 79 Norm Difference for worker 487 is 2.011731
INFO:root:FL Epoch: 79 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1274
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610458
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266202
INFO:root:FL Epoch: 79 Norm Difference for worker 1274 is 1.990623
INFO:root:FL Epoch: 79 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :998
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401405
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338832
INFO:root:FL Epoch: 79 Norm Difference for worker 998 is 2.111733
INFO:root:FL Epoch: 79 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1460
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357840
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263395
INFO:root:FL Epoch: 79 Norm Difference for worker 1460 is 1.94087
INFO:root:FL Epoch: 79 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9123112707797145, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9122227745101252
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9122216238620968
INFO:root:#### Oracle Cals: 4, Objective Val: 1.912221613153684
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.48887017369270325 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.6199535131454468                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 80 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :951
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815130
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323620
INFO:root:FL Epoch: 80 Norm Difference for worker 951 is 2.035546
INFO:root:FL Epoch: 80 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :196
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 196 is 2.029803
INFO:root:FL Epoch: 80 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :695
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616342
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249684
INFO:root:FL Epoch: 80 Norm Difference for worker 695 is 1.963497
INFO:root:FL Epoch: 80 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1847
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713036
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390745
INFO:root:FL Epoch: 80 Norm Difference for worker 1847 is 1.983464
INFO:root:FL Epoch: 80 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1670
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617815
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232215
INFO:root:FL Epoch: 80 Norm Difference for worker 1670 is 1.919218
INFO:root:FL Epoch: 80 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1872
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436111
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238761
INFO:root:FL Epoch: 80 Norm Difference for worker 1872 is 2.034499
INFO:root:FL Epoch: 80 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636483
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328056
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.965327
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :564
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554709
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427247
INFO:root:FL Epoch: 80 Norm Difference for worker 564 is 2.05294
INFO:root:FL Epoch: 80 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :683
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435670
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213553
INFO:root:FL Epoch: 80 Norm Difference for worker 683 is 1.992949
INFO:root:FL Epoch: 80 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :33
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 33 is 2.164907
INFO:root:FL Epoch: 80 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.887499791894568, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8873515395037672
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8873497001462045
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8873496234486753
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5063102227800033 and Test Accuracy:75.0 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:2.0395910938580832                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1552, 722, 895, 1912, 1905, 370, 1295, 616, 579, 1867]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1552
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530031
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430911
INFO:root:FL Epoch: 81 Norm Difference for worker 1552 is 2.101045
INFO:root:FL Epoch: 81 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :722
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549908
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375146
INFO:root:FL Epoch: 81 Norm Difference for worker 722 is 2.095698
INFO:root:FL Epoch: 81 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :895
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468905
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326171
INFO:root:FL Epoch: 81 Norm Difference for worker 895 is 2.036697
INFO:root:FL Epoch: 81 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1912
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517945
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370224
INFO:root:FL Epoch: 81 Norm Difference for worker 1912 is 2.072577
INFO:root:FL Epoch: 81 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1905
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477636
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291798
INFO:root:FL Epoch: 81 Norm Difference for worker 1905 is 1.923247
INFO:root:FL Epoch: 81 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :370
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593492
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190483
INFO:root:FL Epoch: 81 Norm Difference for worker 370 is 1.914334
INFO:root:FL Epoch: 81 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1295
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560521
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313730
INFO:root:FL Epoch: 81 Norm Difference for worker 1295 is 1.986651
INFO:root:FL Epoch: 81 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :616
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585499
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337164
INFO:root:FL Epoch: 81 Norm Difference for worker 616 is 2.129517
INFO:root:FL Epoch: 81 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :579
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846146
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323455
INFO:root:FL Epoch: 81 Norm Difference for worker 579 is 2.140127
INFO:root:FL Epoch: 81 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1867
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753049
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354267
INFO:root:FL Epoch: 81 Norm Difference for worker 1867 is 2.046089
INFO:root:FL Epoch: 81 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9323350244201847, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9321927629692366
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9321908696267944
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9321908330030633
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5259692668914795 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.8778372208277385                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1016
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586179
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399036
INFO:root:FL Epoch: 82 Norm Difference for worker 1016 is 2.140695
INFO:root:FL Epoch: 82 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1907
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430750
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574824
INFO:root:FL Epoch: 82 Norm Difference for worker 1907 is 2.113122
INFO:root:FL Epoch: 82 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :171
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 171 is 2.082132
INFO:root:FL Epoch: 82 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :180
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.268442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 180 is 2.014925
INFO:root:FL Epoch: 82 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1447
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459298
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179635
INFO:root:FL Epoch: 82 Norm Difference for worker 1447 is 2.092982
INFO:root:FL Epoch: 82 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :316
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616372
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421197
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 316 is 2.016601
INFO:root:FL Epoch: 82 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1107
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542088
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353675
INFO:root:FL Epoch: 82 Norm Difference for worker 1107 is 1.971664
INFO:root:FL Epoch: 82 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :451
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603906
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469164
INFO:root:FL Epoch: 82 Norm Difference for worker 451 is 2.135397
INFO:root:FL Epoch: 82 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1246
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614993
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409054
INFO:root:FL Epoch: 82 Norm Difference for worker 1246 is 2.083282
INFO:root:FL Epoch: 82 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :792
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773647
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208049
INFO:root:FL Epoch: 82 Norm Difference for worker 792 is 1.987786
INFO:root:FL Epoch: 82 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9532381717559808, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9531780399600136
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9531772917089452
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9531772928628266
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.5208795649163863 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.718484620253245                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1537
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526241
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650613
INFO:root:FL Epoch: 83 Norm Difference for worker 1537 is 2.253265
INFO:root:FL Epoch: 83 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :890
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585405
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354944
INFO:root:FL Epoch: 83 Norm Difference for worker 890 is 2.143712
INFO:root:FL Epoch: 83 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1098
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.225099
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340922
INFO:root:FL Epoch: 83 Norm Difference for worker 1098 is 2.002239
INFO:root:FL Epoch: 83 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :872
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478426
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277616
INFO:root:FL Epoch: 83 Norm Difference for worker 872 is 2.097648
INFO:root:FL Epoch: 83 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1229
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833230
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272187
INFO:root:FL Epoch: 83 Norm Difference for worker 1229 is 2.021641
INFO:root:FL Epoch: 83 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :169
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 169 is 1.987907
INFO:root:FL Epoch: 83 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1490
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556336
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322204
INFO:root:FL Epoch: 83 Norm Difference for worker 1490 is 1.988749
INFO:root:FL Epoch: 83 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :659
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502057
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362128
INFO:root:FL Epoch: 83 Norm Difference for worker 659 is 2.160126
INFO:root:FL Epoch: 83 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :81
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 81 is 2.138572
INFO:root:FL Epoch: 83 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :873
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449022
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380249
INFO:root:FL Epoch: 83 Norm Difference for worker 873 is 2.037474
INFO:root:FL Epoch: 83 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9545935165327504, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9543949736668862
INFO:root:#### Oracle Cals: 3, Objective Val: 1.954392528250032
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9543924444183307
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.5293862959917854 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.6771424412727356                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1878
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619640
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290260
INFO:root:FL Epoch: 84 Norm Difference for worker 1878 is 2.074902
INFO:root:FL Epoch: 84 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1224
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493232
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326221
INFO:root:FL Epoch: 84 Norm Difference for worker 1224 is 2.04287
INFO:root:FL Epoch: 84 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :132
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 132 is 2.011521
INFO:root:FL Epoch: 84 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :198
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 198 is 2.018698
INFO:root:FL Epoch: 84 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :140
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 140 is 2.119969
INFO:root:FL Epoch: 84 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :649
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806523
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270532
INFO:root:FL Epoch: 84 Norm Difference for worker 649 is 2.036604
INFO:root:FL Epoch: 84 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :436
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766425
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319081
INFO:root:FL Epoch: 84 Norm Difference for worker 436 is 2.046616
INFO:root:FL Epoch: 84 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :86
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381331
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 86 is 1.92666
INFO:root:FL Epoch: 84 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1238
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566841
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276367
INFO:root:FL Epoch: 84 Norm Difference for worker 1238 is 2.013137
INFO:root:FL Epoch: 84 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1616
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633241
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329349
INFO:root:FL Epoch: 84 Norm Difference for worker 1616 is 2.00739
INFO:root:FL Epoch: 84 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.904897392963295, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9048144444174946
INFO:root:#### Oracle Cals: 3, Objective Val: 1.904813351483808
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9048133279511041
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5269911254153532 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:1.8449960350990295                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :376
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796374
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321208
INFO:root:FL Epoch: 85 Norm Difference for worker 376 is 2.053995
INFO:root:FL Epoch: 85 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :587
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507206
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450946
INFO:root:FL Epoch: 85 Norm Difference for worker 587 is 2.036758
INFO:root:FL Epoch: 85 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1674
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523300
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461616
INFO:root:FL Epoch: 85 Norm Difference for worker 1674 is 1.955451
INFO:root:FL Epoch: 85 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1650
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510364
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405039
INFO:root:FL Epoch: 85 Norm Difference for worker 1650 is 2.096331
INFO:root:FL Epoch: 85 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1395
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481778
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463781
INFO:root:FL Epoch: 85 Norm Difference for worker 1395 is 1.99898
INFO:root:FL Epoch: 85 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :747
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447807
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304179
INFO:root:FL Epoch: 85 Norm Difference for worker 747 is 2.000047
INFO:root:FL Epoch: 85 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :841
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478081
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409746
INFO:root:FL Epoch: 85 Norm Difference for worker 841 is 1.985605
INFO:root:FL Epoch: 85 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1713
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456422
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499721
INFO:root:FL Epoch: 85 Norm Difference for worker 1713 is 1.972254
INFO:root:FL Epoch: 85 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :586
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606175
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256174
INFO:root:FL Epoch: 85 Norm Difference for worker 586 is 2.003278
INFO:root:FL Epoch: 85 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :76
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 76 is 2.039033
INFO:root:FL Epoch: 85 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8948050109575443, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8947600225888712
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8947594909141092
INFO:root:#### Oracle Cals: 4, Objective Val: 1.894759561853481
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5233921583961038 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:1.923851986726125                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1588
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567942
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306769
INFO:root:FL Epoch: 86 Norm Difference for worker 1588 is 1.842809
INFO:root:FL Epoch: 86 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :653
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732551
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375902
INFO:root:FL Epoch: 86 Norm Difference for worker 653 is 1.952214
INFO:root:FL Epoch: 86 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1926
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622248
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329331
INFO:root:FL Epoch: 86 Norm Difference for worker 1926 is 2.013625
INFO:root:FL Epoch: 86 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1027
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535893
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137999
INFO:root:FL Epoch: 86 Norm Difference for worker 1027 is 1.864235
INFO:root:FL Epoch: 86 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :529
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648303
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222681
INFO:root:FL Epoch: 86 Norm Difference for worker 529 is 1.83912
INFO:root:FL Epoch: 86 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1929
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372723
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224606
INFO:root:FL Epoch: 86 Norm Difference for worker 1929 is 1.898042
INFO:root:FL Epoch: 86 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :184
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.159865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 184 is 1.871551
INFO:root:FL Epoch: 86 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1709
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576740
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317544
INFO:root:FL Epoch: 86 Norm Difference for worker 1709 is 1.943629
INFO:root:FL Epoch: 86 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :74
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 74 is 2.017204
INFO:root:FL Epoch: 86 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1001
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670421
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296293
INFO:root:FL Epoch: 86 Norm Difference for worker 1001 is 1.948084
INFO:root:FL Epoch: 86 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.806112955078947, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8059834985219247
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8059818582663423
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8059818651174482
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5329329914906445 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:2.0344688097635903                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1919
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709442
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361979
INFO:root:FL Epoch: 87 Norm Difference for worker 1919 is 2.075366
INFO:root:FL Epoch: 87 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :211
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 211 is 2.090539
INFO:root:FL Epoch: 87 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :692
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415843
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269420
INFO:root:FL Epoch: 87 Norm Difference for worker 692 is 2.049186
INFO:root:FL Epoch: 87 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :756
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576444
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288358
INFO:root:FL Epoch: 87 Norm Difference for worker 756 is 2.162673
INFO:root:FL Epoch: 87 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :452
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367536
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261153
INFO:root:FL Epoch: 87 Norm Difference for worker 452 is 1.95849
INFO:root:FL Epoch: 87 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1940
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622626
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319618
INFO:root:FL Epoch: 87 Norm Difference for worker 1940 is 1.998087
INFO:root:FL Epoch: 87 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1274
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627563
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440101
INFO:root:FL Epoch: 87 Norm Difference for worker 1274 is 1.940292
INFO:root:FL Epoch: 87 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :505
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410703
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339358
INFO:root:FL Epoch: 87 Norm Difference for worker 505 is 2.106957
INFO:root:FL Epoch: 87 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1090
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453173
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265837
INFO:root:FL Epoch: 87 Norm Difference for worker 1090 is 2.048885
INFO:root:FL Epoch: 87 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :674
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645846
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278648
INFO:root:FL Epoch: 87 Norm Difference for worker 674 is 1.923849
INFO:root:FL Epoch: 87 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9162999797600573, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9161530945298817
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9161511947103094
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9161511682403554
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5101645378505483 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.9052225748697917                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :754
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648727
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231237
INFO:root:FL Epoch: 88 Norm Difference for worker 754 is 2.066084
INFO:root:FL Epoch: 88 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1867
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552884
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377520
INFO:root:FL Epoch: 88 Norm Difference for worker 1867 is 1.97833
INFO:root:FL Epoch: 88 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1196
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794585
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413022
INFO:root:FL Epoch: 88 Norm Difference for worker 1196 is 2.015335
INFO:root:FL Epoch: 88 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1355
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528107
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368885
INFO:root:FL Epoch: 88 Norm Difference for worker 1355 is 2.168694
INFO:root:FL Epoch: 88 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1912
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407503
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435121
INFO:root:FL Epoch: 88 Norm Difference for worker 1912 is 2.037648
INFO:root:FL Epoch: 88 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1919
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592133
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241464
INFO:root:FL Epoch: 88 Norm Difference for worker 1919 is 1.938143
INFO:root:FL Epoch: 88 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1518
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406924
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276441
INFO:root:FL Epoch: 88 Norm Difference for worker 1518 is 1.999002
INFO:root:FL Epoch: 88 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :818
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435096
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276000
INFO:root:FL Epoch: 88 Norm Difference for worker 818 is 2.020822
INFO:root:FL Epoch: 88 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1600
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452459
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226590
INFO:root:FL Epoch: 88 Norm Difference for worker 1600 is 2.06536
INFO:root:FL Epoch: 88 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1594
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618116
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491502
INFO:root:FL Epoch: 88 Norm Difference for worker 1594 is 2.008612
INFO:root:FL Epoch: 88 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9149082859640472, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9147806528112423
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9147789927763532
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9147789329964988
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5148289308828466 and Test Accuracy:75.0 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.7898251414299011                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 89 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1856
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518797
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372719
INFO:root:FL Epoch: 89 Norm Difference for worker 1856 is 1.9964
INFO:root:FL Epoch: 89 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :476
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780740
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368188
INFO:root:FL Epoch: 89 Norm Difference for worker 476 is 1.987753
INFO:root:FL Epoch: 89 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :191
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262627
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 191 is 2.067539
INFO:root:FL Epoch: 89 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :401
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746628
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346885
INFO:root:FL Epoch: 89 Norm Difference for worker 401 is 2.082819
INFO:root:FL Epoch: 89 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :350
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674620
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558704
INFO:root:FL Epoch: 89 Norm Difference for worker 350 is 2.162231
INFO:root:FL Epoch: 89 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :34
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 34 is 2.083721
INFO:root:FL Epoch: 89 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :742
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589738
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295836
INFO:root:FL Epoch: 89 Norm Difference for worker 742 is 1.937068
INFO:root:FL Epoch: 89 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1521
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624538
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220379
INFO:root:FL Epoch: 89 Norm Difference for worker 1521 is 2.028386
INFO:root:FL Epoch: 89 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1275
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377661
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269564
INFO:root:FL Epoch: 89 Norm Difference for worker 1275 is 1.934127
INFO:root:FL Epoch: 89 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :107
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467666
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 107 is 2.102514
INFO:root:FL Epoch: 89 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9189537969542014, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9188231165038103
INFO:root:#### Oracle Cals: 3, Objective Val: 1.918821292399827
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9188212635959834
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.5297661423683167 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.7253660559654236                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1193
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512039
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247842
INFO:root:FL Epoch: 90 Norm Difference for worker 1193 is 2.104094
INFO:root:FL Epoch: 90 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :930
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582081
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257147
INFO:root:FL Epoch: 90 Norm Difference for worker 930 is 2.014941
INFO:root:FL Epoch: 90 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1680
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537251
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604339
INFO:root:FL Epoch: 90 Norm Difference for worker 1680 is 2.172029
INFO:root:FL Epoch: 90 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1543
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793828
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291522
INFO:root:FL Epoch: 90 Norm Difference for worker 1543 is 2.069262
INFO:root:FL Epoch: 90 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :25
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 25 is 1.954818
INFO:root:FL Epoch: 90 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1115
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480909
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346460
INFO:root:FL Epoch: 90 Norm Difference for worker 1115 is 2.066743
INFO:root:FL Epoch: 90 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1856
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291619
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163755
INFO:root:FL Epoch: 90 Norm Difference for worker 1856 is 1.83958
INFO:root:FL Epoch: 90 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :687
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606252
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345932
INFO:root:FL Epoch: 90 Norm Difference for worker 687 is 2.148896
INFO:root:FL Epoch: 90 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :24
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 24 is 2.100138
INFO:root:FL Epoch: 90 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :850
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376131
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368143
INFO:root:FL Epoch: 90 Norm Difference for worker 850 is 2.293561
INFO:root:FL Epoch: 90 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9615367659635203, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9613011928405963
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9612981245945316
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9612980850961457
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5156319123857162 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.8736346364021301                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [623, 1591, 1404, 853, 1441, 944, 1326, 1243, 1153, 1122]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 91 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :623
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597556
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376026
INFO:root:FL Epoch: 91 Norm Difference for worker 623 is 2.078848
INFO:root:FL Epoch: 91 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1591
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583312
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405648
INFO:root:FL Epoch: 91 Norm Difference for worker 1591 is 2.126903
INFO:root:FL Epoch: 91 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1404
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445844
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349535
INFO:root:FL Epoch: 91 Norm Difference for worker 1404 is 1.987625
INFO:root:FL Epoch: 91 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :853
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646046
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264718
INFO:root:FL Epoch: 91 Norm Difference for worker 853 is 2.191371
INFO:root:FL Epoch: 91 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1441
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733434
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218866
INFO:root:FL Epoch: 91 Norm Difference for worker 1441 is 2.013387
INFO:root:FL Epoch: 91 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :944
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607701
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254067
INFO:root:FL Epoch: 91 Norm Difference for worker 944 is 2.061318
INFO:root:FL Epoch: 91 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1326
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575411
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262044
INFO:root:FL Epoch: 91 Norm Difference for worker 1326 is 2.125562
INFO:root:FL Epoch: 91 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1243
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684212
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461099
INFO:root:FL Epoch: 91 Norm Difference for worker 1243 is 2.206885
INFO:root:FL Epoch: 91 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1153
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360237
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240094
INFO:root:FL Epoch: 91 Norm Difference for worker 1153 is 2.072397
INFO:root:FL Epoch: 91 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1122
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679190
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422844
INFO:root:FL Epoch: 91 Norm Difference for worker 1122 is 2.101241
INFO:root:FL Epoch: 91 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.973260578450751, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.973121989238628
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9731202807904982
INFO:root:#### Oracle Cals: 4, Objective Val: 1.973120259234857
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.5125165827134076 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:2.222229242324829                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :845
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448738
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342228
INFO:root:FL Epoch: 92 Norm Difference for worker 845 is 1.976525
INFO:root:FL Epoch: 92 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1139
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535510
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274173
INFO:root:FL Epoch: 92 Norm Difference for worker 1139 is 1.962165
INFO:root:FL Epoch: 92 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :844
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583544
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315056
INFO:root:FL Epoch: 92 Norm Difference for worker 844 is 1.830689
INFO:root:FL Epoch: 92 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :540
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484563
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542728
INFO:root:FL Epoch: 92 Norm Difference for worker 540 is 2.235986
INFO:root:FL Epoch: 92 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :872
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758186
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305400
INFO:root:FL Epoch: 92 Norm Difference for worker 872 is 1.967156
INFO:root:FL Epoch: 92 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1177
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532142
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328019
INFO:root:FL Epoch: 92 Norm Difference for worker 1177 is 1.894961
INFO:root:FL Epoch: 92 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1685
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490541
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260670
INFO:root:FL Epoch: 92 Norm Difference for worker 1685 is 1.968355
INFO:root:FL Epoch: 92 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512398
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 175 is 1.997344
INFO:root:FL Epoch: 92 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :376
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709868
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350476
INFO:root:FL Epoch: 92 Norm Difference for worker 376 is 2.106632
INFO:root:FL Epoch: 92 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1367
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646192
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180750
INFO:root:FL Epoch: 92 Norm Difference for worker 1367 is 2.074798
INFO:root:FL Epoch: 92 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8838131651986285, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8835529871884704
INFO:root:#### Oracle Cals: 3, Objective Val: 1.883550223409358
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8835501840954803
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.4900887082604801 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:1.9361910820007324                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 93 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :48
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 48 is 1.964035
INFO:root:FL Epoch: 93 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :872
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453591
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296482
INFO:root:FL Epoch: 93 Norm Difference for worker 872 is 1.781475
INFO:root:FL Epoch: 93 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1196
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786370
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386513
INFO:root:FL Epoch: 93 Norm Difference for worker 1196 is 2.041385
INFO:root:FL Epoch: 93 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1390
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456153
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271466
INFO:root:FL Epoch: 93 Norm Difference for worker 1390 is 1.949155
INFO:root:FL Epoch: 93 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1195
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529404
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197347
INFO:root:FL Epoch: 93 Norm Difference for worker 1195 is 2.099901
INFO:root:FL Epoch: 93 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :341
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511777
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225226
INFO:root:FL Epoch: 93 Norm Difference for worker 341 is 2.172309
INFO:root:FL Epoch: 93 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :279
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495740
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257844
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 279 is 1.963148
INFO:root:FL Epoch: 93 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :241
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629553
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 241 is 2.198709
INFO:root:FL Epoch: 93 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1160
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729600
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383767
INFO:root:FL Epoch: 93 Norm Difference for worker 1160 is 2.115549
INFO:root:FL Epoch: 93 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1421
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280172
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312339
INFO:root:FL Epoch: 93 Norm Difference for worker 1421 is 1.893465
INFO:root:FL Epoch: 93 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9098251387810112, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9095336053888512
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9095299369649172
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9095298259159754
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.47155871987342834 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:2.1246158878008523                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1770
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372857
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231477
INFO:root:FL Epoch: 94 Norm Difference for worker 1770 is 2.113396
INFO:root:FL Epoch: 94 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :149
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565340
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 149 is 2.006472
INFO:root:FL Epoch: 94 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1939
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558816
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272450
INFO:root:FL Epoch: 94 Norm Difference for worker 1939 is 2.207487
INFO:root:FL Epoch: 94 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1250
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470919
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394438
INFO:root:FL Epoch: 94 Norm Difference for worker 1250 is 2.170842
INFO:root:FL Epoch: 94 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :809
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518430
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289514
INFO:root:FL Epoch: 94 Norm Difference for worker 809 is 2.16178
INFO:root:FL Epoch: 94 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :301
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 301 is 2.066846
INFO:root:FL Epoch: 94 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :636
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595967
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316469
INFO:root:FL Epoch: 94 Norm Difference for worker 636 is 2.215633
INFO:root:FL Epoch: 94 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1925
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466393
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270694
INFO:root:FL Epoch: 94 Norm Difference for worker 1925 is 2.15055
INFO:root:FL Epoch: 94 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :125
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 125 is 2.008136
INFO:root:FL Epoch: 94 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1537
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808997
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457219
INFO:root:FL Epoch: 94 Norm Difference for worker 1537 is 2.299321
INFO:root:FL Epoch: 94 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 2.0039761281890023, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 2.003810415488638
INFO:root:#### Oracle Cals: 3, Objective Val: 2.0038084641575726
INFO:root:#### Oracle Cals: 4, Objective Val: 2.0038083611628132
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.4955119332846473 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.713253915309906                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :1495
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549017
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307259
INFO:root:FL Epoch: 95 Norm Difference for worker 1495 is 2.005183
INFO:root:FL Epoch: 95 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1264
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556313
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327211
INFO:root:FL Epoch: 95 Norm Difference for worker 1264 is 1.954148
INFO:root:FL Epoch: 95 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :469
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440368
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322726
INFO:root:FL Epoch: 95 Norm Difference for worker 469 is 1.854982
INFO:root:FL Epoch: 95 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1275
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352508
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187472
INFO:root:FL Epoch: 95 Norm Difference for worker 1275 is 1.804579
INFO:root:FL Epoch: 95 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :734
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480302
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332912
INFO:root:FL Epoch: 95 Norm Difference for worker 734 is 2.009085
INFO:root:FL Epoch: 95 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1533
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844289
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299510
INFO:root:FL Epoch: 95 Norm Difference for worker 1533 is 1.976532
INFO:root:FL Epoch: 95 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1555
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340633
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300495
INFO:root:FL Epoch: 95 Norm Difference for worker 1555 is 2.002146
INFO:root:FL Epoch: 95 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :94
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484647
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 94 is 1.951329
INFO:root:FL Epoch: 95 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :311
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.253953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 311 is 1.983006
INFO:root:FL Epoch: 95 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :243
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 243 is 1.967868
INFO:root:FL Epoch: 95 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8434207942292253, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8433088297102496
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8433074599827655
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8433074425519902
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.5088174237924463 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.9001366098721821                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735284
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338562
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 2.01702
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1172
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674824
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420085
INFO:root:FL Epoch: 96 Norm Difference for worker 1172 is 2.180967
INFO:root:FL Epoch: 96 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :440
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285937
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389943
INFO:root:FL Epoch: 96 Norm Difference for worker 440 is 1.946783
INFO:root:FL Epoch: 96 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :207
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.975648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 207 is 1.970154
INFO:root:FL Epoch: 96 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :205
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 205 is 1.964705
INFO:root:FL Epoch: 96 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :542
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430118
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174892
INFO:root:FL Epoch: 96 Norm Difference for worker 542 is 1.854469
INFO:root:FL Epoch: 96 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1428
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402797
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267130
INFO:root:FL Epoch: 96 Norm Difference for worker 1428 is 2.165391
INFO:root:FL Epoch: 96 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1348
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703817
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256354
INFO:root:FL Epoch: 96 Norm Difference for worker 1348 is 1.874448
INFO:root:FL Epoch: 96 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1135
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559117
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436730
INFO:root:FL Epoch: 96 Norm Difference for worker 1135 is 2.020894
INFO:root:FL Epoch: 96 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :308
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381975
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 308 is 1.983869
INFO:root:FL Epoch: 96 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.879546602475823, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.879239205198309
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8792357129566002
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8792356701467172
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.49212340747608857 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.7951567769050598                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 97 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :848
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522954
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328639
INFO:root:FL Epoch: 97 Norm Difference for worker 848 is 2.02124
INFO:root:FL Epoch: 97 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :769
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411090
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403302
INFO:root:FL Epoch: 97 Norm Difference for worker 769 is 2.067311
INFO:root:FL Epoch: 97 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :627
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524550
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387519
INFO:root:FL Epoch: 97 Norm Difference for worker 627 is 1.93598
INFO:root:FL Epoch: 97 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :413
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401521
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308197
INFO:root:FL Epoch: 97 Norm Difference for worker 413 is 2.041384
INFO:root:FL Epoch: 97 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1061
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538952
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430298
INFO:root:FL Epoch: 97 Norm Difference for worker 1061 is 1.91879
INFO:root:FL Epoch: 97 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1302
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743907
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311767
INFO:root:FL Epoch: 97 Norm Difference for worker 1302 is 1.985997
INFO:root:FL Epoch: 97 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1445
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904482
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376809
INFO:root:FL Epoch: 97 Norm Difference for worker 1445 is 2.104611
INFO:root:FL Epoch: 97 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :973
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529229
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359456
INFO:root:FL Epoch: 97 Norm Difference for worker 973 is 2.029042
INFO:root:FL Epoch: 97 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :110
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 110 is 1.986945
INFO:root:FL Epoch: 97 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :15
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 15 is 1.923398
INFO:root:FL Epoch: 97 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8873326165813895, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8872222346093663
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8872209245338594
INFO:root:#### Oracle Cals: 4, Objective Val: 1.887220917075473
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5212359849144431 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:2.0960370898246765                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 98 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :633
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506557
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379668
INFO:root:FL Epoch: 98 Norm Difference for worker 633 is 1.907093
INFO:root:FL Epoch: 98 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :77
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 77 is 1.964228
INFO:root:FL Epoch: 98 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1548
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578625
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208675
INFO:root:FL Epoch: 98 Norm Difference for worker 1548 is 2.055064
INFO:root:FL Epoch: 98 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :734
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849986
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343873
INFO:root:FL Epoch: 98 Norm Difference for worker 734 is 1.927446
INFO:root:FL Epoch: 98 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1609
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430564
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330425
INFO:root:FL Epoch: 98 Norm Difference for worker 1609 is 2.1375
INFO:root:FL Epoch: 98 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1375
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508480
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396920
INFO:root:FL Epoch: 98 Norm Difference for worker 1375 is 2.015322
INFO:root:FL Epoch: 98 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1209
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495253
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285464
INFO:root:FL Epoch: 98 Norm Difference for worker 1209 is 2.064566
INFO:root:FL Epoch: 98 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1751
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513954
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224454
INFO:root:FL Epoch: 98 Norm Difference for worker 1751 is 2.016915
INFO:root:FL Epoch: 98 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1773
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484665
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426686
INFO:root:FL Epoch: 98 Norm Difference for worker 1773 is 2.142588
INFO:root:FL Epoch: 98 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1238
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506277
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254936
INFO:root:FL Epoch: 98 Norm Difference for worker 1238 is 1.977545
INFO:root:FL Epoch: 98 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8976979059230143, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8975367382755306
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8975347739244877
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8975346954071481
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.4991211400312536 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.872280240058899                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 99 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1854
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429779
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326096
INFO:root:FL Epoch: 99 Norm Difference for worker 1854 is 2.110756
INFO:root:FL Epoch: 99 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1767
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432028
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333675
INFO:root:FL Epoch: 99 Norm Difference for worker 1767 is 1.91962
INFO:root:FL Epoch: 99 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1325
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884003
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407263
INFO:root:FL Epoch: 99 Norm Difference for worker 1325 is 2.03685
INFO:root:FL Epoch: 99 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :857
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640428
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339508
INFO:root:FL Epoch: 99 Norm Difference for worker 857 is 2.112722
INFO:root:FL Epoch: 99 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :918
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511881
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281836
INFO:root:FL Epoch: 99 Norm Difference for worker 918 is 1.974102
INFO:root:FL Epoch: 99 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :86
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727488
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 86 is 1.798115
INFO:root:FL Epoch: 99 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :420
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614192
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238042
INFO:root:FL Epoch: 99 Norm Difference for worker 420 is 2.07166
INFO:root:FL Epoch: 99 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :564
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416611
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307849
INFO:root:FL Epoch: 99 Norm Difference for worker 564 is 1.891749
INFO:root:FL Epoch: 99 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :958
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930728
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510369
INFO:root:FL Epoch: 99 Norm Difference for worker 958 is 2.035102
INFO:root:FL Epoch: 99 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :800
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425083
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298490
INFO:root:FL Epoch: 99 Norm Difference for worker 800 is 2.021964
INFO:root:FL Epoch: 99 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.875020914383507, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8748090423661408
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8748060648854774
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8748060262147224
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.5239585077061373 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.8135409156481426                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1823
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469418
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414137
INFO:root:FL Epoch: 100 Norm Difference for worker 1823 is 2.106755
INFO:root:FL Epoch: 100 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1049
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474212
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508744
INFO:root:FL Epoch: 100 Norm Difference for worker 1049 is 1.934783
INFO:root:FL Epoch: 100 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1864
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561818
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260532
INFO:root:FL Epoch: 100 Norm Difference for worker 1864 is 2.030432
INFO:root:FL Epoch: 100 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1066
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608827
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309099
INFO:root:FL Epoch: 100 Norm Difference for worker 1066 is 2.025239
INFO:root:FL Epoch: 100 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1740
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669875
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323869
INFO:root:FL Epoch: 100 Norm Difference for worker 1740 is 1.891166
INFO:root:FL Epoch: 100 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1716
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536480
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429596
INFO:root:FL Epoch: 100 Norm Difference for worker 1716 is 2.049275
INFO:root:FL Epoch: 100 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :840
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499945
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285764
INFO:root:FL Epoch: 100 Norm Difference for worker 840 is 1.774885
INFO:root:FL Epoch: 100 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :11
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 11 is 1.84279
INFO:root:FL Epoch: 100 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1887
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374043
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314873
INFO:root:FL Epoch: 100 Norm Difference for worker 1887 is 1.910737
INFO:root:FL Epoch: 100 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :845
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396691
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367323
INFO:root:FL Epoch: 100 Norm Difference for worker 845 is 1.92988
INFO:root:FL Epoch: 100 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8369422685592318, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8367277438467717
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8367249699359953
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8367249349692671
INFO:root:Aggregating After Defense
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5018124773221857 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:2.1233723958333335                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.990152
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189055
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.1854060348123312 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.1241087056696415 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 2.510944
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771798
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314134
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.21432571237285933 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.14582848697900772 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 2.678059
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824622
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199223
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.15318405504028001 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.12499084994196892 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 2.64255
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405918
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288625
INFO:root:FL Epoch: 101 Norm Difference for worker 1526 is 1.972527
INFO:root:FL Epoch: 101 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1322
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604765
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354595
INFO:root:FL Epoch: 101 Norm Difference for worker 1322 is 1.977028
INFO:root:FL Epoch: 101 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :862
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546849
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248458
INFO:root:FL Epoch: 101 Norm Difference for worker 862 is 2.103497
INFO:root:FL Epoch: 101 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :701
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366030
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330068
INFO:root:FL Epoch: 101 Norm Difference for worker 701 is 1.972383
INFO:root:FL Epoch: 101 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1726
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530037
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278525
INFO:root:FL Epoch: 101 Norm Difference for worker 1726 is 2.098815
INFO:root:FL Epoch: 101 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332914
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407780
INFO:root:FL Epoch: 101 Norm Difference for worker 526 is 2.019815
INFO:root:FL Epoch: 101 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1267
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629606
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439752
INFO:root:FL Epoch: 101 Norm Difference for worker 1267 is 2.017372
INFO:root:FL Epoch: 101 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9950043130020383, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9949714670576237
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9949711591183783
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9949711357740147
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.5694131623296177 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.43339229623476666                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1911
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336973
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450924
INFO:root:FL Epoch: 102 Norm Difference for worker 1911 is 2.114692
INFO:root:FL Epoch: 102 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :427
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589370
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460771
INFO:root:FL Epoch: 102 Norm Difference for worker 427 is 2.054161
INFO:root:FL Epoch: 102 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1354
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650669
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320232
INFO:root:FL Epoch: 102 Norm Difference for worker 1354 is 1.858835
INFO:root:FL Epoch: 102 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :10
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 10 is 2.076122
INFO:root:FL Epoch: 102 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1326
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610880
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433479
INFO:root:FL Epoch: 102 Norm Difference for worker 1326 is 1.948617
INFO:root:FL Epoch: 102 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1947
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637797
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255860
INFO:root:FL Epoch: 102 Norm Difference for worker 1947 is 1.928614
INFO:root:FL Epoch: 102 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1506
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642257
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243671
INFO:root:FL Epoch: 102 Norm Difference for worker 1506 is 1.83927
INFO:root:FL Epoch: 102 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1248
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468402
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238501
INFO:root:FL Epoch: 102 Norm Difference for worker 1248 is 1.947202
INFO:root:FL Epoch: 102 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :887
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401363
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283752
INFO:root:FL Epoch: 102 Norm Difference for worker 887 is 1.976038
INFO:root:FL Epoch: 102 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1077
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542592
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358597
INFO:root:FL Epoch: 102 Norm Difference for worker 1077 is 1.905182
INFO:root:FL Epoch: 102 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8252046356590537, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8250573490272846
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8250552985413577
INFO:root:#### Oracle Cals: 4, Objective Val: 1.825055276384556
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5076191653223598 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.7303065260251363                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1424
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605780
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311052
INFO:root:FL Epoch: 103 Norm Difference for worker 1424 is 1.949166
INFO:root:FL Epoch: 103 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :869
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696940
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216911
INFO:root:FL Epoch: 103 Norm Difference for worker 869 is 1.863843
INFO:root:FL Epoch: 103 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1947
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556589
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240263
INFO:root:FL Epoch: 103 Norm Difference for worker 1947 is 1.718786
INFO:root:FL Epoch: 103 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1218
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634593
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344367
INFO:root:FL Epoch: 103 Norm Difference for worker 1218 is 1.994746
INFO:root:FL Epoch: 103 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :731
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618935
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447688
INFO:root:FL Epoch: 103 Norm Difference for worker 731 is 1.926826
INFO:root:FL Epoch: 103 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :391
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700327
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340196
INFO:root:FL Epoch: 103 Norm Difference for worker 391 is 2.086531
INFO:root:FL Epoch: 103 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1873
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430770
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231786
INFO:root:FL Epoch: 103 Norm Difference for worker 1873 is 1.88622
INFO:root:FL Epoch: 103 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :163
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342300
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 163 is 2.010875
INFO:root:FL Epoch: 103 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1175
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334757
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338379
INFO:root:FL Epoch: 103 Norm Difference for worker 1175 is 1.996854
INFO:root:FL Epoch: 103 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1457
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587808
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238075
INFO:root:FL Epoch: 103 Norm Difference for worker 1457 is 1.933114
INFO:root:FL Epoch: 103 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.829448466656106, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.829244785809558
INFO:root:#### Oracle Cals: 3, Objective Val: 1.829241692028523
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8292416118172672
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.4920234592521892 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:1.025911678870519                             and Backdoor Test Accuracy:42.5 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :612
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624691
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401892
INFO:root:FL Epoch: 104 Norm Difference for worker 612 is 2.122365
INFO:root:FL Epoch: 104 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1157
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649657
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294607
INFO:root:FL Epoch: 104 Norm Difference for worker 1157 is 2.088963
INFO:root:FL Epoch: 104 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1471
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550055
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207292
INFO:root:FL Epoch: 104 Norm Difference for worker 1471 is 2.067434
INFO:root:FL Epoch: 104 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :128
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 128 is 2.095672
INFO:root:FL Epoch: 104 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :66
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 66 is 2.099731
INFO:root:FL Epoch: 104 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :879
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498651
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255054
INFO:root:FL Epoch: 104 Norm Difference for worker 879 is 2.086096
INFO:root:FL Epoch: 104 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1042
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529827
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261793
INFO:root:FL Epoch: 104 Norm Difference for worker 1042 is 1.994156
INFO:root:FL Epoch: 104 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1632
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516460
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242433
INFO:root:FL Epoch: 104 Norm Difference for worker 1632 is 2.016476
INFO:root:FL Epoch: 104 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :150
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.798949
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 150 is 2.01898
INFO:root:FL Epoch: 104 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1712
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629847
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375236
INFO:root:FL Epoch: 104 Norm Difference for worker 1712 is 2.02943
INFO:root:FL Epoch: 104 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9258061313914037, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9257315785897131
INFO:root:#### Oracle Cals: 3, Objective Val: 1.925730565689906
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9257305472187798
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5068561136722565 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:0.824397216240565                             and Backdoor Test Accuracy:51.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1124
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434190
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334218
INFO:root:FL Epoch: 105 Norm Difference for worker 1124 is 1.909519
INFO:root:FL Epoch: 105 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :766
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414457
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411731
INFO:root:FL Epoch: 105 Norm Difference for worker 766 is 1.786862
INFO:root:FL Epoch: 105 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :284
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 284 is 1.91884
INFO:root:FL Epoch: 105 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1589
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744704
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385170
INFO:root:FL Epoch: 105 Norm Difference for worker 1589 is 2.031934
INFO:root:FL Epoch: 105 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1409
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402316
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302619
INFO:root:FL Epoch: 105 Norm Difference for worker 1409 is 1.861573
INFO:root:FL Epoch: 105 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1883
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612106
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390298
INFO:root:FL Epoch: 105 Norm Difference for worker 1883 is 1.802774
INFO:root:FL Epoch: 105 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :833
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461864
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325960
INFO:root:FL Epoch: 105 Norm Difference for worker 833 is 1.870794
INFO:root:FL Epoch: 105 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1441
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349535
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309982
INFO:root:FL Epoch: 105 Norm Difference for worker 1441 is 1.864276
INFO:root:FL Epoch: 105 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :847
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514356
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226480
INFO:root:FL Epoch: 105 Norm Difference for worker 847 is 1.847183
INFO:root:FL Epoch: 105 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1423
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300715
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379299
INFO:root:FL Epoch: 105 Norm Difference for worker 1423 is 1.711382
INFO:root:FL Epoch: 105 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7469461908182016, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7467538938708402
INFO:root:#### Oracle Cals: 3, Objective Val: 1.746751402327301
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7467513446677467
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5229877584120807 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:1.2330750823020935                             and Backdoor Test Accuracy:26.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :534
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697617
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373642
INFO:root:FL Epoch: 106 Norm Difference for worker 534 is 2.131123
INFO:root:FL Epoch: 106 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :186
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 186 is 1.881917
INFO:root:FL Epoch: 106 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :452
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549915
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264502
INFO:root:FL Epoch: 106 Norm Difference for worker 452 is 1.831125
INFO:root:FL Epoch: 106 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :985
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416210
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244774
INFO:root:FL Epoch: 106 Norm Difference for worker 985 is 2.020502
INFO:root:FL Epoch: 106 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1302
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603179
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316982
INFO:root:FL Epoch: 106 Norm Difference for worker 1302 is 1.983437
INFO:root:FL Epoch: 106 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1826
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418822
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407611
INFO:root:FL Epoch: 106 Norm Difference for worker 1826 is 1.894358
INFO:root:FL Epoch: 106 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :274
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463452
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 274 is 1.9254
INFO:root:FL Epoch: 106 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1833
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397988
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327441
INFO:root:FL Epoch: 106 Norm Difference for worker 1833 is 1.946889
INFO:root:FL Epoch: 106 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :626
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421864
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289943
INFO:root:FL Epoch: 106 Norm Difference for worker 626 is 1.900728
INFO:root:FL Epoch: 106 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757071
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249235
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.992889
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8343479451470586, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8341634059195244
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8341610600970801
INFO:root:#### Oracle Cals: 4, Objective Val: 1.834161024945244
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5114782382460201 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.0570193827152252                             and Backdoor Test Accuracy:39.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1731
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656719
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200757
INFO:root:FL Epoch: 107 Norm Difference for worker 1731 is 2.058744
INFO:root:FL Epoch: 107 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1909
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724868
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287757
INFO:root:FL Epoch: 107 Norm Difference for worker 1909 is 2.095528
INFO:root:FL Epoch: 107 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1927
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578465
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177900
INFO:root:FL Epoch: 107 Norm Difference for worker 1927 is 1.987358
INFO:root:FL Epoch: 107 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1664
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559187
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206176
INFO:root:FL Epoch: 107 Norm Difference for worker 1664 is 1.937585
INFO:root:FL Epoch: 107 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :392
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578048
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309685
INFO:root:FL Epoch: 107 Norm Difference for worker 392 is 1.969565
INFO:root:FL Epoch: 107 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :575
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750927
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321150
INFO:root:FL Epoch: 107 Norm Difference for worker 575 is 2.232082
INFO:root:FL Epoch: 107 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1365
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440469
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251205
INFO:root:FL Epoch: 107 Norm Difference for worker 1365 is 2.030424
INFO:root:FL Epoch: 107 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :308
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.368794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 308 is 1.884981
INFO:root:FL Epoch: 107 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1329
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469030
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251265
INFO:root:FL Epoch: 107 Norm Difference for worker 1329 is 1.969309
INFO:root:FL Epoch: 107 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :142
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 142 is 2.020316
INFO:root:FL Epoch: 107 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8962727513480582, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.896066810827861
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8960646722398504
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8960646448215521
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.5035525157171137 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.1607277890046437                             and Backdoor Test Accuracy:37.5 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 108 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :65
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353664
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 65 is 2.059009
INFO:root:FL Epoch: 108 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :163
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 163 is 1.998847
INFO:root:FL Epoch: 108 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :504
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597625
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249182
INFO:root:FL Epoch: 108 Norm Difference for worker 504 is 1.970029
INFO:root:FL Epoch: 108 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :120
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 120 is 2.003195
INFO:root:FL Epoch: 108 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1859
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663270
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417318
INFO:root:FL Epoch: 108 Norm Difference for worker 1859 is 2.076808
INFO:root:FL Epoch: 108 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1651
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643253
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438299
INFO:root:FL Epoch: 108 Norm Difference for worker 1651 is 1.858104
INFO:root:FL Epoch: 108 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1272
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378450
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555867
INFO:root:FL Epoch: 108 Norm Difference for worker 1272 is 2.060716
INFO:root:FL Epoch: 108 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :595
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698818
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226804
INFO:root:FL Epoch: 108 Norm Difference for worker 595 is 2.018855
INFO:root:FL Epoch: 108 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :487
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271119
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565347
INFO:root:FL Epoch: 108 Norm Difference for worker 487 is 1.904845
INFO:root:FL Epoch: 108 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1181
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417150
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242917
INFO:root:FL Epoch: 108 Norm Difference for worker 1181 is 1.887481
INFO:root:FL Epoch: 108 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8761596950902872, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.876027996363029
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8760262468820252
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8760261459834637
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.45616181457743926 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:1.0475947360197704                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :659
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383624
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244343
INFO:root:FL Epoch: 109 Norm Difference for worker 659 is 2.030184
INFO:root:FL Epoch: 109 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1630
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545755
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436844
INFO:root:FL Epoch: 109 Norm Difference for worker 1630 is 2.080572
INFO:root:FL Epoch: 109 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :147
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363795
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 147 is 1.986116
INFO:root:FL Epoch: 109 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1704
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534756
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231663
INFO:root:FL Epoch: 109 Norm Difference for worker 1704 is 1.897365
INFO:root:FL Epoch: 109 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1338
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600185
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480225
INFO:root:FL Epoch: 109 Norm Difference for worker 1338 is 1.870193
INFO:root:FL Epoch: 109 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :376
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633908
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291378
INFO:root:FL Epoch: 109 Norm Difference for worker 376 is 1.946134
INFO:root:FL Epoch: 109 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :790
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507446
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328576
INFO:root:FL Epoch: 109 Norm Difference for worker 790 is 1.997316
INFO:root:FL Epoch: 109 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1004
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753457
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380438
INFO:root:FL Epoch: 109 Norm Difference for worker 1004 is 2.073804
INFO:root:FL Epoch: 109 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1131
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588498
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559436
INFO:root:FL Epoch: 109 Norm Difference for worker 1131 is 2.101271
INFO:root:FL Epoch: 109 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :172
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 172 is 1.909525
INFO:root:FL Epoch: 109 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8772705091943047, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8771017500935585
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8770997582110582
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8770997262673363
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.4692779218449312 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.06928555170695                             and Backdoor Test Accuracy:36.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :191
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 191 is 1.8724
INFO:root:FL Epoch: 110 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :844
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257122
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200378
INFO:root:FL Epoch: 110 Norm Difference for worker 844 is 1.799481
INFO:root:FL Epoch: 110 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1062
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612032
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448561
INFO:root:FL Epoch: 110 Norm Difference for worker 1062 is 2.115688
INFO:root:FL Epoch: 110 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1182
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343055
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559246
INFO:root:FL Epoch: 110 Norm Difference for worker 1182 is 1.919602
INFO:root:FL Epoch: 110 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1038
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713368
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479227
INFO:root:FL Epoch: 110 Norm Difference for worker 1038 is 1.892654
INFO:root:FL Epoch: 110 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :791
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321876
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231133
INFO:root:FL Epoch: 110 Norm Difference for worker 791 is 1.917799
INFO:root:FL Epoch: 110 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1015
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415061
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429483
INFO:root:FL Epoch: 110 Norm Difference for worker 1015 is 1.975535
INFO:root:FL Epoch: 110 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :160
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 160 is 2.067393
INFO:root:FL Epoch: 110 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :803
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878842
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301022
INFO:root:FL Epoch: 110 Norm Difference for worker 803 is 1.905618
INFO:root:FL Epoch: 110 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :902
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501821
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231933
INFO:root:FL Epoch: 110 Norm Difference for worker 902 is 1.884655
INFO:root:FL Epoch: 110 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8103558234748256, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8102327581422297
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8102312692482918
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8102312567257095
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.5022633321145001 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.1198611160119374                             and Backdoor Test Accuracy:30.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758861
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273954
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.08623027956734101 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.058202045224606994 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 1.998659
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568383
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222681
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.09430045712118347 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.06611476391553879 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 2.08115
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341932
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.091131
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.12358613001803558 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.07555962465703488 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 2.011656
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :212
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 212 is 1.830139
INFO:root:FL Epoch: 111 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :603
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716288
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269633
INFO:root:FL Epoch: 111 Norm Difference for worker 603 is 1.991922
INFO:root:FL Epoch: 111 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1485
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357852
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300146
INFO:root:FL Epoch: 111 Norm Difference for worker 1485 is 1.959108
INFO:root:FL Epoch: 111 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1334
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435575
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516544
INFO:root:FL Epoch: 111 Norm Difference for worker 1334 is 1.992428
INFO:root:FL Epoch: 111 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :260
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.939749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 260 is 1.958698
INFO:root:FL Epoch: 111 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1352
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476162
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183441
INFO:root:FL Epoch: 111 Norm Difference for worker 1352 is 1.997057
INFO:root:FL Epoch: 111 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1619
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478565
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160982
INFO:root:FL Epoch: 111 Norm Difference for worker 1619 is 1.93764
INFO:root:FL Epoch: 111 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8054776888832944, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8034652798471633
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8032396546907525
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8032119101202027
INFO:root:#### Oracle Cals: 5, Objective Val: 1.8032084333498037
INFO:root:#### Oracle Cals: 6, Objective Val: 1.8032079799413834
INFO:root:#### Oracle Cals: 7, Objective Val: 1.803207923349463
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.5193948184742647 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.2262860412398974                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 112 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :254
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 254 is 2.032413
INFO:root:FL Epoch: 112 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :253
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 253 is 1.977919
INFO:root:FL Epoch: 112 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :267
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326386
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 267 is 2.022825
INFO:root:FL Epoch: 112 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1281
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562277
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212340
INFO:root:FL Epoch: 112 Norm Difference for worker 1281 is 1.9908
INFO:root:FL Epoch: 112 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :552
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523851
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405238
INFO:root:FL Epoch: 112 Norm Difference for worker 552 is 2.119255
INFO:root:FL Epoch: 112 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1889
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499662
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322786
INFO:root:FL Epoch: 112 Norm Difference for worker 1889 is 2.124042
INFO:root:FL Epoch: 112 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1555
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547646
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272605
INFO:root:FL Epoch: 112 Norm Difference for worker 1555 is 2.013874
INFO:root:FL Epoch: 112 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1475
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653483
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298631
INFO:root:FL Epoch: 112 Norm Difference for worker 1475 is 2.004521
INFO:root:FL Epoch: 112 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :334
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 334 is 2.05512
INFO:root:FL Epoch: 112 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :202
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524188
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 202 is 2.132174
INFO:root:FL Epoch: 112 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9078289893620668, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9077314656494613
INFO:root:#### Oracle Cals: 3, Objective Val: 1.907730120849123
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9077301131060518
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.48123561284121347 and Test Accuracy:75.0 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.45604891578356427                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 113 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :173
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 173 is 1.9213
INFO:root:FL Epoch: 113 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1677
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587802
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354205
INFO:root:FL Epoch: 113 Norm Difference for worker 1677 is 1.975936
INFO:root:FL Epoch: 113 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1063
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407093
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316715
INFO:root:FL Epoch: 113 Norm Difference for worker 1063 is 2.014079
INFO:root:FL Epoch: 113 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :828
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573426
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198173
INFO:root:FL Epoch: 113 Norm Difference for worker 828 is 2.100293
INFO:root:FL Epoch: 113 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1243
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642454
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356415
INFO:root:FL Epoch: 113 Norm Difference for worker 1243 is 2.151646
INFO:root:FL Epoch: 113 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1645
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738479
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259798
INFO:root:FL Epoch: 113 Norm Difference for worker 1645 is 1.910092
INFO:root:FL Epoch: 113 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :701
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636420
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226052
INFO:root:FL Epoch: 113 Norm Difference for worker 701 is 1.945043
INFO:root:FL Epoch: 113 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :511
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473258
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205353
INFO:root:FL Epoch: 113 Norm Difference for worker 511 is 1.956306
INFO:root:FL Epoch: 113 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1769
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803270
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370363
INFO:root:FL Epoch: 113 Norm Difference for worker 1769 is 1.940212
INFO:root:FL Epoch: 113 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :539
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700889
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246927
INFO:root:FL Epoch: 113 Norm Difference for worker 539 is 1.989413
INFO:root:FL Epoch: 113 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8624933701801916, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.862366117218062
INFO:root:#### Oracle Cals: 3, Objective Val: 1.862364462909535
INFO:root:#### Oracle Cals: 4, Objective Val: 1.862364401232346
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.4872640494038077 and Test Accuracy:75.0 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.5301515609025955                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1682
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341296
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348067
INFO:root:FL Epoch: 114 Norm Difference for worker 1682 is 1.926729
INFO:root:FL Epoch: 114 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :817
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665426
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245478
INFO:root:FL Epoch: 114 Norm Difference for worker 817 is 1.948503
INFO:root:FL Epoch: 114 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :747
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611741
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261235
INFO:root:FL Epoch: 114 Norm Difference for worker 747 is 1.892317
INFO:root:FL Epoch: 114 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1065
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496332
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416025
INFO:root:FL Epoch: 114 Norm Difference for worker 1065 is 1.884436
INFO:root:FL Epoch: 114 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :615
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347502
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189806
INFO:root:FL Epoch: 114 Norm Difference for worker 615 is 1.94022
INFO:root:FL Epoch: 114 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :439
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335565
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335496
INFO:root:FL Epoch: 114 Norm Difference for worker 439 is 1.880324
INFO:root:FL Epoch: 114 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :501
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424181
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289961
INFO:root:FL Epoch: 114 Norm Difference for worker 501 is 1.913687
INFO:root:FL Epoch: 114 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1941
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567726
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436997
INFO:root:FL Epoch: 114 Norm Difference for worker 1941 is 1.914364
INFO:root:FL Epoch: 114 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :729
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415315
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365414
INFO:root:FL Epoch: 114 Norm Difference for worker 729 is 1.92914
INFO:root:FL Epoch: 114 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1621
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496831
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336841
INFO:root:FL Epoch: 114 Norm Difference for worker 1621 is 1.851189
INFO:root:FL Epoch: 114 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.791777367541141, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7917457903427274
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7917453708166369
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7917453687349694
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.4713333056253545 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.5930834263563156                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1247
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465179
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386483
INFO:root:FL Epoch: 115 Norm Difference for worker 1247 is 2.028376
INFO:root:FL Epoch: 115 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1891
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547480
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230162
INFO:root:FL Epoch: 115 Norm Difference for worker 1891 is 1.885118
INFO:root:FL Epoch: 115 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1092
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622211
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304311
INFO:root:FL Epoch: 115 Norm Difference for worker 1092 is 2.008406
INFO:root:FL Epoch: 115 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1160
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569284
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367311
INFO:root:FL Epoch: 115 Norm Difference for worker 1160 is 2.075108
INFO:root:FL Epoch: 115 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1542
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335778
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340318
INFO:root:FL Epoch: 115 Norm Difference for worker 1542 is 2.0165
INFO:root:FL Epoch: 115 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681212
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355162
INFO:root:FL Epoch: 115 Norm Difference for worker 1248 is 1.953924
INFO:root:FL Epoch: 115 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1758
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668984
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283163
INFO:root:FL Epoch: 115 Norm Difference for worker 1758 is 1.93376
INFO:root:FL Epoch: 115 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :206
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.190856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 206 is 1.691274
INFO:root:FL Epoch: 115 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :881
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503705
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282274
INFO:root:FL Epoch: 115 Norm Difference for worker 881 is 1.755104
INFO:root:FL Epoch: 115 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1311
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433409
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477678
INFO:root:FL Epoch: 115 Norm Difference for worker 1311 is 1.92162
INFO:root:FL Epoch: 115 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8156372053024188, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.815316990029068
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8153125516485704
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8153125485582442
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.47414468141163096 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:0.5906749268372854                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :670
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797028
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285789
INFO:root:FL Epoch: 116 Norm Difference for worker 670 is 1.893304
INFO:root:FL Epoch: 116 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :77
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 77 is 1.779065
INFO:root:FL Epoch: 116 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :14
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 14 is 1.85642
INFO:root:FL Epoch: 116 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :831
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492745
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372489
INFO:root:FL Epoch: 116 Norm Difference for worker 831 is 1.835343
INFO:root:FL Epoch: 116 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :557
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492234
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322179
INFO:root:FL Epoch: 116 Norm Difference for worker 557 is 1.918208
INFO:root:FL Epoch: 116 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1196
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549771
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391886
INFO:root:FL Epoch: 116 Norm Difference for worker 1196 is 2.000028
INFO:root:FL Epoch: 116 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1519
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857911
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294345
INFO:root:FL Epoch: 116 Norm Difference for worker 1519 is 1.887164
INFO:root:FL Epoch: 116 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :237
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 237 is 1.93189
INFO:root:FL Epoch: 116 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1512
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637335
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244928
INFO:root:FL Epoch: 116 Norm Difference for worker 1512 is 1.857102
INFO:root:FL Epoch: 116 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :592
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345215
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365888
INFO:root:FL Epoch: 116 Norm Difference for worker 592 is 1.925666
INFO:root:FL Epoch: 116 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7824288527634098, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.78234824651619
INFO:root:#### Oracle Cals: 3, Objective Val: 1.782347216703815
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7823471451977304
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.47807395633529215 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.5365087141593298                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 117 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :300
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 300 is 2.02211
INFO:root:FL Epoch: 117 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :251
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 251 is 1.976932
INFO:root:FL Epoch: 117 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :562
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597853
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229474
INFO:root:FL Epoch: 117 Norm Difference for worker 562 is 1.868056
INFO:root:FL Epoch: 117 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1356
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815121
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313955
INFO:root:FL Epoch: 117 Norm Difference for worker 1356 is 2.163025
INFO:root:FL Epoch: 117 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :204
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 204 is 2.079288
INFO:root:FL Epoch: 117 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :809
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835587
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347194
INFO:root:FL Epoch: 117 Norm Difference for worker 809 is 1.888355
INFO:root:FL Epoch: 117 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :968
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656666
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347399
INFO:root:FL Epoch: 117 Norm Difference for worker 968 is 1.877484
INFO:root:FL Epoch: 117 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1645
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478675
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230458
INFO:root:FL Epoch: 117 Norm Difference for worker 1645 is 1.90741
INFO:root:FL Epoch: 117 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1482
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603931
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286053
INFO:root:FL Epoch: 117 Norm Difference for worker 1482 is 1.906085
INFO:root:FL Epoch: 117 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :844
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456428
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186001
INFO:root:FL Epoch: 117 Norm Difference for worker 844 is 1.750751
INFO:root:FL Epoch: 117 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8350839776069345, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8347511195555606
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8347465708431498
INFO:root:#### Oracle Cals: 4, Objective Val: 1.834746520058292
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.48472556296516867 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.5594666947921118                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 118 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :191
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369863
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 191 is 1.856722
INFO:root:FL Epoch: 118 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1890
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587963
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335674
INFO:root:FL Epoch: 118 Norm Difference for worker 1890 is 1.924493
INFO:root:FL Epoch: 118 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :999
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498794
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280468
INFO:root:FL Epoch: 118 Norm Difference for worker 999 is 1.913719
INFO:root:FL Epoch: 118 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1404
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358094
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241573
INFO:root:FL Epoch: 118 Norm Difference for worker 1404 is 1.807852
INFO:root:FL Epoch: 118 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :725
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437967
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307984
INFO:root:FL Epoch: 118 Norm Difference for worker 725 is 1.87296
INFO:root:FL Epoch: 118 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1853
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394821
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312993
INFO:root:FL Epoch: 118 Norm Difference for worker 1853 is 2.065484
INFO:root:FL Epoch: 118 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1315
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539726
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365920
INFO:root:FL Epoch: 118 Norm Difference for worker 1315 is 2.022081
INFO:root:FL Epoch: 118 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1082
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490035
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357515
INFO:root:FL Epoch: 118 Norm Difference for worker 1082 is 1.779717
INFO:root:FL Epoch: 118 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :862
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750583
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319910
INFO:root:FL Epoch: 118 Norm Difference for worker 862 is 1.893158
INFO:root:FL Epoch: 118 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :84
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.847822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 84 is 1.853963
INFO:root:FL Epoch: 118 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.806874155146846, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8067092334630113
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8067070787047899
INFO:root:#### Oracle Cals: 4, Objective Val: 1.806707048169996
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.49000386104864235 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:0.6293050150076548                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :917
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469738
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330871
INFO:root:FL Epoch: 119 Norm Difference for worker 917 is 2.107241
INFO:root:FL Epoch: 119 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :474
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388937
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362188
INFO:root:FL Epoch: 119 Norm Difference for worker 474 is 2.081913
INFO:root:FL Epoch: 119 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656276
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321486
INFO:root:FL Epoch: 119 Norm Difference for worker 748 is 2.138618
INFO:root:FL Epoch: 119 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1071
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665128
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264085
INFO:root:FL Epoch: 119 Norm Difference for worker 1071 is 2.045295
INFO:root:FL Epoch: 119 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :436
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600415
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433074
INFO:root:FL Epoch: 119 Norm Difference for worker 436 is 1.972427
INFO:root:FL Epoch: 119 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1413
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404039
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182325
INFO:root:FL Epoch: 119 Norm Difference for worker 1413 is 1.860027
INFO:root:FL Epoch: 119 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :141
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 141 is 1.843992
INFO:root:FL Epoch: 119 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :439
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574512
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315528
INFO:root:FL Epoch: 119 Norm Difference for worker 439 is 1.947432
INFO:root:FL Epoch: 119 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :281
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 281 is 1.870206
INFO:root:FL Epoch: 119 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1415
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615850
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363738
INFO:root:FL Epoch: 119 Norm Difference for worker 1415 is 2.216026
INFO:root:FL Epoch: 119 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8934478030000461, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8931734528589304
INFO:root:#### Oracle Cals: 3, Objective Val: 1.893169761711276
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8931697085646537
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.4794989000348484 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:0.5760969618956248                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :672
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547386
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445001
INFO:root:FL Epoch: 120 Norm Difference for worker 672 is 2.008443
INFO:root:FL Epoch: 120 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1130
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666490
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481714
INFO:root:FL Epoch: 120 Norm Difference for worker 1130 is 1.980412
INFO:root:FL Epoch: 120 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :89
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 89 is 1.952153
INFO:root:FL Epoch: 120 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :766
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484551
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248236
INFO:root:FL Epoch: 120 Norm Difference for worker 766 is 1.846133
INFO:root:FL Epoch: 120 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :604
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727423
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193121
INFO:root:FL Epoch: 120 Norm Difference for worker 604 is 1.935785
INFO:root:FL Epoch: 120 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1934
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431143
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262296
INFO:root:FL Epoch: 120 Norm Difference for worker 1934 is 2.04994
INFO:root:FL Epoch: 120 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1085
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335377
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368546
INFO:root:FL Epoch: 120 Norm Difference for worker 1085 is 1.938227
INFO:root:FL Epoch: 120 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1785
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477850
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207548
INFO:root:FL Epoch: 120 Norm Difference for worker 1785 is 1.982679
INFO:root:FL Epoch: 120 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :799
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266850
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274674
INFO:root:FL Epoch: 120 Norm Difference for worker 799 is 1.990012
INFO:root:FL Epoch: 120 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :394
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541457
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314273
INFO:root:FL Epoch: 120 Norm Difference for worker 394 is 1.893535
INFO:root:FL Epoch: 120 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8536241270788387, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8535462604415602
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8535452869237372
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8535452932348135
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.47038831255015207 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:0.5612364759047827                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481049
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204241
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.05458151207615932 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.057187200710177424 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 1.804508
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442821
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196568
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.052528766759981714 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.05825216844677925 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 1.720978
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383348
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.089175
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.04713920255502065 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.05791249573230743 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 1.729369
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1516
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435679
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339728
INFO:root:FL Epoch: 121 Norm Difference for worker 1516 is 1.919292
INFO:root:FL Epoch: 121 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1691
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572252
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346902
INFO:root:FL Epoch: 121 Norm Difference for worker 1691 is 1.872375
INFO:root:FL Epoch: 121 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1534
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460927
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163627
INFO:root:FL Epoch: 121 Norm Difference for worker 1534 is 1.835079
INFO:root:FL Epoch: 121 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1245
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405429
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368512
INFO:root:FL Epoch: 121 Norm Difference for worker 1245 is 1.878495
INFO:root:FL Epoch: 121 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1693
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571661
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190874
INFO:root:FL Epoch: 121 Norm Difference for worker 1693 is 1.814277
INFO:root:FL Epoch: 121 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :520
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513947
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475046
INFO:root:FL Epoch: 121 Norm Difference for worker 520 is 1.890776
INFO:root:FL Epoch: 121 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628352
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260935
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 1.845655
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6693417282958083, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6650743586964731
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6645507456865052
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6644796837807039
INFO:root:#### Oracle Cals: 5, Objective Val: 1.6644696405742783
INFO:root:#### Oracle Cals: 6, Objective Val: 1.664468224638232
INFO:root:#### Oracle Cals: 7, Objective Val: 1.6644680152077225
INFO:root:#### Oracle Cals: 8, Objective Val: 1.6644680053377765
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.47556906938552856 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.1767364206413428                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 122 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :847
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517850
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248546
INFO:root:FL Epoch: 122 Norm Difference for worker 847 is 2.049112
INFO:root:FL Epoch: 122 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :302
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 302 is 1.999746
INFO:root:FL Epoch: 122 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1156
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547943
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265373
INFO:root:FL Epoch: 122 Norm Difference for worker 1156 is 2.043278
INFO:root:FL Epoch: 122 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1187
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485454
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167708
INFO:root:FL Epoch: 122 Norm Difference for worker 1187 is 2.033727
INFO:root:FL Epoch: 122 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :252
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189767
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 252 is 2.086908
INFO:root:FL Epoch: 122 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :460
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352109
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272143
INFO:root:FL Epoch: 122 Norm Difference for worker 460 is 2.243011
INFO:root:FL Epoch: 122 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1246
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440996
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665463
INFO:root:FL Epoch: 122 Norm Difference for worker 1246 is 2.13987
INFO:root:FL Epoch: 122 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :151
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 151 is 2.075716
INFO:root:FL Epoch: 122 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :556
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707629
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325661
INFO:root:FL Epoch: 122 Norm Difference for worker 556 is 2.122913
INFO:root:FL Epoch: 122 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1367
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383887
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276722
INFO:root:FL Epoch: 122 Norm Difference for worker 1367 is 2.168303
INFO:root:FL Epoch: 122 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.968290833254268, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9681584540671078
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9681568057090664
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9681568356765407
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.48249465753050413 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.37917228043079376                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :900
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632625
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328434
INFO:root:FL Epoch: 123 Norm Difference for worker 900 is 1.936032
INFO:root:FL Epoch: 123 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :614
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834588
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328328
INFO:root:FL Epoch: 123 Norm Difference for worker 614 is 1.962731
INFO:root:FL Epoch: 123 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1916
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579991
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206945
INFO:root:FL Epoch: 123 Norm Difference for worker 1916 is 1.988768
INFO:root:FL Epoch: 123 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1149
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395145
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447619
INFO:root:FL Epoch: 123 Norm Difference for worker 1149 is 1.998421
INFO:root:FL Epoch: 123 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1225
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799601
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353087
INFO:root:FL Epoch: 123 Norm Difference for worker 1225 is 1.973246
INFO:root:FL Epoch: 123 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :315
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.385711
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 315 is 1.864413
INFO:root:FL Epoch: 123 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :66
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 66 is 1.934191
INFO:root:FL Epoch: 123 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :959
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693622
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344490
INFO:root:FL Epoch: 123 Norm Difference for worker 959 is 2.063871
INFO:root:FL Epoch: 123 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :938
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582637
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249851
INFO:root:FL Epoch: 123 Norm Difference for worker 938 is 1.997247
INFO:root:FL Epoch: 123 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1349
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474721
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320309
INFO:root:FL Epoch: 123 Norm Difference for worker 1349 is 1.990313
INFO:root:FL Epoch: 123 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8585015152753295, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8584216428221916
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8584204921767689
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8584204934078015
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.49857226364752827 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.39816251893838245                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :1329
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761486
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279417
INFO:root:FL Epoch: 124 Norm Difference for worker 1329 is 1.890617
INFO:root:FL Epoch: 124 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1737
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428756
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295324
INFO:root:FL Epoch: 124 Norm Difference for worker 1737 is 1.818505
INFO:root:FL Epoch: 124 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :570
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379361
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255307
INFO:root:FL Epoch: 124 Norm Difference for worker 570 is 1.753306
INFO:root:FL Epoch: 124 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1802
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542889
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284290
INFO:root:FL Epoch: 124 Norm Difference for worker 1802 is 1.87817
INFO:root:FL Epoch: 124 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1438
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755127
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412722
INFO:root:FL Epoch: 124 Norm Difference for worker 1438 is 1.863178
INFO:root:FL Epoch: 124 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :725
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415623
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225703
INFO:root:FL Epoch: 124 Norm Difference for worker 725 is 1.838426
INFO:root:FL Epoch: 124 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :394
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433451
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358202
INFO:root:FL Epoch: 124 Norm Difference for worker 394 is 1.841694
INFO:root:FL Epoch: 124 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :456
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513479
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201285
INFO:root:FL Epoch: 124 Norm Difference for worker 456 is 1.920146
INFO:root:FL Epoch: 124 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1801
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568171
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172156
INFO:root:FL Epoch: 124 Norm Difference for worker 1801 is 1.903762
INFO:root:FL Epoch: 124 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1221
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546916
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329338
INFO:root:FL Epoch: 124 Norm Difference for worker 1221 is 1.911602
INFO:root:FL Epoch: 124 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7440264469202995, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7439787197950192
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7439781321658894
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7439781223320499
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.46231210494742675 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.33159322291612625                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :371
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433661
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250085
INFO:root:FL Epoch: 125 Norm Difference for worker 371 is 1.989511
INFO:root:FL Epoch: 125 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :455
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798775
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430321
INFO:root:FL Epoch: 125 Norm Difference for worker 455 is 2.155986
INFO:root:FL Epoch: 125 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :747
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438394
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323636
INFO:root:FL Epoch: 125 Norm Difference for worker 747 is 1.889359
INFO:root:FL Epoch: 125 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :106
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.782715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344362
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 106 is 1.989882
INFO:root:FL Epoch: 125 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1722
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288705
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167754
INFO:root:FL Epoch: 125 Norm Difference for worker 1722 is 1.942209
INFO:root:FL Epoch: 125 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :631
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483024
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242561
INFO:root:FL Epoch: 125 Norm Difference for worker 631 is 1.998349
INFO:root:FL Epoch: 125 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :374
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750834
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248492
INFO:root:FL Epoch: 125 Norm Difference for worker 374 is 1.791318
INFO:root:FL Epoch: 125 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1617
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529239
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381111
INFO:root:FL Epoch: 125 Norm Difference for worker 1617 is 1.946367
INFO:root:FL Epoch: 125 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :513
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.941810
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457794
INFO:root:FL Epoch: 125 Norm Difference for worker 513 is 2.111179
INFO:root:FL Epoch: 125 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1270
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506494
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169786
INFO:root:FL Epoch: 125 Norm Difference for worker 1270 is 1.884754
INFO:root:FL Epoch: 125 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.851203297528986, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8509401927559705
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8509368393450027
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8509367713884453
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.46931033975937786 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.39327385276556015                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 126 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1262
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497856
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262058
INFO:root:FL Epoch: 126 Norm Difference for worker 1262 is 2.031178
INFO:root:FL Epoch: 126 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :808
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351836
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290929
INFO:root:FL Epoch: 126 Norm Difference for worker 808 is 1.820655
INFO:root:FL Epoch: 126 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :93
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526795
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181902
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 93 is 1.931452
INFO:root:FL Epoch: 126 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1323
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711827
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235396
INFO:root:FL Epoch: 126 Norm Difference for worker 1323 is 1.939092
INFO:root:FL Epoch: 126 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1090
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539950
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208260
INFO:root:FL Epoch: 126 Norm Difference for worker 1090 is 1.726859
INFO:root:FL Epoch: 126 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :844
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265677
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288590
INFO:root:FL Epoch: 126 Norm Difference for worker 844 is 1.701995
INFO:root:FL Epoch: 126 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :915
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581726
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298987
INFO:root:FL Epoch: 126 Norm Difference for worker 915 is 1.927545
INFO:root:FL Epoch: 126 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :433
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456314
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385088
INFO:root:FL Epoch: 126 Norm Difference for worker 433 is 1.817156
INFO:root:FL Epoch: 126 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :605
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648323
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290775
INFO:root:FL Epoch: 126 Norm Difference for worker 605 is 1.827737
INFO:root:FL Epoch: 126 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :416
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641259
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244816
INFO:root:FL Epoch: 126 Norm Difference for worker 416 is 1.894304
INFO:root:FL Epoch: 126 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7606920926909193, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.76045122507833
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7604482312151832
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7604482024142212
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.4566743181032293 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.4214428166548411                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :857
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477805
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281823
INFO:root:FL Epoch: 127 Norm Difference for worker 857 is 2.121133
INFO:root:FL Epoch: 127 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1514
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498998
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293839
INFO:root:FL Epoch: 127 Norm Difference for worker 1514 is 1.904665
INFO:root:FL Epoch: 127 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :267
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.175591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 267 is 1.882665
INFO:root:FL Epoch: 127 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1586
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865938
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405832
INFO:root:FL Epoch: 127 Norm Difference for worker 1586 is 1.936664
INFO:root:FL Epoch: 127 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :889
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441146
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269672
INFO:root:FL Epoch: 127 Norm Difference for worker 889 is 2.002532
INFO:root:FL Epoch: 127 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1059
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606407
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197793
INFO:root:FL Epoch: 127 Norm Difference for worker 1059 is 1.821912
INFO:root:FL Epoch: 127 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1388
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393512
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289088
INFO:root:FL Epoch: 127 Norm Difference for worker 1388 is 1.883657
INFO:root:FL Epoch: 127 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1617
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401836
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313935
INFO:root:FL Epoch: 127 Norm Difference for worker 1617 is 1.90677
INFO:root:FL Epoch: 127 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1454
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315979
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204877
INFO:root:FL Epoch: 127 Norm Difference for worker 1454 is 1.832906
INFO:root:FL Epoch: 127 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1616
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485924
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420717
INFO:root:FL Epoch: 127 Norm Difference for worker 1616 is 1.899283
INFO:root:FL Epoch: 127 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8023780359939732, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8021006031167628
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8020974016575921
INFO:root:#### Oracle Cals: 4, Objective Val: 1.802097372197306
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.4614611285574296 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.5381708741188049                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 128 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :310
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 310 is 1.984271
INFO:root:FL Epoch: 128 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :104
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.352778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 104 is 2.031664
INFO:root:FL Epoch: 128 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :160
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.784215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 160 is 2.045996
INFO:root:FL Epoch: 128 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :498
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399203
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364982
INFO:root:FL Epoch: 128 Norm Difference for worker 498 is 2.00807
INFO:root:FL Epoch: 128 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :577
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595826
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357624
INFO:root:FL Epoch: 128 Norm Difference for worker 577 is 2.049633
INFO:root:FL Epoch: 128 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1023
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399457
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219218
INFO:root:FL Epoch: 128 Norm Difference for worker 1023 is 1.965487
INFO:root:FL Epoch: 128 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :911
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733981
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322902
INFO:root:FL Epoch: 128 Norm Difference for worker 911 is 1.97101
INFO:root:FL Epoch: 128 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :823
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586344
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348662
INFO:root:FL Epoch: 128 Norm Difference for worker 823 is 1.992136
INFO:root:FL Epoch: 128 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1667
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664115
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292562
INFO:root:FL Epoch: 128 Norm Difference for worker 1667 is 2.068279
INFO:root:FL Epoch: 128 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :754
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462224
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297842
INFO:root:FL Epoch: 128 Norm Difference for worker 754 is 1.932119
INFO:root:FL Epoch: 128 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8866614515332065, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8865954735590584
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8865944965492063
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8865944804423187
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.46244894055759206 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.525254691640536                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1492
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492058
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219101
INFO:root:FL Epoch: 129 Norm Difference for worker 1492 is 1.950405
INFO:root:FL Epoch: 129 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :354
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583186
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294792
INFO:root:FL Epoch: 129 Norm Difference for worker 354 is 1.883828
INFO:root:FL Epoch: 129 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :33
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 33 is 1.935097
INFO:root:FL Epoch: 129 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1440
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569669
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234139
INFO:root:FL Epoch: 129 Norm Difference for worker 1440 is 1.878287
INFO:root:FL Epoch: 129 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :773
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491766
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207004
INFO:root:FL Epoch: 129 Norm Difference for worker 773 is 1.863022
INFO:root:FL Epoch: 129 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1028
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.972321
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543733
INFO:root:FL Epoch: 129 Norm Difference for worker 1028 is 1.909771
INFO:root:FL Epoch: 129 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :863
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588529
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434386
INFO:root:FL Epoch: 129 Norm Difference for worker 863 is 1.952139
INFO:root:FL Epoch: 129 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :755
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560140
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348381
INFO:root:FL Epoch: 129 Norm Difference for worker 755 is 1.977985
INFO:root:FL Epoch: 129 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1307
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707664
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386793
INFO:root:FL Epoch: 129 Norm Difference for worker 1307 is 1.912813
INFO:root:FL Epoch: 129 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1724
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626995
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280666
INFO:root:FL Epoch: 129 Norm Difference for worker 1724 is 2.016678
INFO:root:FL Epoch: 129 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8070916883247978, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8070593350615365
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8070589765364498
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8070589823834036
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.4690905686687021 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.6691913257042567                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 130 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :324
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.837914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231607
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 324 is 1.837412
INFO:root:FL Epoch: 130 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :145
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580256
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 145 is 1.81882
INFO:root:FL Epoch: 130 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :544
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578105
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328011
INFO:root:FL Epoch: 130 Norm Difference for worker 544 is 1.913326
INFO:root:FL Epoch: 130 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :970
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461050
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259882
INFO:root:FL Epoch: 130 Norm Difference for worker 970 is 1.995725
INFO:root:FL Epoch: 130 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1423
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494040
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264584
INFO:root:FL Epoch: 130 Norm Difference for worker 1423 is 1.795269
INFO:root:FL Epoch: 130 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1402
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295900
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295806
INFO:root:FL Epoch: 130 Norm Difference for worker 1402 is 1.911314
INFO:root:FL Epoch: 130 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :689
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335548
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490297
INFO:root:FL Epoch: 130 Norm Difference for worker 689 is 1.898448
INFO:root:FL Epoch: 130 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1486
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512139
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341087
INFO:root:FL Epoch: 130 Norm Difference for worker 1486 is 1.936793
INFO:root:FL Epoch: 130 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :765
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361575
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149266
INFO:root:FL Epoch: 130 Norm Difference for worker 765 is 1.95642
INFO:root:FL Epoch: 130 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :11
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.400947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239095
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 11 is 1.818041
INFO:root:FL Epoch: 130 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7778802012231698, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7777606776835972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7777591525859546
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7777591463867644
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.46799567166496725 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.5479875753323237                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272501
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202421
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.06785182033975919 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.04489310011267662 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 1.517148
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309560
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.106526
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.10078106711929043 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.04741989653557539 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 1.527292
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306566
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170316
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.04765663684035341 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.04605984296649694 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 1.498004
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1513
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408532
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207432
INFO:root:FL Epoch: 131 Norm Difference for worker 1513 is 1.80444
INFO:root:FL Epoch: 131 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1131
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821890
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412810
INFO:root:FL Epoch: 131 Norm Difference for worker 1131 is 1.984454
INFO:root:FL Epoch: 131 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :516
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479301
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352993
INFO:root:FL Epoch: 131 Norm Difference for worker 516 is 1.979236
INFO:root:FL Epoch: 131 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :950
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499790
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311660
INFO:root:FL Epoch: 131 Norm Difference for worker 950 is 1.903545
INFO:root:FL Epoch: 131 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :910
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350785
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401172
INFO:root:FL Epoch: 131 Norm Difference for worker 910 is 1.863294
INFO:root:FL Epoch: 131 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :386
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336252
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193659
INFO:root:FL Epoch: 131 Norm Difference for worker 386 is 1.851106
INFO:root:FL Epoch: 131 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :240
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519140
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 240 is 1.966809
INFO:root:FL Epoch: 131 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6350500396811496, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6267075885299085
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6256364105510654
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6254769297026201
INFO:root:#### Oracle Cals: 5, Objective Val: 1.6254520030595532
INFO:root:#### Oracle Cals: 6, Objective Val: 1.6254480703212728
INFO:root:#### Oracle Cals: 7, Objective Val: 1.6254474429800683
INFO:root:#### Oracle Cals: 8, Objective Val: 1.6254473662579236
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.4911816085086149 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.1845808799068133                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 132 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :1511
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564774
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322124
INFO:root:FL Epoch: 132 Norm Difference for worker 1511 is 2.12568
INFO:root:FL Epoch: 132 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1912
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459791
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216432
INFO:root:FL Epoch: 132 Norm Difference for worker 1912 is 1.892633
INFO:root:FL Epoch: 132 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :355
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647020
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273045
INFO:root:FL Epoch: 132 Norm Difference for worker 355 is 2.025428
INFO:root:FL Epoch: 132 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :961
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623071
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359616
INFO:root:FL Epoch: 132 Norm Difference for worker 961 is 2.121289
INFO:root:FL Epoch: 132 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :352
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706419
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198988
INFO:root:FL Epoch: 132 Norm Difference for worker 352 is 2.03301
INFO:root:FL Epoch: 132 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :366
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268870
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326161
INFO:root:FL Epoch: 132 Norm Difference for worker 366 is 2.045724
INFO:root:FL Epoch: 132 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :136
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.152700
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 136 is 1.972004
INFO:root:FL Epoch: 132 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :335
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 335 is 1.982571
INFO:root:FL Epoch: 132 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1156
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776424
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280978
INFO:root:FL Epoch: 132 Norm Difference for worker 1156 is 1.890782
INFO:root:FL Epoch: 132 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1522
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690601
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358759
INFO:root:FL Epoch: 132 Norm Difference for worker 1522 is 1.955686
INFO:root:FL Epoch: 132 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8866609044464362, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.886467363691918
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8864648170218736
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8864648007421694
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.47209787018158855 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.2724779446919759                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1447
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422509
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278666
INFO:root:FL Epoch: 133 Norm Difference for worker 1447 is 1.932589
INFO:root:FL Epoch: 133 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1313
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580258
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264485
INFO:root:FL Epoch: 133 Norm Difference for worker 1313 is 1.929184
INFO:root:FL Epoch: 133 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1892
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422270
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277885
INFO:root:FL Epoch: 133 Norm Difference for worker 1892 is 1.877484
INFO:root:FL Epoch: 133 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580075
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313658
INFO:root:FL Epoch: 133 Norm Difference for worker 700 is 1.97963
INFO:root:FL Epoch: 133 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1180
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482573
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358687
INFO:root:FL Epoch: 133 Norm Difference for worker 1180 is 1.898042
INFO:root:FL Epoch: 133 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :208
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687303
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 208 is 1.91517
INFO:root:FL Epoch: 133 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1366
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684967
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184507
INFO:root:FL Epoch: 133 Norm Difference for worker 1366 is 1.822558
INFO:root:FL Epoch: 133 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1174
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684572
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364982
INFO:root:FL Epoch: 133 Norm Difference for worker 1174 is 1.983814
INFO:root:FL Epoch: 133 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :968
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414436
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540139
INFO:root:FL Epoch: 133 Norm Difference for worker 968 is 1.931998
INFO:root:FL Epoch: 133 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579031
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265982
INFO:root:FL Epoch: 133 Norm Difference for worker 869 is 1.958524
INFO:root:FL Epoch: 133 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.81052571189655, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8104656669851487
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8104650476951918
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8104650207975013
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.43850623421809254 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.2982368643085162                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1137
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497930
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326718
INFO:root:FL Epoch: 134 Norm Difference for worker 1137 is 2.044252
INFO:root:FL Epoch: 134 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1389
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745643
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218265
INFO:root:FL Epoch: 134 Norm Difference for worker 1389 is 1.92974
INFO:root:FL Epoch: 134 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :158
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620294
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 158 is 1.999773
INFO:root:FL Epoch: 134 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :892
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403758
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225541
INFO:root:FL Epoch: 134 Norm Difference for worker 892 is 1.934561
INFO:root:FL Epoch: 134 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :314
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 314 is 1.907525
INFO:root:FL Epoch: 134 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :737
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763827
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436509
INFO:root:FL Epoch: 134 Norm Difference for worker 737 is 2.014745
INFO:root:FL Epoch: 134 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1206
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699081
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270700
INFO:root:FL Epoch: 134 Norm Difference for worker 1206 is 1.931217
INFO:root:FL Epoch: 134 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :362
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591342
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227402
INFO:root:FL Epoch: 134 Norm Difference for worker 362 is 1.949049
INFO:root:FL Epoch: 134 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1354
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281289
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373961
INFO:root:FL Epoch: 134 Norm Difference for worker 1354 is 1.914981
INFO:root:FL Epoch: 134 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :650
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757278
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222126
INFO:root:FL Epoch: 134 Norm Difference for worker 650 is 1.977247
INFO:root:FL Epoch: 134 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8362585262522806, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8361741395370985
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8361729241972389
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8361728994353914
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.45549462297383475 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.32245037456353504                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1702
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584887
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308063
INFO:root:FL Epoch: 135 Norm Difference for worker 1702 is 1.85768
INFO:root:FL Epoch: 135 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :19
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.799277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 19 is 1.879095
INFO:root:FL Epoch: 135 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :779
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458006
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363178
INFO:root:FL Epoch: 135 Norm Difference for worker 779 is 1.817919
INFO:root:FL Epoch: 135 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1874
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358871
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219457
INFO:root:FL Epoch: 135 Norm Difference for worker 1874 is 1.854627
INFO:root:FL Epoch: 135 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :153
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380944
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 153 is 1.84147
INFO:root:FL Epoch: 135 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :751
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514792
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201502
INFO:root:FL Epoch: 135 Norm Difference for worker 751 is 1.820386
INFO:root:FL Epoch: 135 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1409
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531955
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226204
INFO:root:FL Epoch: 135 Norm Difference for worker 1409 is 1.829976
INFO:root:FL Epoch: 135 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1891
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589116
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307376
INFO:root:FL Epoch: 135 Norm Difference for worker 1891 is 1.810702
INFO:root:FL Epoch: 135 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1327
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417527
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331072
INFO:root:FL Epoch: 135 Norm Difference for worker 1327 is 1.783449
INFO:root:FL Epoch: 135 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :312
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 312 is 1.925517
INFO:root:FL Epoch: 135 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7388412509809719, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.738803184103877
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7388027329210627
INFO:root:#### Oracle Cals: 4, Objective Val: 1.738802720497129
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.44281164162299214 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.3499065116047859                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :950
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582632
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227586
INFO:root:FL Epoch: 136 Norm Difference for worker 950 is 1.85921
INFO:root:FL Epoch: 136 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1614
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560930
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414057
INFO:root:FL Epoch: 136 Norm Difference for worker 1614 is 2.110439
INFO:root:FL Epoch: 136 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1069
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.912666
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309786
INFO:root:FL Epoch: 136 Norm Difference for worker 1069 is 2.008433
INFO:root:FL Epoch: 136 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1082
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460504
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403068
INFO:root:FL Epoch: 136 Norm Difference for worker 1082 is 1.730019
INFO:root:FL Epoch: 136 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :755
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588759
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195049
INFO:root:FL Epoch: 136 Norm Difference for worker 755 is 1.917537
INFO:root:FL Epoch: 136 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :211
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 211 is 2.034765
INFO:root:FL Epoch: 136 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :626
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553030
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205691
INFO:root:FL Epoch: 136 Norm Difference for worker 626 is 1.691215
INFO:root:FL Epoch: 136 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1801
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369422
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428458
INFO:root:FL Epoch: 136 Norm Difference for worker 1801 is 1.926192
INFO:root:FL Epoch: 136 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :592
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294031
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185271
INFO:root:FL Epoch: 136 Norm Difference for worker 592 is 1.83976
INFO:root:FL Epoch: 136 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :113
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 113 is 1.824876
INFO:root:FL Epoch: 136 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.797383999178602, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7969251249724718
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7969187336114083
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7969186147140812
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.4398745789247401 and Test Accuracy:80.0 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.42028812567392987                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :935
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602793
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304244
INFO:root:FL Epoch: 137 Norm Difference for worker 935 is 1.958253
INFO:root:FL Epoch: 137 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1785
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412404
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348390
INFO:root:FL Epoch: 137 Norm Difference for worker 1785 is 1.961216
INFO:root:FL Epoch: 137 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :769
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374667
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242816
INFO:root:FL Epoch: 137 Norm Difference for worker 769 is 2.139958
INFO:root:FL Epoch: 137 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :514
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278584
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231766
INFO:root:FL Epoch: 137 Norm Difference for worker 514 is 1.86953
INFO:root:FL Epoch: 137 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :59
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 59 is 1.974872
INFO:root:FL Epoch: 137 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1601
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614340
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195408
INFO:root:FL Epoch: 137 Norm Difference for worker 1601 is 1.892306
INFO:root:FL Epoch: 137 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1554
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715283
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212107
INFO:root:FL Epoch: 137 Norm Difference for worker 1554 is 1.923952
INFO:root:FL Epoch: 137 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1492
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645093
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337436
INFO:root:FL Epoch: 137 Norm Difference for worker 1492 is 1.944051
INFO:root:FL Epoch: 137 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :393
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559632
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340949
INFO:root:FL Epoch: 137 Norm Difference for worker 393 is 2.092848
INFO:root:FL Epoch: 137 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1921
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668682
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323491
INFO:root:FL Epoch: 137 Norm Difference for worker 1921 is 2.026925
INFO:root:FL Epoch: 137 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8603234492803549, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.86019069545081
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8601890163060706
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8601889557470521
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.43790610046947703 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.4129391362269719                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :589
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506053
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515009
INFO:root:FL Epoch: 138 Norm Difference for worker 589 is 1.936426
INFO:root:FL Epoch: 138 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1143
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536835
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408042
INFO:root:FL Epoch: 138 Norm Difference for worker 1143 is 1.964936
INFO:root:FL Epoch: 138 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1020
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486499
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424125
INFO:root:FL Epoch: 138 Norm Difference for worker 1020 is 1.861306
INFO:root:FL Epoch: 138 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1022
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381634
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291599
INFO:root:FL Epoch: 138 Norm Difference for worker 1022 is 1.782591
INFO:root:FL Epoch: 138 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :730
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331920
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172140
INFO:root:FL Epoch: 138 Norm Difference for worker 730 is 1.871202
INFO:root:FL Epoch: 138 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :346
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491388
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293563
INFO:root:FL Epoch: 138 Norm Difference for worker 346 is 1.803192
INFO:root:FL Epoch: 138 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.223771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 1.9287
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :139
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 139 is 1.809517
INFO:root:FL Epoch: 138 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1469
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640363
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293590
INFO:root:FL Epoch: 138 Norm Difference for worker 1469 is 1.933081
INFO:root:FL Epoch: 138 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1364
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837862
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262922
INFO:root:FL Epoch: 138 Norm Difference for worker 1364 is 1.931363
INFO:root:FL Epoch: 138 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7664810886070164, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7663446360789063
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7663426727398441
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7663426206644386
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.43351856925908255 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.506055548787117                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 139 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :545
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703400
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272931
INFO:root:FL Epoch: 139 Norm Difference for worker 545 is 1.943215
INFO:root:FL Epoch: 139 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :55
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.191376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 55 is 1.80194
INFO:root:FL Epoch: 139 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :702
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714084
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435532
INFO:root:FL Epoch: 139 Norm Difference for worker 702 is 1.916812
INFO:root:FL Epoch: 139 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1861
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532702
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355220
INFO:root:FL Epoch: 139 Norm Difference for worker 1861 is 1.990773
INFO:root:FL Epoch: 139 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1745
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650067
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314748
INFO:root:FL Epoch: 139 Norm Difference for worker 1745 is 1.883271
INFO:root:FL Epoch: 139 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :524
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515935
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362151
INFO:root:FL Epoch: 139 Norm Difference for worker 524 is 1.925423
INFO:root:FL Epoch: 139 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :900
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549236
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269033
INFO:root:FL Epoch: 139 Norm Difference for worker 900 is 1.779942
INFO:root:FL Epoch: 139 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :492
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399472
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388257
INFO:root:FL Epoch: 139 Norm Difference for worker 492 is 1.896472
INFO:root:FL Epoch: 139 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1013
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671806
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313568
INFO:root:FL Epoch: 139 Norm Difference for worker 1013 is 1.970432
INFO:root:FL Epoch: 139 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1556
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593238
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267827
INFO:root:FL Epoch: 139 Norm Difference for worker 1556 is 1.79476
INFO:root:FL Epoch: 139 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.770877079886757, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7707372855907972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7707357243899353
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7707356989522935
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.4718477883759667 and Test Accuracy:75.0 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.3724820837378502                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :1834
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813701
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190142
INFO:root:FL Epoch: 140 Norm Difference for worker 1834 is 1.960573
INFO:root:FL Epoch: 140 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :946
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520974
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285389
INFO:root:FL Epoch: 140 Norm Difference for worker 946 is 1.914669
INFO:root:FL Epoch: 140 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :646
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528677
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504698
INFO:root:FL Epoch: 140 Norm Difference for worker 646 is 1.932874
INFO:root:FL Epoch: 140 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1428
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686382
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327316
INFO:root:FL Epoch: 140 Norm Difference for worker 1428 is 1.956563
INFO:root:FL Epoch: 140 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :50
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 50 is 1.958428
INFO:root:FL Epoch: 140 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1198
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659580
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414656
INFO:root:FL Epoch: 140 Norm Difference for worker 1198 is 1.960451
INFO:root:FL Epoch: 140 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1355
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578910
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259037
INFO:root:FL Epoch: 140 Norm Difference for worker 1355 is 1.909272
INFO:root:FL Epoch: 140 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :222
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 222 is 1.762858
INFO:root:FL Epoch: 140 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1642
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764612
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222256
INFO:root:FL Epoch: 140 Norm Difference for worker 1642 is 1.943761
INFO:root:FL Epoch: 140 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1223
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610383
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369091
INFO:root:FL Epoch: 140 Norm Difference for worker 1223 is 2.118354
INFO:root:FL Epoch: 140 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8333020967714255, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8331778936179988
INFO:root:#### Oracle Cals: 3, Objective Val: 1.833176386543451
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8331763377598225
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.4730640404364642 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.3873271495103836                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230707
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.092327
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.05435980887462696 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.03809567391872406 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 1.377026
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.190201
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324192
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.03592667131063839 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.042896598018705843 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 1.463453
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211525
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.119568
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.11687447813649972 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.04169883523136377 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 1.403977
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1878
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543285
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212973
INFO:root:FL Epoch: 141 Norm Difference for worker 1878 is 1.988403
INFO:root:FL Epoch: 141 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :962
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529471
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239451
INFO:root:FL Epoch: 141 Norm Difference for worker 962 is 1.841357
INFO:root:FL Epoch: 141 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427746
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245756
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.842721
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :976
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647537
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407334
INFO:root:FL Epoch: 141 Norm Difference for worker 976 is 1.9278
INFO:root:FL Epoch: 141 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :769
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709602
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311224
INFO:root:FL Epoch: 141 Norm Difference for worker 769 is 1.823219
INFO:root:FL Epoch: 141 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :465
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409154
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334938
INFO:root:FL Epoch: 141 Norm Difference for worker 465 is 1.843836
INFO:root:FL Epoch: 141 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1750
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778497
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565608
INFO:root:FL Epoch: 141 Norm Difference for worker 1750 is 1.993495
INFO:root:FL Epoch: 141 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.616179524022882, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6066635395892586
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6054456968173538
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6052663974945611
INFO:root:#### Oracle Cals: 5, Objective Val: 1.6052388134554112
INFO:root:#### Oracle Cals: 6, Objective Val: 1.6052344975918094
INFO:root:#### Oracle Cals: 7, Objective Val: 1.605233830233515
INFO:root:#### Oracle Cals: 8, Objective Val: 1.6052337175725309
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.49815015407169566 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.14423161000013351                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1841
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725169
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285119
INFO:root:FL Epoch: 142 Norm Difference for worker 1841 is 2.063732
INFO:root:FL Epoch: 142 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1522
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425348
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296987
INFO:root:FL Epoch: 142 Norm Difference for worker 1522 is 1.940615
INFO:root:FL Epoch: 142 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :23
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529170
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458029
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 23 is 2.271364
INFO:root:FL Epoch: 142 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1157
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511390
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243724
INFO:root:FL Epoch: 142 Norm Difference for worker 1157 is 2.150898
INFO:root:FL Epoch: 142 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :56
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465467
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 56 is 2.060083
INFO:root:FL Epoch: 142 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1269
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426486
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429561
INFO:root:FL Epoch: 142 Norm Difference for worker 1269 is 2.023098
INFO:root:FL Epoch: 142 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :442
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486105
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390126
INFO:root:FL Epoch: 142 Norm Difference for worker 442 is 2.048743
INFO:root:FL Epoch: 142 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :577
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558918
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181563
INFO:root:FL Epoch: 142 Norm Difference for worker 577 is 2.2026
INFO:root:FL Epoch: 142 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :219
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.733962
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 219 is 2.21368
INFO:root:FL Epoch: 142 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1614
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567651
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240054
INFO:root:FL Epoch: 142 Norm Difference for worker 1614 is 2.16906
INFO:root:FL Epoch: 142 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 2.0019367771057195, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 2.0017151350947144
INFO:root:#### Oracle Cals: 3, Objective Val: 2.0017125048449227
INFO:root:#### Oracle Cals: 4, Objective Val: 2.0017124698702404
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.49486855899586396 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.21106106912096342                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1520
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406160
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286284
INFO:root:FL Epoch: 143 Norm Difference for worker 1520 is 1.898871
INFO:root:FL Epoch: 143 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1151
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578773
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315643
INFO:root:FL Epoch: 143 Norm Difference for worker 1151 is 1.914364
INFO:root:FL Epoch: 143 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :182
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 182 is 1.947091
INFO:root:FL Epoch: 143 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :755
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534750
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213118
INFO:root:FL Epoch: 143 Norm Difference for worker 755 is 1.884009
INFO:root:FL Epoch: 143 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :86
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 86 is 1.814971
INFO:root:FL Epoch: 143 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1828
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422901
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303931
INFO:root:FL Epoch: 143 Norm Difference for worker 1828 is 1.934822
INFO:root:FL Epoch: 143 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1417
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612825
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294627
INFO:root:FL Epoch: 143 Norm Difference for worker 1417 is 1.864008
INFO:root:FL Epoch: 143 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :504
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619201
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214958
INFO:root:FL Epoch: 143 Norm Difference for worker 504 is 1.838526
INFO:root:FL Epoch: 143 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :250
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474566
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 250 is 1.869995
INFO:root:FL Epoch: 143 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :634
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835761
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268739
INFO:root:FL Epoch: 143 Norm Difference for worker 634 is 1.75432
INFO:root:FL Epoch: 143 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7568182354920652, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7567533193626008
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7567525043841743
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7567524940432666
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.44724802935824676 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.27343469361464184                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1753
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794661
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316330
INFO:root:FL Epoch: 144 Norm Difference for worker 1753 is 1.897048
INFO:root:FL Epoch: 144 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1838
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518383
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292307
INFO:root:FL Epoch: 144 Norm Difference for worker 1838 is 1.917463
INFO:root:FL Epoch: 144 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :71
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 71 is 1.877099
INFO:root:FL Epoch: 144 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :711
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744576
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215167
INFO:root:FL Epoch: 144 Norm Difference for worker 711 is 1.915448
INFO:root:FL Epoch: 144 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :960
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594278
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291838
INFO:root:FL Epoch: 144 Norm Difference for worker 960 is 1.976438
INFO:root:FL Epoch: 144 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :665
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778281
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332601
INFO:root:FL Epoch: 144 Norm Difference for worker 665 is 1.901712
INFO:root:FL Epoch: 144 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1500
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877228
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228587
INFO:root:FL Epoch: 144 Norm Difference for worker 1500 is 1.976129
INFO:root:FL Epoch: 144 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1467
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821523
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246900
INFO:root:FL Epoch: 144 Norm Difference for worker 1467 is 1.883227
INFO:root:FL Epoch: 144 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :800
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505580
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320703
INFO:root:FL Epoch: 144 Norm Difference for worker 800 is 1.94333
INFO:root:FL Epoch: 144 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :787
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406576
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308170
INFO:root:FL Epoch: 144 Norm Difference for worker 787 is 1.976954
INFO:root:FL Epoch: 144 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8081801450770987, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.80813516482494
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8081346291929987
INFO:root:#### Oracle Cals: 4, Objective Val: 1.808134622807127
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.48103173164760366 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.32672764857610065                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :380
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220764
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349121
INFO:root:FL Epoch: 145 Norm Difference for worker 380 is 1.901689
INFO:root:FL Epoch: 145 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :95
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 95 is 1.934144
INFO:root:FL Epoch: 145 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :818
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282884
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203929
INFO:root:FL Epoch: 145 Norm Difference for worker 818 is 1.774047
INFO:root:FL Epoch: 145 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1766
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628488
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405401
INFO:root:FL Epoch: 145 Norm Difference for worker 1766 is 2.016755
INFO:root:FL Epoch: 145 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1585
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312051
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217479
INFO:root:FL Epoch: 145 Norm Difference for worker 1585 is 1.866379
INFO:root:FL Epoch: 145 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1927
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663110
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388098
INFO:root:FL Epoch: 145 Norm Difference for worker 1927 is 1.875131
INFO:root:FL Epoch: 145 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1721
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298332
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700170
INFO:root:FL Epoch: 145 Norm Difference for worker 1721 is 1.844487
INFO:root:FL Epoch: 145 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648134
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290023
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 1.933268
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1393
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413484
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242724
INFO:root:FL Epoch: 145 Norm Difference for worker 1393 is 1.927122
INFO:root:FL Epoch: 145 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1170
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377171
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285418
INFO:root:FL Epoch: 145 Norm Difference for worker 1170 is 1.833712
INFO:root:FL Epoch: 145 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.771845829692903, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7717579335538627
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7717567868803041
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7717567595640402
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.4439159894690794 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.2823004101713498                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :968
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466448
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268794
INFO:root:FL Epoch: 146 Norm Difference for worker 968 is 1.820103
INFO:root:FL Epoch: 146 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :715
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877918
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369641
INFO:root:FL Epoch: 146 Norm Difference for worker 715 is 2.064798
INFO:root:FL Epoch: 146 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :798
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367839
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261439
INFO:root:FL Epoch: 146 Norm Difference for worker 798 is 1.805801
INFO:root:FL Epoch: 146 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1158
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582077
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308401
INFO:root:FL Epoch: 146 Norm Difference for worker 1158 is 1.921412
INFO:root:FL Epoch: 146 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1312
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600202
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205416
INFO:root:FL Epoch: 146 Norm Difference for worker 1312 is 1.835802
INFO:root:FL Epoch: 146 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :656
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364720
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343260
INFO:root:FL Epoch: 146 Norm Difference for worker 656 is 1.951103
INFO:root:FL Epoch: 146 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :911
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545745
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295148
INFO:root:FL Epoch: 146 Norm Difference for worker 911 is 1.858207
INFO:root:FL Epoch: 146 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :391
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604794
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341609
INFO:root:FL Epoch: 146 Norm Difference for worker 391 is 2.027801
INFO:root:FL Epoch: 146 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 1.82863
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :800
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406799
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178241
INFO:root:FL Epoch: 146 Norm Difference for worker 800 is 1.869451
INFO:root:FL Epoch: 146 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7861211108748964, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7859811197383872
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7859795119851454
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7859795030935743
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.4670085644020754 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.37123940885066986                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1230
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806072
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175976
INFO:root:FL Epoch: 147 Norm Difference for worker 1230 is 1.85078
INFO:root:FL Epoch: 147 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1810
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409965
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250245
INFO:root:FL Epoch: 147 Norm Difference for worker 1810 is 1.744956
INFO:root:FL Epoch: 147 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :202
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 202 is 1.879529
INFO:root:FL Epoch: 147 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :692
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653432
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370949
INFO:root:FL Epoch: 147 Norm Difference for worker 692 is 1.900102
INFO:root:FL Epoch: 147 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1869
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328157
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446402
INFO:root:FL Epoch: 147 Norm Difference for worker 1869 is 1.896987
INFO:root:FL Epoch: 147 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1931
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422591
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351340
INFO:root:FL Epoch: 147 Norm Difference for worker 1931 is 1.949996
INFO:root:FL Epoch: 147 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1058
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544011
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332514
INFO:root:FL Epoch: 147 Norm Difference for worker 1058 is 1.984489
INFO:root:FL Epoch: 147 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :783
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575710
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312666
INFO:root:FL Epoch: 147 Norm Difference for worker 783 is 1.860314
INFO:root:FL Epoch: 147 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :536
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520460
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274218
INFO:root:FL Epoch: 147 Norm Difference for worker 536 is 1.880532
INFO:root:FL Epoch: 147 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :950
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536152
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154689
INFO:root:FL Epoch: 147 Norm Difference for worker 950 is 1.834117
INFO:root:FL Epoch: 147 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7699698549784146, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7698993477590463
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7698984901328618
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7698984945168617
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.4489462112679201 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.369527871410052                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :376
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382204
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247177
INFO:root:FL Epoch: 148 Norm Difference for worker 376 is 1.800365
INFO:root:FL Epoch: 148 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :932
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424863
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329439
INFO:root:FL Epoch: 148 Norm Difference for worker 932 is 1.92521
INFO:root:FL Epoch: 148 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :206
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.171315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 206 is 1.659272
INFO:root:FL Epoch: 148 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :532
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648924
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229653
INFO:root:FL Epoch: 148 Norm Difference for worker 532 is 1.946898
INFO:root:FL Epoch: 148 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1088
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315014
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246591
INFO:root:FL Epoch: 148 Norm Difference for worker 1088 is 1.751314
INFO:root:FL Epoch: 148 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :339
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 339 is 1.880067
INFO:root:FL Epoch: 148 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1682
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356963
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195773
INFO:root:FL Epoch: 148 Norm Difference for worker 1682 is 1.719195
INFO:root:FL Epoch: 148 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :436
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688072
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300045
INFO:root:FL Epoch: 148 Norm Difference for worker 436 is 1.83291
INFO:root:FL Epoch: 148 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1295
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437783
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262453
INFO:root:FL Epoch: 148 Norm Difference for worker 1295 is 1.851454
INFO:root:FL Epoch: 148 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1789
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439264
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285361
INFO:root:FL Epoch: 148 Norm Difference for worker 1789 is 1.774091
INFO:root:FL Epoch: 148 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7159062723548535, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7157018621701843
INFO:root:#### Oracle Cals: 3, Objective Val: 1.71569940987875
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7156993648207561
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.45998193411266103 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.32453519105911255                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :648
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424084
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184307
INFO:root:FL Epoch: 149 Norm Difference for worker 648 is 1.914354
INFO:root:FL Epoch: 149 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1268
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808234
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488927
INFO:root:FL Epoch: 149 Norm Difference for worker 1268 is 1.825522
INFO:root:FL Epoch: 149 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :337
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 337 is 1.956365
INFO:root:FL Epoch: 149 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1086
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525167
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400111
INFO:root:FL Epoch: 149 Norm Difference for worker 1086 is 1.847441
INFO:root:FL Epoch: 149 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1112
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664177
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294694
INFO:root:FL Epoch: 149 Norm Difference for worker 1112 is 2.057029
INFO:root:FL Epoch: 149 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :725
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612092
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179103
INFO:root:FL Epoch: 149 Norm Difference for worker 725 is 1.797632
INFO:root:FL Epoch: 149 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :610
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851420
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367786
INFO:root:FL Epoch: 149 Norm Difference for worker 610 is 1.895869
INFO:root:FL Epoch: 149 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1600
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403269
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288351
INFO:root:FL Epoch: 149 Norm Difference for worker 1600 is 2.108962
INFO:root:FL Epoch: 149 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :335
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387915
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.168050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 335 is 1.859517
INFO:root:FL Epoch: 149 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :996
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318498
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348258
INFO:root:FL Epoch: 149 Norm Difference for worker 996 is 1.961713
INFO:root:FL Epoch: 149 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8112034529922008, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8110444267343353
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8110424002610999
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8110424122904338
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.45898208986310396 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.36264317731062573                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :969
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662179
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261227
INFO:root:FL Epoch: 150 Norm Difference for worker 969 is 1.848738
INFO:root:FL Epoch: 150 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :73
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.764463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.328424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 73 is 2.031446
INFO:root:FL Epoch: 150 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1089
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788210
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318786
INFO:root:FL Epoch: 150 Norm Difference for worker 1089 is 1.85393
INFO:root:FL Epoch: 150 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1428
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737097
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345172
INFO:root:FL Epoch: 150 Norm Difference for worker 1428 is 2.114863
INFO:root:FL Epoch: 150 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :306
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 306 is 2.029383
INFO:root:FL Epoch: 150 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :424
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488121
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310983
INFO:root:FL Epoch: 150 Norm Difference for worker 424 is 1.834518
INFO:root:FL Epoch: 150 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1357
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519369
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366395
INFO:root:FL Epoch: 150 Norm Difference for worker 1357 is 2.084539
INFO:root:FL Epoch: 150 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :441
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 1.019045
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339418
INFO:root:FL Epoch: 150 Norm Difference for worker 441 is 2.108001
INFO:root:FL Epoch: 150 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :62
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260820
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 62 is 1.830367
INFO:root:FL Epoch: 150 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :459
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451767
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124386
INFO:root:FL Epoch: 150 Norm Difference for worker 459 is 1.840314
INFO:root:FL Epoch: 150 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8378460736316702, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8375350599803089
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8375307043747107
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8375306277454855
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.45202382610124703 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.3742069775859515                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219290
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124814
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.06012612379466494 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.036068512964993714 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 1.188054
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303063
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.075543
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.05492095944161216 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.03419565418735147 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 1.227779
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196508
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.080047
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.051348185477157436 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.06651109177619219 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 1.365467
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :954
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432865
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413109
INFO:root:FL Epoch: 151 Norm Difference for worker 954 is 1.953363
INFO:root:FL Epoch: 151 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1013
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736133
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380407
INFO:root:FL Epoch: 151 Norm Difference for worker 1013 is 1.826477
INFO:root:FL Epoch: 151 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :183
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 183 is 1.955561
INFO:root:FL Epoch: 151 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :593
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582269
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528056
INFO:root:FL Epoch: 151 Norm Difference for worker 593 is 2.01918
INFO:root:FL Epoch: 151 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1646
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625158
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381099
INFO:root:FL Epoch: 151 Norm Difference for worker 1646 is 1.95867
INFO:root:FL Epoch: 151 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :153
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515857
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 153 is 1.791442
INFO:root:FL Epoch: 151 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :653
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805076
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460173
INFO:root:FL Epoch: 151 Norm Difference for worker 653 is 1.969009
INFO:root:FL Epoch: 151 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5989384476224577, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5861945817213738
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5844924488131393
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5842241375096908
INFO:root:#### Oracle Cals: 5, Objective Val: 1.5841796589091215
INFO:root:#### Oracle Cals: 6, Objective Val: 1.5841721673430085
INFO:root:#### Oracle Cals: 7, Objective Val: 1.5841708918766828
INFO:root:#### Oracle Cals: 8, Objective Val: 1.5841706762087602
INFO:root:#### Oracle Cals: 9, Objective Val: 1.584170658134693
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.4584876561866087 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.1155046783387661                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1082
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543839
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160075
INFO:root:FL Epoch: 152 Norm Difference for worker 1082 is 1.904335
INFO:root:FL Epoch: 152 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :949
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265755
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301654
INFO:root:FL Epoch: 152 Norm Difference for worker 949 is 2.288906
INFO:root:FL Epoch: 152 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1688
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479901
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249996
INFO:root:FL Epoch: 152 Norm Difference for worker 1688 is 2.298998
INFO:root:FL Epoch: 152 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :734
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319201
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338702
INFO:root:FL Epoch: 152 Norm Difference for worker 734 is 2.020881
INFO:root:FL Epoch: 152 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :277
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203212
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 277 is 2.144062
INFO:root:FL Epoch: 152 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :966
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394806
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455042
INFO:root:FL Epoch: 152 Norm Difference for worker 966 is 2.224375
INFO:root:FL Epoch: 152 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :748
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378380
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373942
INFO:root:FL Epoch: 152 Norm Difference for worker 748 is 2.2534
INFO:root:FL Epoch: 152 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :886
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576392
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312697
INFO:root:FL Epoch: 152 Norm Difference for worker 886 is 2.016534
INFO:root:FL Epoch: 152 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :918
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523577
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372048
INFO:root:FL Epoch: 152 Norm Difference for worker 918 is 2.147215
INFO:root:FL Epoch: 152 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :418
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681473
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271186
INFO:root:FL Epoch: 152 Norm Difference for worker 418 is 2.116521
INFO:root:FL Epoch: 152 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9944095413526242, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9941907790630953
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9941880081375298
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9941879683501371
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.485337529112311 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.19082389151056608                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :115
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 115 is 1.854359
INFO:root:FL Epoch: 153 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :899
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715168
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414117
INFO:root:FL Epoch: 153 Norm Difference for worker 899 is 1.857474
INFO:root:FL Epoch: 153 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1476
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854996
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239681
INFO:root:FL Epoch: 153 Norm Difference for worker 1476 is 1.887507
INFO:root:FL Epoch: 153 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :185
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541513
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.174467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 185 is 1.811412
INFO:root:FL Epoch: 153 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :482
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496287
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227294
INFO:root:FL Epoch: 153 Norm Difference for worker 482 is 1.893424
INFO:root:FL Epoch: 153 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1640
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310244
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588028
INFO:root:FL Epoch: 153 Norm Difference for worker 1640 is 1.866559
INFO:root:FL Epoch: 153 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1042
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470814
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356074
INFO:root:FL Epoch: 153 Norm Difference for worker 1042 is 1.828346
INFO:root:FL Epoch: 153 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :354
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615432
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281744
INFO:root:FL Epoch: 153 Norm Difference for worker 354 is 1.813619
INFO:root:FL Epoch: 153 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :626
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473250
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140777
INFO:root:FL Epoch: 153 Norm Difference for worker 626 is 1.671425
INFO:root:FL Epoch: 153 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :922
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513775
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278027
INFO:root:FL Epoch: 153 Norm Difference for worker 922 is 1.927613
INFO:root:FL Epoch: 153 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7190945707521084, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7189845727077588
INFO:root:#### Oracle Cals: 3, Objective Val: 1.71898322004847
INFO:root:#### Oracle Cals: 4, Objective Val: 1.718983185613875
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.4757904059746686 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.20960817113518715                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :1534
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357589
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293734
INFO:root:FL Epoch: 154 Norm Difference for worker 1534 is 1.892497
INFO:root:FL Epoch: 154 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1285
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559971
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162226
INFO:root:FL Epoch: 154 Norm Difference for worker 1285 is 1.896378
INFO:root:FL Epoch: 154 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :791
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452146
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249234
INFO:root:FL Epoch: 154 Norm Difference for worker 791 is 1.88495
INFO:root:FL Epoch: 154 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :829
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830534
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389734
INFO:root:FL Epoch: 154 Norm Difference for worker 829 is 2.063651
INFO:root:FL Epoch: 154 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1852
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771698
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352576
INFO:root:FL Epoch: 154 Norm Difference for worker 1852 is 1.845815
INFO:root:FL Epoch: 154 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1002
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507610
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206585
INFO:root:FL Epoch: 154 Norm Difference for worker 1002 is 1.854648
INFO:root:FL Epoch: 154 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :160
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376860
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 160 is 1.929692
INFO:root:FL Epoch: 154 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1586
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678871
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441685
INFO:root:FL Epoch: 154 Norm Difference for worker 1586 is 2.042458
INFO:root:FL Epoch: 154 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1575
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399889
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278870
INFO:root:FL Epoch: 154 Norm Difference for worker 1575 is 1.923387
INFO:root:FL Epoch: 154 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :545
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458521
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374078
INFO:root:FL Epoch: 154 Norm Difference for worker 545 is 1.862656
INFO:root:FL Epoch: 154 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8012859756321282, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.801161520437655
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8011601658008927
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8011601686014347
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.45040175494025736 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.23736897483468056                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 155 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1219
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760321
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304791
INFO:root:FL Epoch: 155 Norm Difference for worker 1219 is 1.958652
INFO:root:FL Epoch: 155 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :334
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 334 is 1.850936
INFO:root:FL Epoch: 155 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :82
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463273
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 82 is 1.817079
INFO:root:FL Epoch: 155 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :426
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469576
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275954
INFO:root:FL Epoch: 155 Norm Difference for worker 426 is 1.874724
INFO:root:FL Epoch: 155 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :457
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423395
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220191
INFO:root:FL Epoch: 155 Norm Difference for worker 457 is 1.962033
INFO:root:FL Epoch: 155 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :687
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247028
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352083
INFO:root:FL Epoch: 155 Norm Difference for worker 687 is 1.908259
INFO:root:FL Epoch: 155 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :836
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352268
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311978
INFO:root:FL Epoch: 155 Norm Difference for worker 836 is 1.915865
INFO:root:FL Epoch: 155 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1157
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710919
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441112
INFO:root:FL Epoch: 155 Norm Difference for worker 1157 is 1.946501
INFO:root:FL Epoch: 155 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :845
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595672
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336128
INFO:root:FL Epoch: 155 Norm Difference for worker 845 is 1.842759
INFO:root:FL Epoch: 155 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :422
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359011
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184183
INFO:root:FL Epoch: 155 Norm Difference for worker 422 is 1.892679
INFO:root:FL Epoch: 155 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7852606590873852, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7852177943814973
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7852172996256046
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7852172355094624
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.4692154561772066 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.2329451578358809                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :1330
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328585
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251240
INFO:root:FL Epoch: 156 Norm Difference for worker 1330 is 1.964664
INFO:root:FL Epoch: 156 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1035
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685923
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429476
INFO:root:FL Epoch: 156 Norm Difference for worker 1035 is 1.934898
INFO:root:FL Epoch: 156 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :774
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592949
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273500
INFO:root:FL Epoch: 156 Norm Difference for worker 774 is 1.817548
INFO:root:FL Epoch: 156 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1736
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340638
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376493
INFO:root:FL Epoch: 156 Norm Difference for worker 1736 is 2.034655
INFO:root:FL Epoch: 156 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1439
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736121
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289435
INFO:root:FL Epoch: 156 Norm Difference for worker 1439 is 1.940124
INFO:root:FL Epoch: 156 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :824
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581665
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369400
INFO:root:FL Epoch: 156 Norm Difference for worker 824 is 1.911527
INFO:root:FL Epoch: 156 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :957
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632040
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426600
INFO:root:FL Epoch: 156 Norm Difference for worker 957 is 1.855545
INFO:root:FL Epoch: 156 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :80
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 80 is 1.770598
INFO:root:FL Epoch: 156 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :952
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581301
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323399
INFO:root:FL Epoch: 156 Norm Difference for worker 952 is 1.94181
INFO:root:FL Epoch: 156 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :703
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687758
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228929
INFO:root:FL Epoch: 156 Norm Difference for worker 703 is 1.917421
INFO:root:FL Epoch: 156 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.808654787826513, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8084864543175971
INFO:root:#### Oracle Cals: 3, Objective Val: 1.808484390586102
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8084843544254867
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.4696650207042694 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.23366510743896166                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :1090
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730166
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252195
INFO:root:FL Epoch: 157 Norm Difference for worker 1090 is 1.735676
INFO:root:FL Epoch: 157 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1884
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626212
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240246
INFO:root:FL Epoch: 157 Norm Difference for worker 1884 is 1.779915
INFO:root:FL Epoch: 157 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1139
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600276
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250943
INFO:root:FL Epoch: 157 Norm Difference for worker 1139 is 1.720208
INFO:root:FL Epoch: 157 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :349
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618631
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261815
INFO:root:FL Epoch: 157 Norm Difference for worker 349 is 1.788341
INFO:root:FL Epoch: 157 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :877
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437114
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207055
INFO:root:FL Epoch: 157 Norm Difference for worker 877 is 1.729746
INFO:root:FL Epoch: 157 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :538
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523602
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317197
INFO:root:FL Epoch: 157 Norm Difference for worker 538 is 1.838684
INFO:root:FL Epoch: 157 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :147
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 147 is 1.841343
INFO:root:FL Epoch: 157 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1085
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514598
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318600
INFO:root:FL Epoch: 157 Norm Difference for worker 1085 is 1.778001
INFO:root:FL Epoch: 157 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1142
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655085
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321495
INFO:root:FL Epoch: 157 Norm Difference for worker 1142 is 1.755734
INFO:root:FL Epoch: 157 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :98
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 98 is 1.871849
INFO:root:FL Epoch: 157 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6757376505844133, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6756978783301495
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6756974846819546
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6756974197807675
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.4736899610827951 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.1800253875553608                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 158 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :527
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459465
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252338
INFO:root:FL Epoch: 158 Norm Difference for worker 527 is 1.922386
INFO:root:FL Epoch: 158 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :126
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392102
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 126 is 1.836844
INFO:root:FL Epoch: 158 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1253
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328292
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313132
INFO:root:FL Epoch: 158 Norm Difference for worker 1253 is 2.015586
INFO:root:FL Epoch: 158 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :917
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745881
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240358
INFO:root:FL Epoch: 158 Norm Difference for worker 917 is 1.993608
INFO:root:FL Epoch: 158 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1316
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657918
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218550
INFO:root:FL Epoch: 158 Norm Difference for worker 1316 is 1.894119
INFO:root:FL Epoch: 158 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550630
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349897
INFO:root:FL Epoch: 158 Norm Difference for worker 1311 is 1.837612
INFO:root:FL Epoch: 158 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498932
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 311 is 1.992816
INFO:root:FL Epoch: 158 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :779
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686449
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253694
INFO:root:FL Epoch: 158 Norm Difference for worker 779 is 1.976683
INFO:root:FL Epoch: 158 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1872
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480101
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250345
INFO:root:FL Epoch: 158 Norm Difference for worker 1872 is 1.863938
INFO:root:FL Epoch: 158 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :900
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384579
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362183
INFO:root:FL Epoch: 158 Norm Difference for worker 900 is 1.803782
INFO:root:FL Epoch: 158 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8114347939765865, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8112976841639385
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8112959030339586
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8112958763384566
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.4601953660740572 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.1867604193588098                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :757
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 1.025420
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253417
INFO:root:FL Epoch: 159 Norm Difference for worker 757 is 1.927583
INFO:root:FL Epoch: 159 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1832
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439834
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271289
INFO:root:FL Epoch: 159 Norm Difference for worker 1832 is 1.983906
INFO:root:FL Epoch: 159 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :439
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506651
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241446
INFO:root:FL Epoch: 159 Norm Difference for worker 439 is 1.879309
INFO:root:FL Epoch: 159 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :689
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365270
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288577
INFO:root:FL Epoch: 159 Norm Difference for worker 689 is 1.892724
INFO:root:FL Epoch: 159 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :232
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 232 is 1.9678
INFO:root:FL Epoch: 159 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1446
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401091
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210597
INFO:root:FL Epoch: 159 Norm Difference for worker 1446 is 1.842647
INFO:root:FL Epoch: 159 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1516
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449539
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149181
INFO:root:FL Epoch: 159 Norm Difference for worker 1516 is 1.840452
INFO:root:FL Epoch: 159 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :603
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300181
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276548
INFO:root:FL Epoch: 159 Norm Difference for worker 603 is 1.856423
INFO:root:FL Epoch: 159 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1899
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622151
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203162
INFO:root:FL Epoch: 159 Norm Difference for worker 1899 is 1.820628
INFO:root:FL Epoch: 159 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1913
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464591
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418828
INFO:root:FL Epoch: 159 Norm Difference for worker 1913 is 1.95384
INFO:root:FL Epoch: 159 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7875994983577808, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7875386895730543
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7875379550714077
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7875379559051978
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.4822143614292145 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.249491053322951                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 160 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :492
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337713
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.112419
INFO:root:FL Epoch: 160 Norm Difference for worker 492 is 1.643076
INFO:root:FL Epoch: 160 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :665
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539657
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336741
INFO:root:FL Epoch: 160 Norm Difference for worker 665 is 1.788482
INFO:root:FL Epoch: 160 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1803
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353215
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239896
INFO:root:FL Epoch: 160 Norm Difference for worker 1803 is 1.914719
INFO:root:FL Epoch: 160 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1792
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397615
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297899
INFO:root:FL Epoch: 160 Norm Difference for worker 1792 is 1.735911
INFO:root:FL Epoch: 160 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1299
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.961919
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321826
INFO:root:FL Epoch: 160 Norm Difference for worker 1299 is 1.899721
INFO:root:FL Epoch: 160 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :384
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702054
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262714
INFO:root:FL Epoch: 160 Norm Difference for worker 384 is 1.763612
INFO:root:FL Epoch: 160 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1039
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690910
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434170
INFO:root:FL Epoch: 160 Norm Difference for worker 1039 is 1.963505
INFO:root:FL Epoch: 160 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :603
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453416
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303993
INFO:root:FL Epoch: 160 Norm Difference for worker 603 is 1.720443
INFO:root:FL Epoch: 160 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :159
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 159 is 1.836781
INFO:root:FL Epoch: 160 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :209
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 209 is 1.874187
INFO:root:FL Epoch: 160 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.711562216357681, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7113357619728622
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7113329685393164
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7113328740035463
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.4640656376586241 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.2436241035660108                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.145548
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.118891
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.053917873185127974 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.030621056072413923 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 1.076135
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.089164
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.096923
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.049476147474100195 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.03197288829833269 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 1.104604
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.136118
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.074145
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.04492659432192644 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.030540229100733996 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 1.168766
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :906
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465168
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205155
INFO:root:FL Epoch: 161 Norm Difference for worker 906 is 1.771627
INFO:root:FL Epoch: 161 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1144
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661096
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285308
INFO:root:FL Epoch: 161 Norm Difference for worker 1144 is 1.876625
INFO:root:FL Epoch: 161 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1064
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288478
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315145
INFO:root:FL Epoch: 161 Norm Difference for worker 1064 is 1.830272
INFO:root:FL Epoch: 161 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :596
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526786
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289984
INFO:root:FL Epoch: 161 Norm Difference for worker 596 is 1.946719
INFO:root:FL Epoch: 161 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1021
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324506
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366304
INFO:root:FL Epoch: 161 Norm Difference for worker 1021 is 1.817315
INFO:root:FL Epoch: 161 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :234
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345750
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 234 is 1.866023
INFO:root:FL Epoch: 161 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1844
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552523
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229251
INFO:root:FL Epoch: 161 Norm Difference for worker 1844 is 1.823558
INFO:root:FL Epoch: 161 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5151624741658152, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.499685645222507
INFO:root:#### Oracle Cals: 3, Objective Val: 1.497478856943842
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4971075677029178
INFO:root:#### Oracle Cals: 5, Objective Val: 1.4970419911952124
INFO:root:#### Oracle Cals: 6, Objective Val: 1.4970302068863277
INFO:root:#### Oracle Cals: 7, Objective Val: 1.497028110469035
INFO:root:#### Oracle Cals: 8, Objective Val: 1.497027681698486
INFO:root:#### Oracle Cals: 9, Objective Val: 1.4970276143851575
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.45941316906143637 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.11345981961737077                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451269
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152412
INFO:root:FL Epoch: 162 Norm Difference for worker 941 is 2.078648
INFO:root:FL Epoch: 162 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1390
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490543
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172425
INFO:root:FL Epoch: 162 Norm Difference for worker 1390 is 2.134215
INFO:root:FL Epoch: 162 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675317
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282404
INFO:root:FL Epoch: 162 Norm Difference for worker 1941 is 2.052366
INFO:root:FL Epoch: 162 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :884
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 1.216994
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408695
INFO:root:FL Epoch: 162 Norm Difference for worker 884 is 2.198076
INFO:root:FL Epoch: 162 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :44
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533490
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 44 is 2.12183
INFO:root:FL Epoch: 162 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1585
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599711
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272899
INFO:root:FL Epoch: 162 Norm Difference for worker 1585 is 2.153889
INFO:root:FL Epoch: 162 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1081
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566387
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205580
INFO:root:FL Epoch: 162 Norm Difference for worker 1081 is 2.157859
INFO:root:FL Epoch: 162 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1024
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338197
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378063
INFO:root:FL Epoch: 162 Norm Difference for worker 1024 is 2.207089
INFO:root:FL Epoch: 162 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1886
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591928
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192964
INFO:root:FL Epoch: 162 Norm Difference for worker 1886 is 2.068232
INFO:root:FL Epoch: 162 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1439
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311173
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241800
INFO:root:FL Epoch: 162 Norm Difference for worker 1439 is 2.083976
INFO:root:FL Epoch: 162 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9847321737692427, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9846817353920607
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9846810987155248
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9846811096475379
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.44501687148038077 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.15329576656222343                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1559
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570346
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413041
INFO:root:FL Epoch: 163 Norm Difference for worker 1559 is 1.900264
INFO:root:FL Epoch: 163 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1487
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476968
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346668
INFO:root:FL Epoch: 163 Norm Difference for worker 1487 is 1.990003
INFO:root:FL Epoch: 163 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :359
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811659
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228602
INFO:root:FL Epoch: 163 Norm Difference for worker 359 is 1.83032
INFO:root:FL Epoch: 163 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1586
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530658
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414795
INFO:root:FL Epoch: 163 Norm Difference for worker 1586 is 1.875201
INFO:root:FL Epoch: 163 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1338
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510464
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596383
INFO:root:FL Epoch: 163 Norm Difference for worker 1338 is 1.925564
INFO:root:FL Epoch: 163 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1840
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646168
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274427
INFO:root:FL Epoch: 163 Norm Difference for worker 1840 is 2.008283
INFO:root:FL Epoch: 163 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :901
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386832
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214322
INFO:root:FL Epoch: 163 Norm Difference for worker 901 is 1.77505
INFO:root:FL Epoch: 163 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :711
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574818
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281037
INFO:root:FL Epoch: 163 Norm Difference for worker 711 is 1.850546
INFO:root:FL Epoch: 163 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1413
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507998
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281559
INFO:root:FL Epoch: 163 Norm Difference for worker 1413 is 1.873423
INFO:root:FL Epoch: 163 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :431
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513224
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303531
INFO:root:FL Epoch: 163 Norm Difference for worker 431 is 1.883185
INFO:root:FL Epoch: 163 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.778131924102155, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.778037178787386
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7780360260521815
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7780360122445087
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.4476598536267 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.18968743458390236                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 164 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1316
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306846
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195924
INFO:root:FL Epoch: 164 Norm Difference for worker 1316 is 1.731578
INFO:root:FL Epoch: 164 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :898
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512510
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282760
INFO:root:FL Epoch: 164 Norm Difference for worker 898 is 1.845291
INFO:root:FL Epoch: 164 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :465
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663993
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203429
INFO:root:FL Epoch: 164 Norm Difference for worker 465 is 1.93325
INFO:root:FL Epoch: 164 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :599
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536848
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284621
INFO:root:FL Epoch: 164 Norm Difference for worker 599 is 1.855047
INFO:root:FL Epoch: 164 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1822
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584159
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230121
INFO:root:FL Epoch: 164 Norm Difference for worker 1822 is 1.861799
INFO:root:FL Epoch: 164 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1634
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508779
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377801
INFO:root:FL Epoch: 164 Norm Difference for worker 1634 is 1.916941
INFO:root:FL Epoch: 164 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1455
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591052
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247492
INFO:root:FL Epoch: 164 Norm Difference for worker 1455 is 1.799256
INFO:root:FL Epoch: 164 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :250
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 250 is 1.810313
INFO:root:FL Epoch: 164 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :791
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526592
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208790
INFO:root:FL Epoch: 164 Norm Difference for worker 791 is 1.766488
INFO:root:FL Epoch: 164 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1388
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549633
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229026
INFO:root:FL Epoch: 164 Norm Difference for worker 1388 is 1.814646
INFO:root:FL Epoch: 164 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7318023483918294, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7317152962073608
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7317140356048297
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7317140153806363
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.45507294816129346 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.21075307205319405                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 165 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :1295
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509330
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200183
INFO:root:FL Epoch: 165 Norm Difference for worker 1295 is 1.700222
INFO:root:FL Epoch: 165 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1294
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398750
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261151
INFO:root:FL Epoch: 165 Norm Difference for worker 1294 is 1.963393
INFO:root:FL Epoch: 165 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1754
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805490
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598890
INFO:root:FL Epoch: 165 Norm Difference for worker 1754 is 1.868702
INFO:root:FL Epoch: 165 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :782
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643600
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241075
INFO:root:FL Epoch: 165 Norm Difference for worker 782 is 2.097134
INFO:root:FL Epoch: 165 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :108
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.266982
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216002
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 108 is 1.824672
INFO:root:FL Epoch: 165 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1018
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518866
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552870
INFO:root:FL Epoch: 165 Norm Difference for worker 1018 is 1.908432
INFO:root:FL Epoch: 165 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :832
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469636
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196990
INFO:root:FL Epoch: 165 Norm Difference for worker 832 is 1.959965
INFO:root:FL Epoch: 165 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :133
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 133 is 1.957116
INFO:root:FL Epoch: 165 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :12
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 12 is 1.928203
INFO:root:FL Epoch: 165 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :34
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.835873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 34 is 1.773871
INFO:root:FL Epoch: 165 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.789582448119366, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7892955334727503
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7892917467759726
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7892917359607985
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.4672826844103196 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.20391704017917314                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 166 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :319
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.262931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277074
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 319 is 1.712438
INFO:root:FL Epoch: 166 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :958
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370501
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268177
INFO:root:FL Epoch: 166 Norm Difference for worker 958 is 1.895657
INFO:root:FL Epoch: 166 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1164
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499141
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406518
INFO:root:FL Epoch: 166 Norm Difference for worker 1164 is 1.925317
INFO:root:FL Epoch: 166 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :515
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407466
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285053
INFO:root:FL Epoch: 166 Norm Difference for worker 515 is 1.87085
INFO:root:FL Epoch: 166 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :688
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516160
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385344
INFO:root:FL Epoch: 166 Norm Difference for worker 688 is 1.79986
INFO:root:FL Epoch: 166 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1693
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634721
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291527
INFO:root:FL Epoch: 166 Norm Difference for worker 1693 is 1.789139
INFO:root:FL Epoch: 166 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1070
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771891
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473009
INFO:root:FL Epoch: 166 Norm Difference for worker 1070 is 1.917201
INFO:root:FL Epoch: 166 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1237
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481981
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437169
INFO:root:FL Epoch: 166 Norm Difference for worker 1237 is 1.834116
INFO:root:FL Epoch: 166 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1365
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481704
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179023
INFO:root:FL Epoch: 166 Norm Difference for worker 1365 is 1.756886
INFO:root:FL Epoch: 166 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :936
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515118
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437230
INFO:root:FL Epoch: 166 Norm Difference for worker 936 is 1.810682
INFO:root:FL Epoch: 166 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7258646383027687, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.725751002659249
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7257496423680614
INFO:root:#### Oracle Cals: 4, Objective Val: 1.725749625325651
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.44881168358466206 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.22412429253260294                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :106
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705701
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 106 is 1.761297
INFO:root:FL Epoch: 167 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328421
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179043
INFO:root:FL Epoch: 167 Norm Difference for worker 755 is 1.721888
INFO:root:FL Epoch: 167 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :81
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322191
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 81 is 1.834786
INFO:root:FL Epoch: 167 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1241
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773618
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351681
INFO:root:FL Epoch: 167 Norm Difference for worker 1241 is 1.740684
INFO:root:FL Epoch: 167 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :665
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424923
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275086
INFO:root:FL Epoch: 167 Norm Difference for worker 665 is 1.651929
INFO:root:FL Epoch: 167 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1244
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578769
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280040
INFO:root:FL Epoch: 167 Norm Difference for worker 1244 is 1.774949
INFO:root:FL Epoch: 167 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472124
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312155
INFO:root:FL Epoch: 167 Norm Difference for worker 1755 is 1.721412
INFO:root:FL Epoch: 167 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1189
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486601
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263264
INFO:root:FL Epoch: 167 Norm Difference for worker 1189 is 1.83867
INFO:root:FL Epoch: 167 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :785
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.899379
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296338
INFO:root:FL Epoch: 167 Norm Difference for worker 785 is 1.818256
INFO:root:FL Epoch: 167 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1463
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580828
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335385
INFO:root:FL Epoch: 167 Norm Difference for worker 1463 is 1.979324
INFO:root:FL Epoch: 167 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6825856828798733, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6823594911061952
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6823566193187827
INFO:root:#### Oracle Cals: 4, Objective Val: 1.682356581181759
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.44652314396465526 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.21958637361725172                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1872
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300792
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342141
INFO:root:FL Epoch: 168 Norm Difference for worker 1872 is 1.802783
INFO:root:FL Epoch: 168 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1711
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497963
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342915
INFO:root:FL Epoch: 168 Norm Difference for worker 1711 is 1.888132
INFO:root:FL Epoch: 168 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :18
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 18 is 1.765568
INFO:root:FL Epoch: 168 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :202
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 202 is 1.784399
INFO:root:FL Epoch: 168 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306812
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 1.84577
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1782
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534435
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338782
INFO:root:FL Epoch: 168 Norm Difference for worker 1782 is 1.846807
INFO:root:FL Epoch: 168 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1869
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377420
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189038
INFO:root:FL Epoch: 168 Norm Difference for worker 1869 is 1.75874
INFO:root:FL Epoch: 168 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1830
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360268
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331650
INFO:root:FL Epoch: 168 Norm Difference for worker 1830 is 1.876964
INFO:root:FL Epoch: 168 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1197
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462157
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420141
INFO:root:FL Epoch: 168 Norm Difference for worker 1197 is 1.993228
INFO:root:FL Epoch: 168 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1476
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488269
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187632
INFO:root:FL Epoch: 168 Norm Difference for worker 1476 is 1.766745
INFO:root:FL Epoch: 168 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7296466412233173, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7294616371937848
INFO:root:#### Oracle Cals: 3, Objective Val: 1.729459328609461
INFO:root:#### Oracle Cals: 4, Objective Val: 1.729459315801903
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.44756487011909485 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.23239560425281525                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 169 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :945
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558121
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171028
INFO:root:FL Epoch: 169 Norm Difference for worker 945 is 1.636856
INFO:root:FL Epoch: 169 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :273
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.211148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 273 is 1.825217
INFO:root:FL Epoch: 169 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1442
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634689
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200043
INFO:root:FL Epoch: 169 Norm Difference for worker 1442 is 1.787558
INFO:root:FL Epoch: 169 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :952
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318430
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205090
INFO:root:FL Epoch: 169 Norm Difference for worker 952 is 1.883386
INFO:root:FL Epoch: 169 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1360
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303706
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332051
INFO:root:FL Epoch: 169 Norm Difference for worker 1360 is 1.903682
INFO:root:FL Epoch: 169 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :854
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703215
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222127
INFO:root:FL Epoch: 169 Norm Difference for worker 854 is 1.851363
INFO:root:FL Epoch: 169 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :821
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572689
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219298
INFO:root:FL Epoch: 169 Norm Difference for worker 821 is 1.896074
INFO:root:FL Epoch: 169 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1782
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300262
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207231
INFO:root:FL Epoch: 169 Norm Difference for worker 1782 is 1.707173
INFO:root:FL Epoch: 169 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :807
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576240
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452166
INFO:root:FL Epoch: 169 Norm Difference for worker 807 is 1.979158
INFO:root:FL Epoch: 169 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :24
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 24 is 1.866903
INFO:root:FL Epoch: 169 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.723348059052829, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.723059694595103
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7230558330915184
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7230557782904918
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.4490634904188268 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.19304622958103815                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :603
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346576
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233304
INFO:root:FL Epoch: 170 Norm Difference for worker 603 is 1.785318
INFO:root:FL Epoch: 170 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :40
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.303430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 40 is 1.911397
INFO:root:FL Epoch: 170 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1838
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862470
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366326
INFO:root:FL Epoch: 170 Norm Difference for worker 1838 is 1.953495
INFO:root:FL Epoch: 170 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :467
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527913
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246262
INFO:root:FL Epoch: 170 Norm Difference for worker 467 is 1.72163
INFO:root:FL Epoch: 170 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :350
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362407
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373027
INFO:root:FL Epoch: 170 Norm Difference for worker 350 is 2.005859
INFO:root:FL Epoch: 170 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :263
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.221091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 263 is 2.010478
INFO:root:FL Epoch: 170 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1301
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486776
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247665
INFO:root:FL Epoch: 170 Norm Difference for worker 1301 is 2.154458
INFO:root:FL Epoch: 170 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :833
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569964
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262451
INFO:root:FL Epoch: 170 Norm Difference for worker 833 is 1.889992
INFO:root:FL Epoch: 170 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :465
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502762
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309914
INFO:root:FL Epoch: 170 Norm Difference for worker 465 is 1.870543
INFO:root:FL Epoch: 170 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :863
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562424
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409024
INFO:root:FL Epoch: 170 Norm Difference for worker 863 is 1.921643
INFO:root:FL Epoch: 170 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.804895626977766, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8045792219005752
INFO:root:#### Oracle Cals: 3, Objective Val: 1.8045753706709897
INFO:root:#### Oracle Cals: 4, Objective Val: 1.80457530905518
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.4496862064389622 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.20558027302225432                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.146628
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.044850
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.071008601381133 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.02950470009818673 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.976593
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.145635
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.058450
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.029480053189521033 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.027052608877420427 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 1.012633
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.120468
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113230
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.0419241227209568 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.02658117264509201 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 1.027466
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :694
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487399
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213170
INFO:root:FL Epoch: 171 Norm Difference for worker 694 is 1.743118
INFO:root:FL Epoch: 171 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1305
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470208
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245454
INFO:root:FL Epoch: 171 Norm Difference for worker 1305 is 1.873101
INFO:root:FL Epoch: 171 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1063
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838994
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244114
INFO:root:FL Epoch: 171 Norm Difference for worker 1063 is 1.87606
INFO:root:FL Epoch: 171 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1767
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466822
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369502
INFO:root:FL Epoch: 171 Norm Difference for worker 1767 is 1.778363
INFO:root:FL Epoch: 171 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :318
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701122
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 318 is 1.82379
INFO:root:FL Epoch: 171 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :760
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556265
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253375
INFO:root:FL Epoch: 171 Norm Difference for worker 760 is 1.927957
INFO:root:FL Epoch: 171 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1876
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565817
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142260
INFO:root:FL Epoch: 171 Norm Difference for worker 1876 is 1.952689
INFO:root:FL Epoch: 171 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.480633488907534, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4628764506844607
INFO:root:#### Oracle Cals: 3, Objective Val: 1.460312967123139
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4598772065271102
INFO:root:#### Oracle Cals: 5, Objective Val: 1.4597999372055377
INFO:root:#### Oracle Cals: 6, Objective Val: 1.4597860999086358
INFO:root:#### Oracle Cals: 7, Objective Val: 1.4597835397416248
INFO:root:#### Oracle Cals: 8, Objective Val: 1.459783107235478
INFO:root:#### Oracle Cals: 9, Objective Val: 1.4597830147252298
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.4716855410267325 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.07937048096209764                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1003
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759721
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.114564
INFO:root:FL Epoch: 172 Norm Difference for worker 1003 is 1.908258
INFO:root:FL Epoch: 172 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :375
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 1.185403
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174656
INFO:root:FL Epoch: 172 Norm Difference for worker 375 is 2.001434
INFO:root:FL Epoch: 172 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :966
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649788
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307153
INFO:root:FL Epoch: 172 Norm Difference for worker 966 is 2.155322
INFO:root:FL Epoch: 172 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :334
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511623
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 334 is 1.917618
INFO:root:FL Epoch: 172 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :312
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.176418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 312 is 2.139787
INFO:root:FL Epoch: 172 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1747
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563443
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237211
INFO:root:FL Epoch: 172 Norm Difference for worker 1747 is 2.249493
INFO:root:FL Epoch: 172 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1294
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697128
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231607
INFO:root:FL Epoch: 172 Norm Difference for worker 1294 is 2.082219
INFO:root:FL Epoch: 172 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :737
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438407
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261629
INFO:root:FL Epoch: 172 Norm Difference for worker 737 is 2.300998
INFO:root:FL Epoch: 172 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1064
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522821
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411218
INFO:root:FL Epoch: 172 Norm Difference for worker 1064 is 2.024062
INFO:root:FL Epoch: 172 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1392
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450689
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225675
INFO:root:FL Epoch: 172 Norm Difference for worker 1392 is 2.009036
INFO:root:FL Epoch: 172 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9526573907058147, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9522619661892662
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9522572232250492
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9522571599473488
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.4612753093242645 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.13984261515239874                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1721
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662813
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249806
INFO:root:FL Epoch: 173 Norm Difference for worker 1721 is 1.74736
INFO:root:FL Epoch: 173 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1093
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.973209
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478663
INFO:root:FL Epoch: 173 Norm Difference for worker 1093 is 1.94695
INFO:root:FL Epoch: 173 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1173
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563826
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308461
INFO:root:FL Epoch: 173 Norm Difference for worker 1173 is 1.993274
INFO:root:FL Epoch: 173 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :968
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629644
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441492
INFO:root:FL Epoch: 173 Norm Difference for worker 968 is 1.9815
INFO:root:FL Epoch: 173 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :270
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 270 is 1.886786
INFO:root:FL Epoch: 173 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :894
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515322
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234879
INFO:root:FL Epoch: 173 Norm Difference for worker 894 is 1.773436
INFO:root:FL Epoch: 173 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :594
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540394
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392055
INFO:root:FL Epoch: 173 Norm Difference for worker 594 is 1.962032
INFO:root:FL Epoch: 173 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1009
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716526
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157851
INFO:root:FL Epoch: 173 Norm Difference for worker 1009 is 2.118116
INFO:root:FL Epoch: 173 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1378
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812779
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261139
INFO:root:FL Epoch: 173 Norm Difference for worker 1378 is 1.973431
INFO:root:FL Epoch: 173 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :906
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258090
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272423
INFO:root:FL Epoch: 173 Norm Difference for worker 906 is 1.789278
INFO:root:FL Epoch: 173 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7914643040695999, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7911275753735376
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7911229069708594
INFO:root:#### Oracle Cals: 4, Objective Val: 1.791122846628618
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.4695974570863387 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.1421873817841212                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 174 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :1667
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501540
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165413
INFO:root:FL Epoch: 174 Norm Difference for worker 1667 is 1.770415
INFO:root:FL Epoch: 174 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :907
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602629
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173226
INFO:root:FL Epoch: 174 Norm Difference for worker 907 is 1.880321
INFO:root:FL Epoch: 174 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1313
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565001
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202400
INFO:root:FL Epoch: 174 Norm Difference for worker 1313 is 1.758424
INFO:root:FL Epoch: 174 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :522
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629828
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454096
INFO:root:FL Epoch: 174 Norm Difference for worker 522 is 1.790867
INFO:root:FL Epoch: 174 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :913
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639514
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421017
INFO:root:FL Epoch: 174 Norm Difference for worker 913 is 1.942055
INFO:root:FL Epoch: 174 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1260
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323385
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225878
INFO:root:FL Epoch: 174 Norm Difference for worker 1260 is 1.843288
INFO:root:FL Epoch: 174 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1683
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 1.178279
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549153
INFO:root:FL Epoch: 174 Norm Difference for worker 1683 is 2.0231
INFO:root:FL Epoch: 174 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :925
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356098
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173077
INFO:root:FL Epoch: 174 Norm Difference for worker 925 is 1.666429
INFO:root:FL Epoch: 174 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1459
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483527
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309838
INFO:root:FL Epoch: 174 Norm Difference for worker 1459 is 1.98667
INFO:root:FL Epoch: 174 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1264
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282166
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589386
INFO:root:FL Epoch: 174 Norm Difference for worker 1264 is 1.839006
INFO:root:FL Epoch: 174 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7406911614112042, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7404185331240447
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7404151199101936
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7404150666002
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.45341471363516417 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.16440031304955482                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544995
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341749
INFO:root:FL Epoch: 175 Norm Difference for worker 850 is 1.852052
INFO:root:FL Epoch: 175 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619766
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552258
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 1.8854
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1212
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413441
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332592
INFO:root:FL Epoch: 175 Norm Difference for worker 1212 is 1.841116
INFO:root:FL Epoch: 175 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1570
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421485
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300535
INFO:root:FL Epoch: 175 Norm Difference for worker 1570 is 1.865747
INFO:root:FL Epoch: 175 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :305
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 305 is 1.746198
INFO:root:FL Epoch: 175 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1197
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667858
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208892
INFO:root:FL Epoch: 175 Norm Difference for worker 1197 is 1.832166
INFO:root:FL Epoch: 175 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1169
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518827
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240111
INFO:root:FL Epoch: 175 Norm Difference for worker 1169 is 1.870757
INFO:root:FL Epoch: 175 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1057
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749192
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649668
INFO:root:FL Epoch: 175 Norm Difference for worker 1057 is 1.912731
INFO:root:FL Epoch: 175 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1584
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586268
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434627
INFO:root:FL Epoch: 175 Norm Difference for worker 1584 is 1.80361
INFO:root:FL Epoch: 175 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1528
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461554
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324328
INFO:root:FL Epoch: 175 Norm Difference for worker 1528 is 1.649016
INFO:root:FL Epoch: 175 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7179675017517673, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7178355250757258
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7178339824350175
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7178339238962919
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.45331614333040576 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.17487303291757902                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :637
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679356
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251042
INFO:root:FL Epoch: 176 Norm Difference for worker 637 is 2.01209
INFO:root:FL Epoch: 176 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1889
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621727
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194839
INFO:root:FL Epoch: 176 Norm Difference for worker 1889 is 1.795755
INFO:root:FL Epoch: 176 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :528
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655057
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281236
INFO:root:FL Epoch: 176 Norm Difference for worker 528 is 1.894203
INFO:root:FL Epoch: 176 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1101
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613525
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387063
INFO:root:FL Epoch: 176 Norm Difference for worker 1101 is 1.752766
INFO:root:FL Epoch: 176 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1673
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698220
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284664
INFO:root:FL Epoch: 176 Norm Difference for worker 1673 is 1.819795
INFO:root:FL Epoch: 176 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :974
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529158
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351965
INFO:root:FL Epoch: 176 Norm Difference for worker 974 is 1.794628
INFO:root:FL Epoch: 176 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1233
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455794
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302627
INFO:root:FL Epoch: 176 Norm Difference for worker 1233 is 1.930324
INFO:root:FL Epoch: 176 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :787
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406729
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372136
INFO:root:FL Epoch: 176 Norm Difference for worker 787 is 1.918827
INFO:root:FL Epoch: 176 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :977
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520671
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321975
INFO:root:FL Epoch: 176 Norm Difference for worker 977 is 1.826144
INFO:root:FL Epoch: 176 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :516
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607230
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167114
INFO:root:FL Epoch: 176 Norm Difference for worker 516 is 1.769419
INFO:root:FL Epoch: 176 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7430602630880319, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7428782612512128
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7428760859511472
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7428760978097158
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.4480922870776233 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.19752110540866852                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :313
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 313 is 1.698174
INFO:root:FL Epoch: 177 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :908
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779223
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217515
INFO:root:FL Epoch: 177 Norm Difference for worker 908 is 1.824832
INFO:root:FL Epoch: 177 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :557
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656650
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411822
INFO:root:FL Epoch: 177 Norm Difference for worker 557 is 1.743682
INFO:root:FL Epoch: 177 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :881
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284374
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358387
INFO:root:FL Epoch: 177 Norm Difference for worker 881 is 1.641754
INFO:root:FL Epoch: 177 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1256
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384603
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248175
INFO:root:FL Epoch: 177 Norm Difference for worker 1256 is 1.764674
INFO:root:FL Epoch: 177 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :539
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925302
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324949
INFO:root:FL Epoch: 177 Norm Difference for worker 539 is 1.804693
INFO:root:FL Epoch: 177 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237828
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 1.717978
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :220
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.161626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 220 is 1.657836
INFO:root:FL Epoch: 177 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :342
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344716
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237797
INFO:root:FL Epoch: 177 Norm Difference for worker 342 is 1.91
INFO:root:FL Epoch: 177 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1936
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418897
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279980
INFO:root:FL Epoch: 177 Norm Difference for worker 1936 is 1.841184
INFO:root:FL Epoch: 177 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.658079828316573, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6578960746839675
INFO:root:#### Oracle Cals: 3, Objective Val: 1.657893931667165
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6578939414297547
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.4427771287805894 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.19315719231963158                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :1855
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540281
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535463
INFO:root:FL Epoch: 178 Norm Difference for worker 1855 is 1.823742
INFO:root:FL Epoch: 178 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :418
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392399
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498744
INFO:root:FL Epoch: 178 Norm Difference for worker 418 is 1.703099
INFO:root:FL Epoch: 178 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1550
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668410
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254421
INFO:root:FL Epoch: 178 Norm Difference for worker 1550 is 1.737427
INFO:root:FL Epoch: 178 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1800
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442049
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307123
INFO:root:FL Epoch: 178 Norm Difference for worker 1800 is 1.809754
INFO:root:FL Epoch: 178 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1189
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621151
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203383
INFO:root:FL Epoch: 178 Norm Difference for worker 1189 is 1.7734
INFO:root:FL Epoch: 178 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :611
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625660
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241791
INFO:root:FL Epoch: 178 Norm Difference for worker 611 is 1.757501
INFO:root:FL Epoch: 178 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :325
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 325 is 1.779197
INFO:root:FL Epoch: 178 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :983
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642859
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397453
INFO:root:FL Epoch: 178 Norm Difference for worker 983 is 1.982679
INFO:root:FL Epoch: 178 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572843
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208390
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.869107
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.799914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 1.697407
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.679927927333318, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6797331356765728
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6797309267880784
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6797309057375236
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.4641128059695749 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.17109247545401254                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1226
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516827
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277388
INFO:root:FL Epoch: 179 Norm Difference for worker 1226 is 1.82415
INFO:root:FL Epoch: 179 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1285
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516071
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153392
INFO:root:FL Epoch: 179 Norm Difference for worker 1285 is 1.791728
INFO:root:FL Epoch: 179 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :972
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761939
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269855
INFO:root:FL Epoch: 179 Norm Difference for worker 972 is 1.917836
INFO:root:FL Epoch: 179 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :393
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357592
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272487
INFO:root:FL Epoch: 179 Norm Difference for worker 393 is 1.917697
INFO:root:FL Epoch: 179 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :977
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283415
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496105
INFO:root:FL Epoch: 179 Norm Difference for worker 977 is 1.807318
INFO:root:FL Epoch: 179 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :59
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.195973
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 59 is 1.801984
INFO:root:FL Epoch: 179 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :575
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499972
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317827
INFO:root:FL Epoch: 179 Norm Difference for worker 575 is 1.851821
INFO:root:FL Epoch: 179 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :472
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304846
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303571
INFO:root:FL Epoch: 179 Norm Difference for worker 472 is 1.752129
INFO:root:FL Epoch: 179 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1689
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669064
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374575
INFO:root:FL Epoch: 179 Norm Difference for worker 1689 is 2.013777
INFO:root:FL Epoch: 179 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :565
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423930
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243902
INFO:root:FL Epoch: 179 Norm Difference for worker 565 is 1.822686
INFO:root:FL Epoch: 179 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.739249870040303, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.739112309518937
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7391107489092217
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7391107305740459
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.4509574525496539 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.16674805184205374                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1850
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626258
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437609
INFO:root:FL Epoch: 180 Norm Difference for worker 1850 is 1.861093
INFO:root:FL Epoch: 180 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :989
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512835
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311210
INFO:root:FL Epoch: 180 Norm Difference for worker 989 is 1.836466
INFO:root:FL Epoch: 180 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :611
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341810
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262961
INFO:root:FL Epoch: 180 Norm Difference for worker 611 is 1.732932
INFO:root:FL Epoch: 180 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :637
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545276
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188574
INFO:root:FL Epoch: 180 Norm Difference for worker 637 is 1.886851
INFO:root:FL Epoch: 180 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1690
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718333
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435454
INFO:root:FL Epoch: 180 Norm Difference for worker 1690 is 1.874167
INFO:root:FL Epoch: 180 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1250
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562575
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416919
INFO:root:FL Epoch: 180 Norm Difference for worker 1250 is 1.943208
INFO:root:FL Epoch: 180 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :844
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396411
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325738
INFO:root:FL Epoch: 180 Norm Difference for worker 844 is 1.632378
INFO:root:FL Epoch: 180 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1444
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391934
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290830
INFO:root:FL Epoch: 180 Norm Difference for worker 1444 is 1.791975
INFO:root:FL Epoch: 180 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :120
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 120 is 1.781371
INFO:root:FL Epoch: 180 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :134
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559406
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 134 is 1.876398
INFO:root:FL Epoch: 180 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.715426695073005, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7152871890513948
INFO:root:#### Oracle Cals: 3, Objective Val: 1.715285333657996
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7152852942577628
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.4529290742733899 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.2260002108911673                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.139299
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.091203
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.07075742601106565 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.03421055972576141 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.96197
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.146415
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.088669
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.05200621020048857 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.030603117123246194 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.96713
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.121434
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.092407
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.08301611399898927 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.040120715461671355 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.96524
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :869
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542787
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368675
INFO:root:FL Epoch: 181 Norm Difference for worker 869 is 1.783911
INFO:root:FL Epoch: 181 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :716
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493156
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211098
INFO:root:FL Epoch: 181 Norm Difference for worker 716 is 1.599216
INFO:root:FL Epoch: 181 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1560
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271131
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228154
INFO:root:FL Epoch: 181 Norm Difference for worker 1560 is 1.760194
INFO:root:FL Epoch: 181 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :623
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734724
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352527
INFO:root:FL Epoch: 181 Norm Difference for worker 623 is 1.807121
INFO:root:FL Epoch: 181 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1018
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687881
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278834
INFO:root:FL Epoch: 181 Norm Difference for worker 1018 is 1.762947
INFO:root:FL Epoch: 181 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :195
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361135
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.211440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 195 is 1.782451
INFO:root:FL Epoch: 181 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1034
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621010
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328285
INFO:root:FL Epoch: 181 Norm Difference for worker 1034 is 1.834012
INFO:root:FL Epoch: 181 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.402439147484584, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3862569968757235
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3838986317770268
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3834909899115937
INFO:root:#### Oracle Cals: 5, Objective Val: 1.3834170486073043
INFO:root:#### Oracle Cals: 6, Objective Val: 1.3834034330736364
INFO:root:#### Oracle Cals: 7, Objective Val: 1.3834009293351723
INFO:root:#### Oracle Cals: 8, Objective Val: 1.3834004226771084
INFO:root:#### Oracle Cals: 9, Objective Val: 1.383400503104534
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.4586859520743875 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.09417238179594278                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1201
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358379
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269917
INFO:root:FL Epoch: 182 Norm Difference for worker 1201 is 1.946354
INFO:root:FL Epoch: 182 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1052
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468630
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484609
INFO:root:FL Epoch: 182 Norm Difference for worker 1052 is 2.118604
INFO:root:FL Epoch: 182 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :959
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396452
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232634
INFO:root:FL Epoch: 182 Norm Difference for worker 959 is 2.066575
INFO:root:FL Epoch: 182 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1624
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598884
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201985
INFO:root:FL Epoch: 182 Norm Difference for worker 1624 is 2.032351
INFO:root:FL Epoch: 182 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :825
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664291
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291703
INFO:root:FL Epoch: 182 Norm Difference for worker 825 is 1.936079
INFO:root:FL Epoch: 182 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1782
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583734
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324306
INFO:root:FL Epoch: 182 Norm Difference for worker 1782 is 2.07699
INFO:root:FL Epoch: 182 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :488
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732342
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176507
INFO:root:FL Epoch: 182 Norm Difference for worker 488 is 1.992156
INFO:root:FL Epoch: 182 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :507
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 1.032327
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265657
INFO:root:FL Epoch: 182 Norm Difference for worker 507 is 2.205883
INFO:root:FL Epoch: 182 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1078
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472045
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209288
INFO:root:FL Epoch: 182 Norm Difference for worker 1078 is 2.147543
INFO:root:FL Epoch: 182 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1849
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545266
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150446
INFO:root:FL Epoch: 182 Norm Difference for worker 1849 is 1.997218
INFO:root:FL Epoch: 182 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9216002432340094, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9214535337553074
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9214518620314645
INFO:root:#### Oracle Cals: 4, Objective Val: 1.921451841732451
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.4560564703801099 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.1213761530816555                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1215
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822956
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281709
INFO:root:FL Epoch: 183 Norm Difference for worker 1215 is 1.836942
INFO:root:FL Epoch: 183 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1520
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318433
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188555
INFO:root:FL Epoch: 183 Norm Difference for worker 1520 is 1.715049
INFO:root:FL Epoch: 183 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :630
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401836
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361735
INFO:root:FL Epoch: 183 Norm Difference for worker 630 is 2.119766
INFO:root:FL Epoch: 183 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :563
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489710
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262704
INFO:root:FL Epoch: 183 Norm Difference for worker 563 is 1.725477
INFO:root:FL Epoch: 183 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 1.799155
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1104
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600766
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256143
INFO:root:FL Epoch: 183 Norm Difference for worker 1104 is 1.847634
INFO:root:FL Epoch: 183 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1522
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330726
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279649
INFO:root:FL Epoch: 183 Norm Difference for worker 1522 is 1.673946
INFO:root:FL Epoch: 183 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1754
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508671
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201372
INFO:root:FL Epoch: 183 Norm Difference for worker 1754 is 1.785243
INFO:root:FL Epoch: 183 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :48
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 48 is 1.675871
INFO:root:FL Epoch: 183 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1604
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693584
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202193
INFO:root:FL Epoch: 183 Norm Difference for worker 1604 is 1.838194
INFO:root:FL Epoch: 183 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7058116540124828, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7054460813860255
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7054416773852563
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7054416228932576
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.46180752620977517 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.12082424946129322                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1775
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497854
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239475
INFO:root:FL Epoch: 184 Norm Difference for worker 1775 is 1.742231
INFO:root:FL Epoch: 184 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1560
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387600
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230130
INFO:root:FL Epoch: 184 Norm Difference for worker 1560 is 1.668194
INFO:root:FL Epoch: 184 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1234
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538111
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472718
INFO:root:FL Epoch: 184 Norm Difference for worker 1234 is 1.903379
INFO:root:FL Epoch: 184 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1381
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290470
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320262
INFO:root:FL Epoch: 184 Norm Difference for worker 1381 is 1.941728
INFO:root:FL Epoch: 184 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1244
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452116
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343240
INFO:root:FL Epoch: 184 Norm Difference for worker 1244 is 1.85618
INFO:root:FL Epoch: 184 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1478
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613417
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175328
INFO:root:FL Epoch: 184 Norm Difference for worker 1478 is 1.636633
INFO:root:FL Epoch: 184 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1887
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298471
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213797
INFO:root:FL Epoch: 184 Norm Difference for worker 1887 is 1.860155
INFO:root:FL Epoch: 184 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :825
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320637
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323445
INFO:root:FL Epoch: 184 Norm Difference for worker 825 is 1.591843
INFO:root:FL Epoch: 184 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :202
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.222331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 202 is 1.731196
INFO:root:FL Epoch: 184 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :471
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666452
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291070
INFO:root:FL Epoch: 184 Norm Difference for worker 471 is 1.927658
INFO:root:FL Epoch: 184 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.692710397688293, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6922439752894434
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6922378727043565
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6922377832625901
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.432913881890914 and Test Accuracy:80.0 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.1194523988912503                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1656
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523483
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171433
INFO:root:FL Epoch: 185 Norm Difference for worker 1656 is 1.762534
INFO:root:FL Epoch: 185 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1518
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361443
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281274
INFO:root:FL Epoch: 185 Norm Difference for worker 1518 is 1.804067
INFO:root:FL Epoch: 185 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1088
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528073
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378356
INFO:root:FL Epoch: 185 Norm Difference for worker 1088 is 1.687689
INFO:root:FL Epoch: 185 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :559
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677391
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327789
INFO:root:FL Epoch: 185 Norm Difference for worker 559 is 1.87628
INFO:root:FL Epoch: 185 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :487
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646922
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313338
INFO:root:FL Epoch: 185 Norm Difference for worker 487 is 1.680874
INFO:root:FL Epoch: 185 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :317
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 317 is 1.829539
INFO:root:FL Epoch: 185 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1080
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669588
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368049
INFO:root:FL Epoch: 185 Norm Difference for worker 1080 is 1.964586
INFO:root:FL Epoch: 185 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.127760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 1.879527
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1146
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456452
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285607
INFO:root:FL Epoch: 185 Norm Difference for worker 1146 is 1.860435
INFO:root:FL Epoch: 185 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 1.763725
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7162474178378686, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7159931886064834
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7159897917126212
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7159897222905112
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.4478176236152649 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.1457394411166509                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517648
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194639
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.789121
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :785
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354867
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404824
INFO:root:FL Epoch: 186 Norm Difference for worker 785 is 1.821539
INFO:root:FL Epoch: 186 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :663
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779303
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223531
INFO:root:FL Epoch: 186 Norm Difference for worker 663 is 1.812064
INFO:root:FL Epoch: 186 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1530
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762576
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568927
INFO:root:FL Epoch: 186 Norm Difference for worker 1530 is 1.904652
INFO:root:FL Epoch: 186 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :738
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798245
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158115
INFO:root:FL Epoch: 186 Norm Difference for worker 738 is 1.808581
INFO:root:FL Epoch: 186 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :128
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274780
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 128 is 1.924138
INFO:root:FL Epoch: 186 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1070
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425043
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288262
INFO:root:FL Epoch: 186 Norm Difference for worker 1070 is 1.893785
INFO:root:FL Epoch: 186 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :823
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701273
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278006
INFO:root:FL Epoch: 186 Norm Difference for worker 823 is 1.789168
INFO:root:FL Epoch: 186 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :385
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655853
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341782
INFO:root:FL Epoch: 186 Norm Difference for worker 385 is 1.838778
INFO:root:FL Epoch: 186 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :503
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467596
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166984
INFO:root:FL Epoch: 186 Norm Difference for worker 503 is 1.821074
INFO:root:FL Epoch: 186 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7428429021824319, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7427477795542818
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7427467156471614
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7427466923608024
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.4295366967425627 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.1477027510603269                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 187 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :301
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 301 is 1.732143
INFO:root:FL Epoch: 187 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :277
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 277 is 1.81474
INFO:root:FL Epoch: 187 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :269
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526535
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 269 is 1.733963
INFO:root:FL Epoch: 187 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1198
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546996
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317249
INFO:root:FL Epoch: 187 Norm Difference for worker 1198 is 1.744801
INFO:root:FL Epoch: 187 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :545
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388512
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341456
INFO:root:FL Epoch: 187 Norm Difference for worker 545 is 1.835133
INFO:root:FL Epoch: 187 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1043
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503722
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386642
INFO:root:FL Epoch: 187 Norm Difference for worker 1043 is 1.774545
INFO:root:FL Epoch: 187 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :766
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420645
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261608
INFO:root:FL Epoch: 187 Norm Difference for worker 766 is 1.618073
INFO:root:FL Epoch: 187 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :736
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419817
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262331
INFO:root:FL Epoch: 187 Norm Difference for worker 736 is 1.842846
INFO:root:FL Epoch: 187 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :458
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662352
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258237
INFO:root:FL Epoch: 187 Norm Difference for worker 458 is 1.767468
INFO:root:FL Epoch: 187 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1218
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481563
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147001
INFO:root:FL Epoch: 187 Norm Difference for worker 1218 is 1.772897
INFO:root:FL Epoch: 187 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6677966327392977, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6677012603304946
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6676999332775828
INFO:root:#### Oracle Cals: 4, Objective Val: 1.667699917133465
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.4521963350913104 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.16096915553013483                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 188 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :1848
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530448
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177859
INFO:root:FL Epoch: 188 Norm Difference for worker 1848 is 1.694738
INFO:root:FL Epoch: 188 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :77
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.257278
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.167736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 77 is 1.73859
INFO:root:FL Epoch: 188 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1719
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478115
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244101
INFO:root:FL Epoch: 188 Norm Difference for worker 1719 is 1.764973
INFO:root:FL Epoch: 188 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :49
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 49 is 2.052938
INFO:root:FL Epoch: 188 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :382
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506866
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200086
INFO:root:FL Epoch: 188 Norm Difference for worker 382 is 1.928779
INFO:root:FL Epoch: 188 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :721
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427246
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282179
INFO:root:FL Epoch: 188 Norm Difference for worker 721 is 2.008118
INFO:root:FL Epoch: 188 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1690
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711462
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239427
INFO:root:FL Epoch: 188 Norm Difference for worker 1690 is 1.868257
INFO:root:FL Epoch: 188 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1774
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547687
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343516
INFO:root:FL Epoch: 188 Norm Difference for worker 1774 is 1.809083
INFO:root:FL Epoch: 188 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1927
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409408
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347656
INFO:root:FL Epoch: 188 Norm Difference for worker 1927 is 1.78141
INFO:root:FL Epoch: 188 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :433
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436962
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273493
INFO:root:FL Epoch: 188 Norm Difference for worker 433 is 1.829495
INFO:root:FL Epoch: 188 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7382185406066895, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7378452056704972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7378402194991756
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7378401571435085
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.4452872714575599 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.17145130907495817                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :486
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554897
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258431
INFO:root:FL Epoch: 189 Norm Difference for worker 486 is 1.800012
INFO:root:FL Epoch: 189 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1170
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851226
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304405
INFO:root:FL Epoch: 189 Norm Difference for worker 1170 is 1.962047
INFO:root:FL Epoch: 189 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1606
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729260
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185007
INFO:root:FL Epoch: 189 Norm Difference for worker 1606 is 1.870844
INFO:root:FL Epoch: 189 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1307
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446599
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298036
INFO:root:FL Epoch: 189 Norm Difference for worker 1307 is 1.885022
INFO:root:FL Epoch: 189 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :901
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301323
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293472
INFO:root:FL Epoch: 189 Norm Difference for worker 901 is 1.701463
INFO:root:FL Epoch: 189 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :556
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588553
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248550
INFO:root:FL Epoch: 189 Norm Difference for worker 556 is 1.736808
INFO:root:FL Epoch: 189 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :740
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421761
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172883
INFO:root:FL Epoch: 189 Norm Difference for worker 740 is 1.78345
INFO:root:FL Epoch: 189 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :927
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543563
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320217
INFO:root:FL Epoch: 189 Norm Difference for worker 927 is 1.562147
INFO:root:FL Epoch: 189 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :270
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 270 is 1.855174
INFO:root:FL Epoch: 189 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :488
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369581
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237492
INFO:root:FL Epoch: 189 Norm Difference for worker 488 is 1.728322
INFO:root:FL Epoch: 189 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.693645080730169, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.693364226768557
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6933603251162572
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6933602952803242
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.4486405288471895 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.16807332510749498                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :256
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 256 is 1.756206
INFO:root:FL Epoch: 190 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :751
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435188
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423817
INFO:root:FL Epoch: 190 Norm Difference for worker 751 is 1.726146
INFO:root:FL Epoch: 190 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1156
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434566
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261488
INFO:root:FL Epoch: 190 Norm Difference for worker 1156 is 1.741709
INFO:root:FL Epoch: 190 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1330
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434514
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263465
INFO:root:FL Epoch: 190 Norm Difference for worker 1330 is 1.872012
INFO:root:FL Epoch: 190 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :859
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520943
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349916
INFO:root:FL Epoch: 190 Norm Difference for worker 859 is 1.932296
INFO:root:FL Epoch: 190 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :257
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.234875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 257 is 1.879363
INFO:root:FL Epoch: 190 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1432
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524387
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331458
INFO:root:FL Epoch: 190 Norm Difference for worker 1432 is 1.801117
INFO:root:FL Epoch: 190 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490565
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536823
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 1.963243
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1730
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359064
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414930
INFO:root:FL Epoch: 190 Norm Difference for worker 1730 is 1.970609
INFO:root:FL Epoch: 190 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :608
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563998
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199219
INFO:root:FL Epoch: 190 Norm Difference for worker 608 is 1.859726
INFO:root:FL Epoch: 190 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7567824858060677, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7566231957582006
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7566213516274727
INFO:root:#### Oracle Cals: 4, Objective Val: 1.756621329622875
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.4563320717390846 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.18151049812634787                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.133344
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.073465
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.02715275002022584 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.025797722674906255 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.793627
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.100014
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.089275
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.051631728652864695 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.028290925733745097 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.775347
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.106652
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.038654
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.05183209339156747 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.029744228534400462 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.782543
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1898
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341496
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390268
INFO:root:FL Epoch: 191 Norm Difference for worker 1898 is 1.79817
INFO:root:FL Epoch: 191 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453116
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168984
INFO:root:FL Epoch: 191 Norm Difference for worker 555 is 1.760147
INFO:root:FL Epoch: 191 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :925
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412244
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374762
INFO:root:FL Epoch: 191 Norm Difference for worker 925 is 1.687531
INFO:root:FL Epoch: 191 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :113
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.308892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 113 is 1.724329
INFO:root:FL Epoch: 191 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1363
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467281
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249305
INFO:root:FL Epoch: 191 Norm Difference for worker 1363 is 1.909482
INFO:root:FL Epoch: 191 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1837
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426273
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167344
INFO:root:FL Epoch: 191 Norm Difference for worker 1837 is 1.766981
INFO:root:FL Epoch: 191 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :781
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558857
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308499
INFO:root:FL Epoch: 191 Norm Difference for worker 781 is 1.778118
INFO:root:FL Epoch: 191 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3898787274314501, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3689032899101927
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3653331515019091
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3645929667984031
INFO:root:#### Oracle Cals: 5, Objective Val: 1.3644309258953435
INFO:root:#### Oracle Cals: 6, Objective Val: 1.364394857583965
INFO:root:#### Oracle Cals: 7, Objective Val: 1.3643868184105057
INFO:root:#### Oracle Cals: 8, Objective Val: 1.3643849630755986
INFO:root:#### Oracle Cals: 9, Objective Val: 1.364384551910334
INFO:root:#### Oracle Cals: 10, Objective Val: 1.364384465448291
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.46587730856502757 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.07234502770006657                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :562
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477454
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202608
INFO:root:FL Epoch: 192 Norm Difference for worker 562 is 2.0326
INFO:root:FL Epoch: 192 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1742
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481448
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210955
INFO:root:FL Epoch: 192 Norm Difference for worker 1742 is 2.097121
INFO:root:FL Epoch: 192 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :947
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840720
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266613
INFO:root:FL Epoch: 192 Norm Difference for worker 947 is 2.048769
INFO:root:FL Epoch: 192 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :406
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427615
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274830
INFO:root:FL Epoch: 192 Norm Difference for worker 406 is 2.291875
INFO:root:FL Epoch: 192 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1259
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668679
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313870
INFO:root:FL Epoch: 192 Norm Difference for worker 1259 is 2.160858
INFO:root:FL Epoch: 192 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :390
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782461
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186873
INFO:root:FL Epoch: 192 Norm Difference for worker 390 is 2.117649
INFO:root:FL Epoch: 192 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1140
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511147
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233520
INFO:root:FL Epoch: 192 Norm Difference for worker 1140 is 2.103129
INFO:root:FL Epoch: 192 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1411
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.983407
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407772
INFO:root:FL Epoch: 192 Norm Difference for worker 1411 is 2.237944
INFO:root:FL Epoch: 192 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :66
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653959
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 66 is 2.184287
INFO:root:FL Epoch: 192 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :468
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760074
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232337
INFO:root:FL Epoch: 192 Norm Difference for worker 468 is 2.00077
INFO:root:FL Epoch: 192 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.9921201804256965, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.9919843607856098
INFO:root:#### Oracle Cals: 3, Objective Val: 1.9919827157891719
INFO:root:#### Oracle Cals: 4, Objective Val: 1.9919827005025672
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.4508389322196736 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.13441421588261923                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1614
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503648
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343290
INFO:root:FL Epoch: 193 Norm Difference for worker 1614 is 1.958362
INFO:root:FL Epoch: 193 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :504
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243994
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158051
INFO:root:FL Epoch: 193 Norm Difference for worker 504 is 1.774183
INFO:root:FL Epoch: 193 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1022
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414835
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194092
INFO:root:FL Epoch: 193 Norm Difference for worker 1022 is 1.732551
INFO:root:FL Epoch: 193 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :580
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678327
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281485
INFO:root:FL Epoch: 193 Norm Difference for worker 580 is 1.902094
INFO:root:FL Epoch: 193 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1730
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320041
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274197
INFO:root:FL Epoch: 193 Norm Difference for worker 1730 is 1.832768
INFO:root:FL Epoch: 193 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :828
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974344
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260698
INFO:root:FL Epoch: 193 Norm Difference for worker 828 is 2.008601
INFO:root:FL Epoch: 193 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1619
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399107
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466926
INFO:root:FL Epoch: 193 Norm Difference for worker 1619 is 1.903774
INFO:root:FL Epoch: 193 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1205
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426412
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278684
INFO:root:FL Epoch: 193 Norm Difference for worker 1205 is 1.892202
INFO:root:FL Epoch: 193 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :511
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426105
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294509
INFO:root:FL Epoch: 193 Norm Difference for worker 511 is 1.897783
INFO:root:FL Epoch: 193 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1270
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700766
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233429
INFO:root:FL Epoch: 193 Norm Difference for worker 1270 is 1.799319
INFO:root:FL Epoch: 193 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7609235162422159, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7607590814648164
INFO:root:#### Oracle Cals: 3, Objective Val: 1.760757176435559
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7607571623393814
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.4694831406368929 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.1212623833368222                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281095
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 135 is 1.899605
INFO:root:FL Epoch: 194 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1532
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466979
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306282
INFO:root:FL Epoch: 194 Norm Difference for worker 1532 is 1.824281
INFO:root:FL Epoch: 194 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1525
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720356
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256413
INFO:root:FL Epoch: 194 Norm Difference for worker 1525 is 1.97442
INFO:root:FL Epoch: 194 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :103
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.190322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 103 is 1.834641
INFO:root:FL Epoch: 194 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1790
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634721
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159096
INFO:root:FL Epoch: 194 Norm Difference for worker 1790 is 1.832844
INFO:root:FL Epoch: 194 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :752
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406039
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271440
INFO:root:FL Epoch: 194 Norm Difference for worker 752 is 1.883519
INFO:root:FL Epoch: 194 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :784
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718232
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156405
INFO:root:FL Epoch: 194 Norm Difference for worker 784 is 1.842235
INFO:root:FL Epoch: 194 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :630
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640106
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185236
INFO:root:FL Epoch: 194 Norm Difference for worker 630 is 1.909934
INFO:root:FL Epoch: 194 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1283
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377912
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289635
INFO:root:FL Epoch: 194 Norm Difference for worker 1283 is 1.906511
INFO:root:FL Epoch: 194 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1290
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597569
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231432
INFO:root:FL Epoch: 194 Norm Difference for worker 1290 is 1.845056
INFO:root:FL Epoch: 194 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7665452888873123, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7664919676101523
INFO:root:#### Oracle Cals: 3, Objective Val: 1.766491334776033
INFO:root:#### Oracle Cals: 4, Objective Val: 1.766491340171267
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.47086238861083984 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.15666688606142998                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :926
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366648
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303478
INFO:root:FL Epoch: 195 Norm Difference for worker 926 is 1.653492
INFO:root:FL Epoch: 195 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :191
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 191 is 1.746536
INFO:root:FL Epoch: 195 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1426
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294207
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272795
INFO:root:FL Epoch: 195 Norm Difference for worker 1426 is 1.919345
INFO:root:FL Epoch: 195 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :261
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353375
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 261 is 1.903503
INFO:root:FL Epoch: 195 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :874
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746934
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382506
INFO:root:FL Epoch: 195 Norm Difference for worker 874 is 1.846572
INFO:root:FL Epoch: 195 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :700
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553121
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181158
INFO:root:FL Epoch: 195 Norm Difference for worker 700 is 1.854375
INFO:root:FL Epoch: 195 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :7
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 7 is 1.829458
INFO:root:FL Epoch: 195 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :301
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263880
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 301 is 1.77693
INFO:root:FL Epoch: 195 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :502
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533703
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227918
INFO:root:FL Epoch: 195 Norm Difference for worker 502 is 1.719074
INFO:root:FL Epoch: 195 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1471
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532766
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344732
INFO:root:FL Epoch: 195 Norm Difference for worker 1471 is 1.807504
INFO:root:FL Epoch: 195 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6941337153216245, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6939708629350383
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6939690033622024
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6939689588384979
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.460601361358867 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.1248389258980751                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :437
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530051
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245048
INFO:root:FL Epoch: 196 Norm Difference for worker 437 is 1.688941
INFO:root:FL Epoch: 196 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 1.925963
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1524
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781251
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300339
INFO:root:FL Epoch: 196 Norm Difference for worker 1524 is 1.805488
INFO:root:FL Epoch: 196 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :130
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574097
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 130 is 1.793317
INFO:root:FL Epoch: 196 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :478
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732650
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199992
INFO:root:FL Epoch: 196 Norm Difference for worker 478 is 1.873068
INFO:root:FL Epoch: 196 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :911
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336087
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299377
INFO:root:FL Epoch: 196 Norm Difference for worker 911 is 1.797807
INFO:root:FL Epoch: 196 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1227
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533542
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133585
INFO:root:FL Epoch: 196 Norm Difference for worker 1227 is 1.793319
INFO:root:FL Epoch: 196 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1529
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558348
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331535
INFO:root:FL Epoch: 196 Norm Difference for worker 1529 is 1.908977
INFO:root:FL Epoch: 196 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1567
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541628
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218151
INFO:root:FL Epoch: 196 Norm Difference for worker 1567 is 1.897352
INFO:root:FL Epoch: 196 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :633
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515178
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233298
INFO:root:FL Epoch: 196 Norm Difference for worker 633 is 1.721919
INFO:root:FL Epoch: 196 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7193923374702005, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7192927217015763
INFO:root:#### Oracle Cals: 3, Objective Val: 1.719291474718466
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7192914700417545
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.4484453814871171 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.18595352148016295                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1836
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507279
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301987
INFO:root:FL Epoch: 197 Norm Difference for worker 1836 is 1.766395
INFO:root:FL Epoch: 197 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1738
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591259
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275387
INFO:root:FL Epoch: 197 Norm Difference for worker 1738 is 1.830649
INFO:root:FL Epoch: 197 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :552
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496219
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427830
INFO:root:FL Epoch: 197 Norm Difference for worker 552 is 1.901799
INFO:root:FL Epoch: 197 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350895
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 1.589767
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1244
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459047
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327836
INFO:root:FL Epoch: 197 Norm Difference for worker 1244 is 1.709624
INFO:root:FL Epoch: 197 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :932
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314316
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345152
INFO:root:FL Epoch: 197 Norm Difference for worker 932 is 1.759309
INFO:root:FL Epoch: 197 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1049
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338280
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400905
INFO:root:FL Epoch: 197 Norm Difference for worker 1049 is 1.816455
INFO:root:FL Epoch: 197 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1589
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767363
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363713
INFO:root:FL Epoch: 197 Norm Difference for worker 1589 is 1.906992
INFO:root:FL Epoch: 197 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :208
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.953743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 208 is 1.787104
INFO:root:FL Epoch: 197 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :677
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500570
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251052
INFO:root:FL Epoch: 197 Norm Difference for worker 677 is 1.874773
INFO:root:FL Epoch: 197 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6923748049074154, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6921622644108276
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6921594711610144
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6921594295695066
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.45287965501056 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.18296013275782266                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :1491
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513116
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270640
INFO:root:FL Epoch: 198 Norm Difference for worker 1491 is 1.781479
INFO:root:FL Epoch: 198 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1790
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463699
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276627
INFO:root:FL Epoch: 198 Norm Difference for worker 1790 is 1.666788
INFO:root:FL Epoch: 198 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1639
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630087
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273809
INFO:root:FL Epoch: 198 Norm Difference for worker 1639 is 1.882898
INFO:root:FL Epoch: 198 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1719
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454866
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195463
INFO:root:FL Epoch: 198 Norm Difference for worker 1719 is 1.634013
INFO:root:FL Epoch: 198 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :448
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595591
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329531
INFO:root:FL Epoch: 198 Norm Difference for worker 448 is 1.830539
INFO:root:FL Epoch: 198 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1768
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689832
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284914
INFO:root:FL Epoch: 198 Norm Difference for worker 1768 is 1.932219
INFO:root:FL Epoch: 198 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1077
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548707
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339809
INFO:root:FL Epoch: 198 Norm Difference for worker 1077 is 1.617114
INFO:root:FL Epoch: 198 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1215
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580152
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280225
INFO:root:FL Epoch: 198 Norm Difference for worker 1215 is 1.794271
INFO:root:FL Epoch: 198 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1640
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589994
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270470
INFO:root:FL Epoch: 198 Norm Difference for worker 1640 is 1.688791
INFO:root:FL Epoch: 198 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1128
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221926
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220407
INFO:root:FL Epoch: 198 Norm Difference for worker 1128 is 1.709546
INFO:root:FL Epoch: 198 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6596500539596428, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6593802832576465
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6593767564865953
INFO:root:#### Oracle Cals: 4, Objective Val: 1.659376690309621
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.456207333242192 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.19769052043557167                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :180
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.179253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326186
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 180 is 1.733901
INFO:root:FL Epoch: 199 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1879
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523721
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364784
INFO:root:FL Epoch: 199 Norm Difference for worker 1879 is 1.88124
INFO:root:FL Epoch: 199 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1185
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395190
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316402
INFO:root:FL Epoch: 199 Norm Difference for worker 1185 is 1.922844
INFO:root:FL Epoch: 199 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :280
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.234077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 280 is 1.841867
INFO:root:FL Epoch: 199 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1055
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408323
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323190
INFO:root:FL Epoch: 199 Norm Difference for worker 1055 is 1.795188
INFO:root:FL Epoch: 199 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1690
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405966
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197536
INFO:root:FL Epoch: 199 Norm Difference for worker 1690 is 1.777413
INFO:root:FL Epoch: 199 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :722
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487107
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281070
INFO:root:FL Epoch: 199 Norm Difference for worker 722 is 1.823697
INFO:root:FL Epoch: 199 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :933
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617988
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184455
INFO:root:FL Epoch: 199 Norm Difference for worker 933 is 1.847081
INFO:root:FL Epoch: 199 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1874
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298375
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237028
INFO:root:FL Epoch: 199 Norm Difference for worker 1874 is 1.785026
INFO:root:FL Epoch: 199 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1457
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774053
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371910
INFO:root:FL Epoch: 199 Norm Difference for worker 1457 is 1.800678
INFO:root:FL Epoch: 199 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.718198364714002, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7181104446537363
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7181094121554334
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7181093750496783
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.4480387884027818 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.20436220491925874                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :487
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395459
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270506
INFO:root:FL Epoch: 200 Norm Difference for worker 487 is 1.636889
INFO:root:FL Epoch: 200 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :707
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608934
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507756
INFO:root:FL Epoch: 200 Norm Difference for worker 707 is 1.885865
INFO:root:FL Epoch: 200 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :38
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.208998
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 38 is 1.781084
INFO:root:FL Epoch: 200 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :996
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560479
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215573
INFO:root:FL Epoch: 200 Norm Difference for worker 996 is 1.706086
INFO:root:FL Epoch: 200 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1140
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687718
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421010
INFO:root:FL Epoch: 200 Norm Difference for worker 1140 is 1.770819
INFO:root:FL Epoch: 200 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1706
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537462
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295831
INFO:root:FL Epoch: 200 Norm Difference for worker 1706 is 1.861895
INFO:root:FL Epoch: 200 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :765
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544860
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220662
INFO:root:FL Epoch: 200 Norm Difference for worker 765 is 1.81691
INFO:root:FL Epoch: 200 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1194
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751775
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350958
INFO:root:FL Epoch: 200 Norm Difference for worker 1194 is 1.942187
INFO:root:FL Epoch: 200 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1234
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525947
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216851
INFO:root:FL Epoch: 200 Norm Difference for worker 1234 is 1.86714
INFO:root:FL Epoch: 200 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1892
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420491
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295580
INFO:root:FL Epoch: 200 Norm Difference for worker 1892 is 1.805846
INFO:root:FL Epoch: 200 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7086801084276715, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.708499140033578
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7084964029782812
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7084962585885586
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.4395851229920107 and Test Accuracy:80.0 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.15988868723313013                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.134894
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.034025
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.04939403540144364 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.027015908062458037 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.743027
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.079330
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.056777
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.040482951793819666 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.027406123466789722 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.74128
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.135002
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.056910
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.04333570304637154 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.02609941493719816 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.75811
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1449
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 1.224545
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450420
INFO:root:FL Epoch: 201 Norm Difference for worker 1449 is 1.938653
INFO:root:FL Epoch: 201 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1835
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713178
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586768
INFO:root:FL Epoch: 201 Norm Difference for worker 1835 is 1.830834
INFO:root:FL Epoch: 201 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1755
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324499
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181525
INFO:root:FL Epoch: 201 Norm Difference for worker 1755 is 1.738841
INFO:root:FL Epoch: 201 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :22
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263257
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 22 is 1.769408
INFO:root:FL Epoch: 201 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1640
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665636
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175625
INFO:root:FL Epoch: 201 Norm Difference for worker 1640 is 1.567149
INFO:root:FL Epoch: 201 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :544
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389406
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327270
INFO:root:FL Epoch: 201 Norm Difference for worker 544 is 1.785897
INFO:root:FL Epoch: 201 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :122
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 122 is 1.68967
INFO:root:FL Epoch: 201 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3713983899211706, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3495054566088849
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3458172730030458
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3450561943807486
INFO:root:#### Oracle Cals: 5, Objective Val: 1.3448908473105186
INFO:root:#### Oracle Cals: 6, Objective Val: 1.3448544158825786
INFO:root:#### Oracle Cals: 7, Objective Val: 1.3448463341359729
INFO:root:#### Oracle Cals: 8, Objective Val: 1.3448446222188661
INFO:root:#### Oracle Cals: 9, Objective Val: 1.3448441326758362
INFO:root:#### Oracle Cals: 10, Objective Val: 1.344844048618711
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.45094775802948894 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.07613694791992505                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1483
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419672
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356728
INFO:root:FL Epoch: 202 Norm Difference for worker 1483 is 2.098971
INFO:root:FL Epoch: 202 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :377
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545214
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205060
INFO:root:FL Epoch: 202 Norm Difference for worker 377 is 2.147417
INFO:root:FL Epoch: 202 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :300
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387406
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 300 is 1.923625
INFO:root:FL Epoch: 202 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :982
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304264
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309127
INFO:root:FL Epoch: 202 Norm Difference for worker 982 is 2.090338
INFO:root:FL Epoch: 202 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :93
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.326661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 93 is 1.920963
INFO:root:FL Epoch: 202 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1665
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265081
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173533
INFO:root:FL Epoch: 202 Norm Difference for worker 1665 is 2.089757
INFO:root:FL Epoch: 202 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1168
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586133
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336486
INFO:root:FL Epoch: 202 Norm Difference for worker 1168 is 1.860062
INFO:root:FL Epoch: 202 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :351
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779101
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456591
INFO:root:FL Epoch: 202 Norm Difference for worker 351 is 1.995718
INFO:root:FL Epoch: 202 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :124
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566442
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.268206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 124 is 2.092626
INFO:root:FL Epoch: 202 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1314
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326195
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133934
INFO:root:FL Epoch: 202 Norm Difference for worker 1314 is 2.032159
INFO:root:FL Epoch: 202 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.8980225050320443, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8978600572253839
INFO:root:#### Oracle Cals: 3, Objective Val: 1.897857991685759
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8978579524665695
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.4643438703873578 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.12190822201470534                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1790
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531454
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216840
INFO:root:FL Epoch: 203 Norm Difference for worker 1790 is 1.616816
INFO:root:FL Epoch: 203 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1275
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412875
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252485
INFO:root:FL Epoch: 203 Norm Difference for worker 1275 is 1.59587
INFO:root:FL Epoch: 203 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1712
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525990
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161117
INFO:root:FL Epoch: 203 Norm Difference for worker 1712 is 1.786672
INFO:root:FL Epoch: 203 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :594
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411427
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245366
INFO:root:FL Epoch: 203 Norm Difference for worker 594 is 1.877579
INFO:root:FL Epoch: 203 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :256
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 256 is 1.775798
INFO:root:FL Epoch: 203 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1075
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255678
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177256
INFO:root:FL Epoch: 203 Norm Difference for worker 1075 is 1.848996
INFO:root:FL Epoch: 203 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1770
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302722
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205102
INFO:root:FL Epoch: 203 Norm Difference for worker 1770 is 1.715676
INFO:root:FL Epoch: 203 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1543
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481326
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382516
INFO:root:FL Epoch: 203 Norm Difference for worker 1543 is 1.831401
INFO:root:FL Epoch: 203 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :483
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391850
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360217
INFO:root:FL Epoch: 203 Norm Difference for worker 483 is 1.790351
INFO:root:FL Epoch: 203 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :433
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687000
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218943
INFO:root:FL Epoch: 203 Norm Difference for worker 433 is 1.79743
INFO:root:FL Epoch: 203 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6596122198118486, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6594029667677477
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6594001210079095
INFO:root:#### Oracle Cals: 4, Objective Val: 1.659400082147743
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.47020867992849913 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.13050547987222672                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :643
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313553
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286738
INFO:root:FL Epoch: 204 Norm Difference for worker 643 is 1.893202
INFO:root:FL Epoch: 204 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :796
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753213
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204901
INFO:root:FL Epoch: 204 Norm Difference for worker 796 is 1.753074
INFO:root:FL Epoch: 204 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1743
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560047
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283485
INFO:root:FL Epoch: 204 Norm Difference for worker 1743 is 1.785273
INFO:root:FL Epoch: 204 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1572
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.948717
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289021
INFO:root:FL Epoch: 204 Norm Difference for worker 1572 is 1.810079
INFO:root:FL Epoch: 204 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :644
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854895
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279730
INFO:root:FL Epoch: 204 Norm Difference for worker 644 is 1.83768
INFO:root:FL Epoch: 204 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :893
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382080
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179712
INFO:root:FL Epoch: 204 Norm Difference for worker 893 is 1.75862
INFO:root:FL Epoch: 204 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :307
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 307 is 1.890868
INFO:root:FL Epoch: 204 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1460
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.188849
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224900
INFO:root:FL Epoch: 204 Norm Difference for worker 1460 is 1.630073
INFO:root:FL Epoch: 204 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1890
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630097
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249453
INFO:root:FL Epoch: 204 Norm Difference for worker 1890 is 1.754994
INFO:root:FL Epoch: 204 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :179
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 179 is 1.838973
INFO:root:FL Epoch: 204 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6911204983402568, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6909699780327698
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6909677984504687
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6909677692287746
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.46074950169114504 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.13210437260568142                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1646
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755843
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443211
INFO:root:FL Epoch: 205 Norm Difference for worker 1646 is 1.830151
INFO:root:FL Epoch: 205 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 1.922777
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :498
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.187325
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197173
INFO:root:FL Epoch: 205 Norm Difference for worker 498 is 1.807306
INFO:root:FL Epoch: 205 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :132
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 132 is 1.707623
INFO:root:FL Epoch: 205 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376763
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267722
INFO:root:FL Epoch: 205 Norm Difference for worker 1171 is 1.739855
INFO:root:FL Epoch: 205 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :587
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789694
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275348
INFO:root:FL Epoch: 205 Norm Difference for worker 587 is 1.899242
INFO:root:FL Epoch: 205 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1921
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488730
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262595
INFO:root:FL Epoch: 205 Norm Difference for worker 1921 is 1.80428
INFO:root:FL Epoch: 205 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1482
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228356
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306338
INFO:root:FL Epoch: 205 Norm Difference for worker 1482 is 1.753533
INFO:root:FL Epoch: 205 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :230
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 230 is 1.86596
INFO:root:FL Epoch: 205 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1399
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532294
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185580
INFO:root:FL Epoch: 205 Norm Difference for worker 1399 is 1.78626
INFO:root:FL Epoch: 205 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.706425186786929, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.706301408787449
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7062998926062334
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7062998545945114
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.47341327106251435 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.12597295828163624                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 206 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :118
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.872866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 118 is 1.823504
INFO:root:FL Epoch: 206 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1272
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619468
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215953
INFO:root:FL Epoch: 206 Norm Difference for worker 1272 is 1.967731
INFO:root:FL Epoch: 206 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1114
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502555
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244678
INFO:root:FL Epoch: 206 Norm Difference for worker 1114 is 1.862982
INFO:root:FL Epoch: 206 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :236
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 236 is 2.041327
INFO:root:FL Epoch: 206 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552164
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291977
INFO:root:FL Epoch: 206 Norm Difference for worker 1838 is 1.847277
INFO:root:FL Epoch: 206 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1835
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713258
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175976
INFO:root:FL Epoch: 206 Norm Difference for worker 1835 is 1.732996
INFO:root:FL Epoch: 206 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :460
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367761
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344016
INFO:root:FL Epoch: 206 Norm Difference for worker 460 is 1.869039
INFO:root:FL Epoch: 206 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1482
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400210
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234603
INFO:root:FL Epoch: 206 Norm Difference for worker 1482 is 1.58809
INFO:root:FL Epoch: 206 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :289
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.228971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 289 is 1.686336
INFO:root:FL Epoch: 206 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :329
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 329 is 1.879679
INFO:root:FL Epoch: 206 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7300208086868025, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7296728905561682
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7296675730033122
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7296674652602726
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.4742959930616267 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.12206321954727173                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1442
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612833
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314520
INFO:root:FL Epoch: 207 Norm Difference for worker 1442 is 1.70272
INFO:root:FL Epoch: 207 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1664
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748064
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229275
INFO:root:FL Epoch: 207 Norm Difference for worker 1664 is 1.585585
INFO:root:FL Epoch: 207 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :483
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.845473
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395058
INFO:root:FL Epoch: 207 Norm Difference for worker 483 is 1.825675
INFO:root:FL Epoch: 207 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :754
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247632
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416737
INFO:root:FL Epoch: 207 Norm Difference for worker 754 is 1.796702
INFO:root:FL Epoch: 207 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :166
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 166 is 1.694331
INFO:root:FL Epoch: 207 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1570
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525654
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237534
INFO:root:FL Epoch: 207 Norm Difference for worker 1570 is 1.784053
INFO:root:FL Epoch: 207 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :541
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799540
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314951
INFO:root:FL Epoch: 207 Norm Difference for worker 541 is 1.826358
INFO:root:FL Epoch: 207 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1604
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561961
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240358
INFO:root:FL Epoch: 207 Norm Difference for worker 1604 is 1.810106
INFO:root:FL Epoch: 207 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :800
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517372
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280709
INFO:root:FL Epoch: 207 Norm Difference for worker 800 is 1.786152
INFO:root:FL Epoch: 207 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :277
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 277 is 1.697281
INFO:root:FL Epoch: 207 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.655828669522633, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.65569895801776
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6556972833047452
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6556972691493632
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.4541047443361843 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.11196767600874107                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1406
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293779
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238030
INFO:root:FL Epoch: 208 Norm Difference for worker 1406 is 1.914011
INFO:root:FL Epoch: 208 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :774
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447144
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313213
INFO:root:FL Epoch: 208 Norm Difference for worker 774 is 1.746195
INFO:root:FL Epoch: 208 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :854
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484206
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158945
INFO:root:FL Epoch: 208 Norm Difference for worker 854 is 1.645339
INFO:root:FL Epoch: 208 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1449
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770589
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316212
INFO:root:FL Epoch: 208 Norm Difference for worker 1449 is 1.902044
INFO:root:FL Epoch: 208 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :741
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385967
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393989
INFO:root:FL Epoch: 208 Norm Difference for worker 741 is 1.788935
INFO:root:FL Epoch: 208 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :740
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539882
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216102
INFO:root:FL Epoch: 208 Norm Difference for worker 740 is 1.744606
INFO:root:FL Epoch: 208 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1869
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680126
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130239
INFO:root:FL Epoch: 208 Norm Difference for worker 1869 is 1.651115
INFO:root:FL Epoch: 208 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1080
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567407
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404560
INFO:root:FL Epoch: 208 Norm Difference for worker 1080 is 1.933882
INFO:root:FL Epoch: 208 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1637
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387249
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489823
INFO:root:FL Epoch: 208 Norm Difference for worker 1637 is 1.963473
INFO:root:FL Epoch: 208 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1546
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237631
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420421
INFO:root:FL Epoch: 208 Norm Difference for worker 1546 is 1.742043
INFO:root:FL Epoch: 208 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7025191183100297, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7022189807716037
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7022150098159372
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7022149320817408
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.4651361668811125 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.1237247164050738                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1904
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385555
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224068
INFO:root:FL Epoch: 209 Norm Difference for worker 1904 is 1.872229
INFO:root:FL Epoch: 209 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1753
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626469
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302675
INFO:root:FL Epoch: 209 Norm Difference for worker 1753 is 1.743528
INFO:root:FL Epoch: 209 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1821
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650694
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353938
INFO:root:FL Epoch: 209 Norm Difference for worker 1821 is 1.729347
INFO:root:FL Epoch: 209 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1207
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608202
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307767
INFO:root:FL Epoch: 209 Norm Difference for worker 1207 is 1.725179
INFO:root:FL Epoch: 209 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :9
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260639
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 9 is 1.773826
INFO:root:FL Epoch: 209 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1378
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464721
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259124
INFO:root:FL Epoch: 209 Norm Difference for worker 1378 is 1.891604
INFO:root:FL Epoch: 209 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :211
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377567
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 211 is 1.777508
INFO:root:FL Epoch: 209 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :883
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361801
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204854
INFO:root:FL Epoch: 209 Norm Difference for worker 883 is 1.754653
INFO:root:FL Epoch: 209 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :876
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382080
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378365
INFO:root:FL Epoch: 209 Norm Difference for worker 876 is 1.814607
INFO:root:FL Epoch: 209 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :812
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881994
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308578
INFO:root:FL Epoch: 209 Norm Difference for worker 812 is 1.729016
INFO:root:FL Epoch: 209 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6821669195672926, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6820505635606728
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6820491723309374
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6820491827005661
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.4713105243795058 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.13367553241550922                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :321
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 321 is 1.799388
INFO:root:FL Epoch: 210 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :758
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694712
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257898
INFO:root:FL Epoch: 210 Norm Difference for worker 758 is 1.634734
INFO:root:FL Epoch: 210 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :550
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487636
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246520
INFO:root:FL Epoch: 210 Norm Difference for worker 550 is 1.69224
INFO:root:FL Epoch: 210 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1387
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496056
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166355
INFO:root:FL Epoch: 210 Norm Difference for worker 1387 is 1.620543
INFO:root:FL Epoch: 210 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1806
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470694
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319541
INFO:root:FL Epoch: 210 Norm Difference for worker 1806 is 1.585668
INFO:root:FL Epoch: 210 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581919
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266174
INFO:root:FL Epoch: 210 Norm Difference for worker 760 is 1.657562
INFO:root:FL Epoch: 210 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :316
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.316186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342652
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 316 is 1.637751
INFO:root:FL Epoch: 210 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1694
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.861920
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325199
INFO:root:FL Epoch: 210 Norm Difference for worker 1694 is 1.707232
INFO:root:FL Epoch: 210 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :937
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413921
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306686
INFO:root:FL Epoch: 210 Norm Difference for worker 937 is 1.629694
INFO:root:FL Epoch: 210 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1178
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535505
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355968
INFO:root:FL Epoch: 210 Norm Difference for worker 1178 is 1.645475
INFO:root:FL Epoch: 210 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.561121840069907, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5610069971241831
INFO:root:#### Oracle Cals: 3, Objective Val: 1.561005808643424
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5610057859203093
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.4550403461736791 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.1448542463282744                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.110416
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.053981
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.0636719233977298 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.03075309805572033 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.7076
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.166780
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.072338
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.037954319113244615 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.029423259757459165 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.691348
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.142488
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.071165
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.049215753097087145 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.03152737338095903 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.69273
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1428
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378475
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171913
INFO:root:FL Epoch: 211 Norm Difference for worker 1428 is 1.657068
INFO:root:FL Epoch: 211 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :391
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579764
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419446
INFO:root:FL Epoch: 211 Norm Difference for worker 391 is 1.817936
INFO:root:FL Epoch: 211 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1560
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504707
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186066
INFO:root:FL Epoch: 211 Norm Difference for worker 1560 is 1.494779
INFO:root:FL Epoch: 211 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1489
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439120
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400716
INFO:root:FL Epoch: 211 Norm Difference for worker 1489 is 1.829618
INFO:root:FL Epoch: 211 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :106
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 106 is 1.631535
INFO:root:FL Epoch: 211 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :729
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541888
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311840
INFO:root:FL Epoch: 211 Norm Difference for worker 729 is 1.696429
INFO:root:FL Epoch: 211 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1080
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835250
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273012
INFO:root:FL Epoch: 211 Norm Difference for worker 1080 is 1.641593
INFO:root:FL Epoch: 211 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3068149741037098, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2845436434364073
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2807186242034407
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2799122583051317
INFO:root:#### Oracle Cals: 5, Objective Val: 1.2797340535429709
INFO:root:#### Oracle Cals: 6, Objective Val: 1.2796942201164705
INFO:root:#### Oracle Cals: 7, Objective Val: 1.2796853368984644
INFO:root:#### Oracle Cals: 8, Objective Val: 1.279683292814975
INFO:root:#### Oracle Cals: 9, Objective Val: 1.2796828603328256
INFO:root:#### Oracle Cals: 10, Objective Val: 1.2796827431250077
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.46752963872516856 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.07051928869138162                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :850
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593859
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159796
INFO:root:FL Epoch: 212 Norm Difference for worker 850 is 1.841216
INFO:root:FL Epoch: 212 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1190
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500445
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296597
INFO:root:FL Epoch: 212 Norm Difference for worker 1190 is 1.842582
INFO:root:FL Epoch: 212 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :991
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469246
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193874
INFO:root:FL Epoch: 212 Norm Difference for worker 991 is 1.989327
INFO:root:FL Epoch: 212 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :137
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475245
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 137 is 1.974181
INFO:root:FL Epoch: 212 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1175
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379125
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219969
INFO:root:FL Epoch: 212 Norm Difference for worker 1175 is 1.865012
INFO:root:FL Epoch: 212 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1765
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680000
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357242
INFO:root:FL Epoch: 212 Norm Difference for worker 1765 is 1.806283
INFO:root:FL Epoch: 212 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1107
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431019
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224386
INFO:root:FL Epoch: 212 Norm Difference for worker 1107 is 1.848541
INFO:root:FL Epoch: 212 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :415
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560162
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313466
INFO:root:FL Epoch: 212 Norm Difference for worker 415 is 1.911245
INFO:root:FL Epoch: 212 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1168
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552862
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318701
INFO:root:FL Epoch: 212 Norm Difference for worker 1168 is 1.890843
INFO:root:FL Epoch: 212 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :123
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428121
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352216
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 123 is 1.998495
INFO:root:FL Epoch: 212 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7804313513364698, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7803276357637519
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7803262235600994
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7803262173155683
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.4660610644256367 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.08481730458637078                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1125
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454706
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259967
INFO:root:FL Epoch: 213 Norm Difference for worker 1125 is 1.907429
INFO:root:FL Epoch: 213 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :873
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631891
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275852
INFO:root:FL Epoch: 213 Norm Difference for worker 873 is 1.902016
INFO:root:FL Epoch: 213 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1501
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255182
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282743
INFO:root:FL Epoch: 213 Norm Difference for worker 1501 is 2.00262
INFO:root:FL Epoch: 213 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1370
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622152
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215762
INFO:root:FL Epoch: 213 Norm Difference for worker 1370 is 1.783773
INFO:root:FL Epoch: 213 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1513
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633217
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312211
INFO:root:FL Epoch: 213 Norm Difference for worker 1513 is 1.861178
INFO:root:FL Epoch: 213 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :744
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974825
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136846
INFO:root:FL Epoch: 213 Norm Difference for worker 744 is 1.77917
INFO:root:FL Epoch: 213 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :533
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603779
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438873
INFO:root:FL Epoch: 213 Norm Difference for worker 533 is 2.145877
INFO:root:FL Epoch: 213 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1237
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495377
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291914
INFO:root:FL Epoch: 213 Norm Difference for worker 1237 is 1.911324
INFO:root:FL Epoch: 213 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1929
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355135
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156223
INFO:root:FL Epoch: 213 Norm Difference for worker 1929 is 1.643114
INFO:root:FL Epoch: 213 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1117
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303318
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383192
INFO:root:FL Epoch: 213 Norm Difference for worker 1117 is 1.689209
INFO:root:FL Epoch: 213 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.761712974412788, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7612228251277
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7612158925773864
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7612157286234444
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.4755303211071912 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.097611374532183                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1192
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709439
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162562
INFO:root:FL Epoch: 214 Norm Difference for worker 1192 is 1.832184
INFO:root:FL Epoch: 214 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1056
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582995
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270817
INFO:root:FL Epoch: 214 Norm Difference for worker 1056 is 1.743574
INFO:root:FL Epoch: 214 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :257
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324447
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290309
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 257 is 1.784939
INFO:root:FL Epoch: 214 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :852
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593711
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244850
INFO:root:FL Epoch: 214 Norm Difference for worker 852 is 1.773324
INFO:root:FL Epoch: 214 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1024
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421154
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419920
INFO:root:FL Epoch: 214 Norm Difference for worker 1024 is 1.7648
INFO:root:FL Epoch: 214 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1453
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497204
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155536
INFO:root:FL Epoch: 214 Norm Difference for worker 1453 is 1.718873
INFO:root:FL Epoch: 214 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1392
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634220
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399774
INFO:root:FL Epoch: 214 Norm Difference for worker 1392 is 1.705174
INFO:root:FL Epoch: 214 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1700
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355486
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260975
INFO:root:FL Epoch: 214 Norm Difference for worker 1700 is 1.730533
INFO:root:FL Epoch: 214 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :203
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504415
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 203 is 1.898094
INFO:root:FL Epoch: 214 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :661
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791944
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228080
INFO:root:FL Epoch: 214 Norm Difference for worker 661 is 1.879423
INFO:root:FL Epoch: 214 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.685253994291887, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6851506436193895
INFO:root:#### Oracle Cals: 3, Objective Val: 1.685149361617776
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6851493474790007
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.4583248829140383 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.10357911388079326                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :408
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406450
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142817
INFO:root:FL Epoch: 215 Norm Difference for worker 408 is 1.647471
INFO:root:FL Epoch: 215 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1362
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532961
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203125
INFO:root:FL Epoch: 215 Norm Difference for worker 1362 is 1.762006
INFO:root:FL Epoch: 215 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :158
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 158 is 1.783161
INFO:root:FL Epoch: 215 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :368
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665829
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273621
INFO:root:FL Epoch: 215 Norm Difference for worker 368 is 1.79712
INFO:root:FL Epoch: 215 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :468
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703547
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277921
INFO:root:FL Epoch: 215 Norm Difference for worker 468 is 1.730394
INFO:root:FL Epoch: 215 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1463
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645432
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340167
INFO:root:FL Epoch: 215 Norm Difference for worker 1463 is 1.876173
INFO:root:FL Epoch: 215 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :341
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353612
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304997
INFO:root:FL Epoch: 215 Norm Difference for worker 341 is 1.905459
INFO:root:FL Epoch: 215 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1793
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717990
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413790
INFO:root:FL Epoch: 215 Norm Difference for worker 1793 is 1.847181
INFO:root:FL Epoch: 215 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :609
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717360
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202138
INFO:root:FL Epoch: 215 Norm Difference for worker 609 is 1.799985
INFO:root:FL Epoch: 215 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :594
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412391
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214714
INFO:root:FL Epoch: 215 Norm Difference for worker 594 is 1.822824
INFO:root:FL Epoch: 215 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6916010741900105, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6914655015513813
INFO:root:#### Oracle Cals: 3, Objective Val: 1.691463635634131
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6914636232879579
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.4771266825058881 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.10676108362774055                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1256
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316478
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273965
INFO:root:FL Epoch: 216 Norm Difference for worker 1256 is 1.696607
INFO:root:FL Epoch: 216 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1698
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325116
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279720
INFO:root:FL Epoch: 216 Norm Difference for worker 1698 is 1.74931
INFO:root:FL Epoch: 216 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :318
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.893233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 318 is 1.645133
INFO:root:FL Epoch: 216 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1075
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289977
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224840
INFO:root:FL Epoch: 216 Norm Difference for worker 1075 is 1.681265
INFO:root:FL Epoch: 216 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :427
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549195
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391696
INFO:root:FL Epoch: 216 Norm Difference for worker 427 is 1.683592
INFO:root:FL Epoch: 216 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :895
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314237
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163117
INFO:root:FL Epoch: 216 Norm Difference for worker 895 is 1.713578
INFO:root:FL Epoch: 216 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1686
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449407
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185868
INFO:root:FL Epoch: 216 Norm Difference for worker 1686 is 1.64803
INFO:root:FL Epoch: 216 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :939
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766823
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360282
INFO:root:FL Epoch: 216 Norm Difference for worker 939 is 1.790674
INFO:root:FL Epoch: 216 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1008
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534956
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536167
INFO:root:FL Epoch: 216 Norm Difference for worker 1008 is 1.916524
INFO:root:FL Epoch: 216 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1785
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471542
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327683
INFO:root:FL Epoch: 216 Norm Difference for worker 1785 is 1.785011
INFO:root:FL Epoch: 216 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6373151689102357, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.637114582836925
INFO:root:#### Oracle Cals: 3, Objective Val: 1.637112091332248
INFO:root:#### Oracle Cals: 4, Objective Val: 1.637112030226389
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.4542578090639675 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.1279626345882813                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :795
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410671
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252487
INFO:root:FL Epoch: 217 Norm Difference for worker 795 is 1.641779
INFO:root:FL Epoch: 217 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1488
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413210
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302465
INFO:root:FL Epoch: 217 Norm Difference for worker 1488 is 1.744304
INFO:root:FL Epoch: 217 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :830
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675288
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432023
INFO:root:FL Epoch: 217 Norm Difference for worker 830 is 1.602942
INFO:root:FL Epoch: 217 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1412
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618558
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184338
INFO:root:FL Epoch: 217 Norm Difference for worker 1412 is 1.786152
INFO:root:FL Epoch: 217 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1025
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302395
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174482
INFO:root:FL Epoch: 217 Norm Difference for worker 1025 is 1.718794
INFO:root:FL Epoch: 217 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365020
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190750
INFO:root:FL Epoch: 217 Norm Difference for worker 1652 is 1.774008
INFO:root:FL Epoch: 217 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :631
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525173
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184583
INFO:root:FL Epoch: 217 Norm Difference for worker 631 is 1.676193
INFO:root:FL Epoch: 217 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1898
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373664
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364385
INFO:root:FL Epoch: 217 Norm Difference for worker 1898 is 1.705529
INFO:root:FL Epoch: 217 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :872
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279700
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336176
INFO:root:FL Epoch: 217 Norm Difference for worker 872 is 1.654936
INFO:root:FL Epoch: 217 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :698
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387677
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381420
INFO:root:FL Epoch: 217 Norm Difference for worker 698 is 1.850044
INFO:root:FL Epoch: 217 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6197809905900602, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6196403154592962
INFO:root:#### Oracle Cals: 3, Objective Val: 1.619638511581539
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6196384944107878
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.4741531417650335 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.13577735672394434                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1823
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538491
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181033
INFO:root:FL Epoch: 218 Norm Difference for worker 1823 is 1.696809
INFO:root:FL Epoch: 218 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :16
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.812382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 16 is 1.734336
INFO:root:FL Epoch: 218 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1683
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426771
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362608
INFO:root:FL Epoch: 218 Norm Difference for worker 1683 is 1.76122
INFO:root:FL Epoch: 218 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1802
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419125
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354307
INFO:root:FL Epoch: 218 Norm Difference for worker 1802 is 1.626119
INFO:root:FL Epoch: 218 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :663
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663136
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234418
INFO:root:FL Epoch: 218 Norm Difference for worker 663 is 1.641155
INFO:root:FL Epoch: 218 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1406
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408222
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257270
INFO:root:FL Epoch: 218 Norm Difference for worker 1406 is 1.68775
INFO:root:FL Epoch: 218 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1358
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269964
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174366
INFO:root:FL Epoch: 218 Norm Difference for worker 1358 is 1.644763
INFO:root:FL Epoch: 218 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :240
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362409
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 240 is 1.815143
INFO:root:FL Epoch: 218 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :101
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300143
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 101 is 1.697275
INFO:root:FL Epoch: 218 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1363
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721088
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366407
INFO:root:FL Epoch: 218 Norm Difference for worker 1363 is 1.889477
INFO:root:FL Epoch: 218 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6274261703662962, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6272673670657989
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6272653121497525
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6272652871862405
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.451916391358656 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.14043788673977056                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 219 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :185
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464040
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220503
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 185 is 1.576189
INFO:root:FL Epoch: 219 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1693
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572529
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368301
INFO:root:FL Epoch: 219 Norm Difference for worker 1693 is 1.628206
INFO:root:FL Epoch: 219 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :737
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490802
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281919
INFO:root:FL Epoch: 219 Norm Difference for worker 737 is 1.698254
INFO:root:FL Epoch: 219 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1553
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358724
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201261
INFO:root:FL Epoch: 219 Norm Difference for worker 1553 is 1.721231
INFO:root:FL Epoch: 219 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :560
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452519
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328196
INFO:root:FL Epoch: 219 Norm Difference for worker 560 is 1.639791
INFO:root:FL Epoch: 219 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1190
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294881
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139946
INFO:root:FL Epoch: 219 Norm Difference for worker 1190 is 1.523776
INFO:root:FL Epoch: 219 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :926
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410670
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218364
INFO:root:FL Epoch: 219 Norm Difference for worker 926 is 1.43969
INFO:root:FL Epoch: 219 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :912
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501762
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504757
INFO:root:FL Epoch: 219 Norm Difference for worker 912 is 1.685109
INFO:root:FL Epoch: 219 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471029
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351290
INFO:root:FL Epoch: 219 Norm Difference for worker 1477 is 1.622478
INFO:root:FL Epoch: 219 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :173
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 173 is 1.666927
INFO:root:FL Epoch: 219 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5280775628899914, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5278691255357268
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5278661591586022
INFO:root:#### Oracle Cals: 4, Objective Val: 1.527866149527915
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.45867519694216113 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.11831535771489143                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1326
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636215
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625660
INFO:root:FL Epoch: 220 Norm Difference for worker 1326 is 1.81477
INFO:root:FL Epoch: 220 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :919
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489298
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323720
INFO:root:FL Epoch: 220 Norm Difference for worker 919 is 1.772955
INFO:root:FL Epoch: 220 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1829
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 1.007707
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314296
INFO:root:FL Epoch: 220 Norm Difference for worker 1829 is 1.742142
INFO:root:FL Epoch: 220 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1536
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894402
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205784
INFO:root:FL Epoch: 220 Norm Difference for worker 1536 is 1.692377
INFO:root:FL Epoch: 220 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1533
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615908
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265466
INFO:root:FL Epoch: 220 Norm Difference for worker 1533 is 1.782849
INFO:root:FL Epoch: 220 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1562
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375917
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239366
INFO:root:FL Epoch: 220 Norm Difference for worker 1562 is 1.69475
INFO:root:FL Epoch: 220 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :524
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506621
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388638
INFO:root:FL Epoch: 220 Norm Difference for worker 524 is 1.623492
INFO:root:FL Epoch: 220 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :652
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559577
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256251
INFO:root:FL Epoch: 220 Norm Difference for worker 652 is 1.659658
INFO:root:FL Epoch: 220 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1778
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562539
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301251
INFO:root:FL Epoch: 220 Norm Difference for worker 1778 is 1.754907
INFO:root:FL Epoch: 220 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :59
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 59 is 1.729637
INFO:root:FL Epoch: 220 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6287868820099325, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6286881519115055
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6286869921011957
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6286869258470282
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.4593230003819746 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.11050150295098622                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.098764
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.074657
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.028834787818292778 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.026490187272429466 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.693385
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.112596
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.066482
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.033769093143443264 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.028553594090044498 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.643425
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.092398
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.050893
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.03511562291532755 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.02739101480692625 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.635796
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :316
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 316 is 1.642254
INFO:root:FL Epoch: 221 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1143
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511312
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283247
INFO:root:FL Epoch: 221 Norm Difference for worker 1143 is 1.791743
INFO:root:FL Epoch: 221 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :39
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 39 is 1.758319
INFO:root:FL Epoch: 221 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :451
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404912
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235957
INFO:root:FL Epoch: 221 Norm Difference for worker 451 is 1.730884
INFO:root:FL Epoch: 221 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1522
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577763
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256500
INFO:root:FL Epoch: 221 Norm Difference for worker 1522 is 1.620299
INFO:root:FL Epoch: 221 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1199
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530844
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476988
INFO:root:FL Epoch: 221 Norm Difference for worker 1199 is 1.694986
INFO:root:FL Epoch: 221 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1403
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578311
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204684
INFO:root:FL Epoch: 221 Norm Difference for worker 1403 is 1.804114
INFO:root:FL Epoch: 221 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.328706306352566, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3070196328428116
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3034035835095372
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3026787234399313
INFO:root:#### Oracle Cals: 5, Objective Val: 1.3025272528187752
INFO:root:#### Oracle Cals: 6, Objective Val: 1.3024951869131252
INFO:root:#### Oracle Cals: 7, Objective Val: 1.3024884093510614
INFO:root:#### Oracle Cals: 8, Objective Val: 1.3024870690565296
INFO:root:#### Oracle Cals: 9, Objective Val: 1.3024866629508185
INFO:root:#### Oracle Cals: 10, Objective Val: 1.302486615064427
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.4586076648796306 and Test Accuracy:80.0 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.05941694540282091                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1432
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326747
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213334
INFO:root:FL Epoch: 222 Norm Difference for worker 1432 is 1.830721
INFO:root:FL Epoch: 222 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1879
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541856
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246904
INFO:root:FL Epoch: 222 Norm Difference for worker 1879 is 1.926085
INFO:root:FL Epoch: 222 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1374
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588023
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260409
INFO:root:FL Epoch: 222 Norm Difference for worker 1374 is 1.813738
INFO:root:FL Epoch: 222 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :138
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 138 is 2.105076
INFO:root:FL Epoch: 222 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1818
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626984
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265997
INFO:root:FL Epoch: 222 Norm Difference for worker 1818 is 2.042773
INFO:root:FL Epoch: 222 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1897
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382311
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253564
INFO:root:FL Epoch: 222 Norm Difference for worker 1897 is 1.943401
INFO:root:FL Epoch: 222 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1713
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542873
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268152
INFO:root:FL Epoch: 222 Norm Difference for worker 1713 is 1.911027
INFO:root:FL Epoch: 222 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1190
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272553
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162570
INFO:root:FL Epoch: 222 Norm Difference for worker 1190 is 1.596232
INFO:root:FL Epoch: 222 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678922
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386721
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 2.147522
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1704
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643088
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521205
INFO:root:FL Epoch: 222 Norm Difference for worker 1704 is 2.04087
INFO:root:FL Epoch: 222 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.817560738722738, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.8170883357649394
INFO:root:#### Oracle Cals: 3, Objective Val: 1.817081423690523
INFO:root:#### Oracle Cals: 4, Objective Val: 1.8170813311359872
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.4523871032630696 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.09777951054275036                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 270 is 1.542832
INFO:root:FL Epoch: 223 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :754
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639593
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254918
INFO:root:FL Epoch: 223 Norm Difference for worker 754 is 1.785164
INFO:root:FL Epoch: 223 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :153
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 153 is 1.631654
INFO:root:FL Epoch: 223 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :729
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659721
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317509
INFO:root:FL Epoch: 223 Norm Difference for worker 729 is 1.716098
INFO:root:FL Epoch: 223 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464734
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243133
INFO:root:FL Epoch: 223 Norm Difference for worker 1270 is 1.604989
INFO:root:FL Epoch: 223 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :198
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351461
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 198 is 1.848826
INFO:root:FL Epoch: 223 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :422
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663281
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229026
INFO:root:FL Epoch: 223 Norm Difference for worker 422 is 1.75111
INFO:root:FL Epoch: 223 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :357
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439995
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198157
INFO:root:FL Epoch: 223 Norm Difference for worker 357 is 1.651438
INFO:root:FL Epoch: 223 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1197
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565671
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293134
INFO:root:FL Epoch: 223 Norm Difference for worker 1197 is 1.830518
INFO:root:FL Epoch: 223 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1215
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309931
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170751
INFO:root:FL Epoch: 223 Norm Difference for worker 1215 is 1.772281
INFO:root:FL Epoch: 223 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6183220223731523, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.61811968890675
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6181170486237724
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6181170230474882
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.44612036382450776 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.08860099626084168                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :1695
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414014
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348468
INFO:root:FL Epoch: 224 Norm Difference for worker 1695 is 1.897241
INFO:root:FL Epoch: 224 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651130
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517108
INFO:root:FL Epoch: 224 Norm Difference for worker 1865 is 1.948118
INFO:root:FL Epoch: 224 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1713
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354590
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195343
INFO:root:FL Epoch: 224 Norm Difference for worker 1713 is 1.587554
INFO:root:FL Epoch: 224 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :297
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.286357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.187060
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 297 is 1.620131
INFO:root:FL Epoch: 224 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1928
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257749
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280124
INFO:root:FL Epoch: 224 Norm Difference for worker 1928 is 1.729299
INFO:root:FL Epoch: 224 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1649
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720979
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260072
INFO:root:FL Epoch: 224 Norm Difference for worker 1649 is 1.858993
INFO:root:FL Epoch: 224 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :866
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647686
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382939
INFO:root:FL Epoch: 224 Norm Difference for worker 866 is 1.861392
INFO:root:FL Epoch: 224 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1522
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390994
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179024
INFO:root:FL Epoch: 224 Norm Difference for worker 1522 is 1.607257
INFO:root:FL Epoch: 224 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :950
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478750
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262645
INFO:root:FL Epoch: 224 Norm Difference for worker 950 is 1.624057
INFO:root:FL Epoch: 224 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1672
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358293
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255625
INFO:root:FL Epoch: 224 Norm Difference for worker 1672 is 1.693062
INFO:root:FL Epoch: 224 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6513135045475154, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6508959686006615
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6508910061883126
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6508909605257225
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.4344478477449978 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.0897002803782622                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :772
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739087
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397135
INFO:root:FL Epoch: 225 Norm Difference for worker 772 is 1.783075
INFO:root:FL Epoch: 225 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :146
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 146 is 1.862865
INFO:root:FL Epoch: 225 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :483
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321201
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183358
INFO:root:FL Epoch: 225 Norm Difference for worker 483 is 1.700123
INFO:root:FL Epoch: 225 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :630
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.923794
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375524
INFO:root:FL Epoch: 225 Norm Difference for worker 630 is 1.76665
INFO:root:FL Epoch: 225 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1459
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530854
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248039
INFO:root:FL Epoch: 225 Norm Difference for worker 1459 is 1.830948
INFO:root:FL Epoch: 225 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1607
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556879
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182745
INFO:root:FL Epoch: 225 Norm Difference for worker 1607 is 1.637848
INFO:root:FL Epoch: 225 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1636
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841666
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225482
INFO:root:FL Epoch: 225 Norm Difference for worker 1636 is 1.68133
INFO:root:FL Epoch: 225 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1906
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497143
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250225
INFO:root:FL Epoch: 225 Norm Difference for worker 1906 is 1.751387
INFO:root:FL Epoch: 225 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1540
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702729
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484980
INFO:root:FL Epoch: 225 Norm Difference for worker 1540 is 1.826505
INFO:root:FL Epoch: 225 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :320
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685781
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241731
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 320 is 1.669893
INFO:root:FL Epoch: 225 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6555851660963872, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.655446273839496
INFO:root:#### Oracle Cals: 3, Objective Val: 1.655444658515691
INFO:root:#### Oracle Cals: 4, Objective Val: 1.655444673867718
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.4467691077905543 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.09538757304350536                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :607
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586114
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130813
INFO:root:FL Epoch: 226 Norm Difference for worker 607 is 1.818565
INFO:root:FL Epoch: 226 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1256
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472415
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220159
INFO:root:FL Epoch: 226 Norm Difference for worker 1256 is 1.710659
INFO:root:FL Epoch: 226 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :305
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.366717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200944
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 305 is 1.620555
INFO:root:FL Epoch: 226 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1249
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745175
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162049
INFO:root:FL Epoch: 226 Norm Difference for worker 1249 is 1.728429
INFO:root:FL Epoch: 226 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1338
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684179
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333292
INFO:root:FL Epoch: 226 Norm Difference for worker 1338 is 1.696085
INFO:root:FL Epoch: 226 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :942
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540206
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219724
INFO:root:FL Epoch: 226 Norm Difference for worker 942 is 1.728465
INFO:root:FL Epoch: 226 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1340
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725021
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271112
INFO:root:FL Epoch: 226 Norm Difference for worker 1340 is 1.789862
INFO:root:FL Epoch: 226 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :822
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553168
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338770
INFO:root:FL Epoch: 226 Norm Difference for worker 822 is 1.76003
INFO:root:FL Epoch: 226 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :41
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.240903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 41 is 1.677807
INFO:root:FL Epoch: 226 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1770
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414264
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278572
INFO:root:FL Epoch: 226 Norm Difference for worker 1770 is 1.62463
INFO:root:FL Epoch: 226 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.614537053658001, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6144033639402107
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6144016920855475
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6144016701932935
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.4516787003068363 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.09377642162144184                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 227 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :77
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 77 is 1.547947
INFO:root:FL Epoch: 227 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :907
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425010
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246909
INFO:root:FL Epoch: 227 Norm Difference for worker 907 is 1.828261
INFO:root:FL Epoch: 227 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :431
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583314
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234849
INFO:root:FL Epoch: 227 Norm Difference for worker 431 is 1.727981
INFO:root:FL Epoch: 227 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1546
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583703
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188874
INFO:root:FL Epoch: 227 Norm Difference for worker 1546 is 1.665781
INFO:root:FL Epoch: 227 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1892
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435812
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170236
INFO:root:FL Epoch: 227 Norm Difference for worker 1892 is 1.780234
INFO:root:FL Epoch: 227 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :70
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230726
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 70 is 1.682273
INFO:root:FL Epoch: 227 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1513
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726279
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337734
INFO:root:FL Epoch: 227 Norm Difference for worker 1513 is 1.67686
INFO:root:FL Epoch: 227 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :959
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.218701
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183902
INFO:root:FL Epoch: 227 Norm Difference for worker 959 is 1.657189
INFO:root:FL Epoch: 227 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :274
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 274 is 1.760981
INFO:root:FL Epoch: 227 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :157
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.185711
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 157 is 1.782976
INFO:root:FL Epoch: 227 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6087452241500784, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6086174329722454
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6086156294885219
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6086156249042256
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.45354359290179086 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.0889826628069083                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :683
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499272
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373687
INFO:root:FL Epoch: 228 Norm Difference for worker 683 is 1.851168
INFO:root:FL Epoch: 228 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1670
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481866
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217746
INFO:root:FL Epoch: 228 Norm Difference for worker 1670 is 1.753788
INFO:root:FL Epoch: 228 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1846
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830956
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151850
INFO:root:FL Epoch: 228 Norm Difference for worker 1846 is 1.744786
INFO:root:FL Epoch: 228 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :949
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544327
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214385
INFO:root:FL Epoch: 228 Norm Difference for worker 949 is 1.794368
INFO:root:FL Epoch: 228 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1749
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589990
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217886
INFO:root:FL Epoch: 228 Norm Difference for worker 1749 is 1.727724
INFO:root:FL Epoch: 228 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1722
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376971
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195155
INFO:root:FL Epoch: 228 Norm Difference for worker 1722 is 1.696284
INFO:root:FL Epoch: 228 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :993
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575776
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167330
INFO:root:FL Epoch: 228 Norm Difference for worker 993 is 1.667039
INFO:root:FL Epoch: 228 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1085
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666014
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326236
INFO:root:FL Epoch: 228 Norm Difference for worker 1085 is 1.664642
INFO:root:FL Epoch: 228 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :948
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436674
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211647
INFO:root:FL Epoch: 228 Norm Difference for worker 948 is 1.783473
INFO:root:FL Epoch: 228 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1414
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318794
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364473
INFO:root:FL Epoch: 228 Norm Difference for worker 1414 is 1.732793
INFO:root:FL Epoch: 228 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6419567057500135, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6418723703886737
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6418712781067004
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6418712541262908
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.4680887986631954 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.0946885384619236                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :958
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543931
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303593
INFO:root:FL Epoch: 229 Norm Difference for worker 958 is 1.858635
INFO:root:FL Epoch: 229 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :924
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406072
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253923
INFO:root:FL Epoch: 229 Norm Difference for worker 924 is 1.701514
INFO:root:FL Epoch: 229 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :923
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700187
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465706
INFO:root:FL Epoch: 229 Norm Difference for worker 923 is 1.86201
INFO:root:FL Epoch: 229 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :170
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.171580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 170 is 1.697048
INFO:root:FL Epoch: 229 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1886
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480456
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304807
INFO:root:FL Epoch: 229 Norm Difference for worker 1886 is 1.776112
INFO:root:FL Epoch: 229 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :71
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 71 is 1.635867
INFO:root:FL Epoch: 229 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :912
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597658
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259449
INFO:root:FL Epoch: 229 Norm Difference for worker 912 is 1.665263
INFO:root:FL Epoch: 229 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1134
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292064
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198216
INFO:root:FL Epoch: 229 Norm Difference for worker 1134 is 1.786049
INFO:root:FL Epoch: 229 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1808
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608869
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420465
INFO:root:FL Epoch: 229 Norm Difference for worker 1808 is 1.783064
INFO:root:FL Epoch: 229 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1870
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345887
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239122
INFO:root:FL Epoch: 229 Norm Difference for worker 1870 is 1.825114
INFO:root:FL Epoch: 229 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.65696801680313, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.656802506176566
INFO:root:#### Oracle Cals: 3, Objective Val: 1.656800332649217
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6568002419472885
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.4844430790228002 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.11224435828626156                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :1469
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235570
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389027
INFO:root:FL Epoch: 230 Norm Difference for worker 1469 is 1.805509
INFO:root:FL Epoch: 230 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :582
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790866
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543060
INFO:root:FL Epoch: 230 Norm Difference for worker 582 is 1.817971
INFO:root:FL Epoch: 230 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :963
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356115
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384604
INFO:root:FL Epoch: 230 Norm Difference for worker 963 is 1.840753
INFO:root:FL Epoch: 230 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :936
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759819
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251527
INFO:root:FL Epoch: 230 Norm Difference for worker 936 is 1.732278
INFO:root:FL Epoch: 230 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1610
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585488
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247041
INFO:root:FL Epoch: 230 Norm Difference for worker 1610 is 1.735144
INFO:root:FL Epoch: 230 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1285
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311438
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225832
INFO:root:FL Epoch: 230 Norm Difference for worker 1285 is 1.637113
INFO:root:FL Epoch: 230 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :954
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489886
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376225
INFO:root:FL Epoch: 230 Norm Difference for worker 954 is 1.774857
INFO:root:FL Epoch: 230 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :660
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443258
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171816
INFO:root:FL Epoch: 230 Norm Difference for worker 660 is 1.669101
INFO:root:FL Epoch: 230 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :200
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446393
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 200 is 1.734809
INFO:root:FL Epoch: 230 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :238
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 238 is 1.893882
INFO:root:FL Epoch: 230 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6622567060841633, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6621227767689972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6621210510631814
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6621210213491273
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.46924299177001505 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.12692562863230705                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.085953
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.060375
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.03674149544288715 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.028237932734191416 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.637981
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.096897
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.040351
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.039540430841346584 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.0276846150867641 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.598707
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.086437
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.059618
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.032530548982322216 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.027410226687788964 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.679936
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :182
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.157173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 182 is 1.656048
INFO:root:FL Epoch: 231 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :207
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358136
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 207 is 1.6919
INFO:root:FL Epoch: 231 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1332
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625732
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332840
INFO:root:FL Epoch: 231 Norm Difference for worker 1332 is 1.696461
INFO:root:FL Epoch: 231 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :956
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404050
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350960
INFO:root:FL Epoch: 231 Norm Difference for worker 956 is 1.753065
INFO:root:FL Epoch: 231 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464724
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424504
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 1.684077
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1364
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607929
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217181
INFO:root:FL Epoch: 231 Norm Difference for worker 1364 is 1.522248
INFO:root:FL Epoch: 231 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :648
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571089
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334600
INFO:root:FL Epoch: 231 Norm Difference for worker 648 is 1.671072
INFO:root:FL Epoch: 231 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2809310576107016, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2585575426137143
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2545744981500997
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2537081742582576
INFO:root:#### Oracle Cals: 5, Objective Val: 1.2535105739561194
INFO:root:#### Oracle Cals: 6, Objective Val: 1.2534649547648253
INFO:root:#### Oracle Cals: 7, Objective Val: 1.253454437487454
INFO:root:#### Oracle Cals: 8, Objective Val: 1.2534519496324315
INFO:root:#### Oracle Cals: 9, Objective Val: 1.2534514038764166
INFO:root:#### Oracle Cals: 10, Objective Val: 1.2534512667030182
INFO:root:#### Oracle Cals: 11, Objective Val: 1.2534512496895616
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.467626236817416 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.04987650690600276                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1755
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498628
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133245
INFO:root:FL Epoch: 232 Norm Difference for worker 1755 is 1.719476
INFO:root:FL Epoch: 232 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1533
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697480
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183037
INFO:root:FL Epoch: 232 Norm Difference for worker 1533 is 2.027273
INFO:root:FL Epoch: 232 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1003
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270057
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170786
INFO:root:FL Epoch: 232 Norm Difference for worker 1003 is 2.095232
INFO:root:FL Epoch: 232 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1514
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304351
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221306
INFO:root:FL Epoch: 232 Norm Difference for worker 1514 is 2.074376
INFO:root:FL Epoch: 232 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :482
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673854
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317693
INFO:root:FL Epoch: 232 Norm Difference for worker 482 is 1.812204
INFO:root:FL Epoch: 232 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :38
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 38 is 1.615952
INFO:root:FL Epoch: 232 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1305
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537780
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238123
INFO:root:FL Epoch: 232 Norm Difference for worker 1305 is 1.839484
INFO:root:FL Epoch: 232 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :806
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 1.012328
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608026
INFO:root:FL Epoch: 232 Norm Difference for worker 806 is 2.039392
INFO:root:FL Epoch: 232 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315130
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167011
INFO:root:FL Epoch: 232 Norm Difference for worker 1291 is 1.738908
INFO:root:FL Epoch: 232 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1342
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017044
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143023
INFO:root:FL Epoch: 232 Norm Difference for worker 1342 is 1.76738
INFO:root:FL Epoch: 232 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7662992074765214, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7657705491611104
INFO:root:#### Oracle Cals: 3, Objective Val: 1.765762304246808
INFO:root:#### Oracle Cals: 4, Objective Val: 1.765762144002871
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.4502736119663014 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.0637694721420606                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1736
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586649
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251018
INFO:root:FL Epoch: 233 Norm Difference for worker 1736 is 1.946408
INFO:root:FL Epoch: 233 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1347
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425224
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246751
INFO:root:FL Epoch: 233 Norm Difference for worker 1347 is 1.890715
INFO:root:FL Epoch: 233 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :965
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510725
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185046
INFO:root:FL Epoch: 233 Norm Difference for worker 965 is 1.674598
INFO:root:FL Epoch: 233 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1370
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641031
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228009
INFO:root:FL Epoch: 233 Norm Difference for worker 1370 is 1.67679
INFO:root:FL Epoch: 233 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :121
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395516
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 121 is 1.711689
INFO:root:FL Epoch: 233 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1393
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387560
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319608
INFO:root:FL Epoch: 233 Norm Difference for worker 1393 is 1.854165
INFO:root:FL Epoch: 233 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :456
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460355
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378971
INFO:root:FL Epoch: 233 Norm Difference for worker 456 is 1.622334
INFO:root:FL Epoch: 233 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1814
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419759
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200634
INFO:root:FL Epoch: 233 Norm Difference for worker 1814 is 1.746474
INFO:root:FL Epoch: 233 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1922
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324471
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405888
INFO:root:FL Epoch: 233 Norm Difference for worker 1922 is 1.685636
INFO:root:FL Epoch: 233 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :825
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426488
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154418
INFO:root:FL Epoch: 233 Norm Difference for worker 825 is 1.544163
INFO:root:FL Epoch: 233 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6402195159560042, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6399002759304813
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6398962041021536
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6398961516586592
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.4472121824236477 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.055779763186971344                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1426
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572678
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246701
INFO:root:FL Epoch: 234 Norm Difference for worker 1426 is 1.845043
INFO:root:FL Epoch: 234 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1515
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560992
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599980
INFO:root:FL Epoch: 234 Norm Difference for worker 1515 is 1.7494
INFO:root:FL Epoch: 234 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1029
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521102
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413897
INFO:root:FL Epoch: 234 Norm Difference for worker 1029 is 1.720837
INFO:root:FL Epoch: 234 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1283
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392119
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303981
INFO:root:FL Epoch: 234 Norm Difference for worker 1283 is 1.748181
INFO:root:FL Epoch: 234 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :292
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.279300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.137706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 292 is 1.829153
INFO:root:FL Epoch: 234 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :988
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583635
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286503
INFO:root:FL Epoch: 234 Norm Difference for worker 988 is 1.69629
INFO:root:FL Epoch: 234 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :434
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495695
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247636
INFO:root:FL Epoch: 234 Norm Difference for worker 434 is 1.658976
INFO:root:FL Epoch: 234 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1197
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617160
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197038
INFO:root:FL Epoch: 234 Norm Difference for worker 1197 is 1.79048
INFO:root:FL Epoch: 234 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1772
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830666
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222821
INFO:root:FL Epoch: 234 Norm Difference for worker 1772 is 1.856405
INFO:root:FL Epoch: 234 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1338
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716847
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166803
INFO:root:FL Epoch: 234 Norm Difference for worker 1338 is 1.658101
INFO:root:FL Epoch: 234 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6632627111601128, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6631295691320989
INFO:root:#### Oracle Cals: 3, Objective Val: 1.663127981724067
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6631279266022294
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.448168628356036 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.06651060655713081                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :522
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588193
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328177
INFO:root:FL Epoch: 235 Norm Difference for worker 522 is 1.670219
INFO:root:FL Epoch: 235 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1084
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486714
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302515
INFO:root:FL Epoch: 235 Norm Difference for worker 1084 is 1.783913
INFO:root:FL Epoch: 235 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386100
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175934
INFO:root:FL Epoch: 235 Norm Difference for worker 794 is 1.793535
INFO:root:FL Epoch: 235 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1467
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478262
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355260
INFO:root:FL Epoch: 235 Norm Difference for worker 1467 is 1.712788
INFO:root:FL Epoch: 235 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306186
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342977
INFO:root:FL Epoch: 235 Norm Difference for worker 1794 is 1.841544
INFO:root:FL Epoch: 235 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1935
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325478
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383987
INFO:root:FL Epoch: 235 Norm Difference for worker 1935 is 1.803631
INFO:root:FL Epoch: 235 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479996
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251772
INFO:root:FL Epoch: 235 Norm Difference for worker 1180 is 1.746412
INFO:root:FL Epoch: 235 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1316
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650358
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290213
INFO:root:FL Epoch: 235 Norm Difference for worker 1316 is 1.70058
INFO:root:FL Epoch: 235 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1029
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324035
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283721
INFO:root:FL Epoch: 235 Norm Difference for worker 1029 is 1.627268
INFO:root:FL Epoch: 235 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1087
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.191576
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431593
INFO:root:FL Epoch: 235 Norm Difference for worker 1087 is 1.713006
INFO:root:FL Epoch: 235 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6482066256715786, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.648110184727219
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6481089491864813
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6481089337811758
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.4632446222445544 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.10368685610592365                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1500
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762871
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556798
INFO:root:FL Epoch: 236 Norm Difference for worker 1500 is 1.797753
INFO:root:FL Epoch: 236 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1518
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338230
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376844
INFO:root:FL Epoch: 236 Norm Difference for worker 1518 is 1.75887
INFO:root:FL Epoch: 236 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675828
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213423
INFO:root:FL Epoch: 236 Norm Difference for worker 1356 is 1.90779
INFO:root:FL Epoch: 236 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1009
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458736
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280220
INFO:root:FL Epoch: 236 Norm Difference for worker 1009 is 1.773022
INFO:root:FL Epoch: 236 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :923
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338508
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272130
INFO:root:FL Epoch: 236 Norm Difference for worker 923 is 1.686777
INFO:root:FL Epoch: 236 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1137
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633034
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311669
INFO:root:FL Epoch: 236 Norm Difference for worker 1137 is 1.863961
INFO:root:FL Epoch: 236 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1947
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467998
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298212
INFO:root:FL Epoch: 236 Norm Difference for worker 1947 is 1.666813
INFO:root:FL Epoch: 236 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523613
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376252
INFO:root:FL Epoch: 236 Norm Difference for worker 1178 is 1.635178
INFO:root:FL Epoch: 236 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :44
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.198091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 44 is 1.747804
INFO:root:FL Epoch: 236 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :161
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.347865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 161 is 1.672769
INFO:root:FL Epoch: 236 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6574507157753096, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6572872686681566
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6572852795612891
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6572852544454095
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.4571565249386956 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.10745954886078835                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :312
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.842000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 312 is 1.637071
INFO:root:FL Epoch: 237 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1612
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522910
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266000
INFO:root:FL Epoch: 237 Norm Difference for worker 1612 is 1.68852
INFO:root:FL Epoch: 237 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1685
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614867
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395567
INFO:root:FL Epoch: 237 Norm Difference for worker 1685 is 1.726552
INFO:root:FL Epoch: 237 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :582
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800464
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372923
INFO:root:FL Epoch: 237 Norm Difference for worker 582 is 1.71758
INFO:root:FL Epoch: 237 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :797
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 1.001148
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313708
INFO:root:FL Epoch: 237 Norm Difference for worker 797 is 1.801378
INFO:root:FL Epoch: 237 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :600
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505830
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492483
INFO:root:FL Epoch: 237 Norm Difference for worker 600 is 1.796861
INFO:root:FL Epoch: 237 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :237
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 237 is 1.678174
INFO:root:FL Epoch: 237 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1308
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639131
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203511
INFO:root:FL Epoch: 237 Norm Difference for worker 1308 is 1.690547
INFO:root:FL Epoch: 237 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :534
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613498
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191255
INFO:root:FL Epoch: 237 Norm Difference for worker 534 is 1.65932
INFO:root:FL Epoch: 237 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :844
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220819
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227361
INFO:root:FL Epoch: 237 Norm Difference for worker 844 is 1.523762
INFO:root:FL Epoch: 237 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6022361872703133, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6020817167073034
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6020797372244686
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6020797287455326
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.4665675163269043 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.10566664673388004                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :58
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.898745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 58 is 1.7366
INFO:root:FL Epoch: 238 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :859
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419826
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286889
INFO:root:FL Epoch: 238 Norm Difference for worker 859 is 1.648887
INFO:root:FL Epoch: 238 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :433
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242724
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225618
INFO:root:FL Epoch: 238 Norm Difference for worker 433 is 1.528231
INFO:root:FL Epoch: 238 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1026
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617315
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326994
INFO:root:FL Epoch: 238 Norm Difference for worker 1026 is 1.813275
INFO:root:FL Epoch: 238 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :994
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773263
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472822
INFO:root:FL Epoch: 238 Norm Difference for worker 994 is 1.672703
INFO:root:FL Epoch: 238 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1506
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269380
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233298
INFO:root:FL Epoch: 238 Norm Difference for worker 1506 is 1.651033
INFO:root:FL Epoch: 238 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :858
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397097
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302511
INFO:root:FL Epoch: 238 Norm Difference for worker 858 is 1.646844
INFO:root:FL Epoch: 238 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :763
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837432
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292328
INFO:root:FL Epoch: 238 Norm Difference for worker 763 is 1.691703
INFO:root:FL Epoch: 238 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1007
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534246
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350537
INFO:root:FL Epoch: 238 Norm Difference for worker 1007 is 1.666335
INFO:root:FL Epoch: 238 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :921
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515598
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350807
INFO:root:FL Epoch: 238 Norm Difference for worker 921 is 1.797644
INFO:root:FL Epoch: 238 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5906270297443057, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5904636146495013
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5904617168618775
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5904616571231884
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.46328914340804606 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.10337769240140915                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1052
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569411
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281593
INFO:root:FL Epoch: 239 Norm Difference for worker 1052 is 1.527733
INFO:root:FL Epoch: 239 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :845
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439256
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163904
INFO:root:FL Epoch: 239 Norm Difference for worker 845 is 1.714385
INFO:root:FL Epoch: 239 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :221
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355869
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 221 is 1.63126
INFO:root:FL Epoch: 239 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :456
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388548
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171515
INFO:root:FL Epoch: 239 Norm Difference for worker 456 is 1.643717
INFO:root:FL Epoch: 239 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :255
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 255 is 1.665356
INFO:root:FL Epoch: 239 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :587
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538419
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213396
INFO:root:FL Epoch: 239 Norm Difference for worker 587 is 1.642079
INFO:root:FL Epoch: 239 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :86
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 86 is 1.629961
INFO:root:FL Epoch: 239 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1398
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402492
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242624
INFO:root:FL Epoch: 239 Norm Difference for worker 1398 is 1.581513
INFO:root:FL Epoch: 239 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :451
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442437
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188374
INFO:root:FL Epoch: 239 Norm Difference for worker 451 is 1.583105
INFO:root:FL Epoch: 239 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1030
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662137
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364520
INFO:root:FL Epoch: 239 Norm Difference for worker 1030 is 1.787817
INFO:root:FL Epoch: 239 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5455228727640975, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5453755927195019
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5453738827801038
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5453738406826785
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.44833239737678976 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.10346794314682484                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1503
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536584
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283224
INFO:root:FL Epoch: 240 Norm Difference for worker 1503 is 1.693509
INFO:root:FL Epoch: 240 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527650
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196052
INFO:root:FL Epoch: 240 Norm Difference for worker 627 is 1.693459
INFO:root:FL Epoch: 240 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1705
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316802
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267328
INFO:root:FL Epoch: 240 Norm Difference for worker 1705 is 1.749476
INFO:root:FL Epoch: 240 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1702
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674044
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324937
INFO:root:FL Epoch: 240 Norm Difference for worker 1702 is 1.652822
INFO:root:FL Epoch: 240 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1356
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421564
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309761
INFO:root:FL Epoch: 240 Norm Difference for worker 1356 is 1.80539
INFO:root:FL Epoch: 240 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :22
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483517
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 22 is 1.722296
INFO:root:FL Epoch: 240 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1709
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540119
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249297
INFO:root:FL Epoch: 240 Norm Difference for worker 1709 is 1.709445
INFO:root:FL Epoch: 240 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :31
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.362031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 31 is 1.690249
INFO:root:FL Epoch: 240 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :42
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 42 is 1.60859
INFO:root:FL Epoch: 240 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :358
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473558
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216043
INFO:root:FL Epoch: 240 Norm Difference for worker 358 is 1.520552
INFO:root:FL Epoch: 240 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5830802315793562, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.582881049139172
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5828785269915502
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5828784900991812
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.4663236123674056 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.117331737652421                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.097558
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.066093
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.03561071725562215 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.0251574769616127 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.574078
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.089984
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.034505
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.042190619433919586 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.02862299680709839 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.594678
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.091358
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.083606
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.04868489938477675 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.026222164556384087 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.574217
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1593
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472898
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215192
INFO:root:FL Epoch: 241 Norm Difference for worker 1593 is 1.520692
INFO:root:FL Epoch: 241 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1631
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320315
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137372
INFO:root:FL Epoch: 241 Norm Difference for worker 1631 is 1.557005
INFO:root:FL Epoch: 241 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1647
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702638
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335638
INFO:root:FL Epoch: 241 Norm Difference for worker 1647 is 1.790452
INFO:root:FL Epoch: 241 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1726
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457399
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203803
INFO:root:FL Epoch: 241 Norm Difference for worker 1726 is 1.682612
INFO:root:FL Epoch: 241 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1002
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786496
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245113
INFO:root:FL Epoch: 241 Norm Difference for worker 1002 is 1.638691
INFO:root:FL Epoch: 241 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1907
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457137
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302533
INFO:root:FL Epoch: 241 Norm Difference for worker 1907 is 1.634885
INFO:root:FL Epoch: 241 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :518
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848601
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343904
INFO:root:FL Epoch: 241 Norm Difference for worker 518 is 1.704674
INFO:root:FL Epoch: 241 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2537022068379715, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2296007037917969
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2250210706672988
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2239407862315952
INFO:root:#### Oracle Cals: 5, Objective Val: 1.223674211180159
INFO:root:#### Oracle Cals: 6, Objective Val: 1.2236080486061374
INFO:root:#### Oracle Cals: 7, Objective Val: 1.2235916533303657
INFO:root:#### Oracle Cals: 8, Objective Val: 1.223587587620317
INFO:root:#### Oracle Cals: 9, Objective Val: 1.2235865806843793
INFO:root:#### Oracle Cals: 10, Objective Val: 1.2235863723724933
INFO:root:#### Oracle Cals: 11, Objective Val: 1.2235862844346979
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.4793478075195761 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.05665616691112518                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1813
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441481
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127076
INFO:root:FL Epoch: 242 Norm Difference for worker 1813 is 1.735855
INFO:root:FL Epoch: 242 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1657
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308740
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282270
INFO:root:FL Epoch: 242 Norm Difference for worker 1657 is 1.966343
INFO:root:FL Epoch: 242 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1921
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581140
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362997
INFO:root:FL Epoch: 242 Norm Difference for worker 1921 is 1.92932
INFO:root:FL Epoch: 242 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :123
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 123 is 1.909652
INFO:root:FL Epoch: 242 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :56
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496952
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 56 is 1.853125
INFO:root:FL Epoch: 242 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :975
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591792
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238296
INFO:root:FL Epoch: 242 Norm Difference for worker 975 is 1.995407
INFO:root:FL Epoch: 242 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1165
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673192
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178765
INFO:root:FL Epoch: 242 Norm Difference for worker 1165 is 1.758254
INFO:root:FL Epoch: 242 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :380
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722691
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270769
INFO:root:FL Epoch: 242 Norm Difference for worker 380 is 1.815546
INFO:root:FL Epoch: 242 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :313
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 313 is 1.797318
INFO:root:FL Epoch: 242 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1324
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535460
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151041
INFO:root:FL Epoch: 242 Norm Difference for worker 1324 is 1.870993
INFO:root:FL Epoch: 242 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7528314805793188, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7526200106256224
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7526171491461175
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7526171735043738
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.4885924616280724 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.06894585893799861                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1593
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396886
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264197
INFO:root:FL Epoch: 243 Norm Difference for worker 1593 is 1.591418
INFO:root:FL Epoch: 243 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1300
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530890
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252781
INFO:root:FL Epoch: 243 Norm Difference for worker 1300 is 1.683099
INFO:root:FL Epoch: 243 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :642
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510728
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405460
INFO:root:FL Epoch: 243 Norm Difference for worker 642 is 1.672001
INFO:root:FL Epoch: 243 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1371
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513833
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222985
INFO:root:FL Epoch: 243 Norm Difference for worker 1371 is 1.922271
INFO:root:FL Epoch: 243 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :278
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.139250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 278 is 1.76093
INFO:root:FL Epoch: 243 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :562
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443432
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261108
INFO:root:FL Epoch: 243 Norm Difference for worker 562 is 1.697028
INFO:root:FL Epoch: 243 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1220
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633511
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271087
INFO:root:FL Epoch: 243 Norm Difference for worker 1220 is 1.717862
INFO:root:FL Epoch: 243 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :620
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638728
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266614
INFO:root:FL Epoch: 243 Norm Difference for worker 620 is 1.770557
INFO:root:FL Epoch: 243 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :885
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636278
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282482
INFO:root:FL Epoch: 243 Norm Difference for worker 885 is 1.746091
INFO:root:FL Epoch: 243 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1473
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479925
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384781
INFO:root:FL Epoch: 243 Norm Difference for worker 1473 is 1.933101
INFO:root:FL Epoch: 243 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6580097432792604, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6577313404670304
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6577281378754938
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6577281174602168
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.4949822408311507 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.0736773672203223                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :828
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581963
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331062
INFO:root:FL Epoch: 244 Norm Difference for worker 828 is 1.911708
INFO:root:FL Epoch: 244 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1531
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710899
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299381
INFO:root:FL Epoch: 244 Norm Difference for worker 1531 is 1.786971
INFO:root:FL Epoch: 244 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :942
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659506
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356010
INFO:root:FL Epoch: 244 Norm Difference for worker 942 is 1.805145
INFO:root:FL Epoch: 244 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1585
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315754
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197375
INFO:root:FL Epoch: 244 Norm Difference for worker 1585 is 1.633282
INFO:root:FL Epoch: 244 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :214
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 214 is 1.754451
INFO:root:FL Epoch: 244 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1712
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556433
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235896
INFO:root:FL Epoch: 244 Norm Difference for worker 1712 is 1.727178
INFO:root:FL Epoch: 244 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :760
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470422
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416155
INFO:root:FL Epoch: 244 Norm Difference for worker 760 is 1.69361
INFO:root:FL Epoch: 244 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1577
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526526
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364233
INFO:root:FL Epoch: 244 Norm Difference for worker 1577 is 1.75678
INFO:root:FL Epoch: 244 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :161
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534315
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 161 is 1.689771
INFO:root:FL Epoch: 244 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :872
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463715
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266085
INFO:root:FL Epoch: 244 Norm Difference for worker 872 is 1.630037
INFO:root:FL Epoch: 244 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6427744909067872, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6426224274899601
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6426207186858837
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6426207282951135
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.4783579374060911 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.08066489423314731                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 245 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :42
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 42 is 1.59369
INFO:root:FL Epoch: 245 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 320 is 1.689478
INFO:root:FL Epoch: 245 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1861
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385008
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285419
INFO:root:FL Epoch: 245 Norm Difference for worker 1861 is 1.813845
INFO:root:FL Epoch: 245 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :965
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372527
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186703
INFO:root:FL Epoch: 245 Norm Difference for worker 965 is 1.646792
INFO:root:FL Epoch: 245 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :484
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944067
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257694
INFO:root:FL Epoch: 245 Norm Difference for worker 484 is 1.926151
INFO:root:FL Epoch: 245 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :884
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368171
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333478
INFO:root:FL Epoch: 245 Norm Difference for worker 884 is 1.659363
INFO:root:FL Epoch: 245 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1238
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409325
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278025
INFO:root:FL Epoch: 245 Norm Difference for worker 1238 is 1.665007
INFO:root:FL Epoch: 245 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :214
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 214 is 1.579326
INFO:root:FL Epoch: 245 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1012
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470851
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250085
INFO:root:FL Epoch: 245 Norm Difference for worker 1012 is 1.708179
INFO:root:FL Epoch: 245 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :674
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378140
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214730
INFO:root:FL Epoch: 245 Norm Difference for worker 674 is 1.622869
INFO:root:FL Epoch: 245 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6016340074363031, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6014053396798877
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6014023527160512
INFO:root:#### Oracle Cals: 4, Objective Val: 1.601402321443248
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.491302935516133 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.07581563418110211                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :501
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471657
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381478
INFO:root:FL Epoch: 246 Norm Difference for worker 501 is 1.751127
INFO:root:FL Epoch: 246 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1726
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497517
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336204
INFO:root:FL Epoch: 246 Norm Difference for worker 1726 is 1.865506
INFO:root:FL Epoch: 246 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1606
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379827
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269383
INFO:root:FL Epoch: 246 Norm Difference for worker 1606 is 1.672025
INFO:root:FL Epoch: 246 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1903
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468161
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191951
INFO:root:FL Epoch: 246 Norm Difference for worker 1903 is 1.800136
INFO:root:FL Epoch: 246 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :59
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.730152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 59 is 1.655111
INFO:root:FL Epoch: 246 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1152
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435851
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276689
INFO:root:FL Epoch: 246 Norm Difference for worker 1152 is 1.799098
INFO:root:FL Epoch: 246 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :944
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386011
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252759
INFO:root:FL Epoch: 246 Norm Difference for worker 944 is 1.723665
INFO:root:FL Epoch: 246 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1138
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771347
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203192
INFO:root:FL Epoch: 246 Norm Difference for worker 1138 is 1.742123
INFO:root:FL Epoch: 246 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :484
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284690
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190386
INFO:root:FL Epoch: 246 Norm Difference for worker 484 is 1.739365
INFO:root:FL Epoch: 246 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1176
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410138
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129132
INFO:root:FL Epoch: 246 Norm Difference for worker 1176 is 1.657534
INFO:root:FL Epoch: 246 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6516840802590333, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6515443458465788
INFO:root:#### Oracle Cals: 3, Objective Val: 1.651542718992548
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6515426977210712
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.4923943964874043 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.08214814464251201                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1188
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622811
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353486
INFO:root:FL Epoch: 247 Norm Difference for worker 1188 is 1.747421
INFO:root:FL Epoch: 247 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1113
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418263
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326252
INFO:root:FL Epoch: 247 Norm Difference for worker 1113 is 1.77884
INFO:root:FL Epoch: 247 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1084
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565084
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277601
INFO:root:FL Epoch: 247 Norm Difference for worker 1084 is 1.59368
INFO:root:FL Epoch: 247 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1606
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509203
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333838
INFO:root:FL Epoch: 247 Norm Difference for worker 1606 is 1.532566
INFO:root:FL Epoch: 247 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :769
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339187
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342581
INFO:root:FL Epoch: 247 Norm Difference for worker 769 is 1.814635
INFO:root:FL Epoch: 247 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :829
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808870
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288571
INFO:root:FL Epoch: 247 Norm Difference for worker 829 is 1.785647
INFO:root:FL Epoch: 247 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :116
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.871899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 116 is 1.727687
INFO:root:FL Epoch: 247 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :544
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391729
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341426
INFO:root:FL Epoch: 247 Norm Difference for worker 544 is 1.643833
INFO:root:FL Epoch: 247 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1566
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540859
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379494
INFO:root:FL Epoch: 247 Norm Difference for worker 1566 is 1.743354
INFO:root:FL Epoch: 247 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1301
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629298
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261066
INFO:root:FL Epoch: 247 Norm Difference for worker 1301 is 1.751151
INFO:root:FL Epoch: 247 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6244929968337602, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6243210436695072
INFO:root:#### Oracle Cals: 3, Objective Val: 1.624318523065834
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6243184932544024
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.46968897826531353 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.0834459060182174                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :36
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372740
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 36 is 1.802214
INFO:root:FL Epoch: 248 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1147
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525271
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276786
INFO:root:FL Epoch: 248 Norm Difference for worker 1147 is 1.759485
INFO:root:FL Epoch: 248 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :785
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589395
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195055
INFO:root:FL Epoch: 248 Norm Difference for worker 785 is 1.633759
INFO:root:FL Epoch: 248 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :826
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770923
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506060
INFO:root:FL Epoch: 248 Norm Difference for worker 826 is 1.682385
INFO:root:FL Epoch: 248 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :778
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657937
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349542
INFO:root:FL Epoch: 248 Norm Difference for worker 778 is 1.845752
INFO:root:FL Epoch: 248 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :373
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515994
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374483
INFO:root:FL Epoch: 248 Norm Difference for worker 373 is 1.739818
INFO:root:FL Epoch: 248 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1904
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516677
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262581
INFO:root:FL Epoch: 248 Norm Difference for worker 1904 is 1.753025
INFO:root:FL Epoch: 248 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :495
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782476
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360559
INFO:root:FL Epoch: 248 Norm Difference for worker 495 is 1.769167
INFO:root:FL Epoch: 248 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :501
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470405
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265365
INFO:root:FL Epoch: 248 Norm Difference for worker 501 is 1.566859
INFO:root:FL Epoch: 248 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :869
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358651
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299971
INFO:root:FL Epoch: 248 Norm Difference for worker 869 is 1.692278
INFO:root:FL Epoch: 248 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.621231209880336, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6210764012340566
INFO:root:#### Oracle Cals: 3, Objective Val: 1.621074161395391
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6210741125812136
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.46081139234935536 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.07631903017560641                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :606
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688436
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153395
INFO:root:FL Epoch: 249 Norm Difference for worker 606 is 1.545267
INFO:root:FL Epoch: 249 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1727
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435196
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229138
INFO:root:FL Epoch: 249 Norm Difference for worker 1727 is 1.646037
INFO:root:FL Epoch: 249 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :935
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472461
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344504
INFO:root:FL Epoch: 249 Norm Difference for worker 935 is 1.613102
INFO:root:FL Epoch: 249 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :362
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400012
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378724
INFO:root:FL Epoch: 249 Norm Difference for worker 362 is 1.712649
INFO:root:FL Epoch: 249 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :666
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647691
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342481
INFO:root:FL Epoch: 249 Norm Difference for worker 666 is 1.73313
INFO:root:FL Epoch: 249 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :491
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396878
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240720
INFO:root:FL Epoch: 249 Norm Difference for worker 491 is 1.533186
INFO:root:FL Epoch: 249 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :80
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269422
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 80 is 1.42152
INFO:root:FL Epoch: 249 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1533
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454212
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217799
INFO:root:FL Epoch: 249 Norm Difference for worker 1533 is 1.587806
INFO:root:FL Epoch: 249 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :496
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586736
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324779
INFO:root:FL Epoch: 249 Norm Difference for worker 496 is 1.613922
INFO:root:FL Epoch: 249 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :290
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608164
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395681
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 290 is 1.834217
INFO:root:FL Epoch: 249 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5283529107664653, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5280267278638047
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5280230658805034
INFO:root:#### Oracle Cals: 4, Objective Val: 1.528023002216443
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.4685370641596177 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.1032196885595719                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 250 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :78
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311848
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 78 is 1.498322
INFO:root:FL Epoch: 250 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :296
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656759
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 296 is 1.681771
INFO:root:FL Epoch: 250 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1388
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653354
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197472
INFO:root:FL Epoch: 250 Norm Difference for worker 1388 is 1.595897
INFO:root:FL Epoch: 250 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :169
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 169 is 1.607384
INFO:root:FL Epoch: 250 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :351
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312969
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244057
INFO:root:FL Epoch: 250 Norm Difference for worker 351 is 1.613541
INFO:root:FL Epoch: 250 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1200
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691828
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381699
INFO:root:FL Epoch: 250 Norm Difference for worker 1200 is 1.660062
INFO:root:FL Epoch: 250 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1052
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524499
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291484
INFO:root:FL Epoch: 250 Norm Difference for worker 1052 is 1.526754
INFO:root:FL Epoch: 250 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :729
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611577
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156547
INFO:root:FL Epoch: 250 Norm Difference for worker 729 is 1.533318
INFO:root:FL Epoch: 250 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :151
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 151 is 1.676596
INFO:root:FL Epoch: 250 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1317
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695013
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216487
INFO:root:FL Epoch: 250 Norm Difference for worker 1317 is 1.556724
INFO:root:FL Epoch: 250 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4999829538199054, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4998885141434306
INFO:root:#### Oracle Cals: 3, Objective Val: 1.499887513338276
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4998874794825785
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.4512987759183435 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.09299487931032975                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.088008
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.035199
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.027964588565131027 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.025978780165314675 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.526514
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.071272
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.027242
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.021290848885352414 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.026023223251104354 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.537978
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.079122
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.055904
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.03999835376938184 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.024360095988959073 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.560565
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :764
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243529
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226215
INFO:root:FL Epoch: 251 Norm Difference for worker 764 is 1.586914
INFO:root:FL Epoch: 251 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1000
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476031
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283758
INFO:root:FL Epoch: 251 Norm Difference for worker 1000 is 1.862456
INFO:root:FL Epoch: 251 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :718
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532523
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122450
INFO:root:FL Epoch: 251 Norm Difference for worker 718 is 1.680546
INFO:root:FL Epoch: 251 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :697
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582587
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215160
INFO:root:FL Epoch: 251 Norm Difference for worker 697 is 1.817888
INFO:root:FL Epoch: 251 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :204
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.311743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.209647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 204 is 1.622679
INFO:root:FL Epoch: 251 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1862
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511452
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219939
INFO:root:FL Epoch: 251 Norm Difference for worker 1862 is 1.64764
INFO:root:FL Epoch: 251 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :913
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447712
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315532
INFO:root:FL Epoch: 251 Norm Difference for worker 913 is 1.760851
INFO:root:FL Epoch: 251 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.302744482669677, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.277122877757455
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2721078197482958
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2708797086574295
INFO:root:#### Oracle Cals: 5, Objective Val: 1.2705629486145684
INFO:root:#### Oracle Cals: 6, Objective Val: 1.2704805630041665
INFO:root:#### Oracle Cals: 7, Objective Val: 1.270459067138754
INFO:root:#### Oracle Cals: 8, Objective Val: 1.2704534884021315
INFO:root:#### Oracle Cals: 9, Objective Val: 1.270452245783678
INFO:root:#### Oracle Cals: 10, Objective Val: 1.2704516732881503
INFO:root:#### Oracle Cals: 11, Objective Val: 1.2704515774469831
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.4762800633907318 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.04513649735599756                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1465
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591473
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252377
INFO:root:FL Epoch: 252 Norm Difference for worker 1465 is 1.962225
INFO:root:FL Epoch: 252 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732980
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141834
INFO:root:FL Epoch: 252 Norm Difference for worker 1481 is 2.0093
INFO:root:FL Epoch: 252 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1390
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285574
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146653
INFO:root:FL Epoch: 252 Norm Difference for worker 1390 is 1.804161
INFO:root:FL Epoch: 252 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1870
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766408
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299513
INFO:root:FL Epoch: 252 Norm Difference for worker 1870 is 1.865405
INFO:root:FL Epoch: 252 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :755
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631176
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196160
INFO:root:FL Epoch: 252 Norm Difference for worker 755 is 1.758966
INFO:root:FL Epoch: 252 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1728
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739847
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453627
INFO:root:FL Epoch: 252 Norm Difference for worker 1728 is 1.987732
INFO:root:FL Epoch: 252 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1074
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969871
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444236
INFO:root:FL Epoch: 252 Norm Difference for worker 1074 is 2.009686
INFO:root:FL Epoch: 252 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443553
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335551
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 1.972022
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1734
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542390
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246179
INFO:root:FL Epoch: 252 Norm Difference for worker 1734 is 1.885916
INFO:root:FL Epoch: 252 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1268
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456331
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218658
INFO:root:FL Epoch: 252 Norm Difference for worker 1268 is 1.717865
INFO:root:FL Epoch: 252 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7835420995418978, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7833044026843348
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7833012509334971
INFO:root:#### Oracle Cals: 4, Objective Val: 1.783301237397641
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.4577835658017327 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.05908463057130575                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1274
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757430
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310508
INFO:root:FL Epoch: 253 Norm Difference for worker 1274 is 1.729522
INFO:root:FL Epoch: 253 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1234
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570804
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147385
INFO:root:FL Epoch: 253 Norm Difference for worker 1234 is 1.716705
INFO:root:FL Epoch: 253 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :852
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618668
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254834
INFO:root:FL Epoch: 253 Norm Difference for worker 852 is 1.651465
INFO:root:FL Epoch: 253 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1737
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593539
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296862
INFO:root:FL Epoch: 253 Norm Difference for worker 1737 is 1.663043
INFO:root:FL Epoch: 253 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1163
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481068
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244543
INFO:root:FL Epoch: 253 Norm Difference for worker 1163 is 1.652317
INFO:root:FL Epoch: 253 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :213
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 213 is 1.789051
INFO:root:FL Epoch: 253 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1350
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409408
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568044
INFO:root:FL Epoch: 253 Norm Difference for worker 1350 is 1.799285
INFO:root:FL Epoch: 253 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :291
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 291 is 1.725316
INFO:root:FL Epoch: 253 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :800
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796364
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199920
INFO:root:FL Epoch: 253 Norm Difference for worker 800 is 1.655759
INFO:root:FL Epoch: 253 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1016
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640827
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288557
INFO:root:FL Epoch: 253 Norm Difference for worker 1016 is 1.745885
INFO:root:FL Epoch: 253 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6184477710172296, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.618366510657863
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6183655090052962
INFO:root:#### Oracle Cals: 4, Objective Val: 1.618365501842975
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.4501066199120353 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.06289973265180986                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 254 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1754
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344642
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239188
INFO:root:FL Epoch: 254 Norm Difference for worker 1754 is 1.629863
INFO:root:FL Epoch: 254 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1163
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403202
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353241
INFO:root:FL Epoch: 254 Norm Difference for worker 1163 is 1.548728
INFO:root:FL Epoch: 254 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :896
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779460
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203274
INFO:root:FL Epoch: 254 Norm Difference for worker 896 is 1.628654
INFO:root:FL Epoch: 254 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :38
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.152867
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 38 is 1.471687
INFO:root:FL Epoch: 254 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1431
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424693
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241131
INFO:root:FL Epoch: 254 Norm Difference for worker 1431 is 1.6095
INFO:root:FL Epoch: 254 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :945
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337079
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261857
INFO:root:FL Epoch: 254 Norm Difference for worker 945 is 1.45992
INFO:root:FL Epoch: 254 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1882
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728696
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216677
INFO:root:FL Epoch: 254 Norm Difference for worker 1882 is 1.603728
INFO:root:FL Epoch: 254 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1311
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859677
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242444
INFO:root:FL Epoch: 254 Norm Difference for worker 1311 is 1.622659
INFO:root:FL Epoch: 254 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :721
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391620
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327932
INFO:root:FL Epoch: 254 Norm Difference for worker 721 is 1.801477
INFO:root:FL Epoch: 254 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :844
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555528
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308056
INFO:root:FL Epoch: 254 Norm Difference for worker 844 is 1.569022
INFO:root:FL Epoch: 254 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5077960695075925, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5075179521576842
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5075145130359733
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5075144693182736
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.4545384996077594 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.05676897522062063                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1458
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536691
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175647
INFO:root:FL Epoch: 255 Norm Difference for worker 1458 is 1.652668
INFO:root:FL Epoch: 255 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :415
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328632
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249624
INFO:root:FL Epoch: 255 Norm Difference for worker 415 is 1.699798
INFO:root:FL Epoch: 255 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1593
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511497
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200977
INFO:root:FL Epoch: 255 Norm Difference for worker 1593 is 1.545098
INFO:root:FL Epoch: 255 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1941
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280402
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221830
INFO:root:FL Epoch: 255 Norm Difference for worker 1941 is 1.614883
INFO:root:FL Epoch: 255 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :575
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394323
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251473
INFO:root:FL Epoch: 255 Norm Difference for worker 575 is 1.807725
INFO:root:FL Epoch: 255 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1329
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379494
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203215
INFO:root:FL Epoch: 255 Norm Difference for worker 1329 is 1.582713
INFO:root:FL Epoch: 255 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :88
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 88 is 1.803173
INFO:root:FL Epoch: 255 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1317
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304775
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270499
INFO:root:FL Epoch: 255 Norm Difference for worker 1317 is 1.613886
INFO:root:FL Epoch: 255 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1582
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771062
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393503
INFO:root:FL Epoch: 255 Norm Difference for worker 1582 is 1.896061
INFO:root:FL Epoch: 255 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742814
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274725
INFO:root:FL Epoch: 255 Norm Difference for worker 1124 is 1.749439
INFO:root:FL Epoch: 255 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6032350135769278, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6029563838461578
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6029525918704988
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6029525868586654
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.4468756896608016 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.06727512460201979                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1806
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398833
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435948
INFO:root:FL Epoch: 256 Norm Difference for worker 1806 is 1.558867
INFO:root:FL Epoch: 256 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :864
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370997
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150756
INFO:root:FL Epoch: 256 Norm Difference for worker 864 is 1.680923
INFO:root:FL Epoch: 256 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1226
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727658
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366479
INFO:root:FL Epoch: 256 Norm Difference for worker 1226 is 1.682784
INFO:root:FL Epoch: 256 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :325
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 325 is 1.643649
INFO:root:FL Epoch: 256 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :424
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553587
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228704
INFO:root:FL Epoch: 256 Norm Difference for worker 424 is 1.591842
INFO:root:FL Epoch: 256 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1188
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391397
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264054
INFO:root:FL Epoch: 256 Norm Difference for worker 1188 is 1.742039
INFO:root:FL Epoch: 256 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1760
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658923
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264612
INFO:root:FL Epoch: 256 Norm Difference for worker 1760 is 1.888232
INFO:root:FL Epoch: 256 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :100
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494915
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 100 is 1.618178
INFO:root:FL Epoch: 256 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1464
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332582
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222892
INFO:root:FL Epoch: 256 Norm Difference for worker 1464 is 1.610065
INFO:root:FL Epoch: 256 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :887
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486635
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152152
INFO:root:FL Epoch: 256 Norm Difference for worker 887 is 1.783309
INFO:root:FL Epoch: 256 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5889071555105945, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5886141021301174
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5886109704878089
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5886109371766661
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.45937859486131105 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.053349449609716736                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1443
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480523
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299406
INFO:root:FL Epoch: 257 Norm Difference for worker 1443 is 1.694211
INFO:root:FL Epoch: 257 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :3
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290366
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 3 is 1.76432
INFO:root:FL Epoch: 257 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :324
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 324 is 1.671853
INFO:root:FL Epoch: 257 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :653
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590987
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303234
INFO:root:FL Epoch: 257 Norm Difference for worker 653 is 1.60264
INFO:root:FL Epoch: 257 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :780
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333342
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209793
INFO:root:FL Epoch: 257 Norm Difference for worker 780 is 1.708294
INFO:root:FL Epoch: 257 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :610
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461848
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320482
INFO:root:FL Epoch: 257 Norm Difference for worker 610 is 1.574337
INFO:root:FL Epoch: 257 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :309
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 309 is 1.671255
INFO:root:FL Epoch: 257 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :393
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627434
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305133
INFO:root:FL Epoch: 257 Norm Difference for worker 393 is 1.828615
INFO:root:FL Epoch: 257 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1556
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421963
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288968
INFO:root:FL Epoch: 257 Norm Difference for worker 1556 is 1.589351
INFO:root:FL Epoch: 257 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :602
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603991
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326327
INFO:root:FL Epoch: 257 Norm Difference for worker 602 is 1.785539
INFO:root:FL Epoch: 257 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5953762712002904, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5952412025121505
INFO:root:#### Oracle Cals: 3, Objective Val: 1.595239509222971
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5952394718275125
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.45799562335014343 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.07169010893752177                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1162
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481812
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335550
INFO:root:FL Epoch: 258 Norm Difference for worker 1162 is 1.640186
INFO:root:FL Epoch: 258 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1887
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482374
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244858
INFO:root:FL Epoch: 258 Norm Difference for worker 1887 is 1.5506
INFO:root:FL Epoch: 258 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1228
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558890
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302095
INFO:root:FL Epoch: 258 Norm Difference for worker 1228 is 1.855651
INFO:root:FL Epoch: 258 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1028
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690735
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312777
INFO:root:FL Epoch: 258 Norm Difference for worker 1028 is 1.665683
INFO:root:FL Epoch: 258 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1657
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387782
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154400
INFO:root:FL Epoch: 258 Norm Difference for worker 1657 is 1.709702
INFO:root:FL Epoch: 258 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1687
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499185
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212769
INFO:root:FL Epoch: 258 Norm Difference for worker 1687 is 1.814658
INFO:root:FL Epoch: 258 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1086
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519758
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299179
INFO:root:FL Epoch: 258 Norm Difference for worker 1086 is 1.660638
INFO:root:FL Epoch: 258 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :388
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499955
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268243
INFO:root:FL Epoch: 258 Norm Difference for worker 388 is 1.692505
INFO:root:FL Epoch: 258 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :429
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436765
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153643
INFO:root:FL Epoch: 258 Norm Difference for worker 429 is 1.696875
INFO:root:FL Epoch: 258 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :973
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290760
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268894
INFO:root:FL Epoch: 258 Norm Difference for worker 973 is 1.694953
INFO:root:FL Epoch: 258 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6071855897168572, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6070001580360702
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6069979994835444
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6069979364995428
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.45438164472579956 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.07765673877050479                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 259 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :9
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 9 is 1.648106
INFO:root:FL Epoch: 259 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1195
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538281
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315981
INFO:root:FL Epoch: 259 Norm Difference for worker 1195 is 1.635846
INFO:root:FL Epoch: 259 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :213
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 213 is 1.711663
INFO:root:FL Epoch: 259 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :53
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 53 is 1.586757
INFO:root:FL Epoch: 259 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :147
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.314729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.158820
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 147 is 1.552158
INFO:root:FL Epoch: 259 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1859
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892252
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246131
INFO:root:FL Epoch: 259 Norm Difference for worker 1859 is 1.704443
INFO:root:FL Epoch: 259 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :429
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496359
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269490
INFO:root:FL Epoch: 259 Norm Difference for worker 429 is 1.593718
INFO:root:FL Epoch: 259 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1183
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.936089
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134086
INFO:root:FL Epoch: 259 Norm Difference for worker 1183 is 1.605402
INFO:root:FL Epoch: 259 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1225
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578318
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443928
INFO:root:FL Epoch: 259 Norm Difference for worker 1225 is 1.777158
INFO:root:FL Epoch: 259 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1102
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389503
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270258
INFO:root:FL Epoch: 259 Norm Difference for worker 1102 is 1.610665
INFO:root:FL Epoch: 259 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5541595505346866, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5540155144150944
INFO:root:#### Oracle Cals: 3, Objective Val: 1.554013315167887
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5540133038315895
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.45952722430229187 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.07400650003304084                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1793
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788737
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532231
INFO:root:FL Epoch: 260 Norm Difference for worker 1793 is 1.73291
INFO:root:FL Epoch: 260 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1652
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344889
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324045
INFO:root:FL Epoch: 260 Norm Difference for worker 1652 is 1.772688
INFO:root:FL Epoch: 260 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1184
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474084
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296301
INFO:root:FL Epoch: 260 Norm Difference for worker 1184 is 1.75591
INFO:root:FL Epoch: 260 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1482
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610129
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250542
INFO:root:FL Epoch: 260 Norm Difference for worker 1482 is 1.503999
INFO:root:FL Epoch: 260 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1085
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312780
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435802
INFO:root:FL Epoch: 260 Norm Difference for worker 1085 is 1.527079
INFO:root:FL Epoch: 260 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :257
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 257 is 1.675832
INFO:root:FL Epoch: 260 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1289
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320079
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190909
INFO:root:FL Epoch: 260 Norm Difference for worker 1289 is 1.498842
INFO:root:FL Epoch: 260 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1365
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277819
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156721
INFO:root:FL Epoch: 260 Norm Difference for worker 1365 is 1.563622
INFO:root:FL Epoch: 260 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :864
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491223
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201194
INFO:root:FL Epoch: 260 Norm Difference for worker 864 is 1.563107
INFO:root:FL Epoch: 260 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1611
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689056
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194681
INFO:root:FL Epoch: 260 Norm Difference for worker 1611 is 1.686682
INFO:root:FL Epoch: 260 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5354264507383473, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5350578064253697
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5350523924774522
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5350523400224467
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.459532503696049 and Test Accuracy:80.0 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.08815632077554862                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.055450
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.075001
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.029831872942547005 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.022063568606972693 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.530216
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.059496
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.055993
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.029765718150883913 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.022011160291731356 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.502846
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.092203
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.032137
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.026104773317153256 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.024040868785232306 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.490072
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :947
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600018
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207558
INFO:root:FL Epoch: 261 Norm Difference for worker 947 is 1.57904
INFO:root:FL Epoch: 261 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1647
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772628
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291522
INFO:root:FL Epoch: 261 Norm Difference for worker 1647 is 1.790081
INFO:root:FL Epoch: 261 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :422
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545428
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344983
INFO:root:FL Epoch: 261 Norm Difference for worker 422 is 1.594819
INFO:root:FL Epoch: 261 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :127
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 127 is 1.659233
INFO:root:FL Epoch: 261 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1270
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502169
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331209
INFO:root:FL Epoch: 261 Norm Difference for worker 1270 is 1.520976
INFO:root:FL Epoch: 261 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1475
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634599
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192973
INFO:root:FL Epoch: 261 Norm Difference for worker 1475 is 1.594878
INFO:root:FL Epoch: 261 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1332
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479424
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373064
INFO:root:FL Epoch: 261 Norm Difference for worker 1332 is 1.665036
INFO:root:FL Epoch: 261 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2332960551183896, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2087903402531976
INFO:root:#### Oracle Cals: 3, Objective Val: 1.203982454223366
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2028101479604785
INFO:root:#### Oracle Cals: 5, Objective Val: 1.2025113079604808
INFO:root:#### Oracle Cals: 6, Objective Val: 1.2024348392853146
INFO:root:#### Oracle Cals: 7, Objective Val: 1.202415342384809
INFO:root:#### Oracle Cals: 8, Objective Val: 1.2024103781662423
INFO:root:#### Oracle Cals: 9, Objective Val: 1.2024091272760653
INFO:root:#### Oracle Cals: 10, Objective Val: 1.2024088034190448
INFO:root:#### Oracle Cals: 11, Objective Val: 1.202408718687658
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.4836196268306059 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.03922569006681442                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 262 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1712
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541212
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394781
INFO:root:FL Epoch: 262 Norm Difference for worker 1712 is 1.821441
INFO:root:FL Epoch: 262 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :818
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306372
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209463
INFO:root:FL Epoch: 262 Norm Difference for worker 818 is 1.733018
INFO:root:FL Epoch: 262 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :28
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233615
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 28 is 1.814172
INFO:root:FL Epoch: 262 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :800
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368757
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164542
INFO:root:FL Epoch: 262 Norm Difference for worker 800 is 1.695103
INFO:root:FL Epoch: 262 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :258
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.228321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 258 is 2.112377
INFO:root:FL Epoch: 262 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1584
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282527
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196248
INFO:root:FL Epoch: 262 Norm Difference for worker 1584 is 1.879739
INFO:root:FL Epoch: 262 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1423
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594794
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332457
INFO:root:FL Epoch: 262 Norm Difference for worker 1423 is 1.784138
INFO:root:FL Epoch: 262 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1175
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411605
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181988
INFO:root:FL Epoch: 262 Norm Difference for worker 1175 is 1.852718
INFO:root:FL Epoch: 262 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :625
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535295
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173794
INFO:root:FL Epoch: 262 Norm Difference for worker 625 is 1.854555
INFO:root:FL Epoch: 262 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1520
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481135
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340575
INFO:root:FL Epoch: 262 Norm Difference for worker 1520 is 1.855775
INFO:root:FL Epoch: 262 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7278582262535778, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7275831355015554
INFO:root:#### Oracle Cals: 3, Objective Val: 1.727580203479475
INFO:root:#### Oracle Cals: 4, Objective Val: 1.727580185808453
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.46917305799091563 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.06002194061875343                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :979
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812334
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364902
INFO:root:FL Epoch: 263 Norm Difference for worker 979 is 1.939333
INFO:root:FL Epoch: 263 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1707
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619482
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435215
INFO:root:FL Epoch: 263 Norm Difference for worker 1707 is 1.776993
INFO:root:FL Epoch: 263 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :50
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413285
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326319
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 50 is 1.677945
INFO:root:FL Epoch: 263 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :20
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.155458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 20 is 1.695131
INFO:root:FL Epoch: 263 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :945
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435140
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202351
INFO:root:FL Epoch: 263 Norm Difference for worker 945 is 1.434825
INFO:root:FL Epoch: 263 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :232
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 232 is 1.807229
INFO:root:FL Epoch: 263 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1938
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501652
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338723
INFO:root:FL Epoch: 263 Norm Difference for worker 1938 is 1.767396
INFO:root:FL Epoch: 263 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1500
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442413
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153848
INFO:root:FL Epoch: 263 Norm Difference for worker 1500 is 1.799163
INFO:root:FL Epoch: 263 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :705
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596971
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313106
INFO:root:FL Epoch: 263 Norm Difference for worker 705 is 1.828251
INFO:root:FL Epoch: 263 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :970
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444724
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388815
INFO:root:FL Epoch: 263 Norm Difference for worker 970 is 1.74984
INFO:root:FL Epoch: 263 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6490266921793308, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6486463488266954
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6486404066505091
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6486403212343383
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.4732181850601645 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.07033585446576278                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1333
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567656
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349852
INFO:root:FL Epoch: 264 Norm Difference for worker 1333 is 1.84905
INFO:root:FL Epoch: 264 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1041
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442685
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303336
INFO:root:FL Epoch: 264 Norm Difference for worker 1041 is 1.724874
INFO:root:FL Epoch: 264 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :704
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450084
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184043
INFO:root:FL Epoch: 264 Norm Difference for worker 704 is 1.698519
INFO:root:FL Epoch: 264 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :272
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260300
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 272 is 1.582058
INFO:root:FL Epoch: 264 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1412
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385557
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289140
INFO:root:FL Epoch: 264 Norm Difference for worker 1412 is 1.726242
INFO:root:FL Epoch: 264 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1475
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415831
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.120551
INFO:root:FL Epoch: 264 Norm Difference for worker 1475 is 1.549263
INFO:root:FL Epoch: 264 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1352
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564692
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203434
INFO:root:FL Epoch: 264 Norm Difference for worker 1352 is 1.701257
INFO:root:FL Epoch: 264 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1251
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495248
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179509
INFO:root:FL Epoch: 264 Norm Difference for worker 1251 is 1.802091
INFO:root:FL Epoch: 264 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :162
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 162 is 1.619462
INFO:root:FL Epoch: 264 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :202
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236841
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 202 is 1.825162
INFO:root:FL Epoch: 264 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6141618402622528, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6139554816878297
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6139528482696794
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6139528748635512
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.4815436478923349 and Test Accuracy:75.0 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.08601233921945095                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :1078
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659326
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154848
INFO:root:FL Epoch: 265 Norm Difference for worker 1078 is 1.683336
INFO:root:FL Epoch: 265 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :339
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 339 is 1.669838
INFO:root:FL Epoch: 265 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1327
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332759
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190728
INFO:root:FL Epoch: 265 Norm Difference for worker 1327 is 1.575992
INFO:root:FL Epoch: 265 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1482
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.210803
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207678
INFO:root:FL Epoch: 265 Norm Difference for worker 1482 is 1.526333
INFO:root:FL Epoch: 265 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1713
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421910
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392028
INFO:root:FL Epoch: 265 Norm Difference for worker 1713 is 1.58621
INFO:root:FL Epoch: 265 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1622
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524758
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239864
INFO:root:FL Epoch: 265 Norm Difference for worker 1622 is 1.621068
INFO:root:FL Epoch: 265 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1408
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595410
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202646
INFO:root:FL Epoch: 265 Norm Difference for worker 1408 is 1.663716
INFO:root:FL Epoch: 265 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1865
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585736
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237365
INFO:root:FL Epoch: 265 Norm Difference for worker 1865 is 1.7404
INFO:root:FL Epoch: 265 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1421
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538540
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151891
INFO:root:FL Epoch: 265 Norm Difference for worker 1421 is 1.476559
INFO:root:FL Epoch: 265 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :325
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 325 is 1.586609
INFO:root:FL Epoch: 265 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5152598581959142, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5150269016449045
INFO:root:#### Oracle Cals: 3, Objective Val: 1.515023737394761
INFO:root:#### Oracle Cals: 4, Objective Val: 1.515023691756241
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.48186031159232645 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.07773708055416743                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423330
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312362
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 1.777847
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :857
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497114
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233298
INFO:root:FL Epoch: 266 Norm Difference for worker 857 is 1.934052
INFO:root:FL Epoch: 266 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :104
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.141851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 104 is 1.76278
INFO:root:FL Epoch: 266 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1713
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300094
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305347
INFO:root:FL Epoch: 266 Norm Difference for worker 1713 is 1.514775
INFO:root:FL Epoch: 266 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1448
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595930
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266925
INFO:root:FL Epoch: 266 Norm Difference for worker 1448 is 1.77448
INFO:root:FL Epoch: 266 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :21
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 21 is 1.619704
INFO:root:FL Epoch: 266 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :596
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448963
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305723
INFO:root:FL Epoch: 266 Norm Difference for worker 596 is 1.906173
INFO:root:FL Epoch: 266 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :894
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.216717
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226296
INFO:root:FL Epoch: 266 Norm Difference for worker 894 is 1.682057
INFO:root:FL Epoch: 266 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1708
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883339
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324155
INFO:root:FL Epoch: 266 Norm Difference for worker 1708 is 1.807188
INFO:root:FL Epoch: 266 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1086
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587242
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200535
INFO:root:FL Epoch: 266 Norm Difference for worker 1086 is 1.573945
INFO:root:FL Epoch: 266 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.62484661179895, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6244210160009023
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6244154604990166
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6244153950386433
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.4720018891727223 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.08457372399667899                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359908
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295086
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 1.536644
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1281
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745127
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235849
INFO:root:FL Epoch: 267 Norm Difference for worker 1281 is 1.449614
INFO:root:FL Epoch: 267 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :462
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603406
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210862
INFO:root:FL Epoch: 267 Norm Difference for worker 462 is 1.618561
INFO:root:FL Epoch: 267 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1092
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409543
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431697
INFO:root:FL Epoch: 267 Norm Difference for worker 1092 is 1.646213
INFO:root:FL Epoch: 267 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :606
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578090
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239152
INFO:root:FL Epoch: 267 Norm Difference for worker 606 is 1.529785
INFO:root:FL Epoch: 267 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1605
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694004
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300305
INFO:root:FL Epoch: 267 Norm Difference for worker 1605 is 1.696836
INFO:root:FL Epoch: 267 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :925
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352720
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249289
INFO:root:FL Epoch: 267 Norm Difference for worker 925 is 1.477875
INFO:root:FL Epoch: 267 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :434
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336616
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189152
INFO:root:FL Epoch: 267 Norm Difference for worker 434 is 1.496905
INFO:root:FL Epoch: 267 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :484
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480677
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274572
INFO:root:FL Epoch: 267 Norm Difference for worker 484 is 1.729041
INFO:root:FL Epoch: 267 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :348
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303125
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421409
INFO:root:FL Epoch: 267 Norm Difference for worker 348 is 1.647605
INFO:root:FL Epoch: 267 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4933959090142757, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4930746630079714
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4930707021372471
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4930706660644382
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.46421269634190726 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.07512048942347367                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1881
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571328
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244782
INFO:root:FL Epoch: 268 Norm Difference for worker 1881 is 1.560202
INFO:root:FL Epoch: 268 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :711
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500985
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213018
INFO:root:FL Epoch: 268 Norm Difference for worker 711 is 1.605187
INFO:root:FL Epoch: 268 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1677
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481889
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399856
INFO:root:FL Epoch: 268 Norm Difference for worker 1677 is 1.673034
INFO:root:FL Epoch: 268 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :664
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456159
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290484
INFO:root:FL Epoch: 268 Norm Difference for worker 664 is 1.77089
INFO:root:FL Epoch: 268 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :661
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347356
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402516
INFO:root:FL Epoch: 268 Norm Difference for worker 661 is 1.656176
INFO:root:FL Epoch: 268 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1595
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369663
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384268
INFO:root:FL Epoch: 268 Norm Difference for worker 1595 is 1.520859
INFO:root:FL Epoch: 268 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :304
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350375
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353055
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 304 is 1.588909
INFO:root:FL Epoch: 268 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1712
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339075
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259965
INFO:root:FL Epoch: 268 Norm Difference for worker 1712 is 1.510018
INFO:root:FL Epoch: 268 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1175
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418058
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115088
INFO:root:FL Epoch: 268 Norm Difference for worker 1175 is 1.617246
INFO:root:FL Epoch: 268 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1844
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376974
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233088
INFO:root:FL Epoch: 268 Norm Difference for worker 1844 is 1.487399
INFO:root:FL Epoch: 268 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5107248188950748, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.510545088953994
INFO:root:#### Oracle Cals: 3, Objective Val: 1.510542716509091
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5105426761093415
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.467258995070177 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.06666880038877328                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1376
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433738
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.135919
INFO:root:FL Epoch: 269 Norm Difference for worker 1376 is 1.677638
INFO:root:FL Epoch: 269 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :336
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 336 is 1.638173
INFO:root:FL Epoch: 269 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1276
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415399
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293562
INFO:root:FL Epoch: 269 Norm Difference for worker 1276 is 1.634495
INFO:root:FL Epoch: 269 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1589
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276353
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178955
INFO:root:FL Epoch: 269 Norm Difference for worker 1589 is 1.748407
INFO:root:FL Epoch: 269 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :673
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409726
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333344
INFO:root:FL Epoch: 269 Norm Difference for worker 673 is 1.614849
INFO:root:FL Epoch: 269 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :525
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730684
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166573
INFO:root:FL Epoch: 269 Norm Difference for worker 525 is 1.773415
INFO:root:FL Epoch: 269 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :278
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.195723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 278 is 1.780125
INFO:root:FL Epoch: 269 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1929
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549665
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130532
INFO:root:FL Epoch: 269 Norm Difference for worker 1929 is 1.554722
INFO:root:FL Epoch: 269 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :883
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410542
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240911
INFO:root:FL Epoch: 269 Norm Difference for worker 883 is 1.687326
INFO:root:FL Epoch: 269 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :602
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429728
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189276
INFO:root:FL Epoch: 269 Norm Difference for worker 602 is 1.582104
INFO:root:FL Epoch: 269 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5745242317449397, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5743659985496166
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5743641089172757
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5743640410885236
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.4697085829342113 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.0776996494581302                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :642
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560136
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203580
INFO:root:FL Epoch: 270 Norm Difference for worker 642 is 1.66693
INFO:root:FL Epoch: 270 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :292
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302756
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 292 is 1.731912
INFO:root:FL Epoch: 270 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1822
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568765
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189261
INFO:root:FL Epoch: 270 Norm Difference for worker 1822 is 1.739193
INFO:root:FL Epoch: 270 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :896
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453667
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386812
INFO:root:FL Epoch: 270 Norm Difference for worker 896 is 1.652123
INFO:root:FL Epoch: 270 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :733
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552416
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288603
INFO:root:FL Epoch: 270 Norm Difference for worker 733 is 1.712564
INFO:root:FL Epoch: 270 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :899
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324354
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215046
INFO:root:FL Epoch: 270 Norm Difference for worker 899 is 1.73587
INFO:root:FL Epoch: 270 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :640
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662256
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191962
INFO:root:FL Epoch: 270 Norm Difference for worker 640 is 1.631393
INFO:root:FL Epoch: 270 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1499
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590108
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251952
INFO:root:FL Epoch: 270 Norm Difference for worker 1499 is 1.596511
INFO:root:FL Epoch: 270 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :203
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179098
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 203 is 1.63904
INFO:root:FL Epoch: 270 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :906
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454566
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.111668
INFO:root:FL Epoch: 270 Norm Difference for worker 906 is 1.535816
INFO:root:FL Epoch: 270 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5698987194392797, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5698103602461038
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5698091406527974
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5698091138261594
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.4775552504202899 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.0917500661065181                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.065181
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.037067
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.030427717370912433 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.021843691263347863 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.490236
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.073566
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.070989
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.03229866782203317 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.0215213724412024 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.502538
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.058477
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.062236
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.03125722877060374 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.02276745708659291 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.482112
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1386
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483288
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155108
INFO:root:FL Epoch: 271 Norm Difference for worker 1386 is 1.600909
INFO:root:FL Epoch: 271 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :312
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 312 is 1.548098
INFO:root:FL Epoch: 271 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :273
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421492
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.204267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 273 is 1.524643
INFO:root:FL Epoch: 271 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :324
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 324 is 1.606554
INFO:root:FL Epoch: 271 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :868
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426048
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223257
INFO:root:FL Epoch: 271 Norm Difference for worker 868 is 1.638494
INFO:root:FL Epoch: 271 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :587
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839798
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289860
INFO:root:FL Epoch: 271 Norm Difference for worker 587 is 1.569116
INFO:root:FL Epoch: 271 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1406
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428940
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219731
INFO:root:FL Epoch: 271 Norm Difference for worker 1406 is 1.600036
INFO:root:FL Epoch: 271 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.198930083649719, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1749363913209998
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1700976725853303
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1688764358206205
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1685532258651914
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1684673642813457
INFO:root:#### Oracle Cals: 7, Objective Val: 1.1684444563512424
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1684386647170344
INFO:root:#### Oracle Cals: 9, Objective Val: 1.1684368711751691
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1684364678064516
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1684364627854753
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.47709883661831126 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.037777334451675415                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1369
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.982906
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182587
INFO:root:FL Epoch: 272 Norm Difference for worker 1369 is 1.951866
INFO:root:FL Epoch: 272 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1078
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418200
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249797
INFO:root:FL Epoch: 272 Norm Difference for worker 1078 is 1.751131
INFO:root:FL Epoch: 272 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :946
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539609
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204039
INFO:root:FL Epoch: 272 Norm Difference for worker 946 is 1.740892
INFO:root:FL Epoch: 272 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1596
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564778
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276222
INFO:root:FL Epoch: 272 Norm Difference for worker 1596 is 1.778619
INFO:root:FL Epoch: 272 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1754
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654416
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213371
INFO:root:FL Epoch: 272 Norm Difference for worker 1754 is 1.748785
INFO:root:FL Epoch: 272 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1893
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655367
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325798
INFO:root:FL Epoch: 272 Norm Difference for worker 1893 is 2.062839
INFO:root:FL Epoch: 272 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :76
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 76 is 1.879992
INFO:root:FL Epoch: 272 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.126988
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 1.812984
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1514
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652688
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307503
INFO:root:FL Epoch: 272 Norm Difference for worker 1514 is 1.851987
INFO:root:FL Epoch: 272 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :134
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.783603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.113066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 134 is 1.756291
INFO:root:FL Epoch: 272 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.7245213772285286, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.7242421628348075
INFO:root:#### Oracle Cals: 3, Objective Val: 1.7242390666914789
INFO:root:#### Oracle Cals: 4, Objective Val: 1.7242390379288532
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.47089215061243844 and Test Accuracy:75.0 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.05735204586138328                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1624
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363880
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193511
INFO:root:FL Epoch: 273 Norm Difference for worker 1624 is 1.619197
INFO:root:FL Epoch: 273 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1303
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.986457
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187148
INFO:root:FL Epoch: 273 Norm Difference for worker 1303 is 1.705188
INFO:root:FL Epoch: 273 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1603
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611028
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244873
INFO:root:FL Epoch: 273 Norm Difference for worker 1603 is 1.670861
INFO:root:FL Epoch: 273 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :789
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628330
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317151
INFO:root:FL Epoch: 273 Norm Difference for worker 789 is 1.636514
INFO:root:FL Epoch: 273 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1461
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336963
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213583
INFO:root:FL Epoch: 273 Norm Difference for worker 1461 is 1.612325
INFO:root:FL Epoch: 273 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1439
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643976
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249210
INFO:root:FL Epoch: 273 Norm Difference for worker 1439 is 1.733486
INFO:root:FL Epoch: 273 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :566
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833595
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281398
INFO:root:FL Epoch: 273 Norm Difference for worker 566 is 1.728387
INFO:root:FL Epoch: 273 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :614
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415615
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350265
INFO:root:FL Epoch: 273 Norm Difference for worker 614 is 1.740493
INFO:root:FL Epoch: 273 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :747
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479894
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324574
INFO:root:FL Epoch: 273 Norm Difference for worker 747 is 1.661084
INFO:root:FL Epoch: 273 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1857
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411934
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246120
INFO:root:FL Epoch: 273 Norm Difference for worker 1857 is 1.774504
INFO:root:FL Epoch: 273 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5968303630627614, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5967070360913393
INFO:root:#### Oracle Cals: 3, Objective Val: 1.596705451248599
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5967054110165793
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.4647355780881994 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.0768225494151314                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :722
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585680
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297968
INFO:root:FL Epoch: 274 Norm Difference for worker 722 is 1.723234
INFO:root:FL Epoch: 274 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1292
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568085
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446132
INFO:root:FL Epoch: 274 Norm Difference for worker 1292 is 1.747656
INFO:root:FL Epoch: 274 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :200
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 200 is 1.671646
INFO:root:FL Epoch: 274 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1745
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351806
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258516
INFO:root:FL Epoch: 274 Norm Difference for worker 1745 is 1.607907
INFO:root:FL Epoch: 274 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1317
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423014
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163502
INFO:root:FL Epoch: 274 Norm Difference for worker 1317 is 1.565776
INFO:root:FL Epoch: 274 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :888
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525878
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236414
INFO:root:FL Epoch: 274 Norm Difference for worker 888 is 1.695531
INFO:root:FL Epoch: 274 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :600
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266903
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223399
INFO:root:FL Epoch: 274 Norm Difference for worker 600 is 1.601936
INFO:root:FL Epoch: 274 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1582
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657197
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344151
INFO:root:FL Epoch: 274 Norm Difference for worker 1582 is 1.820909
INFO:root:FL Epoch: 274 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :122
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.260652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 122 is 1.576689
INFO:root:FL Epoch: 274 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1276
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456976
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227303
INFO:root:FL Epoch: 274 Norm Difference for worker 1276 is 1.437256
INFO:root:FL Epoch: 274 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5530329130676284, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.552738636200584
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5527348961433032
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5527348278024018
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.4502230093759649 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.07192860854168732                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :1037
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321477
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271591
INFO:root:FL Epoch: 275 Norm Difference for worker 1037 is 1.692201
INFO:root:FL Epoch: 275 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1924
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312881
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360399
INFO:root:FL Epoch: 275 Norm Difference for worker 1924 is 1.650659
INFO:root:FL Epoch: 275 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1138
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624071
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191053
INFO:root:FL Epoch: 275 Norm Difference for worker 1138 is 1.797554
INFO:root:FL Epoch: 275 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :939
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802272
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432349
INFO:root:FL Epoch: 275 Norm Difference for worker 939 is 1.790044
INFO:root:FL Epoch: 275 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :622
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819815
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280144
INFO:root:FL Epoch: 275 Norm Difference for worker 622 is 1.724397
INFO:root:FL Epoch: 275 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1818
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692281
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304357
INFO:root:FL Epoch: 275 Norm Difference for worker 1818 is 1.69681
INFO:root:FL Epoch: 275 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :213
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.831072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 213 is 1.766383
INFO:root:FL Epoch: 275 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1662
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670137
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134760
INFO:root:FL Epoch: 275 Norm Difference for worker 1662 is 1.671046
INFO:root:FL Epoch: 275 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :829
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441261
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290426
INFO:root:FL Epoch: 275 Norm Difference for worker 829 is 1.730435
INFO:root:FL Epoch: 275 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :968
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479231
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341662
INFO:root:FL Epoch: 275 Norm Difference for worker 968 is 1.646329
INFO:root:FL Epoch: 275 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.620881404606654, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6208174597768072
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6208166954121483
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6208166613545267
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.4336295688853544 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.0689362237850825                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 276 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :20
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 20 is 1.569379
INFO:root:FL Epoch: 276 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1906
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332338
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357749
INFO:root:FL Epoch: 276 Norm Difference for worker 1906 is 1.580857
INFO:root:FL Epoch: 276 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :168
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.381698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 168 is 1.719315
INFO:root:FL Epoch: 276 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :97
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.223213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 97 is 1.653151
INFO:root:FL Epoch: 276 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :947
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279548
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224694
INFO:root:FL Epoch: 276 Norm Difference for worker 947 is 1.523564
INFO:root:FL Epoch: 276 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :950
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445523
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277202
INFO:root:FL Epoch: 276 Norm Difference for worker 950 is 1.461519
INFO:root:FL Epoch: 276 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1018
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541109
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230491
INFO:root:FL Epoch: 276 Norm Difference for worker 1018 is 1.602301
INFO:root:FL Epoch: 276 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :477
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679474
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431887
INFO:root:FL Epoch: 276 Norm Difference for worker 477 is 1.690362
INFO:root:FL Epoch: 276 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1388
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213986
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253102
INFO:root:FL Epoch: 276 Norm Difference for worker 1388 is 1.606901
INFO:root:FL Epoch: 276 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1776
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454589
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210677
INFO:root:FL Epoch: 276 Norm Difference for worker 1776 is 1.616893
INFO:root:FL Epoch: 276 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5099409447316752, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.509797640575797
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5097957475504113
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5097957338289971
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.45791054122588215 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.07944977966447671                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :140
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 140 is 1.736723
INFO:root:FL Epoch: 277 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1142
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567122
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196678
INFO:root:FL Epoch: 277 Norm Difference for worker 1142 is 1.596712
INFO:root:FL Epoch: 277 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :362
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551911
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278426
INFO:root:FL Epoch: 277 Norm Difference for worker 362 is 1.596931
INFO:root:FL Epoch: 277 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :200
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 200 is 1.588952
INFO:root:FL Epoch: 277 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :503
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308171
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185924
INFO:root:FL Epoch: 277 Norm Difference for worker 503 is 1.502779
INFO:root:FL Epoch: 277 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1050
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413086
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275270
INFO:root:FL Epoch: 277 Norm Difference for worker 1050 is 1.682185
INFO:root:FL Epoch: 277 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :405
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397819
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202618
INFO:root:FL Epoch: 277 Norm Difference for worker 405 is 1.667822
INFO:root:FL Epoch: 277 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1577
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698598
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190142
INFO:root:FL Epoch: 277 Norm Difference for worker 1577 is 1.640709
INFO:root:FL Epoch: 277 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1490
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.939768
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265997
INFO:root:FL Epoch: 277 Norm Difference for worker 1490 is 1.588738
INFO:root:FL Epoch: 277 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581430
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306323
INFO:root:FL Epoch: 277 Norm Difference for worker 1483 is 1.533173
INFO:root:FL Epoch: 277 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.518276819632264, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.518154276773837
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5181526223844484
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5181526059621961
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.46619993448257446 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.0789340337117513                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 278 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :103
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 103 is 1.510867
INFO:root:FL Epoch: 278 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :304
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 304 is 1.526141
INFO:root:FL Epoch: 278 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1032
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271344
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514204
INFO:root:FL Epoch: 278 Norm Difference for worker 1032 is 1.576408
INFO:root:FL Epoch: 278 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :468
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482618
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256760
INFO:root:FL Epoch: 278 Norm Difference for worker 468 is 1.619106
INFO:root:FL Epoch: 278 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1597
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611671
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323279
INFO:root:FL Epoch: 278 Norm Difference for worker 1597 is 1.553319
INFO:root:FL Epoch: 278 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :227
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.335332
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 227 is 1.599728
INFO:root:FL Epoch: 278 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :380
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444255
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431285
INFO:root:FL Epoch: 278 Norm Difference for worker 380 is 1.694998
INFO:root:FL Epoch: 278 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :825
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477550
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169613
INFO:root:FL Epoch: 278 Norm Difference for worker 825 is 1.432402
INFO:root:FL Epoch: 278 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1670
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746511
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257286
INFO:root:FL Epoch: 278 Norm Difference for worker 1670 is 1.593457
INFO:root:FL Epoch: 278 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1007
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604927
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216186
INFO:root:FL Epoch: 278 Norm Difference for worker 1007 is 1.574331
INFO:root:FL Epoch: 278 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.483594595130127, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4834702346367377
INFO:root:#### Oracle Cals: 3, Objective Val: 1.483468681694411
INFO:root:#### Oracle Cals: 4, Objective Val: 1.483468685732619
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.464991536210565 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.07834948102633159                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1013
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916347
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444127
INFO:root:FL Epoch: 279 Norm Difference for worker 1013 is 1.813782
INFO:root:FL Epoch: 279 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :873
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414314
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303455
INFO:root:FL Epoch: 279 Norm Difference for worker 873 is 1.693146
INFO:root:FL Epoch: 279 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1343
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422260
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248868
INFO:root:FL Epoch: 279 Norm Difference for worker 1343 is 1.569106
INFO:root:FL Epoch: 279 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1746
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419964
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333685
INFO:root:FL Epoch: 279 Norm Difference for worker 1746 is 1.712556
INFO:root:FL Epoch: 279 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :499
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473520
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162717
INFO:root:FL Epoch: 279 Norm Difference for worker 499 is 1.57342
INFO:root:FL Epoch: 279 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1131
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649313
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349797
INFO:root:FL Epoch: 279 Norm Difference for worker 1131 is 1.682849
INFO:root:FL Epoch: 279 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :310
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 310 is 1.593981
INFO:root:FL Epoch: 279 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :223
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.305319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 223 is 1.822767
INFO:root:FL Epoch: 279 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1692
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549587
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348144
INFO:root:FL Epoch: 279 Norm Difference for worker 1692 is 1.8271
INFO:root:FL Epoch: 279 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1352
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529079
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271364
INFO:root:FL Epoch: 279 Norm Difference for worker 1352 is 1.610948
INFO:root:FL Epoch: 279 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5924688908707902, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5922638339381163
INFO:root:#### Oracle Cals: 3, Objective Val: 1.592260815095899
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5922607596088327
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.4781118578770581 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.09750114753842354                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1925
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388873
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263883
INFO:root:FL Epoch: 280 Norm Difference for worker 1925 is 1.670892
INFO:root:FL Epoch: 280 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1145
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496191
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232352
INFO:root:FL Epoch: 280 Norm Difference for worker 1145 is 1.660909
INFO:root:FL Epoch: 280 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :636
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489432
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288593
INFO:root:FL Epoch: 280 Norm Difference for worker 636 is 1.749105
INFO:root:FL Epoch: 280 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1906
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668999
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373579
INFO:root:FL Epoch: 280 Norm Difference for worker 1906 is 1.617478
INFO:root:FL Epoch: 280 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1542
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516626
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349842
INFO:root:FL Epoch: 280 Norm Difference for worker 1542 is 1.59997
INFO:root:FL Epoch: 280 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :348
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409246
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270801
INFO:root:FL Epoch: 280 Norm Difference for worker 348 is 1.608803
INFO:root:FL Epoch: 280 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :704
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.928412
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291023
INFO:root:FL Epoch: 280 Norm Difference for worker 704 is 1.499249
INFO:root:FL Epoch: 280 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1809
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603650
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308700
INFO:root:FL Epoch: 280 Norm Difference for worker 1809 is 1.580112
INFO:root:FL Epoch: 280 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1212
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624355
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232184
INFO:root:FL Epoch: 280 Norm Difference for worker 1212 is 1.573509
INFO:root:FL Epoch: 280 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1390
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433059
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228991
INFO:root:FL Epoch: 280 Norm Difference for worker 1390 is 1.522391
INFO:root:FL Epoch: 280 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5150999035500665, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5149973158359071
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5149960299622633
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5149960098165571
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.46454764113706704 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.08840184224148591                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.065829
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.039849
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.030294785276055336 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.023951314762234686 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.509956
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.085299
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.051740
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.03244395119448503 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.02526340400800109 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.463605
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.072806
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.054131
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.034163207902262606 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.023371750209480523 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.488013
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :907
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483744
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349663
INFO:root:FL Epoch: 281 Norm Difference for worker 907 is 1.606678
INFO:root:FL Epoch: 281 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :330
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602498
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 330 is 1.64333
INFO:root:FL Epoch: 281 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1916
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291241
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309387
INFO:root:FL Epoch: 281 Norm Difference for worker 1916 is 1.49716
INFO:root:FL Epoch: 281 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1435
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550867
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369793
INFO:root:FL Epoch: 281 Norm Difference for worker 1435 is 1.543077
INFO:root:FL Epoch: 281 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1385
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804701
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280962
INFO:root:FL Epoch: 281 Norm Difference for worker 1385 is 1.571437
INFO:root:FL Epoch: 281 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1108
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463681
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438612
INFO:root:FL Epoch: 281 Norm Difference for worker 1108 is 1.634317
INFO:root:FL Epoch: 281 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :449
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501358
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142846
INFO:root:FL Epoch: 281 Norm Difference for worker 449 is 1.561897
INFO:root:FL Epoch: 281 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1971484311807647, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1722653549527893
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1672515945339728
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1659999725584431
INFO:root:#### Oracle Cals: 5, Objective Val: 1.165675281943385
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1655913175079706
INFO:root:#### Oracle Cals: 7, Objective Val: 1.1655697528900102
INFO:root:#### Oracle Cals: 8, Objective Val: 1.165564458413031
INFO:root:#### Oracle Cals: 9, Objective Val: 1.1655629439785442
INFO:root:#### Oracle Cals: 10, Objective Val: 1.16556253598711
INFO:root:#### Oracle Cals: 11, Objective Val: 1.165562411762805
INFO:root:#### Oracle Cals: 12, Objective Val: 1.1655623862713211
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.47799937514697804 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.04138926354547342                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 282 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :194
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.291196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.203018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 194 is 1.797683
INFO:root:FL Epoch: 282 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1670
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264836
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136581
INFO:root:FL Epoch: 282 Norm Difference for worker 1670 is 1.612958
INFO:root:FL Epoch: 282 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :368
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542870
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280953
INFO:root:FL Epoch: 282 Norm Difference for worker 368 is 1.784259
INFO:root:FL Epoch: 282 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1195
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380922
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254652
INFO:root:FL Epoch: 282 Norm Difference for worker 1195 is 1.692488
INFO:root:FL Epoch: 282 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1701
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245475
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220322
INFO:root:FL Epoch: 282 Norm Difference for worker 1701 is 1.76274
INFO:root:FL Epoch: 282 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :24
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.197430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 24 is 1.758063
INFO:root:FL Epoch: 282 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1893
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488496
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259020
INFO:root:FL Epoch: 282 Norm Difference for worker 1893 is 1.838907
INFO:root:FL Epoch: 282 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1109
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665054
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185919
INFO:root:FL Epoch: 282 Norm Difference for worker 1109 is 1.82493
INFO:root:FL Epoch: 282 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1734
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660774
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153945
INFO:root:FL Epoch: 282 Norm Difference for worker 1734 is 1.743626
INFO:root:FL Epoch: 282 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.278293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.191264
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 1.691944
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6533420720766911, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6532050841325652
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6532032159202028
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6532032120406632
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.46557922573650584 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.05635838769376278                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :177
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459832
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 177 is 1.694799
INFO:root:FL Epoch: 283 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :4
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 4 is 1.662865
INFO:root:FL Epoch: 283 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1015
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515961
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203515
INFO:root:FL Epoch: 283 Norm Difference for worker 1015 is 1.634135
INFO:root:FL Epoch: 283 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :346
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314712
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211024
INFO:root:FL Epoch: 283 Norm Difference for worker 346 is 1.514419
INFO:root:FL Epoch: 283 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :215
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.156153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 215 is 1.621946
INFO:root:FL Epoch: 283 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :938
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399112
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374983
INFO:root:FL Epoch: 283 Norm Difference for worker 938 is 1.751859
INFO:root:FL Epoch: 283 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1805
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341433
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293934
INFO:root:FL Epoch: 283 Norm Difference for worker 1805 is 1.730349
INFO:root:FL Epoch: 283 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :495
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605033
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123745
INFO:root:FL Epoch: 283 Norm Difference for worker 495 is 1.66522
INFO:root:FL Epoch: 283 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :999
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276988
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335808
INFO:root:FL Epoch: 283 Norm Difference for worker 999 is 1.637717
INFO:root:FL Epoch: 283 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1886
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746363
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291293
INFO:root:FL Epoch: 283 Norm Difference for worker 1886 is 1.622406
INFO:root:FL Epoch: 283 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.569821449860934, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5697127018999377
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5697113645702017
INFO:root:#### Oracle Cals: 4, Objective Val: 1.569711357157822
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.46367667703067555 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.047581507513920464                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :386
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442633
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244489
INFO:root:FL Epoch: 284 Norm Difference for worker 386 is 1.528437
INFO:root:FL Epoch: 284 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1503
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354228
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224829
INFO:root:FL Epoch: 284 Norm Difference for worker 1503 is 1.653999
INFO:root:FL Epoch: 284 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1701
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409908
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360531
INFO:root:FL Epoch: 284 Norm Difference for worker 1701 is 1.562534
INFO:root:FL Epoch: 284 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :862
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540302
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190793
INFO:root:FL Epoch: 284 Norm Difference for worker 862 is 1.749688
INFO:root:FL Epoch: 284 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1169
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756610
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361531
INFO:root:FL Epoch: 284 Norm Difference for worker 1169 is 1.693169
INFO:root:FL Epoch: 284 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :346
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377115
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207158
INFO:root:FL Epoch: 284 Norm Difference for worker 346 is 1.411184
INFO:root:FL Epoch: 284 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661756
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310590
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 1.654562
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1492
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343359
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208789
INFO:root:FL Epoch: 284 Norm Difference for worker 1492 is 1.582195
INFO:root:FL Epoch: 284 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1401
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552501
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292846
INFO:root:FL Epoch: 284 Norm Difference for worker 1401 is 1.662289
INFO:root:FL Epoch: 284 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :424
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637920
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299610
INFO:root:FL Epoch: 284 Norm Difference for worker 424 is 1.496165
INFO:root:FL Epoch: 284 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5187513051247634, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.518445413550796
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5184401553315268
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5184401333689523
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.4785616415388444 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.05470658279955387                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :1837
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388873
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297378
INFO:root:FL Epoch: 285 Norm Difference for worker 1837 is 1.637681
INFO:root:FL Epoch: 285 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :824
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789332
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340181
INFO:root:FL Epoch: 285 Norm Difference for worker 824 is 1.609926
INFO:root:FL Epoch: 285 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1007
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573315
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310104
INFO:root:FL Epoch: 285 Norm Difference for worker 1007 is 1.583081
INFO:root:FL Epoch: 285 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :253
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 253 is 1.610932
INFO:root:FL Epoch: 285 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1875
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425587
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238124
INFO:root:FL Epoch: 285 Norm Difference for worker 1875 is 1.738482
INFO:root:FL Epoch: 285 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :985
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776570
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315183
INFO:root:FL Epoch: 285 Norm Difference for worker 985 is 1.673638
INFO:root:FL Epoch: 285 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1657
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262078
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233179
INFO:root:FL Epoch: 285 Norm Difference for worker 1657 is 1.561757
INFO:root:FL Epoch: 285 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :468
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333617
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258379
INFO:root:FL Epoch: 285 Norm Difference for worker 468 is 1.655104
INFO:root:FL Epoch: 285 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1548
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332551
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305259
INFO:root:FL Epoch: 285 Norm Difference for worker 1548 is 1.699771
INFO:root:FL Epoch: 285 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1947
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545337
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232004
INFO:root:FL Epoch: 285 Norm Difference for worker 1947 is 1.547432
INFO:root:FL Epoch: 285 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5378539990613804, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5377412003002278
INFO:root:#### Oracle Cals: 3, Objective Val: 1.537739858619429
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5377398135197238
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.47437656977597403 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.06958648469299078                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1275
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394135
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.092765
INFO:root:FL Epoch: 286 Norm Difference for worker 1275 is 1.555797
INFO:root:FL Epoch: 286 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1599
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705642
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293877
INFO:root:FL Epoch: 286 Norm Difference for worker 1599 is 1.734037
INFO:root:FL Epoch: 286 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :419
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534198
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245204
INFO:root:FL Epoch: 286 Norm Difference for worker 419 is 1.500034
INFO:root:FL Epoch: 286 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :900
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483753
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396122
INFO:root:FL Epoch: 286 Norm Difference for worker 900 is 1.60676
INFO:root:FL Epoch: 286 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :474
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520898
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238230
INFO:root:FL Epoch: 286 Norm Difference for worker 474 is 1.802589
INFO:root:FL Epoch: 286 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :471
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379733
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197457
INFO:root:FL Epoch: 286 Norm Difference for worker 471 is 1.704193
INFO:root:FL Epoch: 286 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1727
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556230
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230441
INFO:root:FL Epoch: 286 Norm Difference for worker 1727 is 1.629015
INFO:root:FL Epoch: 286 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :881
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309975
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167899
INFO:root:FL Epoch: 286 Norm Difference for worker 881 is 1.533883
INFO:root:FL Epoch: 286 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :697
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345624
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340285
INFO:root:FL Epoch: 286 Norm Difference for worker 697 is 1.726805
INFO:root:FL Epoch: 286 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :483
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611327
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285498
INFO:root:FL Epoch: 286 Norm Difference for worker 483 is 1.603754
INFO:root:FL Epoch: 286 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5516052187035303, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.551387764505117
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5513851211616614
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5513850879789142
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.45141353852608623 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.05836432178815206                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1262
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631966
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382488
INFO:root:FL Epoch: 287 Norm Difference for worker 1262 is 1.828946
INFO:root:FL Epoch: 287 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :690
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500086
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130780
INFO:root:FL Epoch: 287 Norm Difference for worker 690 is 1.641964
INFO:root:FL Epoch: 287 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :59
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 59 is 1.561576
INFO:root:FL Epoch: 287 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1825
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608819
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390138
INFO:root:FL Epoch: 287 Norm Difference for worker 1825 is 1.740253
INFO:root:FL Epoch: 287 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631733
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302887
INFO:root:FL Epoch: 287 Norm Difference for worker 509 is 1.869375
INFO:root:FL Epoch: 287 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :444
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535016
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271013
INFO:root:FL Epoch: 287 Norm Difference for worker 444 is 1.759759
INFO:root:FL Epoch: 287 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :246
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.829951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411837
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 246 is 1.685868
INFO:root:FL Epoch: 287 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :841
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526879
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314157
INFO:root:FL Epoch: 287 Norm Difference for worker 841 is 1.685705
INFO:root:FL Epoch: 287 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :417
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433209
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396164
INFO:root:FL Epoch: 287 Norm Difference for worker 417 is 1.715045
INFO:root:FL Epoch: 287 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493520
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176145
INFO:root:FL Epoch: 287 Norm Difference for worker 1509 is 1.673345
INFO:root:FL Epoch: 287 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6140736098935475, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6138952712169043
INFO:root:#### Oracle Cals: 3, Objective Val: 1.613893028812727
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6138929720954356
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.44326801335110383 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.0799418988948067                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :893
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469753
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301787
INFO:root:FL Epoch: 288 Norm Difference for worker 893 is 1.589161
INFO:root:FL Epoch: 288 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :133
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 133 is 1.563899
INFO:root:FL Epoch: 288 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :732
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620284
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380615
INFO:root:FL Epoch: 288 Norm Difference for worker 732 is 1.648328
INFO:root:FL Epoch: 288 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452324
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364098
INFO:root:FL Epoch: 288 Norm Difference for worker 912 is 1.481535
INFO:root:FL Epoch: 288 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :831
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577095
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133062
INFO:root:FL Epoch: 288 Norm Difference for worker 831 is 1.563395
INFO:root:FL Epoch: 288 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1258
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597505
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121209
INFO:root:FL Epoch: 288 Norm Difference for worker 1258 is 1.556602
INFO:root:FL Epoch: 288 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1406
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500895
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297566
INFO:root:FL Epoch: 288 Norm Difference for worker 1406 is 1.563535
INFO:root:FL Epoch: 288 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :510
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336602
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210695
INFO:root:FL Epoch: 288 Norm Difference for worker 510 is 1.547193
INFO:root:FL Epoch: 288 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :75
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 75 is 1.657109
INFO:root:FL Epoch: 288 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1065
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751844
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377100
INFO:root:FL Epoch: 288 Norm Difference for worker 1065 is 1.661465
INFO:root:FL Epoch: 288 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4908868312680286, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4908131382303385
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4908122324052282
INFO:root:#### Oracle Cals: 4, Objective Val: 1.490812222760163
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.4695436358451843 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.06932024005800486                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :444
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596427
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167177
INFO:root:FL Epoch: 289 Norm Difference for worker 444 is 1.514461
INFO:root:FL Epoch: 289 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1645
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554514
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251639
INFO:root:FL Epoch: 289 Norm Difference for worker 1645 is 1.479058
INFO:root:FL Epoch: 289 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :199
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494647
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323988
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 199 is 1.681896
INFO:root:FL Epoch: 289 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :500
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371649
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298933
INFO:root:FL Epoch: 289 Norm Difference for worker 500 is 1.561944
INFO:root:FL Epoch: 289 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :917
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611497
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337395
INFO:root:FL Epoch: 289 Norm Difference for worker 917 is 1.681145
INFO:root:FL Epoch: 289 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1421
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384550
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194494
INFO:root:FL Epoch: 289 Norm Difference for worker 1421 is 1.439091
INFO:root:FL Epoch: 289 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1485
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550937
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295638
INFO:root:FL Epoch: 289 Norm Difference for worker 1485 is 1.505314
INFO:root:FL Epoch: 289 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :306
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.126915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 306 is 1.540217
INFO:root:FL Epoch: 289 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :638
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659745
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282929
INFO:root:FL Epoch: 289 Norm Difference for worker 638 is 1.490519
INFO:root:FL Epoch: 289 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1471
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448912
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291536
INFO:root:FL Epoch: 289 Norm Difference for worker 1471 is 1.595761
INFO:root:FL Epoch: 289 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4617634798574488, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4615315712394297
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4615283887318884
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4615284230352845
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.45269692119430094 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.06803275862087806                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1328
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492737
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221224
INFO:root:FL Epoch: 290 Norm Difference for worker 1328 is 1.592963
INFO:root:FL Epoch: 290 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :498
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571131
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236393
INFO:root:FL Epoch: 290 Norm Difference for worker 498 is 1.524901
INFO:root:FL Epoch: 290 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1566
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857767
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217277
INFO:root:FL Epoch: 290 Norm Difference for worker 1566 is 1.570372
INFO:root:FL Epoch: 290 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1908
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296845
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243891
INFO:root:FL Epoch: 290 Norm Difference for worker 1908 is 1.558762
INFO:root:FL Epoch: 290 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1688
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602453
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309818
INFO:root:FL Epoch: 290 Norm Difference for worker 1688 is 1.562223
INFO:root:FL Epoch: 290 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :885
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442716
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158121
INFO:root:FL Epoch: 290 Norm Difference for worker 885 is 1.541363
INFO:root:FL Epoch: 290 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :907
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472877
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310370
INFO:root:FL Epoch: 290 Norm Difference for worker 907 is 1.594542
INFO:root:FL Epoch: 290 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1256
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557530
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261454
INFO:root:FL Epoch: 290 Norm Difference for worker 1256 is 1.469235
INFO:root:FL Epoch: 290 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1058
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327250
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220840
INFO:root:FL Epoch: 290 Norm Difference for worker 1058 is 1.695237
INFO:root:FL Epoch: 290 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1876
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766340
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230388
INFO:root:FL Epoch: 290 Norm Difference for worker 1876 is 1.669136
INFO:root:FL Epoch: 290 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4937310321234574, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4935949468993488
INFO:root:#### Oracle Cals: 3, Objective Val: 1.493593328101581
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4935933039470342
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.4498301428907058 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.07242990906039874                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.071267
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.045197
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.03444471303373575 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.02234470918774605 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.429621
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.094347
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.036609
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.03177301259711385 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.02321513993665576 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.425306
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.071012
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.055511
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.03199154371395707 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.022052014246582985 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.472596
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1366
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390249
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264963
INFO:root:FL Epoch: 291 Norm Difference for worker 1366 is 1.526903
INFO:root:FL Epoch: 291 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1025
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786458
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282483
INFO:root:FL Epoch: 291 Norm Difference for worker 1025 is 1.551582
INFO:root:FL Epoch: 291 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1801
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512742
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333875
INFO:root:FL Epoch: 291 Norm Difference for worker 1801 is 1.638265
INFO:root:FL Epoch: 291 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1023
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396177
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434132
INFO:root:FL Epoch: 291 Norm Difference for worker 1023 is 1.552052
INFO:root:FL Epoch: 291 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :476
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275956
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146363
INFO:root:FL Epoch: 291 Norm Difference for worker 476 is 1.671805
INFO:root:FL Epoch: 291 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355754
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277660
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 1.678536
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1114
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293498
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367976
INFO:root:FL Epoch: 291 Norm Difference for worker 1114 is 1.742943
INFO:root:FL Epoch: 291 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2219498374816942, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1960153596846226
INFO:root:#### Oracle Cals: 3, Objective Val: 1.190732306171383
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1893944982393274
INFO:root:#### Oracle Cals: 5, Objective Val: 1.189043445367497
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1889518162196413
INFO:root:#### Oracle Cals: 7, Objective Val: 1.1889281989347265
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1889222173901275
INFO:root:#### Oracle Cals: 9, Objective Val: 1.188920577142482
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1889201535527607
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1889200786629095
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.4653470831758836 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.03945194867750009                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1472
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435383
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229944
INFO:root:FL Epoch: 292 Norm Difference for worker 1472 is 1.926086
INFO:root:FL Epoch: 292 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1744
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 1.049676
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178594
INFO:root:FL Epoch: 292 Norm Difference for worker 1744 is 1.687184
INFO:root:FL Epoch: 292 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :373
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574403
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204884
INFO:root:FL Epoch: 292 Norm Difference for worker 373 is 1.868773
INFO:root:FL Epoch: 292 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1755
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376242
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224675
INFO:root:FL Epoch: 292 Norm Difference for worker 1755 is 1.585293
INFO:root:FL Epoch: 292 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1251
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462366
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185909
INFO:root:FL Epoch: 292 Norm Difference for worker 1251 is 1.76913
INFO:root:FL Epoch: 292 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :364
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287831
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234872
INFO:root:FL Epoch: 292 Norm Difference for worker 364 is 1.80576
INFO:root:FL Epoch: 292 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :894
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.197084
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.102446
INFO:root:FL Epoch: 292 Norm Difference for worker 894 is 1.485727
INFO:root:FL Epoch: 292 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1005
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547635
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390323
INFO:root:FL Epoch: 292 Norm Difference for worker 1005 is 1.79535
INFO:root:FL Epoch: 292 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :388
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406806
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257794
INFO:root:FL Epoch: 292 Norm Difference for worker 388 is 1.651476
INFO:root:FL Epoch: 292 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1242
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272707
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254391
INFO:root:FL Epoch: 292 Norm Difference for worker 1242 is 1.683421
INFO:root:FL Epoch: 292 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6291926555340068, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6288294123192169
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6288244879325384
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6288244186125826
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.4571948296883527 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.047152395049730934                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1224
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554518
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467431
INFO:root:FL Epoch: 293 Norm Difference for worker 1224 is 1.758604
INFO:root:FL Epoch: 293 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :983
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630362
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314010
INFO:root:FL Epoch: 293 Norm Difference for worker 983 is 1.804945
INFO:root:FL Epoch: 293 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1414
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658003
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164667
INFO:root:FL Epoch: 293 Norm Difference for worker 1414 is 1.636967
INFO:root:FL Epoch: 293 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1763
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619861
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230734
INFO:root:FL Epoch: 293 Norm Difference for worker 1763 is 1.732246
INFO:root:FL Epoch: 293 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :305
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.280577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 305 is 1.650522
INFO:root:FL Epoch: 293 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :650
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370504
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631280
INFO:root:FL Epoch: 293 Norm Difference for worker 650 is 1.692838
INFO:root:FL Epoch: 293 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1660
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456461
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282898
INFO:root:FL Epoch: 293 Norm Difference for worker 1660 is 1.639259
INFO:root:FL Epoch: 293 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1700
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245786
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203172
INFO:root:FL Epoch: 293 Norm Difference for worker 1700 is 1.500747
INFO:root:FL Epoch: 293 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1483
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728660
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131526
INFO:root:FL Epoch: 293 Norm Difference for worker 1483 is 1.475937
INFO:root:FL Epoch: 293 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :860
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471448
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325649
INFO:root:FL Epoch: 293 Norm Difference for worker 860 is 1.779468
INFO:root:FL Epoch: 293 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.579950078553222, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5796475273601014
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5796434817805804
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5796434631544496
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.4738617416690378 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.04599276681741079                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :318
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.220746
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 318 is 1.539588
INFO:root:FL Epoch: 294 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1700
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213099
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218273
INFO:root:FL Epoch: 294 Norm Difference for worker 1700 is 1.324784
INFO:root:FL Epoch: 294 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :951
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708217
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192778
INFO:root:FL Epoch: 294 Norm Difference for worker 951 is 1.61732
INFO:root:FL Epoch: 294 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1022
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417023
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178254
INFO:root:FL Epoch: 294 Norm Difference for worker 1022 is 1.516182
INFO:root:FL Epoch: 294 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1087
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.205936
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202229
INFO:root:FL Epoch: 294 Norm Difference for worker 1087 is 1.570649
INFO:root:FL Epoch: 294 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :931
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504043
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228527
INFO:root:FL Epoch: 294 Norm Difference for worker 931 is 1.676881
INFO:root:FL Epoch: 294 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :653
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373332
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219518
INFO:root:FL Epoch: 294 Norm Difference for worker 653 is 1.545572
INFO:root:FL Epoch: 294 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :272
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 272 is 1.42537
INFO:root:FL Epoch: 294 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1459
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409279
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376452
INFO:root:FL Epoch: 294 Norm Difference for worker 1459 is 1.606673
INFO:root:FL Epoch: 294 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1399
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326978
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209134
INFO:root:FL Epoch: 294 Norm Difference for worker 1399 is 1.60249
INFO:root:FL Epoch: 294 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.461968521012607, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4617126457499887
INFO:root:#### Oracle Cals: 3, Objective Val: 1.461709025137142
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4617089461214372
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.4798780048594755 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.06028146824489037                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :675
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566581
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256057
INFO:root:FL Epoch: 295 Norm Difference for worker 675 is 1.824387
INFO:root:FL Epoch: 295 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1942
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527311
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240474
INFO:root:FL Epoch: 295 Norm Difference for worker 1942 is 1.732691
INFO:root:FL Epoch: 295 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1406
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505847
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171850
INFO:root:FL Epoch: 295 Norm Difference for worker 1406 is 1.532267
INFO:root:FL Epoch: 295 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1321
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513467
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255816
INFO:root:FL Epoch: 295 Norm Difference for worker 1321 is 1.791961
INFO:root:FL Epoch: 295 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :443
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502178
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401984
INFO:root:FL Epoch: 295 Norm Difference for worker 443 is 1.845893
INFO:root:FL Epoch: 295 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :427
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439815
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236755
INFO:root:FL Epoch: 295 Norm Difference for worker 427 is 1.632006
INFO:root:FL Epoch: 295 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1883
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639681
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370915
INFO:root:FL Epoch: 295 Norm Difference for worker 1883 is 1.780838
INFO:root:FL Epoch: 295 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :918
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513269
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250837
INFO:root:FL Epoch: 295 Norm Difference for worker 918 is 1.641688
INFO:root:FL Epoch: 295 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :638
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605762
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366999
INFO:root:FL Epoch: 295 Norm Difference for worker 638 is 1.571813
INFO:root:FL Epoch: 295 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1630
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510741
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382869
INFO:root:FL Epoch: 295 Norm Difference for worker 1630 is 1.850851
INFO:root:FL Epoch: 295 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6210637015303473, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6208065291735005
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6208029657417033
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6208029144448752
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.4849592114196104 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.06970419424275558                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1480
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610688
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206276
INFO:root:FL Epoch: 296 Norm Difference for worker 1480 is 1.729596
INFO:root:FL Epoch: 296 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :79
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369706
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 79 is 1.570566
INFO:root:FL Epoch: 296 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1343
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384554
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157358
INFO:root:FL Epoch: 296 Norm Difference for worker 1343 is 1.504597
INFO:root:FL Epoch: 296 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1312
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660042
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180833
INFO:root:FL Epoch: 296 Norm Difference for worker 1312 is 1.592972
INFO:root:FL Epoch: 296 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :198
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 198 is 1.548634
INFO:root:FL Epoch: 296 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541433
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245189
INFO:root:FL Epoch: 296 Norm Difference for worker 1941 is 1.494831
INFO:root:FL Epoch: 296 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :975
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525141
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161483
INFO:root:FL Epoch: 296 Norm Difference for worker 975 is 1.637539
INFO:root:FL Epoch: 296 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :496
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353129
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152311
INFO:root:FL Epoch: 296 Norm Difference for worker 496 is 1.568697
INFO:root:FL Epoch: 296 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501007
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260087
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 1.645795
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1032
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367462
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213162
INFO:root:FL Epoch: 296 Norm Difference for worker 1032 is 1.476524
INFO:root:FL Epoch: 296 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4889056124549034, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4887325797024051
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4887303845727224
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4887303476163984
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.46075192970388074 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.07498274029543002                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :1570
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589937
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148192
INFO:root:FL Epoch: 297 Norm Difference for worker 1570 is 1.576523
INFO:root:FL Epoch: 297 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1715
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472426
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339634
INFO:root:FL Epoch: 297 Norm Difference for worker 1715 is 1.721442
INFO:root:FL Epoch: 297 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466886
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394210
INFO:root:FL Epoch: 297 Norm Difference for worker 1205 is 1.515501
INFO:root:FL Epoch: 297 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1159
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543877
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301551
INFO:root:FL Epoch: 297 Norm Difference for worker 1159 is 1.678478
INFO:root:FL Epoch: 297 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1186
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670824
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272465
INFO:root:FL Epoch: 297 Norm Difference for worker 1186 is 1.904768
INFO:root:FL Epoch: 297 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :734
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489484
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171279
INFO:root:FL Epoch: 297 Norm Difference for worker 734 is 1.470099
INFO:root:FL Epoch: 297 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1461
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431907
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216157
INFO:root:FL Epoch: 297 Norm Difference for worker 1461 is 1.521862
INFO:root:FL Epoch: 297 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :100
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 100 is 1.656422
INFO:root:FL Epoch: 297 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :989
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663841
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267417
INFO:root:FL Epoch: 297 Norm Difference for worker 989 is 1.619475
INFO:root:FL Epoch: 297 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1614
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421631
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352135
INFO:root:FL Epoch: 297 Norm Difference for worker 1614 is 1.696402
INFO:root:FL Epoch: 297 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5420281657749089, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5415550499394144
INFO:root:#### Oracle Cals: 3, Objective Val: 1.541549391709641
INFO:root:#### Oracle Cals: 4, Objective Val: 1.541549339450665
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.4842275915776982 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.07840413134545088                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :535
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703404
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306316
INFO:root:FL Epoch: 298 Norm Difference for worker 535 is 1.590052
INFO:root:FL Epoch: 298 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :268
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684067
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 268 is 1.672559
INFO:root:FL Epoch: 298 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :968
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380363
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304462
INFO:root:FL Epoch: 298 Norm Difference for worker 968 is 1.588315
INFO:root:FL Epoch: 298 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :728
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650142
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395297
INFO:root:FL Epoch: 298 Norm Difference for worker 728 is 1.693797
INFO:root:FL Epoch: 298 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :188
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249049
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 188 is 1.532009
INFO:root:FL Epoch: 298 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1851
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551396
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349357
INFO:root:FL Epoch: 298 Norm Difference for worker 1851 is 1.598439
INFO:root:FL Epoch: 298 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1892
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402952
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329913
INFO:root:FL Epoch: 298 Norm Difference for worker 1892 is 1.544181
INFO:root:FL Epoch: 298 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :580
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368959
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275596
INFO:root:FL Epoch: 298 Norm Difference for worker 580 is 1.651769
INFO:root:FL Epoch: 298 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1226
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457057
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272617
INFO:root:FL Epoch: 298 Norm Difference for worker 1226 is 1.63316
INFO:root:FL Epoch: 298 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1003
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530628
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.135455
INFO:root:FL Epoch: 298 Norm Difference for worker 1003 is 1.507797
INFO:root:FL Epoch: 298 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5053612438755561, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.505243690128539
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5052421835658205
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5052422016723734
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.4702797637266271 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.059459539130330086                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1318
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666033
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165278
INFO:root:FL Epoch: 299 Norm Difference for worker 1318 is 1.624584
INFO:root:FL Epoch: 299 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591474
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205697
INFO:root:FL Epoch: 299 Norm Difference for worker 1648 is 1.599048
INFO:root:FL Epoch: 299 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :781
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663635
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304904
INFO:root:FL Epoch: 299 Norm Difference for worker 781 is 1.617457
INFO:root:FL Epoch: 299 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1817
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487497
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303810
INFO:root:FL Epoch: 299 Norm Difference for worker 1817 is 1.651635
INFO:root:FL Epoch: 299 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690943
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239747
INFO:root:FL Epoch: 299 Norm Difference for worker 648 is 1.532328
INFO:root:FL Epoch: 299 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :144
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.782572
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 144 is 1.647394
INFO:root:FL Epoch: 299 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1139
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439591
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236237
INFO:root:FL Epoch: 299 Norm Difference for worker 1139 is 1.491696
INFO:root:FL Epoch: 299 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1156
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330914
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188849
INFO:root:FL Epoch: 299 Norm Difference for worker 1156 is 1.486698
INFO:root:FL Epoch: 299 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :598
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711416
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300331
INFO:root:FL Epoch: 299 Norm Difference for worker 598 is 1.644881
INFO:root:FL Epoch: 299 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :650
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498613
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149445
INFO:root:FL Epoch: 299 Norm Difference for worker 650 is 1.592585
INFO:root:FL Epoch: 299 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5023953951746307, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5023012639099107
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5022999660314273
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5022999572476652
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.4599307293401045 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.05971453680346409                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1467
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388227
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192554
INFO:root:FL Epoch: 300 Norm Difference for worker 1467 is 1.542655
INFO:root:FL Epoch: 300 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1937
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296913
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267747
INFO:root:FL Epoch: 300 Norm Difference for worker 1937 is 1.676231
INFO:root:FL Epoch: 300 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1312
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321132
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139039
INFO:root:FL Epoch: 300 Norm Difference for worker 1312 is 1.519245
INFO:root:FL Epoch: 300 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1780
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427356
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316459
INFO:root:FL Epoch: 300 Norm Difference for worker 1780 is 1.43602
INFO:root:FL Epoch: 300 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :228
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 228 is 1.648802
INFO:root:FL Epoch: 300 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :852
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776990
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223408
INFO:root:FL Epoch: 300 Norm Difference for worker 852 is 1.622756
INFO:root:FL Epoch: 300 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :941
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585664
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241905
INFO:root:FL Epoch: 300 Norm Difference for worker 941 is 1.639671
INFO:root:FL Epoch: 300 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1896
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458664
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236744
INFO:root:FL Epoch: 300 Norm Difference for worker 1896 is 1.507316
INFO:root:FL Epoch: 300 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :414
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268208
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454676
INFO:root:FL Epoch: 300 Norm Difference for worker 414 is 1.623269
INFO:root:FL Epoch: 300 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1088
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445138
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168835
INFO:root:FL Epoch: 300 Norm Difference for worker 1088 is 1.423874
INFO:root:FL Epoch: 300 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4778780862031493, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4776413949220562
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4776382567287927
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4776382374596058
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.47032468634493213 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.07016044110059738                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 1443, 486, 588, 551, 1025, 195, 320]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.043205
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.036385
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.0372175593705227 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.02116811154410243 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.400007
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.087495
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.050855
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.03511105966754258 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.02115315981209278 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.409424
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.066455
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.052329
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.03849133476614952 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.020458002295345067 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.422494
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1443
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566176
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178474
INFO:root:FL Epoch: 301 Norm Difference for worker 1443 is 1.624702
INFO:root:FL Epoch: 301 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :486
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333842
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312765
INFO:root:FL Epoch: 301 Norm Difference for worker 486 is 1.586651
INFO:root:FL Epoch: 301 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :588
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752492
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317653
INFO:root:FL Epoch: 301 Norm Difference for worker 588 is 1.682745
INFO:root:FL Epoch: 301 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :551
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644065
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293069
INFO:root:FL Epoch: 301 Norm Difference for worker 551 is 1.603842
INFO:root:FL Epoch: 301 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1025
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617667
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339360
INFO:root:FL Epoch: 301 Norm Difference for worker 1025 is 1.663448
INFO:root:FL Epoch: 301 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :195
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.246189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 195 is 1.542991
INFO:root:FL Epoch: 301 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :320
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 320 is 1.603745
INFO:root:FL Epoch: 301 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2156743164319856, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1891231459909486
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1832022558308632
INFO:root:#### Oracle Cals: 4, Objective Val: 1.181495523392141
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1809702991913174
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1808070773499728
INFO:root:#### Oracle Cals: 7, Objective Val: 1.180756787936308
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1807414227637105
INFO:root:#### Oracle Cals: 9, Objective Val: 1.1807364109651555
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1807349843602164
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1807345326472416
INFO:root:#### Oracle Cals: 12, Objective Val: 1.1807344402237927
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.4827750114833607 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.0431438108595709                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [905, 877, 1238, 1840, 1610, 287, 910, 204, 609, 1756]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :905
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628424
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471290
INFO:root:FL Epoch: 302 Norm Difference for worker 905 is 1.822428
INFO:root:FL Epoch: 302 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :877
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578852
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202179
INFO:root:FL Epoch: 302 Norm Difference for worker 877 is 1.629458
INFO:root:FL Epoch: 302 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1238
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442930
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246683
INFO:root:FL Epoch: 302 Norm Difference for worker 1238 is 1.663138
INFO:root:FL Epoch: 302 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1840
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577073
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227911
INFO:root:FL Epoch: 302 Norm Difference for worker 1840 is 1.822539
INFO:root:FL Epoch: 302 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1610
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520535
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403361
INFO:root:FL Epoch: 302 Norm Difference for worker 1610 is 1.801675
INFO:root:FL Epoch: 302 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :287
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.851885
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 287 is 1.800131
INFO:root:FL Epoch: 302 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :910
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469767
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173698
INFO:root:FL Epoch: 302 Norm Difference for worker 910 is 1.662344
INFO:root:FL Epoch: 302 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :204
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 204 is 1.619147
INFO:root:FL Epoch: 302 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :609
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613578
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282869
INFO:root:FL Epoch: 302 Norm Difference for worker 609 is 1.850525
INFO:root:FL Epoch: 302 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1756
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267154
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146401
INFO:root:FL Epoch: 302 Norm Difference for worker 1756 is 1.796623
INFO:root:FL Epoch: 302 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.648559465710587, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6483507833231643
INFO:root:#### Oracle Cals: 3, Objective Val: 1.6483482529422433
INFO:root:#### Oracle Cals: 4, Objective Val: 1.648348207930947
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.47954031299142275 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.05245045324166616                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1753, 1756, 1355, 139, 584, 1564, 174, 1418, 1113, 648]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1753
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644501
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181520
INFO:root:FL Epoch: 303 Norm Difference for worker 1753 is 1.593673
INFO:root:FL Epoch: 303 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1756
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274106
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234964
INFO:root:FL Epoch: 303 Norm Difference for worker 1756 is 1.517092
INFO:root:FL Epoch: 303 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1355
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615545
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424057
INFO:root:FL Epoch: 303 Norm Difference for worker 1355 is 1.691005
INFO:root:FL Epoch: 303 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :139
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.165481
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 139 is 1.636892
INFO:root:FL Epoch: 303 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :584
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533051
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161576
INFO:root:FL Epoch: 303 Norm Difference for worker 584 is 1.734443
INFO:root:FL Epoch: 303 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1564
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804532
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148897
INFO:root:FL Epoch: 303 Norm Difference for worker 1564 is 1.601262
INFO:root:FL Epoch: 303 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :174
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.843574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 174 is 1.768675
INFO:root:FL Epoch: 303 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1418
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695827
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447131
INFO:root:FL Epoch: 303 Norm Difference for worker 1418 is 1.728406
INFO:root:FL Epoch: 303 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1113
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435831
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362451
INFO:root:FL Epoch: 303 Norm Difference for worker 1113 is 1.634428
INFO:root:FL Epoch: 303 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :648
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345673
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248386
INFO:root:FL Epoch: 303 Norm Difference for worker 648 is 1.601155
INFO:root:FL Epoch: 303 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5585397286698222, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5584186221029204
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5584171298802445
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5584171155852513
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.471851680208655 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.05771607098480066                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [315, 691, 657, 599, 1341, 285, 1303, 1544, 468, 755]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 304 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :315
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 315 is 1.623924
INFO:root:FL Epoch: 304 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :691
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317095
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283617
INFO:root:FL Epoch: 304 Norm Difference for worker 691 is 1.516495
INFO:root:FL Epoch: 304 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :657
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420494
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229874
INFO:root:FL Epoch: 304 Norm Difference for worker 657 is 1.606357
INFO:root:FL Epoch: 304 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :599
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437203
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310450
INFO:root:FL Epoch: 304 Norm Difference for worker 599 is 1.499356
INFO:root:FL Epoch: 304 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1341
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648976
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312518
INFO:root:FL Epoch: 304 Norm Difference for worker 1341 is 1.663426
INFO:root:FL Epoch: 304 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :285
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524427
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.165034
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 285 is 1.47622
INFO:root:FL Epoch: 304 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1303
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628952
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245328
INFO:root:FL Epoch: 304 Norm Difference for worker 1303 is 1.582935
INFO:root:FL Epoch: 304 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1544
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477962
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261584
INFO:root:FL Epoch: 304 Norm Difference for worker 1544 is 1.723281
INFO:root:FL Epoch: 304 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :468
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349364
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291293
INFO:root:FL Epoch: 304 Norm Difference for worker 468 is 1.524844
INFO:root:FL Epoch: 304 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :755
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266783
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299701
INFO:root:FL Epoch: 304 Norm Difference for worker 755 is 1.439966
INFO:root:FL Epoch: 304 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4795819826105656, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.479374851736586
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4793722386616928
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4793721596407996
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.4852936250322005 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.06276866141706705                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [28, 1394, 832, 101, 1000, 1708, 385, 352, 1307, 941]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 305 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :28
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.326476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 28 is 1.408778
INFO:root:FL Epoch: 305 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1394
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672572
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223916
INFO:root:FL Epoch: 305 Norm Difference for worker 1394 is 1.718112
INFO:root:FL Epoch: 305 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :832
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412864
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347781
INFO:root:FL Epoch: 305 Norm Difference for worker 832 is 1.697476
INFO:root:FL Epoch: 305 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :101
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 101 is 1.444088
INFO:root:FL Epoch: 305 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1000
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686601
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340445
INFO:root:FL Epoch: 305 Norm Difference for worker 1000 is 1.723202
INFO:root:FL Epoch: 305 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1708
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491188
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374245
INFO:root:FL Epoch: 305 Norm Difference for worker 1708 is 1.615302
INFO:root:FL Epoch: 305 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :385
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426077
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387925
INFO:root:FL Epoch: 305 Norm Difference for worker 385 is 1.625135
INFO:root:FL Epoch: 305 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :352
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485537
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286512
INFO:root:FL Epoch: 305 Norm Difference for worker 352 is 1.531927
INFO:root:FL Epoch: 305 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1307
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569739
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338651
INFO:root:FL Epoch: 305 Norm Difference for worker 1307 is 1.514288
INFO:root:FL Epoch: 305 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :941
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469545
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224097
INFO:root:FL Epoch: 305 Norm Difference for worker 941 is 1.472453
INFO:root:FL Epoch: 305 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.489142529022558, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.488770154948744
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4887654316718344
INFO:root:#### Oracle Cals: 4, Objective Val: 1.488765344051232
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.45830051250317516 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.06140319320062796                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [1489, 606, 1775, 681, 834, 643, 1374, 711, 1459, 538]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 306 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :1489
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427543
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342700
INFO:root:FL Epoch: 306 Norm Difference for worker 1489 is 1.716347
INFO:root:FL Epoch: 306 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :606
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494507
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226892
INFO:root:FL Epoch: 306 Norm Difference for worker 606 is 1.471275
INFO:root:FL Epoch: 306 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1775
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810331
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367781
INFO:root:FL Epoch: 306 Norm Difference for worker 1775 is 1.727828
INFO:root:FL Epoch: 306 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :681
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383208
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272883
INFO:root:FL Epoch: 306 Norm Difference for worker 681 is 1.548387
INFO:root:FL Epoch: 306 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :834
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536963
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255397
INFO:root:FL Epoch: 306 Norm Difference for worker 834 is 1.726982
INFO:root:FL Epoch: 306 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :643
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343165
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264110
INFO:root:FL Epoch: 306 Norm Difference for worker 643 is 1.564236
INFO:root:FL Epoch: 306 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1374
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486649
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305837
INFO:root:FL Epoch: 306 Norm Difference for worker 1374 is 1.563753
INFO:root:FL Epoch: 306 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :711
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358057
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251331
INFO:root:FL Epoch: 306 Norm Difference for worker 711 is 1.547451
INFO:root:FL Epoch: 306 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1459
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750811
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299359
INFO:root:FL Epoch: 306 Norm Difference for worker 1459 is 1.677242
INFO:root:FL Epoch: 306 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :538
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392158
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278378
INFO:root:FL Epoch: 306 Norm Difference for worker 538 is 1.557985
INFO:root:FL Epoch: 306 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5172589105078242, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5170531639345048
INFO:root:#### Oracle Cals: 3, Objective Val: 1.517050831183387
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5170508093453723
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.45001106139491587 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.04867101740092039                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [906, 614, 1894, 1327, 596, 1690, 1186, 1923, 510, 784]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :906
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387732
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129455
INFO:root:FL Epoch: 307 Norm Difference for worker 906 is 1.526919
INFO:root:FL Epoch: 307 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :614
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499909
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380015
INFO:root:FL Epoch: 307 Norm Difference for worker 614 is 1.615529
INFO:root:FL Epoch: 307 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1894
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630424
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150758
INFO:root:FL Epoch: 307 Norm Difference for worker 1894 is 1.529561
INFO:root:FL Epoch: 307 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1327
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242269
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385708
INFO:root:FL Epoch: 307 Norm Difference for worker 1327 is 1.494025
INFO:root:FL Epoch: 307 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :596
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446655
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309967
INFO:root:FL Epoch: 307 Norm Difference for worker 596 is 1.637699
INFO:root:FL Epoch: 307 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1690
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497390
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281057
INFO:root:FL Epoch: 307 Norm Difference for worker 1690 is 1.567734
INFO:root:FL Epoch: 307 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1186
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465638
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312117
INFO:root:FL Epoch: 307 Norm Difference for worker 1186 is 1.729739
INFO:root:FL Epoch: 307 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1923
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405664
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416999
INFO:root:FL Epoch: 307 Norm Difference for worker 1923 is 1.618063
INFO:root:FL Epoch: 307 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :510
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513022
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211583
INFO:root:FL Epoch: 307 Norm Difference for worker 510 is 1.51712
INFO:root:FL Epoch: 307 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :784
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440222
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277214
INFO:root:FL Epoch: 307 Norm Difference for worker 784 is 1.479987
INFO:root:FL Epoch: 307 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4835777275301456, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4833719220613972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4833696717773666
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4833696238580196
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.4454374348416048 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.04866336410244306                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [1266, 207, 1584, 252, 1605, 1486, 1617, 525, 1340, 1914]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 308 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :1266
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699791
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423648
INFO:root:FL Epoch: 308 Norm Difference for worker 1266 is 1.690247
INFO:root:FL Epoch: 308 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :207
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641145
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 207 is 1.656402
INFO:root:FL Epoch: 308 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1584
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465023
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257149
INFO:root:FL Epoch: 308 Norm Difference for worker 1584 is 1.569765
INFO:root:FL Epoch: 308 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :252
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 252 is 1.663275
INFO:root:FL Epoch: 308 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1605
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698987
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189117
INFO:root:FL Epoch: 308 Norm Difference for worker 1605 is 1.668659
INFO:root:FL Epoch: 308 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1486
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572339
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211378
INFO:root:FL Epoch: 308 Norm Difference for worker 1486 is 1.691396
INFO:root:FL Epoch: 308 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1617
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542043
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348574
INFO:root:FL Epoch: 308 Norm Difference for worker 1617 is 1.611964
INFO:root:FL Epoch: 308 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :525
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518850
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184995
INFO:root:FL Epoch: 308 Norm Difference for worker 525 is 1.710121
INFO:root:FL Epoch: 308 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1340
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587754
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179960
INFO:root:FL Epoch: 308 Norm Difference for worker 1340 is 1.613402
INFO:root:FL Epoch: 308 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1914
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532963
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238488
INFO:root:FL Epoch: 308 Norm Difference for worker 1914 is 1.592886
INFO:root:FL Epoch: 308 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5493642053785504, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5493181785691639
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5493176238968127
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5493176060513976
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.43978635528508353 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.056728120582799114                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [21, 1041, 1494, 370, 1006, 19, 1204, 583, 1772, 502]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 309 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :21
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.138289
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 21 is 1.407618
INFO:root:FL Epoch: 309 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1041
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578337
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208646
INFO:root:FL Epoch: 309 Norm Difference for worker 1041 is 1.531558
INFO:root:FL Epoch: 309 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1494
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.918770
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236832
INFO:root:FL Epoch: 309 Norm Difference for worker 1494 is 1.478871
INFO:root:FL Epoch: 309 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :370
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428256
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416151
INFO:root:FL Epoch: 309 Norm Difference for worker 370 is 1.571221
INFO:root:FL Epoch: 309 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1006
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688989
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342155
INFO:root:FL Epoch: 309 Norm Difference for worker 1006 is 1.502812
INFO:root:FL Epoch: 309 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :19
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 19 is 1.571883
INFO:root:FL Epoch: 309 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1204
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369685
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275236
INFO:root:FL Epoch: 309 Norm Difference for worker 1204 is 1.532314
INFO:root:FL Epoch: 309 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :583
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296146
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210023
INFO:root:FL Epoch: 309 Norm Difference for worker 583 is 1.579234
INFO:root:FL Epoch: 309 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1772
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440400
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452558
INFO:root:FL Epoch: 309 Norm Difference for worker 1772 is 1.600953
INFO:root:FL Epoch: 309 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :502
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544913
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289958
INFO:root:FL Epoch: 309 Norm Difference for worker 502 is 1.513902
INFO:root:FL Epoch: 309 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4399789471079205, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4398741137098405
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4398727181313684
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4398727420453556
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.447381854057312 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.08669117962320645                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [167, 201, 537, 1676, 1913, 909, 1534, 585, 658, 1332]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 310 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :167
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.326198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.316297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 167 is 1.546688
INFO:root:FL Epoch: 310 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :201
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 201 is 1.619064
INFO:root:FL Epoch: 310 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :537
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524710
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382232
INFO:root:FL Epoch: 310 Norm Difference for worker 537 is 1.695035
INFO:root:FL Epoch: 310 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1676
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382145
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280128
INFO:root:FL Epoch: 310 Norm Difference for worker 1676 is 1.695411
INFO:root:FL Epoch: 310 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1913
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545847
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185889
INFO:root:FL Epoch: 310 Norm Difference for worker 1913 is 1.538735
INFO:root:FL Epoch: 310 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :909
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343923
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255448
INFO:root:FL Epoch: 310 Norm Difference for worker 909 is 1.535117
INFO:root:FL Epoch: 310 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1534
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221927
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197844
INFO:root:FL Epoch: 310 Norm Difference for worker 1534 is 1.423987
INFO:root:FL Epoch: 310 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :585
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692356
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248694
INFO:root:FL Epoch: 310 Norm Difference for worker 585 is 1.497244
INFO:root:FL Epoch: 310 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :658
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808839
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265107
INFO:root:FL Epoch: 310 Norm Difference for worker 658 is 1.641191
INFO:root:FL Epoch: 310 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1332
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671574
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249628
INFO:root:FL Epoch: 310 Norm Difference for worker 1332 is 1.510575
INFO:root:FL Epoch: 310 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4793168756129145, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4791185801223021
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4791158926631796
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4791158356412073
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.4577716851935667 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.06916678200165431                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 1910, 621, 208, 1255, 860, 680, 1770]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.127285
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.037188
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.03418422816321254 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.025338599272072316 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.46492
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.113102
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.053483
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.03732548172896107 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.02626507207751274 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.415597
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.068841
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.076010
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.037980707827955484 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.02494261395186186 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.442276
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1910
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313876
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195608
INFO:root:FL Epoch: 311 Norm Difference for worker 1910 is 1.538527
INFO:root:FL Epoch: 311 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :621
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467459
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186743
INFO:root:FL Epoch: 311 Norm Difference for worker 621 is 1.483307
INFO:root:FL Epoch: 311 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :208
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362767
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 208 is 1.513223
INFO:root:FL Epoch: 311 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1255
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523137
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303894
INFO:root:FL Epoch: 311 Norm Difference for worker 1255 is 1.627274
INFO:root:FL Epoch: 311 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :860
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576672
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169604
INFO:root:FL Epoch: 311 Norm Difference for worker 860 is 1.455288
INFO:root:FL Epoch: 311 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :680
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365499
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312974
INFO:root:FL Epoch: 311 Norm Difference for worker 680 is 1.493518
INFO:root:FL Epoch: 311 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1770
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314894
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175995
INFO:root:FL Epoch: 311 Norm Difference for worker 1770 is 1.343259
INFO:root:FL Epoch: 311 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1179202074315295, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.094021384418694
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0893686980470823
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0882710067119672
INFO:root:#### Oracle Cals: 5, Objective Val: 1.0880076627763227
INFO:root:#### Oracle Cals: 6, Objective Val: 1.087945483025844
INFO:root:#### Oracle Cals: 7, Objective Val: 1.0879310210215796
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0879276792876869
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0879269708416766
INFO:root:#### Oracle Cals: 10, Objective Val: 1.0879266949185935
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0879266645190027
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.46911098150645986 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.03947538851449887                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [682, 445, 1687, 664, 651, 289, 709, 742, 1093, 800]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :682
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543606
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 1.597304
INFO:root:FL Epoch: 312 Norm Difference for worker 682 is 2.090942
INFO:root:FL Epoch: 312 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :445
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654084
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220955
INFO:root:FL Epoch: 312 Norm Difference for worker 445 is 1.569351
INFO:root:FL Epoch: 312 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1687
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243000
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213600
INFO:root:FL Epoch: 312 Norm Difference for worker 1687 is 1.745383
INFO:root:FL Epoch: 312 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :664
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859102
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401893
INFO:root:FL Epoch: 312 Norm Difference for worker 664 is 1.73002
INFO:root:FL Epoch: 312 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :651
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415838
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255536
INFO:root:FL Epoch: 312 Norm Difference for worker 651 is 1.699013
INFO:root:FL Epoch: 312 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :289
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.161476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 289 is 1.486107
INFO:root:FL Epoch: 312 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :709
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307718
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191402
INFO:root:FL Epoch: 312 Norm Difference for worker 709 is 1.631488
INFO:root:FL Epoch: 312 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :742
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345466
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137898
INFO:root:FL Epoch: 312 Norm Difference for worker 742 is 1.538633
INFO:root:FL Epoch: 312 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1093
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468802
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131573
INFO:root:FL Epoch: 312 Norm Difference for worker 1093 is 1.623374
INFO:root:FL Epoch: 312 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :800
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568419
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.098564
INFO:root:FL Epoch: 312 Norm Difference for worker 800 is 1.567518
INFO:root:FL Epoch: 312 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.58056916171299, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5798303895237167
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5798215500631112
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5798214662480052
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.46081270189846263 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.047924263402819633                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [1508, 834, 1190, 29, 1700, 246, 1120, 1788, 578, 729]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :1508
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784333
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170646
INFO:root:FL Epoch: 313 Norm Difference for worker 1508 is 1.488008
INFO:root:FL Epoch: 313 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :834
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674216
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320202
INFO:root:FL Epoch: 313 Norm Difference for worker 834 is 1.613475
INFO:root:FL Epoch: 313 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1190
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518562
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166817
INFO:root:FL Epoch: 313 Norm Difference for worker 1190 is 1.415571
INFO:root:FL Epoch: 313 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :29
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651742
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 29 is 1.718864
INFO:root:FL Epoch: 313 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1700
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338667
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148728
INFO:root:FL Epoch: 313 Norm Difference for worker 1700 is 1.317296
INFO:root:FL Epoch: 313 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :246
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.221466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 246 is 1.640136
INFO:root:FL Epoch: 313 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1120
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524495
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529798
INFO:root:FL Epoch: 313 Norm Difference for worker 1120 is 1.68604
INFO:root:FL Epoch: 313 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1788
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480216
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449250
INFO:root:FL Epoch: 313 Norm Difference for worker 1788 is 1.634259
INFO:root:FL Epoch: 313 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :578
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583319
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323673
INFO:root:FL Epoch: 313 Norm Difference for worker 578 is 1.625177
INFO:root:FL Epoch: 313 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :729
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423515
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251098
INFO:root:FL Epoch: 313 Norm Difference for worker 729 is 1.576036
INFO:root:FL Epoch: 313 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4857179656538133, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4852630712170445
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4852562650585686
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4852561470930554
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.4495292796808131 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.052024515345692635                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [1599, 1102, 743, 1678, 1810, 800, 1839, 750, 1145, 1449]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :1599
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322191
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289431
INFO:root:FL Epoch: 314 Norm Difference for worker 1599 is 1.53671
INFO:root:FL Epoch: 314 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1102
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243487
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351312
INFO:root:FL Epoch: 314 Norm Difference for worker 1102 is 1.549932
INFO:root:FL Epoch: 314 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :743
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535209
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172714
INFO:root:FL Epoch: 314 Norm Difference for worker 743 is 1.525271
INFO:root:FL Epoch: 314 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1678
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285028
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194894
INFO:root:FL Epoch: 314 Norm Difference for worker 1678 is 1.516887
INFO:root:FL Epoch: 314 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1810
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422035
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136366
INFO:root:FL Epoch: 314 Norm Difference for worker 1810 is 1.382847
INFO:root:FL Epoch: 314 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :800
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479908
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150426
INFO:root:FL Epoch: 314 Norm Difference for worker 800 is 1.385731
INFO:root:FL Epoch: 314 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1839
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700165
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240654
INFO:root:FL Epoch: 314 Norm Difference for worker 1839 is 1.619534
INFO:root:FL Epoch: 314 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :750
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640632
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374282
INFO:root:FL Epoch: 314 Norm Difference for worker 750 is 1.618679
INFO:root:FL Epoch: 314 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1145
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490077
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206909
INFO:root:FL Epoch: 314 Norm Difference for worker 1145 is 1.67736
INFO:root:FL Epoch: 314 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1449
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499061
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380567
INFO:root:FL Epoch: 314 Norm Difference for worker 1449 is 1.726597
INFO:root:FL Epoch: 314 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4699358534266256, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4695590881691738
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4695537268160306
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4695535935526771
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.47449997768682595 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.055269273618857064                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [984, 720, 1397, 1394, 1003, 1673, 1271, 1114, 1740, 185]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 315 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :984
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552548
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243367
INFO:root:FL Epoch: 315 Norm Difference for worker 984 is 1.645884
INFO:root:FL Epoch: 315 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :720
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587903
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262550
INFO:root:FL Epoch: 315 Norm Difference for worker 720 is 1.588637
INFO:root:FL Epoch: 315 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1397
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312062
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172870
INFO:root:FL Epoch: 315 Norm Difference for worker 1397 is 1.531526
INFO:root:FL Epoch: 315 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1394
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469855
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216136
INFO:root:FL Epoch: 315 Norm Difference for worker 1394 is 1.621355
INFO:root:FL Epoch: 315 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1003
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560470
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220671
INFO:root:FL Epoch: 315 Norm Difference for worker 1003 is 1.459424
INFO:root:FL Epoch: 315 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1673
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575958
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382155
INFO:root:FL Epoch: 315 Norm Difference for worker 1673 is 1.597883
INFO:root:FL Epoch: 315 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1271
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410121
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357744
INFO:root:FL Epoch: 315 Norm Difference for worker 1271 is 1.558004
INFO:root:FL Epoch: 315 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1114
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480798
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279238
INFO:root:FL Epoch: 315 Norm Difference for worker 1114 is 1.599587
INFO:root:FL Epoch: 315 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1740
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625982
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231723
INFO:root:FL Epoch: 315 Norm Difference for worker 1740 is 1.554767
INFO:root:FL Epoch: 315 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :185
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.216145
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 185 is 1.504224
INFO:root:FL Epoch: 315 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4760274864582794, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.475915329592723
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4759137582098292
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4759137286869852
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.47257523238658905 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.06533538394918044                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [1324, 1278, 397, 409, 691, 951, 145, 665, 1649, 1550]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :1324
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598584
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305576
INFO:root:FL Epoch: 316 Norm Difference for worker 1324 is 1.546546
INFO:root:FL Epoch: 316 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1278
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485325
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320966
INFO:root:FL Epoch: 316 Norm Difference for worker 1278 is 1.609479
INFO:root:FL Epoch: 316 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :397
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277910
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189950
INFO:root:FL Epoch: 316 Norm Difference for worker 397 is 1.46915
INFO:root:FL Epoch: 316 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :409
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618907
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178475
INFO:root:FL Epoch: 316 Norm Difference for worker 409 is 1.582603
INFO:root:FL Epoch: 316 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :691
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413340
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370982
INFO:root:FL Epoch: 316 Norm Difference for worker 691 is 1.550251
INFO:root:FL Epoch: 316 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :951
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704537
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244896
INFO:root:FL Epoch: 316 Norm Difference for worker 951 is 1.585131
INFO:root:FL Epoch: 316 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :145
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 145 is 1.464252
INFO:root:FL Epoch: 316 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :665
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410149
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233707
INFO:root:FL Epoch: 316 Norm Difference for worker 665 is 1.537157
INFO:root:FL Epoch: 316 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1649
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353749
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215795
INFO:root:FL Epoch: 316 Norm Difference for worker 1649 is 1.598748
INFO:root:FL Epoch: 316 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1550
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507136
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188499
INFO:root:FL Epoch: 316 Norm Difference for worker 1550 is 1.474023
INFO:root:FL Epoch: 316 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4592148489070098, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.459147754737185
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4591468711668774
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4591468657190467
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.4770285197917153 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.056589652163287006                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [596, 425, 327, 614, 1586, 1405, 196, 226, 526, 243]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :596
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737423
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181198
INFO:root:FL Epoch: 317 Norm Difference for worker 596 is 1.606623
INFO:root:FL Epoch: 317 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :425
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640318
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258149
INFO:root:FL Epoch: 317 Norm Difference for worker 425 is 1.781604
INFO:root:FL Epoch: 317 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :327
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.937936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 327 is 1.827571
INFO:root:FL Epoch: 317 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :614
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607940
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371653
INFO:root:FL Epoch: 317 Norm Difference for worker 614 is 1.582918
INFO:root:FL Epoch: 317 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1586
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650904
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289530
INFO:root:FL Epoch: 317 Norm Difference for worker 1586 is 1.57772
INFO:root:FL Epoch: 317 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1405
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383904
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145588
INFO:root:FL Epoch: 317 Norm Difference for worker 1405 is 1.528757
INFO:root:FL Epoch: 317 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :196
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455035
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 196 is 1.592739
INFO:root:FL Epoch: 317 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :226
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 226 is 1.552296
INFO:root:FL Epoch: 317 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :526
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284589
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320096
INFO:root:FL Epoch: 317 Norm Difference for worker 526 is 1.733953
INFO:root:FL Epoch: 317 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :243
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 243 is 1.495082
INFO:root:FL Epoch: 317 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5408930215355952, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.540542624256103
INFO:root:#### Oracle Cals: 3, Objective Val: 1.540538638310741
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5405385265269445
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.4652879658867331 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.05609387687096993                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [253, 748, 1265, 1438, 1466, 1310, 171, 1495, 820, 920]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :253
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 253 is 1.499644
INFO:root:FL Epoch: 318 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :748
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581653
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286795
INFO:root:FL Epoch: 318 Norm Difference for worker 748 is 1.696132
INFO:root:FL Epoch: 318 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1265
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276542
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246727
INFO:root:FL Epoch: 318 Norm Difference for worker 1265 is 1.537324
INFO:root:FL Epoch: 318 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1438
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699543
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356984
INFO:root:FL Epoch: 318 Norm Difference for worker 1438 is 1.615798
INFO:root:FL Epoch: 318 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1466
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557880
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519419
INFO:root:FL Epoch: 318 Norm Difference for worker 1466 is 1.661888
INFO:root:FL Epoch: 318 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1310
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366729
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210811
INFO:root:FL Epoch: 318 Norm Difference for worker 1310 is 1.552932
INFO:root:FL Epoch: 318 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :171
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.927205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.168187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 171 is 1.569055
INFO:root:FL Epoch: 318 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1495
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510906
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395331
INFO:root:FL Epoch: 318 Norm Difference for worker 1495 is 1.648954
INFO:root:FL Epoch: 318 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :820
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.901597
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360847
INFO:root:FL Epoch: 318 Norm Difference for worker 820 is 1.532757
INFO:root:FL Epoch: 318 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :920
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619557
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315655
INFO:root:FL Epoch: 318 Norm Difference for worker 920 is 1.759562
INFO:root:FL Epoch: 318 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5206408055148415, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.520479752758933
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5204774620911072
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5204774300570851
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.46453039611087127 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.06262954107175271                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1365, 504, 564, 1732, 1905, 1719, 1514, 629, 929, 1382]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1365
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489992
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203504
INFO:root:FL Epoch: 319 Norm Difference for worker 1365 is 1.45428
INFO:root:FL Epoch: 319 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :504
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478095
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326610
INFO:root:FL Epoch: 319 Norm Difference for worker 504 is 1.474065
INFO:root:FL Epoch: 319 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :564
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421265
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200983
INFO:root:FL Epoch: 319 Norm Difference for worker 564 is 1.490939
INFO:root:FL Epoch: 319 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1732
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753176
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303274
INFO:root:FL Epoch: 319 Norm Difference for worker 1732 is 1.577017
INFO:root:FL Epoch: 319 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1905
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519130
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207160
INFO:root:FL Epoch: 319 Norm Difference for worker 1905 is 1.365802
INFO:root:FL Epoch: 319 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1719
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445128
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287637
INFO:root:FL Epoch: 319 Norm Difference for worker 1719 is 1.35541
INFO:root:FL Epoch: 319 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1514
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529895
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225486
INFO:root:FL Epoch: 319 Norm Difference for worker 1514 is 1.476336
INFO:root:FL Epoch: 319 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :629
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434610
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270528
INFO:root:FL Epoch: 319 Norm Difference for worker 629 is 1.38963
INFO:root:FL Epoch: 319 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :929
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715990
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236192
INFO:root:FL Epoch: 319 Norm Difference for worker 929 is 1.57189
INFO:root:FL Epoch: 319 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1382
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596470
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258221
INFO:root:FL Epoch: 319 Norm Difference for worker 1382 is 1.554805
INFO:root:FL Epoch: 319 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3873859170908918, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.387211536997485
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3872092478305036
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3872092280968422
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.46580466891036315 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.06185079676409563                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [64, 124, 326, 1653, 535, 1504, 1731, 1934, 1210, 1637]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 320 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :64
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 64 is 1.587065
INFO:root:FL Epoch: 320 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :124
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.208950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 124 is 1.483719
INFO:root:FL Epoch: 320 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :326
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.375374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.089939
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 326 is 1.485262
INFO:root:FL Epoch: 320 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1653
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526416
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260898
INFO:root:FL Epoch: 320 Norm Difference for worker 1653 is 1.535722
INFO:root:FL Epoch: 320 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :535
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497203
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544865
INFO:root:FL Epoch: 320 Norm Difference for worker 535 is 1.550181
INFO:root:FL Epoch: 320 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1504
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280740
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251666
INFO:root:FL Epoch: 320 Norm Difference for worker 1504 is 1.65134
INFO:root:FL Epoch: 320 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1731
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358861
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184495
INFO:root:FL Epoch: 320 Norm Difference for worker 1731 is 1.420623
INFO:root:FL Epoch: 320 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1934
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567551
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208211
INFO:root:FL Epoch: 320 Norm Difference for worker 1934 is 1.616804
INFO:root:FL Epoch: 320 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1210
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733028
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306219
INFO:root:FL Epoch: 320 Norm Difference for worker 1210 is 1.551662
INFO:root:FL Epoch: 320 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1637
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392441
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241209
INFO:root:FL Epoch: 320 Norm Difference for worker 1637 is 1.69509
INFO:root:FL Epoch: 320 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.466607507055578, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4664304692184957
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4664282341893875
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4664282059096385
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.47524726215530844 and Test Accuracy:75.0 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.06833597489943107                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 1219, 1730, 471, 792, 1830, 1466, 619]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.051864
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.073780
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.04043040440107385 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.023208430968225002 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.369557
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.064330
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.050031
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.03726041301464041 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.022276187501847743 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.398149
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.072841
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.058070
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.032668159964183964 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.02338497033342719 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.370702
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1219
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494473
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416514
INFO:root:FL Epoch: 321 Norm Difference for worker 1219 is 1.544619
INFO:root:FL Epoch: 321 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1730
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564716
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288462
INFO:root:FL Epoch: 321 Norm Difference for worker 1730 is 1.564014
INFO:root:FL Epoch: 321 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :471
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.142543
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184471
INFO:root:FL Epoch: 321 Norm Difference for worker 471 is 1.525403
INFO:root:FL Epoch: 321 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :792
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468465
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375992
INFO:root:FL Epoch: 321 Norm Difference for worker 792 is 1.549466
INFO:root:FL Epoch: 321 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1830
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449230
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207078
INFO:root:FL Epoch: 321 Norm Difference for worker 1830 is 1.610522
INFO:root:FL Epoch: 321 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1466
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211914
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280307
INFO:root:FL Epoch: 321 Norm Difference for worker 1466 is 1.487726
INFO:root:FL Epoch: 321 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :619
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771710
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208592
INFO:root:FL Epoch: 321 Norm Difference for worker 619 is 1.641018
INFO:root:FL Epoch: 321 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1636431123053956, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.138582831336783
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1329461623123462
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1312765091460362
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1307415867256523
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1305666518609223
INFO:root:#### Oracle Cals: 7, Objective Val: 1.1305094444358232
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1304908038539496
INFO:root:#### Oracle Cals: 9, Objective Val: 1.130484684148855
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1304828599349863
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1304820427436073
INFO:root:#### Oracle Cals: 12, Objective Val: 1.1304818309284408
INFO:root:#### Oracle Cals: 13, Objective Val: 1.1304817736228843
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.48955216127283435 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.04122962181766828                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [832, 612, 600, 982, 1725, 1224, 539, 3, 1510, 673]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :832
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422471
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416915
INFO:root:FL Epoch: 322 Norm Difference for worker 832 is 1.700774
INFO:root:FL Epoch: 322 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :612
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768123
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314851
INFO:root:FL Epoch: 322 Norm Difference for worker 612 is 1.61191
INFO:root:FL Epoch: 322 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :600
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.191993
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187002
INFO:root:FL Epoch: 322 Norm Difference for worker 600 is 1.53945
INFO:root:FL Epoch: 322 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :982
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655499
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487573
INFO:root:FL Epoch: 322 Norm Difference for worker 982 is 1.735987
INFO:root:FL Epoch: 322 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1725
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581476
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291706
INFO:root:FL Epoch: 322 Norm Difference for worker 1725 is 1.851163
INFO:root:FL Epoch: 322 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1224
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668976
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206060
INFO:root:FL Epoch: 322 Norm Difference for worker 1224 is 1.593883
INFO:root:FL Epoch: 322 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :539
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469647
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217255
INFO:root:FL Epoch: 322 Norm Difference for worker 539 is 1.619626
INFO:root:FL Epoch: 322 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :3
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 3 is 1.702074
INFO:root:FL Epoch: 322 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1510
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768440
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204482
INFO:root:FL Epoch: 322 Norm Difference for worker 1510 is 1.882937
INFO:root:FL Epoch: 322 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :673
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322936
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340319
INFO:root:FL Epoch: 322 Norm Difference for worker 673 is 1.646727
INFO:root:FL Epoch: 322 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5947027296112855, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.594422218515127
INFO:root:#### Oracle Cals: 3, Objective Val: 1.594418900789354
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5944188837124247
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.5075902956373551 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.06098937367399534                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [888, 344, 814, 1493, 639, 1448, 256, 461, 1908, 337]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :888
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437911
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160884
INFO:root:FL Epoch: 323 Norm Difference for worker 888 is 1.536406
INFO:root:FL Epoch: 323 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :344
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569437
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268027
INFO:root:FL Epoch: 323 Norm Difference for worker 344 is 1.732531
INFO:root:FL Epoch: 323 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :814
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706122
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137392
INFO:root:FL Epoch: 323 Norm Difference for worker 814 is 1.473358
INFO:root:FL Epoch: 323 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1493
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651360
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244527
INFO:root:FL Epoch: 323 Norm Difference for worker 1493 is 1.632329
INFO:root:FL Epoch: 323 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :639
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389750
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240959
INFO:root:FL Epoch: 323 Norm Difference for worker 639 is 1.557107
INFO:root:FL Epoch: 323 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1448
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341590
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274243
INFO:root:FL Epoch: 323 Norm Difference for worker 1448 is 1.592063
INFO:root:FL Epoch: 323 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :256
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.339630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313013
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 256 is 1.575407
INFO:root:FL Epoch: 323 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :461
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343397
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227357
INFO:root:FL Epoch: 323 Norm Difference for worker 461 is 1.51596
INFO:root:FL Epoch: 323 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1908
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395115
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173071
INFO:root:FL Epoch: 323 Norm Difference for worker 1908 is 1.486017
INFO:root:FL Epoch: 323 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :337
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.374702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.177501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 337 is 1.477424
INFO:root:FL Epoch: 323 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4699873192841826, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4697839621238844
INFO:root:#### Oracle Cals: 3, Objective Val: 1.469781650425924
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4697816271180124
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.46529167014009815 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.07239454332739115                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1471, 1574, 1571, 563, 1944, 1599, 1205, 843, 1897, 1775]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1471
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382683
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197830
INFO:root:FL Epoch: 324 Norm Difference for worker 1471 is 1.538982
INFO:root:FL Epoch: 324 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1574
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414255
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150862
INFO:root:FL Epoch: 324 Norm Difference for worker 1574 is 1.629824
INFO:root:FL Epoch: 324 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1571
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380475
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261591
INFO:root:FL Epoch: 324 Norm Difference for worker 1571 is 1.464479
INFO:root:FL Epoch: 324 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :563
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404555
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234591
INFO:root:FL Epoch: 324 Norm Difference for worker 563 is 1.460514
INFO:root:FL Epoch: 324 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1944
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578339
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306512
INFO:root:FL Epoch: 324 Norm Difference for worker 1944 is 1.419505
INFO:root:FL Epoch: 324 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1599
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587639
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198867
INFO:root:FL Epoch: 324 Norm Difference for worker 1599 is 1.43397
INFO:root:FL Epoch: 324 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1205
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346982
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175920
INFO:root:FL Epoch: 324 Norm Difference for worker 1205 is 1.46007
INFO:root:FL Epoch: 324 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :843
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523478
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190927
INFO:root:FL Epoch: 324 Norm Difference for worker 843 is 1.540642
INFO:root:FL Epoch: 324 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1897
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432430
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166018
INFO:root:FL Epoch: 324 Norm Difference for worker 1897 is 1.516655
INFO:root:FL Epoch: 324 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1775
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461909
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326801
INFO:root:FL Epoch: 324 Norm Difference for worker 1775 is 1.482484
INFO:root:FL Epoch: 324 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.410339372993409, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4102463236322471
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4102451992589426
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4102451861431347
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.4724855317788966 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.053670025120178856                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [1096, 570, 779, 298, 1125, 1322, 856, 1417, 826, 661]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :1096
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434095
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301879
INFO:root:FL Epoch: 325 Norm Difference for worker 1096 is 1.596017
INFO:root:FL Epoch: 325 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :570
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675992
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207519
INFO:root:FL Epoch: 325 Norm Difference for worker 570 is 1.532133
INFO:root:FL Epoch: 325 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :779
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425031
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506108
INFO:root:FL Epoch: 325 Norm Difference for worker 779 is 1.657097
INFO:root:FL Epoch: 325 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :298
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689714
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 298 is 1.605343
INFO:root:FL Epoch: 325 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1125
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584333
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223721
INFO:root:FL Epoch: 325 Norm Difference for worker 1125 is 1.624252
INFO:root:FL Epoch: 325 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1322
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300889
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209611
INFO:root:FL Epoch: 325 Norm Difference for worker 1322 is 1.710393
INFO:root:FL Epoch: 325 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :856
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655176
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413372
INFO:root:FL Epoch: 325 Norm Difference for worker 856 is 1.741922
INFO:root:FL Epoch: 325 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1417
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920511
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448739
INFO:root:FL Epoch: 325 Norm Difference for worker 1417 is 1.613258
INFO:root:FL Epoch: 325 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :826
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423143
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355149
INFO:root:FL Epoch: 325 Norm Difference for worker 826 is 1.633042
INFO:root:FL Epoch: 325 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :661
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547092
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208209
INFO:root:FL Epoch: 325 Norm Difference for worker 661 is 1.612054
INFO:root:FL Epoch: 325 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.536263110694576, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5361625658587412
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5361613104730427
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5361612767900403
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.4654185000587912 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.053306108651061855                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [354, 951, 1777, 867, 1140, 1467, 525, 13, 1011, 386]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :354
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706416
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168410
INFO:root:FL Epoch: 326 Norm Difference for worker 354 is 1.512448
INFO:root:FL Epoch: 326 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :951
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439636
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199987
INFO:root:FL Epoch: 326 Norm Difference for worker 951 is 1.460804
INFO:root:FL Epoch: 326 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1777
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685565
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310798
INFO:root:FL Epoch: 326 Norm Difference for worker 1777 is 1.597968
INFO:root:FL Epoch: 326 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :867
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471139
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272902
INFO:root:FL Epoch: 326 Norm Difference for worker 867 is 1.476365
INFO:root:FL Epoch: 326 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1140
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713642
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302607
INFO:root:FL Epoch: 326 Norm Difference for worker 1140 is 1.535599
INFO:root:FL Epoch: 326 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1467
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470209
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211231
INFO:root:FL Epoch: 326 Norm Difference for worker 1467 is 1.498718
INFO:root:FL Epoch: 326 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :525
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426158
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228099
INFO:root:FL Epoch: 326 Norm Difference for worker 525 is 1.517392
INFO:root:FL Epoch: 326 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :13
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 13 is 1.493675
INFO:root:FL Epoch: 326 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1011
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334341
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326034
INFO:root:FL Epoch: 326 Norm Difference for worker 1011 is 1.485408
INFO:root:FL Epoch: 326 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :386
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574483
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192427
INFO:root:FL Epoch: 326 Norm Difference for worker 386 is 1.417036
INFO:root:FL Epoch: 326 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4201680383324475, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.420108527908314
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4201078685104027
INFO:root:#### Oracle Cals: 4, Objective Val: 1.420107828553227
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.47506852185024934 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.05847769230604172                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [394, 43, 1946, 202, 357, 879, 365, 105, 548, 1176]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 327 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :394
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372126
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261277
INFO:root:FL Epoch: 327 Norm Difference for worker 394 is 1.572579
INFO:root:FL Epoch: 327 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :43
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.745012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 43 is 1.651466
INFO:root:FL Epoch: 327 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1946
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377427
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238351
INFO:root:FL Epoch: 327 Norm Difference for worker 1946 is 1.440134
INFO:root:FL Epoch: 327 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :202
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 202 is 1.521636
INFO:root:FL Epoch: 327 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :357
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421897
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264722
INFO:root:FL Epoch: 327 Norm Difference for worker 357 is 1.448421
INFO:root:FL Epoch: 327 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :879
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539230
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201507
INFO:root:FL Epoch: 327 Norm Difference for worker 879 is 1.680997
INFO:root:FL Epoch: 327 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :365
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608680
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268332
INFO:root:FL Epoch: 327 Norm Difference for worker 365 is 1.490816
INFO:root:FL Epoch: 327 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :105
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 105 is 1.694721
INFO:root:FL Epoch: 327 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :548
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404916
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326108
INFO:root:FL Epoch: 327 Norm Difference for worker 548 is 1.645494
INFO:root:FL Epoch: 327 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1176
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678566
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326386
INFO:root:FL Epoch: 327 Norm Difference for worker 1176 is 1.59519
INFO:root:FL Epoch: 327 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4856655677249655, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4854531862216989
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4854505496309582
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4854505275794712
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.4681540219222798 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.04927040357142687                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [1232, 710, 1540, 1486, 1881, 795, 1174, 1718, 1621, 1011]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 328 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :1232
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540524
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419517
INFO:root:FL Epoch: 328 Norm Difference for worker 1232 is 1.577666
INFO:root:FL Epoch: 328 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :710
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312843
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441382
INFO:root:FL Epoch: 328 Norm Difference for worker 710 is 1.55589
INFO:root:FL Epoch: 328 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1540
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449971
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345315
INFO:root:FL Epoch: 328 Norm Difference for worker 1540 is 1.571552
INFO:root:FL Epoch: 328 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1486
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366363
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143466
INFO:root:FL Epoch: 328 Norm Difference for worker 1486 is 1.499062
INFO:root:FL Epoch: 328 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1881
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314856
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122479
INFO:root:FL Epoch: 328 Norm Difference for worker 1881 is 1.492886
INFO:root:FL Epoch: 328 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :795
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451516
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230008
INFO:root:FL Epoch: 328 Norm Difference for worker 795 is 1.433037
INFO:root:FL Epoch: 328 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1174
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462224
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398700
INFO:root:FL Epoch: 328 Norm Difference for worker 1174 is 1.659218
INFO:root:FL Epoch: 328 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1718
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565734
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359565
INFO:root:FL Epoch: 328 Norm Difference for worker 1718 is 1.526673
INFO:root:FL Epoch: 328 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1621
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434233
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189186
INFO:root:FL Epoch: 328 Norm Difference for worker 1621 is 1.532627
INFO:root:FL Epoch: 328 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1011
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306780
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316372
INFO:root:FL Epoch: 328 Norm Difference for worker 1011 is 1.470004
INFO:root:FL Epoch: 328 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4413348489619855, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4412403778741807
INFO:root:#### Oracle Cals: 3, Objective Val: 1.441239152576992
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4412391196606638
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.4639784202856176 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.047345830438037716                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [991, 1293, 318, 707, 1256, 1006, 474, 1060, 1599, 1142]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 329 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :991
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497832
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325679
INFO:root:FL Epoch: 329 Norm Difference for worker 991 is 1.526112
INFO:root:FL Epoch: 329 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1293
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720017
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213009
INFO:root:FL Epoch: 329 Norm Difference for worker 1293 is 1.468268
INFO:root:FL Epoch: 329 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :318
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.306626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 318 is 1.440866
INFO:root:FL Epoch: 329 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :707
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731823
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194474
INFO:root:FL Epoch: 329 Norm Difference for worker 707 is 1.570556
INFO:root:FL Epoch: 329 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1256
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368706
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209531
INFO:root:FL Epoch: 329 Norm Difference for worker 1256 is 1.465575
INFO:root:FL Epoch: 329 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1006
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431343
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130580
INFO:root:FL Epoch: 329 Norm Difference for worker 1006 is 1.541459
INFO:root:FL Epoch: 329 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :474
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581990
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176751
INFO:root:FL Epoch: 329 Norm Difference for worker 474 is 1.622706
INFO:root:FL Epoch: 329 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1060
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365500
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334582
INFO:root:FL Epoch: 329 Norm Difference for worker 1060 is 1.648151
INFO:root:FL Epoch: 329 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1599
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237457
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199617
INFO:root:FL Epoch: 329 Norm Difference for worker 1599 is 1.396867
INFO:root:FL Epoch: 329 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1142
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624485
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275259
INFO:root:FL Epoch: 329 Norm Difference for worker 1142 is 1.55133
INFO:root:FL Epoch: 329 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.44166758695042, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.441507483732639
INFO:root:#### Oracle Cals: 3, Objective Val: 1.441505526556099
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4415054941822898
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.4588755001040066 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.04824836738407612                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [824, 956, 806, 259, 128, 1910, 388, 1464, 189, 1100]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :824
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446834
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306506
INFO:root:FL Epoch: 330 Norm Difference for worker 824 is 1.485206
INFO:root:FL Epoch: 330 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :956
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608088
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249738
INFO:root:FL Epoch: 330 Norm Difference for worker 956 is 1.626682
INFO:root:FL Epoch: 330 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :806
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742263
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231334
INFO:root:FL Epoch: 330 Norm Difference for worker 806 is 1.659427
INFO:root:FL Epoch: 330 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :259
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 259 is 1.687587
INFO:root:FL Epoch: 330 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :128
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379518
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 128 is 1.569556
INFO:root:FL Epoch: 330 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1910
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655087
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415123
INFO:root:FL Epoch: 330 Norm Difference for worker 1910 is 1.647168
INFO:root:FL Epoch: 330 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :388
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195105
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210401
INFO:root:FL Epoch: 330 Norm Difference for worker 388 is 1.445158
INFO:root:FL Epoch: 330 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1464
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398393
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348207
INFO:root:FL Epoch: 330 Norm Difference for worker 1464 is 1.528947
INFO:root:FL Epoch: 330 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :189
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.264815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 189 is 1.534078
INFO:root:FL Epoch: 330 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1100
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432905
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255244
INFO:root:FL Epoch: 330 Norm Difference for worker 1100 is 1.557685
INFO:root:FL Epoch: 330 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.494885401196067, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4947335406618805
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4947319836648656
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4947319645096269
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.4649160977672128 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.05721269796291987                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 218, 858, 782, 846, 1181, 420, 726]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.079894
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.039532
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.03470612084493041 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.02336491122841835 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.349037
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.064261
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.040284
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.03455525326232115 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.02157704858109355 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.360242
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.023472
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.058186
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.03439853231733044 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.021899840235710143 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.353182
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :218
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 218 is 1.552765
INFO:root:FL Epoch: 331 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :858
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607535
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275347
INFO:root:FL Epoch: 331 Norm Difference for worker 858 is 1.534192
INFO:root:FL Epoch: 331 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :782
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533453
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354752
INFO:root:FL Epoch: 331 Norm Difference for worker 782 is 1.584102
INFO:root:FL Epoch: 331 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :846
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527738
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418195
INFO:root:FL Epoch: 331 Norm Difference for worker 846 is 1.734632
INFO:root:FL Epoch: 331 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1181
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438011
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163574
INFO:root:FL Epoch: 331 Norm Difference for worker 1181 is 1.389918
INFO:root:FL Epoch: 331 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :420
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692304
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231141
INFO:root:FL Epoch: 331 Norm Difference for worker 420 is 1.666772
INFO:root:FL Epoch: 331 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :726
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610839
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130136
INFO:root:FL Epoch: 331 Norm Difference for worker 726 is 1.604993
INFO:root:FL Epoch: 331 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.186094415574753, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.15830648807166
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1520054378687337
INFO:root:#### Oracle Cals: 4, Objective Val: 1.150113075316972
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1495067877644287
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1493120870654117
INFO:root:#### Oracle Cals: 7, Objective Val: 1.149250474391147
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1492310558176273
INFO:root:#### Oracle Cals: 9, Objective Val: 1.1492249949713589
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1492232053035067
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1492229683397235
INFO:root:#### Oracle Cals: 12, Objective Val: 1.1492224166734746
INFO:root:#### Oracle Cals: 13, Objective Val: 1.1492224015484764
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.482179359478109 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.03739876812323928                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1137, 943, 1384, 478, 1853, 836, 1335, 1385, 333, 848]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1137
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539248
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247921
INFO:root:FL Epoch: 332 Norm Difference for worker 1137 is 1.729805
INFO:root:FL Epoch: 332 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :943
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.947174
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349027
INFO:root:FL Epoch: 332 Norm Difference for worker 943 is 1.736493
INFO:root:FL Epoch: 332 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1384
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646241
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249113
INFO:root:FL Epoch: 332 Norm Difference for worker 1384 is 1.821985
INFO:root:FL Epoch: 332 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :478
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432723
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149678
INFO:root:FL Epoch: 332 Norm Difference for worker 478 is 1.525844
INFO:root:FL Epoch: 332 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1853
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763990
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157944
INFO:root:FL Epoch: 332 Norm Difference for worker 1853 is 1.90453
INFO:root:FL Epoch: 332 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :836
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371226
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 1.797657
INFO:root:FL Epoch: 332 Norm Difference for worker 836 is 2.524095
INFO:root:FL Epoch: 332 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1335
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328394
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173630
INFO:root:FL Epoch: 332 Norm Difference for worker 1335 is 1.596077
INFO:root:FL Epoch: 332 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1385
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579970
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239353
INFO:root:FL Epoch: 332 Norm Difference for worker 1385 is 1.657155
INFO:root:FL Epoch: 332 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :333
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 333 is 1.774298
INFO:root:FL Epoch: 332 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :848
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506540
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175786
INFO:root:FL Epoch: 332 Norm Difference for worker 848 is 1.727289
INFO:root:FL Epoch: 332 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.6919328631449664, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.6901401888541145
INFO:root:#### Oracle Cals: 3, Objective Val: 1.690123022446169
INFO:root:#### Oracle Cals: 4, Objective Val: 1.6901228477960342
INFO:root:#### Oracle Cals: 5, Objective Val: 1.6901228281139766
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.45339938296991233 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.06004875029126803                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [754, 1821, 539, 906, 684, 557, 1509, 1785, 340, 645]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :754
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250017
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189400
INFO:root:FL Epoch: 333 Norm Difference for worker 754 is 1.440195
INFO:root:FL Epoch: 333 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1821
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372018
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335240
INFO:root:FL Epoch: 333 Norm Difference for worker 1821 is 1.562712
INFO:root:FL Epoch: 333 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :539
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484672
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248214
INFO:root:FL Epoch: 333 Norm Difference for worker 539 is 1.528854
INFO:root:FL Epoch: 333 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :906
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340184
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.101991
INFO:root:FL Epoch: 333 Norm Difference for worker 906 is 1.380289
INFO:root:FL Epoch: 333 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :684
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266836
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418236
INFO:root:FL Epoch: 333 Norm Difference for worker 684 is 1.524628
INFO:root:FL Epoch: 333 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :557
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382989
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397838
INFO:root:FL Epoch: 333 Norm Difference for worker 557 is 1.519803
INFO:root:FL Epoch: 333 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1509
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431688
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379494
INFO:root:FL Epoch: 333 Norm Difference for worker 1509 is 1.465639
INFO:root:FL Epoch: 333 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1785
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404338
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171641
INFO:root:FL Epoch: 333 Norm Difference for worker 1785 is 1.463309
INFO:root:FL Epoch: 333 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :340
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463183
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203222
INFO:root:FL Epoch: 333 Norm Difference for worker 340 is 1.440269
INFO:root:FL Epoch: 333 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :645
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490861
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400107
INFO:root:FL Epoch: 333 Norm Difference for worker 645 is 1.650589
INFO:root:FL Epoch: 333 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4109499543126138, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4108180030250361
INFO:root:#### Oracle Cals: 3, Objective Val: 1.410816290731886
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4108163394150155
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.4424855305868037 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.0470120624328653                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1885, 480, 103, 583, 1552, 1728, 265, 35, 1513, 218]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1885
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588022
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245864
INFO:root:FL Epoch: 334 Norm Difference for worker 1885 is 1.620969
INFO:root:FL Epoch: 334 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :480
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442466
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527362
INFO:root:FL Epoch: 334 Norm Difference for worker 480 is 1.59657
INFO:root:FL Epoch: 334 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :103
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 103 is 1.451146
INFO:root:FL Epoch: 334 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :583
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712873
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216041
INFO:root:FL Epoch: 334 Norm Difference for worker 583 is 1.48094
INFO:root:FL Epoch: 334 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1552
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459810
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199122
INFO:root:FL Epoch: 334 Norm Difference for worker 1552 is 1.597409
INFO:root:FL Epoch: 334 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1728
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389250
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207867
INFO:root:FL Epoch: 334 Norm Difference for worker 1728 is 1.598015
INFO:root:FL Epoch: 334 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :265
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 265 is 1.652796
INFO:root:FL Epoch: 334 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :35
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 35 is 1.467466
INFO:root:FL Epoch: 334 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1513
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458047
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197074
INFO:root:FL Epoch: 334 Norm Difference for worker 1513 is 1.449849
INFO:root:FL Epoch: 334 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :218
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.158224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 218 is 1.78654
INFO:root:FL Epoch: 334 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4825011753842783, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4821778662187717
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4821741893775193
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4821741660976469
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.4637438760084264 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.060974885088702045                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [1862, 981, 783, 483, 92, 332, 409, 1407, 210, 1936]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 335 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :1862
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589624
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275375
INFO:root:FL Epoch: 335 Norm Difference for worker 1862 is 1.551895
INFO:root:FL Epoch: 335 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :981
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571775
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341327
INFO:root:FL Epoch: 335 Norm Difference for worker 981 is 1.592066
INFO:root:FL Epoch: 335 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :783
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463069
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240849
INFO:root:FL Epoch: 335 Norm Difference for worker 783 is 1.526807
INFO:root:FL Epoch: 335 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :483
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249613
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130330
INFO:root:FL Epoch: 335 Norm Difference for worker 483 is 1.354491
INFO:root:FL Epoch: 335 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :92
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406912
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377640
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 92 is 1.545503
INFO:root:FL Epoch: 335 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :332
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.227939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 332 is 1.543107
INFO:root:FL Epoch: 335 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :409
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315724
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293365
INFO:root:FL Epoch: 335 Norm Difference for worker 409 is 1.560553
INFO:root:FL Epoch: 335 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1407
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550066
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250881
INFO:root:FL Epoch: 335 Norm Difference for worker 1407 is 1.538535
INFO:root:FL Epoch: 335 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :210
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 210 is 1.654318
INFO:root:FL Epoch: 335 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1936
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477644
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194186
INFO:root:FL Epoch: 335 Norm Difference for worker 1936 is 1.528629
INFO:root:FL Epoch: 335 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4568491248598663, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4567228024621628
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4567210527309995
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4567210879634847
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.47017940352944765 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.07569115702062845                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [1219, 607, 222, 931, 772, 1596, 769, 484, 896, 852]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 336 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :1219
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573708
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153249
INFO:root:FL Epoch: 336 Norm Difference for worker 1219 is 1.420576
INFO:root:FL Epoch: 336 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :607
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598077
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272280
INFO:root:FL Epoch: 336 Norm Difference for worker 607 is 1.539076
INFO:root:FL Epoch: 336 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :222
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.191791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 222 is 1.427293
INFO:root:FL Epoch: 336 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :931
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382008
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257466
INFO:root:FL Epoch: 336 Norm Difference for worker 931 is 1.601947
INFO:root:FL Epoch: 336 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :772
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314936
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220603
INFO:root:FL Epoch: 336 Norm Difference for worker 772 is 1.528863
INFO:root:FL Epoch: 336 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1596
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500485
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281170
INFO:root:FL Epoch: 336 Norm Difference for worker 1596 is 1.418359
INFO:root:FL Epoch: 336 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :769
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317486
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254816
INFO:root:FL Epoch: 336 Norm Difference for worker 769 is 1.529443
INFO:root:FL Epoch: 336 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :484
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288397
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377717
INFO:root:FL Epoch: 336 Norm Difference for worker 484 is 1.62434
INFO:root:FL Epoch: 336 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :896
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598504
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330717
INFO:root:FL Epoch: 336 Norm Difference for worker 896 is 1.467455
INFO:root:FL Epoch: 336 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :852
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533524
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329876
INFO:root:FL Epoch: 336 Norm Difference for worker 852 is 1.463408
INFO:root:FL Epoch: 336 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4188705282635763, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4187083510568683
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4187064114328647
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4187063855076514
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.47420865472625284 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.06383352167904377                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [1915, 136, 1458, 1617, 113, 225, 258, 144, 640, 920]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 337 Num points on workers: [200 201 200 200 201 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :1915
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894725
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780114
INFO:root:FL Epoch: 337 Norm Difference for worker 1915 is 1.68803
INFO:root:FL Epoch: 337 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :136
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.164739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 136 is 1.493155
INFO:root:FL Epoch: 337 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1458
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321883
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312553
INFO:root:FL Epoch: 337 Norm Difference for worker 1458 is 1.501619
INFO:root:FL Epoch: 337 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1617
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433897
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342110
INFO:root:FL Epoch: 337 Norm Difference for worker 1617 is 1.568567
INFO:root:FL Epoch: 337 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :113
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 113 is 1.581123
INFO:root:FL Epoch: 337 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :225
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.346706
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 225 is 1.597638
INFO:root:FL Epoch: 337 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :258
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 258 is 1.601603
INFO:root:FL Epoch: 337 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :144
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 144 is 1.475078
INFO:root:FL Epoch: 337 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :640
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689341
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324688
INFO:root:FL Epoch: 337 Norm Difference for worker 640 is 1.421747
INFO:root:FL Epoch: 337 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :920
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756364
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187522
INFO:root:FL Epoch: 337 Norm Difference for worker 920 is 1.621354
INFO:root:FL Epoch: 337 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4570086657906032, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4568995185471272
INFO:root:#### Oracle Cals: 3, Objective Val: 1.456898294674414
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4568982543971094
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.4798162439290215 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.07381412293761969                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [483, 1773, 692, 125, 896, 1694, 899, 1396, 1318, 1791]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :483
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567216
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239640
INFO:root:FL Epoch: 338 Norm Difference for worker 483 is 1.361615
INFO:root:FL Epoch: 338 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1773
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305393
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212478
INFO:root:FL Epoch: 338 Norm Difference for worker 1773 is 1.479309
INFO:root:FL Epoch: 338 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :692
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739101
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300809
INFO:root:FL Epoch: 338 Norm Difference for worker 692 is 1.430928
INFO:root:FL Epoch: 338 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :125
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.269385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.160936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 125 is 1.428998
INFO:root:FL Epoch: 338 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :896
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355182
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218077
INFO:root:FL Epoch: 338 Norm Difference for worker 896 is 1.392774
INFO:root:FL Epoch: 338 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1694
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509400
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389949
INFO:root:FL Epoch: 338 Norm Difference for worker 1694 is 1.599759
INFO:root:FL Epoch: 338 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :899
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359381
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196821
INFO:root:FL Epoch: 338 Norm Difference for worker 899 is 1.48197
INFO:root:FL Epoch: 338 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1396
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900630
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275220
INFO:root:FL Epoch: 338 Norm Difference for worker 1396 is 1.513792
INFO:root:FL Epoch: 338 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1318
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268495
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177465
INFO:root:FL Epoch: 338 Norm Difference for worker 1318 is 1.481564
INFO:root:FL Epoch: 338 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1791
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445568
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346810
INFO:root:FL Epoch: 338 Norm Difference for worker 1791 is 1.565945
INFO:root:FL Epoch: 338 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3882356588471505, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3880485502519917
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3880462600823078
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3880463014977131
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.4717836642966551 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.0601872398207585                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [1629, 745, 1002, 1359, 619, 1907, 21, 1557, 205, 802]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 339 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :1629
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578765
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338500
INFO:root:FL Epoch: 339 Norm Difference for worker 1629 is 1.568292
INFO:root:FL Epoch: 339 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :745
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442285
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227935
INFO:root:FL Epoch: 339 Norm Difference for worker 745 is 1.574082
INFO:root:FL Epoch: 339 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1002
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652441
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197968
INFO:root:FL Epoch: 339 Norm Difference for worker 1002 is 1.53291
INFO:root:FL Epoch: 339 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1359
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401818
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257072
INFO:root:FL Epoch: 339 Norm Difference for worker 1359 is 1.573836
INFO:root:FL Epoch: 339 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :619
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699957
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285184
INFO:root:FL Epoch: 339 Norm Difference for worker 619 is 1.612553
INFO:root:FL Epoch: 339 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1907
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335046
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171294
INFO:root:FL Epoch: 339 Norm Difference for worker 1907 is 1.509035
INFO:root:FL Epoch: 339 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :21
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.118986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 21 is 1.325845
INFO:root:FL Epoch: 339 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1557
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344701
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286628
INFO:root:FL Epoch: 339 Norm Difference for worker 1557 is 1.514389
INFO:root:FL Epoch: 339 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :205
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.847491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390362
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 205 is 1.645798
INFO:root:FL Epoch: 339 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :802
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370124
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291829
INFO:root:FL Epoch: 339 Norm Difference for worker 802 is 1.502269
INFO:root:FL Epoch: 339 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4458825851471109, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.445664778808237
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4456618107656267
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4456617182190792
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.4571545264300178 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.05095961193243662                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [871, 60, 930, 1124, 733, 1016, 689, 214, 319, 1111]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 340 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :871
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337623
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.112903
INFO:root:FL Epoch: 340 Norm Difference for worker 871 is 1.476619
INFO:root:FL Epoch: 340 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :60
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.314241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.296782
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 60 is 1.546262
INFO:root:FL Epoch: 340 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :930
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624454
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197893
INFO:root:FL Epoch: 340 Norm Difference for worker 930 is 1.469626
INFO:root:FL Epoch: 340 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1124
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336943
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268998
INFO:root:FL Epoch: 340 Norm Difference for worker 1124 is 1.518607
INFO:root:FL Epoch: 340 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :733
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342583
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203258
INFO:root:FL Epoch: 340 Norm Difference for worker 733 is 1.615463
INFO:root:FL Epoch: 340 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1016
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487824
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150095
INFO:root:FL Epoch: 340 Norm Difference for worker 1016 is 1.474148
INFO:root:FL Epoch: 340 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :689
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384158
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235836
INFO:root:FL Epoch: 340 Norm Difference for worker 689 is 1.541273
INFO:root:FL Epoch: 340 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :214
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 214 is 1.455371
INFO:root:FL Epoch: 340 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :319
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 319 is 1.426012
INFO:root:FL Epoch: 340 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1111
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431161
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367581
INFO:root:FL Epoch: 340 Norm Difference for worker 1111 is 1.525057
INFO:root:FL Epoch: 340 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4260634382565724, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.425959292201117
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4259581240388794
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4259580557769191
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.46662939120741453 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.06117994183053573                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 472, 1059, 560, 655, 898, 1664, 1277]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.058155
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.042494
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.030224982493867476 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.019925721548497678 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.351597
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.057482
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.031462
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.035972061877449356 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.020596948638558387 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.348708
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.036454
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.024052
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.034009311348199844 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.020697395596653224 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.335357
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :472
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446523
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297716
INFO:root:FL Epoch: 341 Norm Difference for worker 472 is 1.466175
INFO:root:FL Epoch: 341 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1059
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229633
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181694
INFO:root:FL Epoch: 341 Norm Difference for worker 1059 is 1.338314
INFO:root:FL Epoch: 341 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :560
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793074
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368271
INFO:root:FL Epoch: 341 Norm Difference for worker 560 is 1.533264
INFO:root:FL Epoch: 341 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :655
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532766
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279573
INFO:root:FL Epoch: 341 Norm Difference for worker 655 is 1.627909
INFO:root:FL Epoch: 341 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :898
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657147
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261285
INFO:root:FL Epoch: 341 Norm Difference for worker 898 is 1.587743
INFO:root:FL Epoch: 341 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1664
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523592
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335034
INFO:root:FL Epoch: 341 Norm Difference for worker 1664 is 1.349598
INFO:root:FL Epoch: 341 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1277
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474804
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278580
INFO:root:FL Epoch: 341 Norm Difference for worker 1277 is 1.46079
INFO:root:FL Epoch: 341 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1022208624003602, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.0762961189616145
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0707530496983853
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0692476854157038
INFO:root:#### Oracle Cals: 5, Objective Val: 1.0688288715484082
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0687152370680175
INFO:root:#### Oracle Cals: 7, Objective Val: 1.068685242407806
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0686771649020392
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0686751130298393
INFO:root:#### Oracle Cals: 10, Objective Val: 1.0686745896153305
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0686746147193544
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.4903591853730819 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.03732205073659619                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1085, 431, 1019, 17, 671, 163, 1750, 1316, 365, 535]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 342 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1085
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466975
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169704
INFO:root:FL Epoch: 342 Norm Difference for worker 1085 is 1.583931
INFO:root:FL Epoch: 342 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :431
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657679
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285817
INFO:root:FL Epoch: 342 Norm Difference for worker 431 is 1.696589
INFO:root:FL Epoch: 342 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1019
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539582
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494058
INFO:root:FL Epoch: 342 Norm Difference for worker 1019 is 1.712095
INFO:root:FL Epoch: 342 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :17
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.866306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 17 is 1.833863
INFO:root:FL Epoch: 342 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :671
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568735
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230518
INFO:root:FL Epoch: 342 Norm Difference for worker 671 is 1.599783
INFO:root:FL Epoch: 342 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :163
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.896988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341482
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 163 is 1.663614
INFO:root:FL Epoch: 342 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1750
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404314
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223862
INFO:root:FL Epoch: 342 Norm Difference for worker 1750 is 1.838334
INFO:root:FL Epoch: 342 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1316
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516841
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476034
INFO:root:FL Epoch: 342 Norm Difference for worker 1316 is 1.609063
INFO:root:FL Epoch: 342 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :365
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311156
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238336
INFO:root:FL Epoch: 342 Norm Difference for worker 365 is 1.569222
INFO:root:FL Epoch: 342 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :535
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286624
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.128964
INFO:root:FL Epoch: 342 Norm Difference for worker 535 is 1.580332
INFO:root:FL Epoch: 342 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5680502118619553, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5678409986130588
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5678386970789586
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5678386078346604
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.48022208844914155 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.0375278756643335                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [807, 1321, 608, 1300, 1732, 245, 865, 1286, 1311, 189]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :807
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549700
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401977
INFO:root:FL Epoch: 343 Norm Difference for worker 807 is 1.580278
INFO:root:FL Epoch: 343 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1321
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456136
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311317
INFO:root:FL Epoch: 343 Norm Difference for worker 1321 is 1.479621
INFO:root:FL Epoch: 343 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :608
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469224
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248044
INFO:root:FL Epoch: 343 Norm Difference for worker 608 is 1.624261
INFO:root:FL Epoch: 343 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1300
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684569
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197427
INFO:root:FL Epoch: 343 Norm Difference for worker 1300 is 1.444076
INFO:root:FL Epoch: 343 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1732
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499656
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335352
INFO:root:FL Epoch: 343 Norm Difference for worker 1732 is 1.547503
INFO:root:FL Epoch: 343 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :245
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 245 is 1.722479
INFO:root:FL Epoch: 343 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :865
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559371
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123667
INFO:root:FL Epoch: 343 Norm Difference for worker 865 is 1.412014
INFO:root:FL Epoch: 343 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1286
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595500
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139997
INFO:root:FL Epoch: 343 Norm Difference for worker 1286 is 1.671924
INFO:root:FL Epoch: 343 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1311
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538386
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510076
INFO:root:FL Epoch: 343 Norm Difference for worker 1311 is 1.575772
INFO:root:FL Epoch: 343 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :189
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.253188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 189 is 1.567703
INFO:root:FL Epoch: 343 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4764995191285128, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4762983977737691
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4762961231634706
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4762960886469512
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.476917424622704 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.03965381750216087                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1045, 1586, 604, 485, 1560, 43, 1653, 8, 197, 1076]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1045
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389016
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351448
INFO:root:FL Epoch: 344 Norm Difference for worker 1045 is 1.528358
INFO:root:FL Epoch: 344 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1586
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510424
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274456
INFO:root:FL Epoch: 344 Norm Difference for worker 1586 is 1.573829
INFO:root:FL Epoch: 344 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :604
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482817
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213025
INFO:root:FL Epoch: 344 Norm Difference for worker 604 is 1.52985
INFO:root:FL Epoch: 344 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :485
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453373
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152436
INFO:root:FL Epoch: 344 Norm Difference for worker 485 is 1.46289
INFO:root:FL Epoch: 344 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1560
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531070
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258236
INFO:root:FL Epoch: 344 Norm Difference for worker 1560 is 1.414226
INFO:root:FL Epoch: 344 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :43
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 43 is 1.608502
INFO:root:FL Epoch: 344 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1653
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534987
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205066
INFO:root:FL Epoch: 344 Norm Difference for worker 1653 is 1.477617
INFO:root:FL Epoch: 344 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :8
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393959
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 8 is 1.383465
INFO:root:FL Epoch: 344 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :197
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 197 is 1.544858
INFO:root:FL Epoch: 344 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1076
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594753
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172719
INFO:root:FL Epoch: 344 Norm Difference for worker 1076 is 1.555765
INFO:root:FL Epoch: 344 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4213609550542223, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.421178224975454
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4211758705222253
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4211758427977748
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.47412312556715575 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.03402246721088886                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [1887, 1618, 192, 1922, 853, 409, 37, 1797, 1173, 354]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 345 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :1887
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458424
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401820
INFO:root:FL Epoch: 345 Norm Difference for worker 1887 is 1.525997
INFO:root:FL Epoch: 345 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1618
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478949
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158726
INFO:root:FL Epoch: 345 Norm Difference for worker 1618 is 1.44681
INFO:root:FL Epoch: 345 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :192
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 192 is 1.537415
INFO:root:FL Epoch: 345 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1922
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384811
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248261
INFO:root:FL Epoch: 345 Norm Difference for worker 1922 is 1.435779
INFO:root:FL Epoch: 345 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :853
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719595
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203153
INFO:root:FL Epoch: 345 Norm Difference for worker 853 is 1.662437
INFO:root:FL Epoch: 345 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :409
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800044
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188398
INFO:root:FL Epoch: 345 Norm Difference for worker 409 is 1.463718
INFO:root:FL Epoch: 345 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :37
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.840535
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 37 is 1.582704
INFO:root:FL Epoch: 345 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1797
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785209
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274388
INFO:root:FL Epoch: 345 Norm Difference for worker 1797 is 1.53014
INFO:root:FL Epoch: 345 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1173
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627923
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359159
INFO:root:FL Epoch: 345 Norm Difference for worker 1173 is 1.535951
INFO:root:FL Epoch: 345 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :354
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426433
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237340
INFO:root:FL Epoch: 345 Norm Difference for worker 354 is 1.539274
INFO:root:FL Epoch: 345 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4369437271152343, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4367995120017596
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4367978729627846
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4367978453967643
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.46558280902750354 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.03874318456898133                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [1581, 1807, 1605, 445, 1804, 852, 67, 1870, 1033, 1199]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :1581
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528667
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230977
INFO:root:FL Epoch: 346 Norm Difference for worker 1581 is 1.585196
INFO:root:FL Epoch: 346 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1807
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238470
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250040
INFO:root:FL Epoch: 346 Norm Difference for worker 1807 is 1.551006
INFO:root:FL Epoch: 346 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1605
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409746
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247608
INFO:root:FL Epoch: 346 Norm Difference for worker 1605 is 1.542427
INFO:root:FL Epoch: 346 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :445
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430764
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255495
INFO:root:FL Epoch: 346 Norm Difference for worker 445 is 1.542605
INFO:root:FL Epoch: 346 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1804
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546879
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309290
INFO:root:FL Epoch: 346 Norm Difference for worker 1804 is 1.696576
INFO:root:FL Epoch: 346 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :852
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245171
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185808
INFO:root:FL Epoch: 346 Norm Difference for worker 852 is 1.378998
INFO:root:FL Epoch: 346 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :67
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 67 is 1.584222
INFO:root:FL Epoch: 346 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1870
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508180
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380818
INFO:root:FL Epoch: 346 Norm Difference for worker 1870 is 1.65041
INFO:root:FL Epoch: 346 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1033
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766488
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161023
INFO:root:FL Epoch: 346 Norm Difference for worker 1033 is 1.42662
INFO:root:FL Epoch: 346 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1199
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587520
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192003
INFO:root:FL Epoch: 346 Norm Difference for worker 1199 is 1.48365
INFO:root:FL Epoch: 346 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4631757217407486, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4629484552718095
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4629457056535937
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4629456715268574
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.458293839412577 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.04180356146146854                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [623, 1667, 1748, 1473, 484, 422, 1584, 1257, 247, 1862]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :623
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552486
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352185
INFO:root:FL Epoch: 347 Norm Difference for worker 623 is 2.012851
INFO:root:FL Epoch: 347 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1667
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618059
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.135185
INFO:root:FL Epoch: 347 Norm Difference for worker 1667 is 1.544836
INFO:root:FL Epoch: 347 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1748
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387104
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311468
INFO:root:FL Epoch: 347 Norm Difference for worker 1748 is 1.718614
INFO:root:FL Epoch: 347 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1473
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253810
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241729
INFO:root:FL Epoch: 347 Norm Difference for worker 1473 is 1.571099
INFO:root:FL Epoch: 347 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :484
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730170
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226384
INFO:root:FL Epoch: 347 Norm Difference for worker 484 is 1.727985
INFO:root:FL Epoch: 347 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :422
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334117
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309374
INFO:root:FL Epoch: 347 Norm Difference for worker 422 is 1.503266
INFO:root:FL Epoch: 347 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1584
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482244
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302014
INFO:root:FL Epoch: 347 Norm Difference for worker 1584 is 1.502879
INFO:root:FL Epoch: 347 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1257
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576414
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416283
INFO:root:FL Epoch: 347 Norm Difference for worker 1257 is 1.543821
INFO:root:FL Epoch: 347 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :247
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 247 is 1.656691
INFO:root:FL Epoch: 347 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1862
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524661
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207473
INFO:root:FL Epoch: 347 Norm Difference for worker 1862 is 1.46082
INFO:root:FL Epoch: 347 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5334781636849961, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.5328517277150824
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5328420342036397
INFO:root:#### Oracle Cals: 4, Objective Val: 1.532841859047233
INFO:root:#### Oracle Cals: 5, Objective Val: 1.5328418690073293
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.45100430180044737 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.047548266438146435                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1637, 1052, 976, 1674, 1323, 573, 1785, 1911, 105, 1649]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1637
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615344
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339354
INFO:root:FL Epoch: 348 Norm Difference for worker 1637 is 1.549319
INFO:root:FL Epoch: 348 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1052
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395641
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216310
INFO:root:FL Epoch: 348 Norm Difference for worker 1052 is 1.37296
INFO:root:FL Epoch: 348 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :976
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386281
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172043
INFO:root:FL Epoch: 348 Norm Difference for worker 976 is 1.482765
INFO:root:FL Epoch: 348 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1674
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691507
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130973
INFO:root:FL Epoch: 348 Norm Difference for worker 1674 is 1.447639
INFO:root:FL Epoch: 348 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1323
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649244
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217309
INFO:root:FL Epoch: 348 Norm Difference for worker 1323 is 1.491768
INFO:root:FL Epoch: 348 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :573
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353271
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126480
INFO:root:FL Epoch: 348 Norm Difference for worker 573 is 1.460913
INFO:root:FL Epoch: 348 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1785
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400015
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350465
INFO:root:FL Epoch: 348 Norm Difference for worker 1785 is 1.488896
INFO:root:FL Epoch: 348 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1911
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360846
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325872
INFO:root:FL Epoch: 348 Norm Difference for worker 1911 is 1.508773
INFO:root:FL Epoch: 348 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :105
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.233770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 105 is 1.519005
INFO:root:FL Epoch: 348 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1649
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443102
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369795
INFO:root:FL Epoch: 348 Norm Difference for worker 1649 is 1.557035
INFO:root:FL Epoch: 348 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.400004001424167, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3998827110979473
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3998810378506161
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3998811248618173
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.44616631374639626 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.04702843135843674                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [1916, 646, 69, 999, 995, 1098, 338, 1684, 334, 1847]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :1916
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358599
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298581
INFO:root:FL Epoch: 349 Norm Difference for worker 1916 is 1.5203
INFO:root:FL Epoch: 349 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :646
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737874
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211327
INFO:root:FL Epoch: 349 Norm Difference for worker 646 is 1.558171
INFO:root:FL Epoch: 349 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :69
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 69 is 1.605639
INFO:root:FL Epoch: 349 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :999
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460651
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259053
INFO:root:FL Epoch: 349 Norm Difference for worker 999 is 1.432565
INFO:root:FL Epoch: 349 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :995
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842978
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268307
INFO:root:FL Epoch: 349 Norm Difference for worker 995 is 1.635966
INFO:root:FL Epoch: 349 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1098
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224477
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216376
INFO:root:FL Epoch: 349 Norm Difference for worker 1098 is 1.358944
INFO:root:FL Epoch: 349 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :338
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.365862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.162487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 338 is 1.456173
INFO:root:FL Epoch: 349 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1684
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487648
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374079
INFO:root:FL Epoch: 349 Norm Difference for worker 1684 is 1.55392
INFO:root:FL Epoch: 349 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :334
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.330679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.196923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 334 is 1.293707
INFO:root:FL Epoch: 349 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1847
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400586
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281558
INFO:root:FL Epoch: 349 Norm Difference for worker 1847 is 1.377626
INFO:root:FL Epoch: 349 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3992533906700708, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3988669893470447
INFO:root:#### Oracle Cals: 3, Objective Val: 1.398861615880238
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3988615408737228
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.4542858942466624 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.05695980694144964                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1040, 598, 1751, 1280, 1514, 131, 1654, 1021, 35, 475]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 350 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1040
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541143
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145859
INFO:root:FL Epoch: 350 Norm Difference for worker 1040 is 1.502655
INFO:root:FL Epoch: 350 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :598
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679997
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275095
INFO:root:FL Epoch: 350 Norm Difference for worker 598 is 1.610662
INFO:root:FL Epoch: 350 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1751
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539342
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320241
INFO:root:FL Epoch: 350 Norm Difference for worker 1751 is 1.609154
INFO:root:FL Epoch: 350 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1280
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475495
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149354
INFO:root:FL Epoch: 350 Norm Difference for worker 1280 is 1.408241
INFO:root:FL Epoch: 350 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1514
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506081
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.088362
INFO:root:FL Epoch: 350 Norm Difference for worker 1514 is 1.400615
INFO:root:FL Epoch: 350 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :131
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 131 is 1.533788
INFO:root:FL Epoch: 350 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1654
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752166
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352701
INFO:root:FL Epoch: 350 Norm Difference for worker 1654 is 1.675495
INFO:root:FL Epoch: 350 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1021
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627763
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291945
INFO:root:FL Epoch: 350 Norm Difference for worker 1021 is 1.414165
INFO:root:FL Epoch: 350 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :35
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206804
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 35 is 1.426884
INFO:root:FL Epoch: 350 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :475
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436781
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151764
INFO:root:FL Epoch: 350 Norm Difference for worker 475 is 1.480746
INFO:root:FL Epoch: 350 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4239017211469427, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4236896117385096
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4236871941733509
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4236871175111927
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.4326682678040336 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.04183928047617277                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 1925, 712, 218, 1646, 399, 1451, 456]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.061139
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.033121
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.026817489104966324 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.021662345435470343 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.341137
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.050999
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.034092
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.023900319822132587 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.021695183403789998 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.32934
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.033968
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.045148
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.027313409838825464 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.021359036955982447 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.36978
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1925
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774495
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272999
INFO:root:FL Epoch: 351 Norm Difference for worker 1925 is 1.582921
INFO:root:FL Epoch: 351 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :712
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782332
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221121
INFO:root:FL Epoch: 351 Norm Difference for worker 712 is 1.59762
INFO:root:FL Epoch: 351 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :218
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384536
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 218 is 1.53487
INFO:root:FL Epoch: 351 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1646
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317972
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270420
INFO:root:FL Epoch: 351 Norm Difference for worker 1646 is 1.387393
INFO:root:FL Epoch: 351 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :399
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680712
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246313
INFO:root:FL Epoch: 351 Norm Difference for worker 399 is 1.539215
INFO:root:FL Epoch: 351 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1451
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476819
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315305
INFO:root:FL Epoch: 351 Norm Difference for worker 1451 is 1.531549
INFO:root:FL Epoch: 351 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :456
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383884
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227386
INFO:root:FL Epoch: 351 Norm Difference for worker 456 is 1.47515
INFO:root:FL Epoch: 351 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1383763828487663, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.112484675707004
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1066964281495426
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1050332021520266
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1045303835862579
INFO:root:#### Oracle Cals: 6, Objective Val: 1.1043786243560754
INFO:root:#### Oracle Cals: 7, Objective Val: 1.1043335383155086
INFO:root:#### Oracle Cals: 8, Objective Val: 1.1043203409808906
INFO:root:#### Oracle Cals: 9, Objective Val: 1.104316482930801
INFO:root:#### Oracle Cals: 10, Objective Val: 1.1043155294229665
INFO:root:#### Oracle Cals: 11, Objective Val: 1.1043152791488684
INFO:root:#### Oracle Cals: 12, Objective Val: 1.1043150169722533
INFO:root:#### Oracle Cals: 13, Objective Val: 1.1043150007177573
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.4506270780282862 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.02816299892341097                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [588, 721, 1883, 1861, 358, 1909, 374, 1674, 1237, 72]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :588
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598302
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378756
INFO:root:FL Epoch: 352 Norm Difference for worker 588 is 1.788994
INFO:root:FL Epoch: 352 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :721
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776744
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291759
INFO:root:FL Epoch: 352 Norm Difference for worker 721 is 1.565832
INFO:root:FL Epoch: 352 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1883
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400990
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188498
INFO:root:FL Epoch: 352 Norm Difference for worker 1883 is 1.57081
INFO:root:FL Epoch: 352 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1861
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268257
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300290
INFO:root:FL Epoch: 352 Norm Difference for worker 1861 is 1.518706
INFO:root:FL Epoch: 352 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :358
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340976
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176850
INFO:root:FL Epoch: 352 Norm Difference for worker 358 is 1.510372
INFO:root:FL Epoch: 352 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1909
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420107
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175973
INFO:root:FL Epoch: 352 Norm Difference for worker 1909 is 1.553392
INFO:root:FL Epoch: 352 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :374
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684654
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273549
INFO:root:FL Epoch: 352 Norm Difference for worker 374 is 1.587022
INFO:root:FL Epoch: 352 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1674
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526254
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.109783
INFO:root:FL Epoch: 352 Norm Difference for worker 1674 is 1.477614
INFO:root:FL Epoch: 352 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1237
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807510
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282645
INFO:root:FL Epoch: 352 Norm Difference for worker 1237 is 1.8003
INFO:root:FL Epoch: 352 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :72
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 72 is 1.527173
INFO:root:FL Epoch: 352 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.5047593038065652, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.504414744841563
INFO:root:#### Oracle Cals: 3, Objective Val: 1.5044106832085138
INFO:root:#### Oracle Cals: 4, Objective Val: 1.5044106475229517
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.4613301096593632 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.02990786001707117                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1237, 882, 946, 571, 1547, 1187, 1344, 1663, 105, 1843]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1237
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370904
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227355
INFO:root:FL Epoch: 353 Norm Difference for worker 1237 is 1.600973
INFO:root:FL Epoch: 353 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :882
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400296
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181242
INFO:root:FL Epoch: 353 Norm Difference for worker 882 is 1.606251
INFO:root:FL Epoch: 353 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :946
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391858
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190399
INFO:root:FL Epoch: 353 Norm Difference for worker 946 is 1.49775
INFO:root:FL Epoch: 353 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :571
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303723
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158507
INFO:root:FL Epoch: 353 Norm Difference for worker 571 is 1.562705
INFO:root:FL Epoch: 353 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1547
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290252
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151404
INFO:root:FL Epoch: 353 Norm Difference for worker 1547 is 1.572522
INFO:root:FL Epoch: 353 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1187
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481572
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253861
INFO:root:FL Epoch: 353 Norm Difference for worker 1187 is 1.504187
INFO:root:FL Epoch: 353 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1344
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773887
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302828
INFO:root:FL Epoch: 353 Norm Difference for worker 1344 is 1.552215
INFO:root:FL Epoch: 353 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1663
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427168
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517071
INFO:root:FL Epoch: 353 Norm Difference for worker 1663 is 1.59492
INFO:root:FL Epoch: 353 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :105
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 105 is 1.631787
INFO:root:FL Epoch: 353 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1843
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.192117
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419657
INFO:root:FL Epoch: 353 Norm Difference for worker 1843 is 1.485158
INFO:root:FL Epoch: 353 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4723713717225926, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4723047250221588
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4723039343128732
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4723038656221459
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.4644830384675194 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.042032940313220024                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [660, 1494, 1242, 1335, 1418, 184, 1837, 178, 10, 14]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 201 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :660
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578597
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280476
INFO:root:FL Epoch: 354 Norm Difference for worker 660 is 1.442406
INFO:root:FL Epoch: 354 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1494
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859904
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315071
INFO:root:FL Epoch: 354 Norm Difference for worker 1494 is 1.478095
INFO:root:FL Epoch: 354 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1242
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736213
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244170
INFO:root:FL Epoch: 354 Norm Difference for worker 1242 is 1.44409
INFO:root:FL Epoch: 354 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1335
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685104
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158793
INFO:root:FL Epoch: 354 Norm Difference for worker 1335 is 1.368495
INFO:root:FL Epoch: 354 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1418
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526362
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178377
INFO:root:FL Epoch: 354 Norm Difference for worker 1418 is 1.446194
INFO:root:FL Epoch: 354 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :184
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.149968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 184 is 1.394351
INFO:root:FL Epoch: 354 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1837
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.158585
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202221
INFO:root:FL Epoch: 354 Norm Difference for worker 1837 is 1.428
INFO:root:FL Epoch: 354 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :178
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 178 is 1.439871
INFO:root:FL Epoch: 354 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :10
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 10 is 1.554312
INFO:root:FL Epoch: 354 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :14
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.362641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 14 is 1.410287
INFO:root:FL Epoch: 354 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3622693667456585, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3621656036128018
INFO:root:#### Oracle Cals: 3, Objective Val: 1.36216444746721
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3621644152285979
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.4494243474567638 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.04322680147985617                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [196, 1723, 1727, 1583, 929, 174, 1542, 1680, 696, 659]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :196
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 196 is 1.488506
INFO:root:FL Epoch: 355 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1723
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455133
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266966
INFO:root:FL Epoch: 355 Norm Difference for worker 1723 is 1.444772
INFO:root:FL Epoch: 355 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1727
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281611
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396843
INFO:root:FL Epoch: 355 Norm Difference for worker 1727 is 1.434305
INFO:root:FL Epoch: 355 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1583
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537105
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256226
INFO:root:FL Epoch: 355 Norm Difference for worker 1583 is 1.544027
INFO:root:FL Epoch: 355 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :929
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323740
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380097
INFO:root:FL Epoch: 355 Norm Difference for worker 929 is 1.603733
INFO:root:FL Epoch: 355 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :174
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438501
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 174 is 1.518928
INFO:root:FL Epoch: 355 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1542
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590315
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121245
INFO:root:FL Epoch: 355 Norm Difference for worker 1542 is 1.393104
INFO:root:FL Epoch: 355 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1680
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606963
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151441
INFO:root:FL Epoch: 355 Norm Difference for worker 1680 is 1.571946
INFO:root:FL Epoch: 355 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :696
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458565
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331323
INFO:root:FL Epoch: 355 Norm Difference for worker 696 is 1.520286
INFO:root:FL Epoch: 355 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :659
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427680
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200005
INFO:root:FL Epoch: 355 Norm Difference for worker 659 is 1.516592
INFO:root:FL Epoch: 355 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4204134006115563, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4202882642305454
INFO:root:#### Oracle Cals: 3, Objective Val: 1.420286451176029
INFO:root:#### Oracle Cals: 4, Objective Val: 1.420286415292902
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.453904332483516 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.04462221389015516                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [65, 648, 1515, 64, 1041, 823, 1336, 1648, 1233, 54]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 356 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :65
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.311707
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 65 is 1.526409
INFO:root:FL Epoch: 356 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386363
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608907
INFO:root:FL Epoch: 356 Norm Difference for worker 648 is 1.944584
INFO:root:FL Epoch: 356 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1515
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566168
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405842
INFO:root:FL Epoch: 356 Norm Difference for worker 1515 is 1.413113
INFO:root:FL Epoch: 356 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :64
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.261955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383403
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 64 is 1.472088
INFO:root:FL Epoch: 356 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1041
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326877
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207053
INFO:root:FL Epoch: 356 Norm Difference for worker 1041 is 1.508359
INFO:root:FL Epoch: 356 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :823
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374956
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329773
INFO:root:FL Epoch: 356 Norm Difference for worker 823 is 1.587419
INFO:root:FL Epoch: 356 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1336
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516490
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234206
INFO:root:FL Epoch: 356 Norm Difference for worker 1336 is 1.516554
INFO:root:FL Epoch: 356 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.951887
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282597
INFO:root:FL Epoch: 356 Norm Difference for worker 1648 is 1.489185
INFO:root:FL Epoch: 356 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1233
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592983
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236020
INFO:root:FL Epoch: 356 Norm Difference for worker 1233 is 1.624646
INFO:root:FL Epoch: 356 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :54
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 54 is 1.447927
INFO:root:FL Epoch: 356 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4689894189271389, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4683662878961181
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4683604446160725
INFO:root:#### Oracle Cals: 4, Objective Val: 1.468360367056644
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.4464283287525177 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.05019707356890043                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1333, 1745, 1844, 1776, 288, 308, 1198, 441, 1571, 614]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1333
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531907
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251471
INFO:root:FL Epoch: 357 Norm Difference for worker 1333 is 1.447084
INFO:root:FL Epoch: 357 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1745
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368459
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184309
INFO:root:FL Epoch: 357 Norm Difference for worker 1745 is 1.378407
INFO:root:FL Epoch: 357 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1844
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361267
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201556
INFO:root:FL Epoch: 357 Norm Difference for worker 1844 is 1.253084
INFO:root:FL Epoch: 357 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1776
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467556
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250726
INFO:root:FL Epoch: 357 Norm Difference for worker 1776 is 1.445763
INFO:root:FL Epoch: 357 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :288
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 288 is 1.46661
INFO:root:FL Epoch: 357 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :308
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 308 is 1.409624
INFO:root:FL Epoch: 357 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1198
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750066
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327380
INFO:root:FL Epoch: 357 Norm Difference for worker 1198 is 1.344714
INFO:root:FL Epoch: 357 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :441
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496106
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428026
INFO:root:FL Epoch: 357 Norm Difference for worker 441 is 1.543991
INFO:root:FL Epoch: 357 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1571
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408899
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443139
INFO:root:FL Epoch: 357 Norm Difference for worker 1571 is 1.525968
INFO:root:FL Epoch: 357 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :614
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654996
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227821
INFO:root:FL Epoch: 357 Norm Difference for worker 614 is 1.341996
INFO:root:FL Epoch: 357 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3355928191908855, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3353768154409553
INFO:root:#### Oracle Cals: 3, Objective Val: 1.335373685542826
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3353735987894209
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.44306472469778624 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.04652709079285463                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1581, 104, 380, 887, 392, 1518, 120, 905, 1181, 65]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1581
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470866
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214184
INFO:root:FL Epoch: 358 Norm Difference for worker 1581 is 1.398119
INFO:root:FL Epoch: 358 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :104
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263627
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 104 is 1.427352
INFO:root:FL Epoch: 358 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :380
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411647
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274516
INFO:root:FL Epoch: 358 Norm Difference for worker 380 is 1.396352
INFO:root:FL Epoch: 358 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :887
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549256
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354596
INFO:root:FL Epoch: 358 Norm Difference for worker 887 is 1.459986
INFO:root:FL Epoch: 358 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :392
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336936
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310422
INFO:root:FL Epoch: 358 Norm Difference for worker 392 is 1.413303
INFO:root:FL Epoch: 358 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1518
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379421
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290054
INFO:root:FL Epoch: 358 Norm Difference for worker 1518 is 1.396419
INFO:root:FL Epoch: 358 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :120
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.290666
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 120 is 1.522684
INFO:root:FL Epoch: 358 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :905
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341336
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343312
INFO:root:FL Epoch: 358 Norm Difference for worker 905 is 1.445668
INFO:root:FL Epoch: 358 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1181
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375029
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179477
INFO:root:FL Epoch: 358 Norm Difference for worker 1181 is 1.383349
INFO:root:FL Epoch: 358 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :65
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 65 is 1.318411
INFO:root:FL Epoch: 358 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.347149774120932, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3470698100119387
INFO:root:#### Oracle Cals: 3, Objective Val: 1.347068897627726
INFO:root:#### Oracle Cals: 4, Objective Val: 1.347068851549115
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.45767884920625124 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.04499199613928795                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [676, 755, 955, 1854, 1219, 281, 1836, 832, 953, 1498]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :676
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662648
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405530
INFO:root:FL Epoch: 359 Norm Difference for worker 676 is 1.61941
INFO:root:FL Epoch: 359 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :755
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364723
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214303
INFO:root:FL Epoch: 359 Norm Difference for worker 755 is 1.317869
INFO:root:FL Epoch: 359 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :955
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663199
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297705
INFO:root:FL Epoch: 359 Norm Difference for worker 955 is 1.513477
INFO:root:FL Epoch: 359 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1854
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563109
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298731
INFO:root:FL Epoch: 359 Norm Difference for worker 1854 is 1.552193
INFO:root:FL Epoch: 359 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1219
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387939
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225554
INFO:root:FL Epoch: 359 Norm Difference for worker 1219 is 1.346053
INFO:root:FL Epoch: 359 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :281
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232273
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 281 is 1.345058
INFO:root:FL Epoch: 359 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1836
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505981
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214830
INFO:root:FL Epoch: 359 Norm Difference for worker 1836 is 1.429009
INFO:root:FL Epoch: 359 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :832
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489946
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260389
INFO:root:FL Epoch: 359 Norm Difference for worker 832 is 1.474269
INFO:root:FL Epoch: 359 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :953
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427196
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218532
INFO:root:FL Epoch: 359 Norm Difference for worker 953 is 1.407353
INFO:root:FL Epoch: 359 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1498
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317911
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292674
INFO:root:FL Epoch: 359 Norm Difference for worker 1498 is 1.438093
INFO:root:FL Epoch: 359 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3629007473576875, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3626254875252544
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3626222647506137
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3626222486277633
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.4514120992492227 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.04049783572554588                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [752, 1335, 1381, 1057, 813, 767, 214, 100, 80, 1821]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :752
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551977
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345120
INFO:root:FL Epoch: 360 Norm Difference for worker 752 is 1.494186
INFO:root:FL Epoch: 360 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1335
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581397
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250216
INFO:root:FL Epoch: 360 Norm Difference for worker 1335 is 1.362069
INFO:root:FL Epoch: 360 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1381
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563011
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383755
INFO:root:FL Epoch: 360 Norm Difference for worker 1381 is 1.57844
INFO:root:FL Epoch: 360 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1057
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.982341
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427107
INFO:root:FL Epoch: 360 Norm Difference for worker 1057 is 1.497627
INFO:root:FL Epoch: 360 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :813
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345243
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167277
INFO:root:FL Epoch: 360 Norm Difference for worker 813 is 1.487816
INFO:root:FL Epoch: 360 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :767
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721856
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392802
INFO:root:FL Epoch: 360 Norm Difference for worker 767 is 1.58884
INFO:root:FL Epoch: 360 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :214
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.123560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 214 is 1.355205
INFO:root:FL Epoch: 360 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :100
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.153304
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 100 is 1.456572
INFO:root:FL Epoch: 360 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :80
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 80 is 1.253201
INFO:root:FL Epoch: 360 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1821
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423728
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284600
INFO:root:FL Epoch: 360 Norm Difference for worker 1821 is 1.473824
INFO:root:FL Epoch: 360 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3769938551444891, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3766841293384786
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3766790395354203
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3766789715086205
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.443241932812859 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.03595966938883066                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 1618, 643, 1710, 966, 640, 1848, 1504]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.047919
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.034682
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.022889829395959776 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.021578851342201232 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.318532
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.066666
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.034170
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.02201121672987938 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.021077584475278854 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.31553
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.046117
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.028581
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.02299339696764946 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.022521755192428827 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.308654
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1618
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545260
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213127
INFO:root:FL Epoch: 361 Norm Difference for worker 1618 is 1.398912
INFO:root:FL Epoch: 361 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :643
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438358
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197269
INFO:root:FL Epoch: 361 Norm Difference for worker 643 is 1.453524
INFO:root:FL Epoch: 361 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1710
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306973
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131013
INFO:root:FL Epoch: 361 Norm Difference for worker 1710 is 1.429093
INFO:root:FL Epoch: 361 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :966
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504032
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190670
INFO:root:FL Epoch: 361 Norm Difference for worker 966 is 1.539632
INFO:root:FL Epoch: 361 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :640
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466148
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277582
INFO:root:FL Epoch: 361 Norm Difference for worker 640 is 1.463284
INFO:root:FL Epoch: 361 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1848
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396389
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236486
INFO:root:FL Epoch: 361 Norm Difference for worker 1848 is 1.396206
INFO:root:FL Epoch: 361 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1504
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438992
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374519
INFO:root:FL Epoch: 361 Norm Difference for worker 1504 is 1.520817
INFO:root:FL Epoch: 361 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.0834519327605678, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.0579882455110512
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0523156329204946
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0507125967105433
INFO:root:#### Oracle Cals: 5, Objective Val: 1.05024683801722
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0501143564188056
INFO:root:#### Oracle Cals: 7, Objective Val: 1.050077945112015
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0500679218594282
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0500652685034932
INFO:root:#### Oracle Cals: 10, Objective Val: 1.0500647387306399
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0500643960122018
INFO:root:#### Oracle Cals: 12, Objective Val: 1.0500644080204244
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.45602208375930786 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.024199585895985365                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [648, 714, 824, 991, 1179, 1599, 585, 1926, 50, 1021]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :648
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540099
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143383
INFO:root:FL Epoch: 362 Norm Difference for worker 648 is 1.491416
INFO:root:FL Epoch: 362 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :714
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676185
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297980
INFO:root:FL Epoch: 362 Norm Difference for worker 714 is 1.674492
INFO:root:FL Epoch: 362 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :824
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359045
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575390
INFO:root:FL Epoch: 362 Norm Difference for worker 824 is 1.577722
INFO:root:FL Epoch: 362 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :991
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299872
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328840
INFO:root:FL Epoch: 362 Norm Difference for worker 991 is 1.498636
INFO:root:FL Epoch: 362 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1179
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260955
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213953
INFO:root:FL Epoch: 362 Norm Difference for worker 1179 is 1.495096
INFO:root:FL Epoch: 362 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1599
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268876
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122972
INFO:root:FL Epoch: 362 Norm Difference for worker 1599 is 1.434617
INFO:root:FL Epoch: 362 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :585
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648444
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148248
INFO:root:FL Epoch: 362 Norm Difference for worker 585 is 1.473362
INFO:root:FL Epoch: 362 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1926
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497819
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227557
INFO:root:FL Epoch: 362 Norm Difference for worker 1926 is 1.552302
INFO:root:FL Epoch: 362 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :50
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 50 is 1.612709
INFO:root:FL Epoch: 362 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1021
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608377
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223388
INFO:root:FL Epoch: 362 Norm Difference for worker 1021 is 1.522341
INFO:root:FL Epoch: 362 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.446280369787944, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4461215132803054
INFO:root:#### Oracle Cals: 3, Objective Val: 1.446119513495366
INFO:root:#### Oracle Cals: 4, Objective Val: 1.446119496724884
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.4457414255422704 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.03150965909784039                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [1332, 1401, 480, 1193, 838, 313, 1411, 1295, 877, 456]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :1332
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293049
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329381
INFO:root:FL Epoch: 363 Norm Difference for worker 1332 is 1.531114
INFO:root:FL Epoch: 363 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1401
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429682
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165977
INFO:root:FL Epoch: 363 Norm Difference for worker 1401 is 1.503353
INFO:root:FL Epoch: 363 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :480
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515508
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342771
INFO:root:FL Epoch: 363 Norm Difference for worker 480 is 1.648001
INFO:root:FL Epoch: 363 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1193
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358651
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314253
INFO:root:FL Epoch: 363 Norm Difference for worker 1193 is 1.665119
INFO:root:FL Epoch: 363 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :838
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652561
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276820
INFO:root:FL Epoch: 363 Norm Difference for worker 838 is 1.539037
INFO:root:FL Epoch: 363 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :313
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.108875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 313 is 1.47184
INFO:root:FL Epoch: 363 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1411
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397240
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384477
INFO:root:FL Epoch: 363 Norm Difference for worker 1411 is 1.574353
INFO:root:FL Epoch: 363 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1295
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367849
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146289
INFO:root:FL Epoch: 363 Norm Difference for worker 1295 is 1.470033
INFO:root:FL Epoch: 363 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :877
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403016
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189704
INFO:root:FL Epoch: 363 Norm Difference for worker 877 is 1.432615
INFO:root:FL Epoch: 363 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :456
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417071
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190053
INFO:root:FL Epoch: 363 Norm Difference for worker 456 is 1.473408
INFO:root:FL Epoch: 363 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.448501473029925, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4482747321224514
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4482716951384125
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4482716522559662
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.469193416483262 and Test Accuracy:75.0 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.029549569201966126                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [161, 1851, 1054, 165, 574, 185, 319, 539, 667, 303]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.10024938 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 364 Num points on workers: [201 200 200 201 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :161
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 161 is 1.490844
INFO:root:FL Epoch: 364 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1851
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646564
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250691
INFO:root:FL Epoch: 364 Norm Difference for worker 1851 is 1.374946
INFO:root:FL Epoch: 364 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1054
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443928
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201859
INFO:root:FL Epoch: 364 Norm Difference for worker 1054 is 1.686344
INFO:root:FL Epoch: 364 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :165
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 165 is 1.551146
INFO:root:FL Epoch: 364 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :574
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343086
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171154
INFO:root:FL Epoch: 364 Norm Difference for worker 574 is 1.573636
INFO:root:FL Epoch: 364 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :185
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.193547
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 185 is 1.317895
INFO:root:FL Epoch: 364 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :319
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.288089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.172310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 319 is 1.487888
INFO:root:FL Epoch: 364 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :539
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569589
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215714
INFO:root:FL Epoch: 364 Norm Difference for worker 539 is 1.55953
INFO:root:FL Epoch: 364 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :667
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377733
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230248
INFO:root:FL Epoch: 364 Norm Difference for worker 667 is 1.413617
INFO:root:FL Epoch: 364 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :303
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595203
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349980
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 303 is 1.536958
INFO:root:FL Epoch: 364 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4134751595482036, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4131299324599944
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4131251340945015
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4131250716043184
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.48647385309724245 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.03599548355365793                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [184, 1587, 703, 353, 1442, 1376, 959, 669, 1830, 1102]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 365 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :184
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.163560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 184 is 1.28463
INFO:root:FL Epoch: 365 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1587
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430924
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151883
INFO:root:FL Epoch: 365 Norm Difference for worker 1587 is 1.62395
INFO:root:FL Epoch: 365 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :703
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274324
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234203
INFO:root:FL Epoch: 365 Norm Difference for worker 703 is 1.575581
INFO:root:FL Epoch: 365 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :353
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634893
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298364
INFO:root:FL Epoch: 365 Norm Difference for worker 353 is 1.618234
INFO:root:FL Epoch: 365 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1442
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383856
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355394
INFO:root:FL Epoch: 365 Norm Difference for worker 1442 is 1.569133
INFO:root:FL Epoch: 365 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1376
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500208
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220652
INFO:root:FL Epoch: 365 Norm Difference for worker 1376 is 1.4426
INFO:root:FL Epoch: 365 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :959
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550436
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249610
INFO:root:FL Epoch: 365 Norm Difference for worker 959 is 1.468906
INFO:root:FL Epoch: 365 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :669
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370290
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264416
INFO:root:FL Epoch: 365 Norm Difference for worker 669 is 1.487119
INFO:root:FL Epoch: 365 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1830
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644386
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145545
INFO:root:FL Epoch: 365 Norm Difference for worker 1830 is 1.525422
INFO:root:FL Epoch: 365 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1102
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262279
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261560
INFO:root:FL Epoch: 365 Norm Difference for worker 1102 is 1.364845
INFO:root:FL Epoch: 365 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.414521306153639, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4142252037049177
INFO:root:#### Oracle Cals: 3, Objective Val: 1.414221434048582
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4142213736202451
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.46573501124101524 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.03428738610818982                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1351, 1724, 887, 1192, 624, 1905, 629, 890, 1653, 1794]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1351
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523819
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497278
INFO:root:FL Epoch: 366 Norm Difference for worker 1351 is 1.575079
INFO:root:FL Epoch: 366 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1724
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635676
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333893
INFO:root:FL Epoch: 366 Norm Difference for worker 1724 is 1.51793
INFO:root:FL Epoch: 366 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :887
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484513
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266921
INFO:root:FL Epoch: 366 Norm Difference for worker 887 is 1.468083
INFO:root:FL Epoch: 366 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1192
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395777
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368935
INFO:root:FL Epoch: 366 Norm Difference for worker 1192 is 1.598906
INFO:root:FL Epoch: 366 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :624
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663021
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327563
INFO:root:FL Epoch: 366 Norm Difference for worker 624 is 1.446455
INFO:root:FL Epoch: 366 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1905
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328750
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227556
INFO:root:FL Epoch: 366 Norm Difference for worker 1905 is 1.270548
INFO:root:FL Epoch: 366 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :629
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626624
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238250
INFO:root:FL Epoch: 366 Norm Difference for worker 629 is 1.348645
INFO:root:FL Epoch: 366 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :890
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360755
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315260
INFO:root:FL Epoch: 366 Norm Difference for worker 890 is 1.614862
INFO:root:FL Epoch: 366 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1653
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238893
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185242
INFO:root:FL Epoch: 366 Norm Difference for worker 1653 is 1.35099
INFO:root:FL Epoch: 366 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1794
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367017
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385583
INFO:root:FL Epoch: 366 Norm Difference for worker 1794 is 1.587863
INFO:root:FL Epoch: 366 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.39081430232692, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3903631132467418
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3903563729498956
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3903562343678195
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.4622137213454527 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.04344874775658051                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [1509, 1066, 558, 1605, 399, 1525, 1148, 677, 1492, 327]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 367 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :1509
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685812
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305638
INFO:root:FL Epoch: 367 Norm Difference for worker 1509 is 1.413969
INFO:root:FL Epoch: 367 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1066
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220451
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310963
INFO:root:FL Epoch: 367 Norm Difference for worker 1066 is 1.567576
INFO:root:FL Epoch: 367 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :558
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375396
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545047
INFO:root:FL Epoch: 367 Norm Difference for worker 558 is 1.655258
INFO:root:FL Epoch: 367 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1605
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259853
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269201
INFO:root:FL Epoch: 367 Norm Difference for worker 1605 is 1.556761
INFO:root:FL Epoch: 367 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :399
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275150
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371645
INFO:root:FL Epoch: 367 Norm Difference for worker 399 is 1.580342
INFO:root:FL Epoch: 367 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1525
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755993
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292957
INFO:root:FL Epoch: 367 Norm Difference for worker 1525 is 1.522023
INFO:root:FL Epoch: 367 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1148
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623515
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307523
INFO:root:FL Epoch: 367 Norm Difference for worker 1148 is 1.616613
INFO:root:FL Epoch: 367 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :677
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451815
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177638
INFO:root:FL Epoch: 367 Norm Difference for worker 677 is 1.59531
INFO:root:FL Epoch: 367 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1492
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751856
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.111682
INFO:root:FL Epoch: 367 Norm Difference for worker 1492 is 1.498819
INFO:root:FL Epoch: 367 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :327
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.964778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 327 is 1.720471
INFO:root:FL Epoch: 367 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4765876198603114, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4764102715858831
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4764080407794837
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4764080275543943
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.4443185715114369 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.0451279024903973                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [783, 277, 1708, 1063, 169, 1279, 247, 1366, 304, 1678]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 368 Num points on workers: [200 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :783
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821527
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270137
INFO:root:FL Epoch: 368 Norm Difference for worker 783 is 1.417452
INFO:root:FL Epoch: 368 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :277
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 277 is 1.424875
INFO:root:FL Epoch: 368 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1708
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496514
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265794
INFO:root:FL Epoch: 368 Norm Difference for worker 1708 is 1.53321
INFO:root:FL Epoch: 368 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1063
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282432
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378737
INFO:root:FL Epoch: 368 Norm Difference for worker 1063 is 1.560887
INFO:root:FL Epoch: 368 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :169
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.311823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237256
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 169 is 1.392394
INFO:root:FL Epoch: 368 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1279
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860627
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351074
INFO:root:FL Epoch: 368 Norm Difference for worker 1279 is 1.500695
INFO:root:FL Epoch: 368 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :247
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.140753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 247 is 1.561166
INFO:root:FL Epoch: 368 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1366
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307919
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228221
INFO:root:FL Epoch: 368 Norm Difference for worker 1366 is 1.419442
INFO:root:FL Epoch: 368 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :304
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 304 is 1.373659
INFO:root:FL Epoch: 368 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1678
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334051
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196888
INFO:root:FL Epoch: 368 Norm Difference for worker 1678 is 1.418485
INFO:root:FL Epoch: 368 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3802648569593823, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3801313453126536
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3801298129635915
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3801298198801923
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.4334106708274168 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.04929742279152075                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [897, 768, 199, 1231, 1007, 245, 1031, 439, 680, 841]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :897
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474380
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186278
INFO:root:FL Epoch: 369 Norm Difference for worker 897 is 1.532022
INFO:root:FL Epoch: 369 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :768
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310552
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382434
INFO:root:FL Epoch: 369 Norm Difference for worker 768 is 1.443575
INFO:root:FL Epoch: 369 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :199
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661439
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 199 is 1.702298
INFO:root:FL Epoch: 369 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1231
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.187322
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341226
INFO:root:FL Epoch: 369 Norm Difference for worker 1231 is 1.503603
INFO:root:FL Epoch: 369 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1007
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672896
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342454
INFO:root:FL Epoch: 369 Norm Difference for worker 1007 is 1.513417
INFO:root:FL Epoch: 369 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :245
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 245 is 1.515018
INFO:root:FL Epoch: 369 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1031
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633875
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305974
INFO:root:FL Epoch: 369 Norm Difference for worker 1031 is 1.621323
INFO:root:FL Epoch: 369 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :439
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573206
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406322
INFO:root:FL Epoch: 369 Norm Difference for worker 439 is 1.441593
INFO:root:FL Epoch: 369 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :680
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418604
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159360
INFO:root:FL Epoch: 369 Norm Difference for worker 680 is 1.484167
INFO:root:FL Epoch: 369 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :841
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730145
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350180
INFO:root:FL Epoch: 369 Norm Difference for worker 841 is 1.471547
INFO:root:FL Epoch: 369 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4390067912201705, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4388555135583714
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4388537191133135
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4388537217689215
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.45635620636098523 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.05174413323402405                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [78, 158, 1509, 571, 30, 818, 201, 1021, 185, 750]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 370 Num points on workers: [201 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :78
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 78 is 1.38912
INFO:root:FL Epoch: 370 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :158
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.326261
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 158 is 1.372826
INFO:root:FL Epoch: 370 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1509
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416493
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274539
INFO:root:FL Epoch: 370 Norm Difference for worker 1509 is 1.314236
INFO:root:FL Epoch: 370 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :571
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464281
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438623
INFO:root:FL Epoch: 370 Norm Difference for worker 571 is 1.447043
INFO:root:FL Epoch: 370 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :30
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.228670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 30 is 1.429599
INFO:root:FL Epoch: 370 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :818
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480428
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357817
INFO:root:FL Epoch: 370 Norm Difference for worker 818 is 1.511639
INFO:root:FL Epoch: 370 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :201
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276404
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 201 is 1.61076
INFO:root:FL Epoch: 370 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1021
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417218
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181648
INFO:root:FL Epoch: 370 Norm Difference for worker 1021 is 1.371497
INFO:root:FL Epoch: 370 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :185
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.294095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 185 is 1.261468
INFO:root:FL Epoch: 370 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :750
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518844
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210426
INFO:root:FL Epoch: 370 Norm Difference for worker 750 is 1.711007
INFO:root:FL Epoch: 370 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3578321891057719, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3570990380514314
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3570904094211864
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3570903128279186
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.4789796734557432 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.04392447912444671                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 1061, 1042, 1852, 1271, 1167, 671, 986]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.058643
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.030061
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.024477490223944187 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.020961307734251023 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.327607
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.038024
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.037606
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.023968521660814684 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.020586140640079974 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.303252
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.050938
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.055241
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.02452749665826559 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.019654581882059576 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.322816
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1061
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559373
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400529
INFO:root:FL Epoch: 371 Norm Difference for worker 1061 is 1.48884
INFO:root:FL Epoch: 371 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1042
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466553
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220439
INFO:root:FL Epoch: 371 Norm Difference for worker 1042 is 1.403439
INFO:root:FL Epoch: 371 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1852
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561556
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477475
INFO:root:FL Epoch: 371 Norm Difference for worker 1852 is 1.445953
INFO:root:FL Epoch: 371 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1271
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635794
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412760
INFO:root:FL Epoch: 371 Norm Difference for worker 1271 is 1.366464
INFO:root:FL Epoch: 371 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1167
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616075
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232792
INFO:root:FL Epoch: 371 Norm Difference for worker 1167 is 1.453104
INFO:root:FL Epoch: 371 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :671
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392872
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189877
INFO:root:FL Epoch: 371 Norm Difference for worker 671 is 1.271819
INFO:root:FL Epoch: 371 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :986
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512642
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296626
INFO:root:FL Epoch: 371 Norm Difference for worker 986 is 1.530761
INFO:root:FL Epoch: 371 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.060699079218638, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.036452935080034
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0312074912013682
INFO:root:#### Oracle Cals: 4, Objective Val: 1.029757923207829
INFO:root:#### Oracle Cals: 5, Objective Val: 1.0293396035958269
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0292200310693773
INFO:root:#### Oracle Cals: 7, Objective Val: 1.0291860232803534
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0291765860335969
INFO:root:#### Oracle Cals: 9, Objective Val: 1.029174076175888
INFO:root:#### Oracle Cals: 10, Objective Val: 1.0291732810292575
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0291730532921046
INFO:root:#### Oracle Cals: 12, Objective Val: 1.0291730878888257
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.49337545913808484 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.028361777774989605                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1304, 439, 523, 1858, 473, 17, 1491, 1571, 364, 119]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1304
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448593
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280159
INFO:root:FL Epoch: 372 Norm Difference for worker 1304 is 1.504058
INFO:root:FL Epoch: 372 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :439
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259666
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190365
INFO:root:FL Epoch: 372 Norm Difference for worker 439 is 1.406113
INFO:root:FL Epoch: 372 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :523
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577824
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169803
INFO:root:FL Epoch: 372 Norm Difference for worker 523 is 1.590443
INFO:root:FL Epoch: 372 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1858
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501755
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201144
INFO:root:FL Epoch: 372 Norm Difference for worker 1858 is 1.596572
INFO:root:FL Epoch: 372 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :473
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.866400
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279383
INFO:root:FL Epoch: 372 Norm Difference for worker 473 is 1.536372
INFO:root:FL Epoch: 372 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :17
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.884063
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 17 is 1.664448
INFO:root:FL Epoch: 372 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1491
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610364
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315118
INFO:root:FL Epoch: 372 Norm Difference for worker 1491 is 1.556283
INFO:root:FL Epoch: 372 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1571
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881151
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345427
INFO:root:FL Epoch: 372 Norm Difference for worker 1571 is 1.477364
INFO:root:FL Epoch: 372 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :364
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576512
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191760
INFO:root:FL Epoch: 372 Norm Difference for worker 364 is 1.596631
INFO:root:FL Epoch: 372 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :119
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.214238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 119 is 1.627954
INFO:root:FL Epoch: 372 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4688402181365399, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4686761618904756
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4686741078196028
INFO:root:#### Oracle Cals: 4, Objective Val: 1.468674075957831
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.49514567150789146 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.04097199998795986                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [1519, 1509, 112, 1748, 415, 1017, 782, 1715, 1356, 1342]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :1519
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602082
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471436
INFO:root:FL Epoch: 373 Norm Difference for worker 1519 is 1.487922
INFO:root:FL Epoch: 373 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1509
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417345
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192153
INFO:root:FL Epoch: 373 Norm Difference for worker 1509 is 1.26416
INFO:root:FL Epoch: 373 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :112
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.799091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 112 is 1.467473
INFO:root:FL Epoch: 373 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1748
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490503
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316991
INFO:root:FL Epoch: 373 Norm Difference for worker 1748 is 1.575605
INFO:root:FL Epoch: 373 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :415
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907074
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208533
INFO:root:FL Epoch: 373 Norm Difference for worker 415 is 1.465579
INFO:root:FL Epoch: 373 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1017
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518125
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469826
INFO:root:FL Epoch: 373 Norm Difference for worker 1017 is 1.574578
INFO:root:FL Epoch: 373 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :782
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457147
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213190
INFO:root:FL Epoch: 373 Norm Difference for worker 782 is 1.665468
INFO:root:FL Epoch: 373 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1715
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480948
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175686
INFO:root:FL Epoch: 373 Norm Difference for worker 1715 is 1.416737
INFO:root:FL Epoch: 373 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1356
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396777
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160423
INFO:root:FL Epoch: 373 Norm Difference for worker 1356 is 1.633146
INFO:root:FL Epoch: 373 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1342
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350648
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215507
INFO:root:FL Epoch: 373 Norm Difference for worker 1342 is 1.496985
INFO:root:FL Epoch: 373 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.425727679137037, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4253730599863308
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4253678981913156
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4253678243349286
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.48385145033107085 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.04557860363274813                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1498, 804, 643, 1075, 1437, 74, 979, 516, 1748, 1798]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1498
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255283
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185916
INFO:root:FL Epoch: 374 Norm Difference for worker 1498 is 1.468284
INFO:root:FL Epoch: 374 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :804
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406856
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309854
INFO:root:FL Epoch: 374 Norm Difference for worker 804 is 1.622732
INFO:root:FL Epoch: 374 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :643
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665505
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284260
INFO:root:FL Epoch: 374 Norm Difference for worker 643 is 1.515227
INFO:root:FL Epoch: 374 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1075
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253919
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166161
INFO:root:FL Epoch: 374 Norm Difference for worker 1075 is 1.429168
INFO:root:FL Epoch: 374 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1437
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.880635
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187987
INFO:root:FL Epoch: 374 Norm Difference for worker 1437 is 1.642061
INFO:root:FL Epoch: 374 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :74
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 74 is 1.524164
INFO:root:FL Epoch: 374 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :979
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737539
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391757
INFO:root:FL Epoch: 374 Norm Difference for worker 979 is 1.553067
INFO:root:FL Epoch: 374 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :516
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626107
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136787
INFO:root:FL Epoch: 374 Norm Difference for worker 516 is 1.525622
INFO:root:FL Epoch: 374 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1748
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511623
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300276
INFO:root:FL Epoch: 374 Norm Difference for worker 1748 is 1.427902
INFO:root:FL Epoch: 374 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1798
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629521
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197927
INFO:root:FL Epoch: 374 Norm Difference for worker 1798 is 1.598987
INFO:root:FL Epoch: 374 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4473170629872356, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4471876284398923
INFO:root:#### Oracle Cals: 3, Objective Val: 1.447185914467047
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4471858623521032
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.4640228783383089 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.044506254916389786                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [317, 105, 1425, 1249, 401, 243, 53, 960, 1525, 1533]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 375 Num points on workers: [201 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :317
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 317 is 1.526384
INFO:root:FL Epoch: 375 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :105
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 105 is 1.321604
INFO:root:FL Epoch: 375 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1425
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577776
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203929
INFO:root:FL Epoch: 375 Norm Difference for worker 1425 is 1.397727
INFO:root:FL Epoch: 375 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1249
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428469
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375093
INFO:root:FL Epoch: 375 Norm Difference for worker 1249 is 1.443931
INFO:root:FL Epoch: 375 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :401
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628240
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309053
INFO:root:FL Epoch: 375 Norm Difference for worker 401 is 1.729382
INFO:root:FL Epoch: 375 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :243
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399610
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 243 is 1.426782
INFO:root:FL Epoch: 375 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :53
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313300
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 53 is 1.426254
INFO:root:FL Epoch: 375 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :960
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385717
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175414
INFO:root:FL Epoch: 375 Norm Difference for worker 960 is 1.402552
INFO:root:FL Epoch: 375 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1525
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739128
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176621
INFO:root:FL Epoch: 375 Norm Difference for worker 1525 is 1.388952
INFO:root:FL Epoch: 375 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1533
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561045
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269604
INFO:root:FL Epoch: 375 Norm Difference for worker 1533 is 1.441637
INFO:root:FL Epoch: 375 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3709104171364483, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.370549398850461
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3705456564247065
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3705456351883405
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.4763298017137191 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.0417589129259189                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1397, 18, 956, 910, 205, 740, 1557, 1744, 425, 1208]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 376 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1397
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454525
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388557
INFO:root:FL Epoch: 376 Norm Difference for worker 1397 is 1.449017
INFO:root:FL Epoch: 376 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :18
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.267117
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 18 is 1.410987
INFO:root:FL Epoch: 376 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :956
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275442
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137746
INFO:root:FL Epoch: 376 Norm Difference for worker 956 is 1.504086
INFO:root:FL Epoch: 376 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :910
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415474
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188795
INFO:root:FL Epoch: 376 Norm Difference for worker 910 is 1.362752
INFO:root:FL Epoch: 376 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :205
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 205 is 1.463167
INFO:root:FL Epoch: 376 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :740
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564571
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330415
INFO:root:FL Epoch: 376 Norm Difference for worker 740 is 1.463414
INFO:root:FL Epoch: 376 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1557
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327574
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150712
INFO:root:FL Epoch: 376 Norm Difference for worker 1557 is 1.344014
INFO:root:FL Epoch: 376 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1744
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437651
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164304
INFO:root:FL Epoch: 376 Norm Difference for worker 1744 is 1.297689
INFO:root:FL Epoch: 376 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :425
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543233
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259511
INFO:root:FL Epoch: 376 Norm Difference for worker 425 is 1.561149
INFO:root:FL Epoch: 376 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1208
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477462
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214748
INFO:root:FL Epoch: 376 Norm Difference for worker 1208 is 1.41644
INFO:root:FL Epoch: 376 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3490528779348976, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3488750571005763
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3488728949180955
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3488728728140802
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.48315848848398996 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.04029174490521351                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [1407, 59, 1055, 261, 1932, 581, 1253, 23, 462, 1153]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :1407
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389685
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314700
INFO:root:FL Epoch: 377 Norm Difference for worker 1407 is 1.451891
INFO:root:FL Epoch: 377 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :59
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646407
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 59 is 1.35776
INFO:root:FL Epoch: 377 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1055
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504506
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259813
INFO:root:FL Epoch: 377 Norm Difference for worker 1055 is 1.476108
INFO:root:FL Epoch: 377 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :261
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 261 is 1.575919
INFO:root:FL Epoch: 377 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1932
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253242
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124583
INFO:root:FL Epoch: 377 Norm Difference for worker 1932 is 1.435261
INFO:root:FL Epoch: 377 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :581
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733115
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321063
INFO:root:FL Epoch: 377 Norm Difference for worker 581 is 1.701351
INFO:root:FL Epoch: 377 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1253
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383227
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395508
INFO:root:FL Epoch: 377 Norm Difference for worker 1253 is 1.551033
INFO:root:FL Epoch: 377 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :23
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557821
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 23 is 1.677828
INFO:root:FL Epoch: 377 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :462
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.198185
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218843
INFO:root:FL Epoch: 377 Norm Difference for worker 462 is 1.472371
INFO:root:FL Epoch: 377 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1153
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706241
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306538
INFO:root:FL Epoch: 377 Norm Difference for worker 1153 is 1.555261
INFO:root:FL Epoch: 377 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4413907784731754, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4410461069442788
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4410415600784385
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4410414690725402
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.49149490104002114 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.048173694560925163                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1066, 1905, 777, 1310, 1028, 1906, 169, 573, 888, 1462]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1066
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331917
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339314
INFO:root:FL Epoch: 378 Norm Difference for worker 1066 is 1.440719
INFO:root:FL Epoch: 378 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1905
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200831
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217995
INFO:root:FL Epoch: 378 Norm Difference for worker 1905 is 1.209612
INFO:root:FL Epoch: 378 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :777
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527712
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258188
INFO:root:FL Epoch: 378 Norm Difference for worker 777 is 1.508979
INFO:root:FL Epoch: 378 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1310
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640063
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184143
INFO:root:FL Epoch: 378 Norm Difference for worker 1310 is 1.373314
INFO:root:FL Epoch: 378 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1028
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466588
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316169
INFO:root:FL Epoch: 378 Norm Difference for worker 1028 is 1.459967
INFO:root:FL Epoch: 378 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1906
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375548
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306451
INFO:root:FL Epoch: 378 Norm Difference for worker 1906 is 1.445323
INFO:root:FL Epoch: 378 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :169
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467206
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.208853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 169 is 1.339335
INFO:root:FL Epoch: 378 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :573
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465341
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264200
INFO:root:FL Epoch: 378 Norm Difference for worker 573 is 1.436546
INFO:root:FL Epoch: 378 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :888
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493407
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190785
INFO:root:FL Epoch: 378 Norm Difference for worker 888 is 1.422893
INFO:root:FL Epoch: 378 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1462
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390490
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475100
INFO:root:FL Epoch: 378 Norm Difference for worker 1462 is 1.525913
INFO:root:FL Epoch: 378 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3319177195347045, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3316809445507825
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3316776097843752
INFO:root:#### Oracle Cals: 4, Objective Val: 1.331677571878867
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.47690541428678174 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.04685694413880507                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1554, 794, 1231, 1576, 294, 838, 310, 790, 612, 300]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1554
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392875
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113592
INFO:root:FL Epoch: 379 Norm Difference for worker 1554 is 1.386146
INFO:root:FL Epoch: 379 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :794
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420669
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322598
INFO:root:FL Epoch: 379 Norm Difference for worker 794 is 1.549804
INFO:root:FL Epoch: 379 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1231
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500132
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316420
INFO:root:FL Epoch: 379 Norm Difference for worker 1231 is 1.56444
INFO:root:FL Epoch: 379 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1576
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578792
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368823
INFO:root:FL Epoch: 379 Norm Difference for worker 1576 is 1.470848
INFO:root:FL Epoch: 379 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :294
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 294 is 1.556063
INFO:root:FL Epoch: 379 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :838
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358301
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262635
INFO:root:FL Epoch: 379 Norm Difference for worker 838 is 1.544278
INFO:root:FL Epoch: 379 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :310
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 310 is 1.433133
INFO:root:FL Epoch: 379 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :790
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588424
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308643
INFO:root:FL Epoch: 379 Norm Difference for worker 790 is 1.57146
INFO:root:FL Epoch: 379 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :612
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455969
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174976
INFO:root:FL Epoch: 379 Norm Difference for worker 612 is 1.454799
INFO:root:FL Epoch: 379 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :300
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 300 is 1.420981
INFO:root:FL Epoch: 379 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4106358339757237, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.410537318946353
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4105358691288066
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4105358192612392
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.4948796419536366 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.05446362029761076                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [932, 1259, 1268, 1635, 1840, 651, 1586, 332, 1409, 1110]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :932
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365629
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235690
INFO:root:FL Epoch: 380 Norm Difference for worker 932 is 1.440909
INFO:root:FL Epoch: 380 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1259
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480311
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280523
INFO:root:FL Epoch: 380 Norm Difference for worker 1259 is 1.449582
INFO:root:FL Epoch: 380 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1268
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617292
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218488
INFO:root:FL Epoch: 380 Norm Difference for worker 1268 is 1.444689
INFO:root:FL Epoch: 380 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1635
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150658
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235743
INFO:root:FL Epoch: 380 Norm Difference for worker 1635 is 1.312003
INFO:root:FL Epoch: 380 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1840
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485142
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233669
INFO:root:FL Epoch: 380 Norm Difference for worker 1840 is 1.476689
INFO:root:FL Epoch: 380 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :651
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533186
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348351
INFO:root:FL Epoch: 380 Norm Difference for worker 651 is 1.471494
INFO:root:FL Epoch: 380 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1586
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592162
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182314
INFO:root:FL Epoch: 380 Norm Difference for worker 1586 is 1.368849
INFO:root:FL Epoch: 380 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :332
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 332 is 1.347732
INFO:root:FL Epoch: 380 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1409
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728541
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206592
INFO:root:FL Epoch: 380 Norm Difference for worker 1409 is 1.363423
INFO:root:FL Epoch: 380 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1110
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545531
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236021
INFO:root:FL Epoch: 380 Norm Difference for worker 1110 is 1.539763
INFO:root:FL Epoch: 380 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3478114158283638, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3476886035979398
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3476870664959086
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3476870272555717
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.48274502508780537 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.04004052964349588                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 1679, 116, 928, 1045, 563, 1144, 438]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.051592
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.030822
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.022088338000078995 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.020909339748322965 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.261811
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.038307
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.026565
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.02174150152131915 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.02028965186327696 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.287235
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.032385
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.057593
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.02540829824283719 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.020351999811828135 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.277111
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1679
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461320
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245619
INFO:root:FL Epoch: 381 Norm Difference for worker 1679 is 1.560464
INFO:root:FL Epoch: 381 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :116
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509616
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.129187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 116 is 1.447166
INFO:root:FL Epoch: 381 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :928
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510211
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261876
INFO:root:FL Epoch: 381 Norm Difference for worker 928 is 1.313211
INFO:root:FL Epoch: 381 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1045
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364143
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463923
INFO:root:FL Epoch: 381 Norm Difference for worker 1045 is 1.332341
INFO:root:FL Epoch: 381 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :563
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386818
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199713
INFO:root:FL Epoch: 381 Norm Difference for worker 563 is 1.306881
INFO:root:FL Epoch: 381 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1144
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313698
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153338
INFO:root:FL Epoch: 381 Norm Difference for worker 1144 is 1.448751
INFO:root:FL Epoch: 381 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :438
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534515
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163212
INFO:root:FL Epoch: 381 Norm Difference for worker 438 is 1.410321
INFO:root:FL Epoch: 381 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.043756404638427, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.018944962767364
INFO:root:#### Oracle Cals: 3, Objective Val: 1.013309968895146
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0116383694982527
INFO:root:#### Oracle Cals: 5, Objective Val: 1.0111186852719545
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0109592177450464
INFO:root:#### Oracle Cals: 7, Objective Val: 1.0109113701762018
INFO:root:#### Oracle Cals: 8, Objective Val: 1.010897279275061
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0108932238249648
INFO:root:#### Oracle Cals: 10, Objective Val: 1.0108919951071584
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0108916657563949
INFO:root:#### Oracle Cals: 12, Objective Val: 1.010891570494965
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.49424270321341124 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.024589640243599813                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [305, 780, 1929, 1520, 481, 1295, 101, 560, 999, 452]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 382 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :305
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 305 is 1.471846
INFO:root:FL Epoch: 382 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :780
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605825
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284796
INFO:root:FL Epoch: 382 Norm Difference for worker 780 is 1.592049
INFO:root:FL Epoch: 382 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1929
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281683
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.093025
INFO:root:FL Epoch: 382 Norm Difference for worker 1929 is 1.363666
INFO:root:FL Epoch: 382 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1520
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323537
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138109
INFO:root:FL Epoch: 382 Norm Difference for worker 1520 is 1.408391
INFO:root:FL Epoch: 382 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :481
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324433
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261877
INFO:root:FL Epoch: 382 Norm Difference for worker 481 is 1.614126
INFO:root:FL Epoch: 382 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1295
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507228
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284951
INFO:root:FL Epoch: 382 Norm Difference for worker 1295 is 1.551648
INFO:root:FL Epoch: 382 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :101
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595904
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 101 is 1.558204
INFO:root:FL Epoch: 382 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :560
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760063
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504713
INFO:root:FL Epoch: 382 Norm Difference for worker 560 is 1.682787
INFO:root:FL Epoch: 382 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :999
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397177
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215375
INFO:root:FL Epoch: 382 Norm Difference for worker 999 is 1.54315
INFO:root:FL Epoch: 382 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :452
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536373
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144787
INFO:root:FL Epoch: 382 Norm Difference for worker 452 is 1.429749
INFO:root:FL Epoch: 382 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4316523391671334, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4314057259101367
INFO:root:#### Oracle Cals: 3, Objective Val: 1.431402665752581
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4314026459211777
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.46576834776822257 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.030933777180810768                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [1594, 712, 1782, 1693, 835, 153, 986, 618, 24, 1431]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :1594
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326906
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268578
INFO:root:FL Epoch: 383 Norm Difference for worker 1594 is 1.554755
INFO:root:FL Epoch: 383 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :712
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320132
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420221
INFO:root:FL Epoch: 383 Norm Difference for worker 712 is 1.507457
INFO:root:FL Epoch: 383 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1782
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484457
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224334
INFO:root:FL Epoch: 383 Norm Difference for worker 1782 is 1.419301
INFO:root:FL Epoch: 383 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1693
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762903
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445698
INFO:root:FL Epoch: 383 Norm Difference for worker 1693 is 1.436369
INFO:root:FL Epoch: 383 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :835
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280362
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194940
INFO:root:FL Epoch: 383 Norm Difference for worker 835 is 1.4654
INFO:root:FL Epoch: 383 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :153
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.285579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.185012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 153 is 1.406973
INFO:root:FL Epoch: 383 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :986
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546134
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148150
INFO:root:FL Epoch: 383 Norm Difference for worker 986 is 1.572729
INFO:root:FL Epoch: 383 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :618
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336993
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419244
INFO:root:FL Epoch: 383 Norm Difference for worker 618 is 1.550016
INFO:root:FL Epoch: 383 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :24
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.185709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 24 is 1.422122
INFO:root:FL Epoch: 383 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1431
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358572
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461152
INFO:root:FL Epoch: 383 Norm Difference for worker 1431 is 1.505163
INFO:root:FL Epoch: 383 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4051519281547256, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.40506324262988
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4050622016622933
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4050621706769792
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.4493221640586853 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.037234789691865444                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [459, 540, 192, 1368, 424, 223, 444, 1119, 917, 1924]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :459
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360401
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170891
INFO:root:FL Epoch: 384 Norm Difference for worker 459 is 1.406983
INFO:root:FL Epoch: 384 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :540
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391000
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228547
INFO:root:FL Epoch: 384 Norm Difference for worker 540 is 1.529142
INFO:root:FL Epoch: 384 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :192
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633650
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325431
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 192 is 1.471363
INFO:root:FL Epoch: 384 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1368
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602922
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156650
INFO:root:FL Epoch: 384 Norm Difference for worker 1368 is 1.446336
INFO:root:FL Epoch: 384 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :424
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300785
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348283
INFO:root:FL Epoch: 384 Norm Difference for worker 424 is 1.376165
INFO:root:FL Epoch: 384 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :223
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413539
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.164951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 223 is 1.50198
INFO:root:FL Epoch: 384 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :444
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283371
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331521
INFO:root:FL Epoch: 384 Norm Difference for worker 444 is 1.456468
INFO:root:FL Epoch: 384 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1119
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538534
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222717
INFO:root:FL Epoch: 384 Norm Difference for worker 1119 is 1.437233
INFO:root:FL Epoch: 384 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :917
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241101
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268089
INFO:root:FL Epoch: 384 Norm Difference for worker 917 is 1.526507
INFO:root:FL Epoch: 384 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1924
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500908
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280017
INFO:root:FL Epoch: 384 Norm Difference for worker 1924 is 1.486796
INFO:root:FL Epoch: 384 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3785172419016036, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3784570169061992
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3784561548047105
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3784561485137172
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.4776887367753422 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.04399610745410124                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [1334, 1921, 1397, 757, 1041, 1479, 1249, 1807, 357, 1506]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 385 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :1334
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285324
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538653
INFO:root:FL Epoch: 385 Norm Difference for worker 1334 is 1.491292
INFO:root:FL Epoch: 385 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1921
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709655
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169194
INFO:root:FL Epoch: 385 Norm Difference for worker 1921 is 1.424751
INFO:root:FL Epoch: 385 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1397
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481369
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275547
INFO:root:FL Epoch: 385 Norm Difference for worker 1397 is 1.393746
INFO:root:FL Epoch: 385 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :757
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745441
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273825
INFO:root:FL Epoch: 385 Norm Difference for worker 757 is 1.501427
INFO:root:FL Epoch: 385 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1041
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636026
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430258
INFO:root:FL Epoch: 385 Norm Difference for worker 1041 is 1.458547
INFO:root:FL Epoch: 385 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1479
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896295
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183315
INFO:root:FL Epoch: 385 Norm Difference for worker 1479 is 1.393781
INFO:root:FL Epoch: 385 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1249
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381518
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166590
INFO:root:FL Epoch: 385 Norm Difference for worker 1249 is 1.334115
INFO:root:FL Epoch: 385 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1807
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286418
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246640
INFO:root:FL Epoch: 385 Norm Difference for worker 1807 is 1.424667
INFO:root:FL Epoch: 385 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :357
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288556
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219339
INFO:root:FL Epoch: 385 Norm Difference for worker 357 is 1.357699
INFO:root:FL Epoch: 385 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1506
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289896
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211357
INFO:root:FL Epoch: 385 Norm Difference for worker 1506 is 1.273474
INFO:root:FL Epoch: 385 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3263330448600272, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3262098769582724
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3262083292774962
INFO:root:#### Oracle Cals: 4, Objective Val: 1.326208323411382
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.47681734316489277 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.03974067854384581                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [546, 1815, 707, 353, 765, 248, 1947, 1395, 1735, 1729]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :546
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834211
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.133804
INFO:root:FL Epoch: 386 Norm Difference for worker 546 is 1.495056
INFO:root:FL Epoch: 386 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1815
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422371
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387458
INFO:root:FL Epoch: 386 Norm Difference for worker 1815 is 1.448783
INFO:root:FL Epoch: 386 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :707
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394364
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308062
INFO:root:FL Epoch: 386 Norm Difference for worker 707 is 1.340916
INFO:root:FL Epoch: 386 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :353
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539300
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190006
INFO:root:FL Epoch: 386 Norm Difference for worker 353 is 1.461801
INFO:root:FL Epoch: 386 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :765
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503458
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293603
INFO:root:FL Epoch: 386 Norm Difference for worker 765 is 1.467208
INFO:root:FL Epoch: 386 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :248
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 248 is 1.449804
INFO:root:FL Epoch: 386 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1947
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665177
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292250
INFO:root:FL Epoch: 386 Norm Difference for worker 1947 is 1.266499
INFO:root:FL Epoch: 386 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1395
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498591
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215409
INFO:root:FL Epoch: 386 Norm Difference for worker 1395 is 1.409779
INFO:root:FL Epoch: 386 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1735
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350409
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340175
INFO:root:FL Epoch: 386 Norm Difference for worker 1735 is 1.42651
INFO:root:FL Epoch: 386 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1729
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621489
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398364
INFO:root:FL Epoch: 386 Norm Difference for worker 1729 is 1.629219
INFO:root:FL Epoch: 386 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3631607318786536, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3628689202126698
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3628651243400056
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3628650775421127
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.4690646038335912 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.04200934463491043                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [134, 1507, 700, 1293, 1148, 473, 855, 1266, 170, 422]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 387 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :134
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.237233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.114631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 134 is 1.415572
INFO:root:FL Epoch: 387 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1507
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309885
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324727
INFO:root:FL Epoch: 387 Norm Difference for worker 1507 is 1.440608
INFO:root:FL Epoch: 387 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :700
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381453
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285024
INFO:root:FL Epoch: 387 Norm Difference for worker 700 is 1.52695
INFO:root:FL Epoch: 387 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1293
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655211
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202575
INFO:root:FL Epoch: 387 Norm Difference for worker 1293 is 1.363807
INFO:root:FL Epoch: 387 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1148
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474871
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432279
INFO:root:FL Epoch: 387 Norm Difference for worker 1148 is 1.469466
INFO:root:FL Epoch: 387 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :473
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422717
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474824
INFO:root:FL Epoch: 387 Norm Difference for worker 473 is 1.391191
INFO:root:FL Epoch: 387 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :855
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740863
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172732
INFO:root:FL Epoch: 387 Norm Difference for worker 855 is 1.497623
INFO:root:FL Epoch: 387 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1266
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430185
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250921
INFO:root:FL Epoch: 387 Norm Difference for worker 1266 is 1.485704
INFO:root:FL Epoch: 387 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :170
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701343
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 170 is 1.33832
INFO:root:FL Epoch: 387 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :422
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499060
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300526
INFO:root:FL Epoch: 387 Norm Difference for worker 422 is 1.327685
INFO:root:FL Epoch: 387 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3495523751505862, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3493988713288978
INFO:root:#### Oracle Cals: 3, Objective Val: 1.349396968800176
INFO:root:#### Oracle Cals: 4, Objective Val: 1.349396936377564
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.46146808652316823 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.040549371701975666                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [832, 1256, 1254, 1459, 72, 786, 887, 1099, 1137, 333]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 388 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :832
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502243
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342700
INFO:root:FL Epoch: 388 Norm Difference for worker 832 is 1.367489
INFO:root:FL Epoch: 388 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1256
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467771
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196777
INFO:root:FL Epoch: 388 Norm Difference for worker 1256 is 1.298877
INFO:root:FL Epoch: 388 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1254
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434021
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312148
INFO:root:FL Epoch: 388 Norm Difference for worker 1254 is 1.458286
INFO:root:FL Epoch: 388 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1459
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544124
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194968
INFO:root:FL Epoch: 388 Norm Difference for worker 1459 is 1.412617
INFO:root:FL Epoch: 388 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :72
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 72 is 1.373173
INFO:root:FL Epoch: 388 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :786
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745704
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338641
INFO:root:FL Epoch: 388 Norm Difference for worker 786 is 1.441366
INFO:root:FL Epoch: 388 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :887
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444144
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154653
INFO:root:FL Epoch: 388 Norm Difference for worker 887 is 1.390421
INFO:root:FL Epoch: 388 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1099
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561057
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217257
INFO:root:FL Epoch: 388 Norm Difference for worker 1099 is 1.471866
INFO:root:FL Epoch: 388 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1137
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611959
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285188
INFO:root:FL Epoch: 388 Norm Difference for worker 1137 is 1.499674
INFO:root:FL Epoch: 388 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :333
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 333 is 1.474697
INFO:root:FL Epoch: 388 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3397374408232197, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3396055962516547
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3396037215730014
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3396037055043823
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.4607310785966761 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.04506948683410883                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [1513, 991, 1679, 1102, 716, 905, 546, 26, 1404, 1045]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :1513
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224068
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199470
INFO:root:FL Epoch: 389 Norm Difference for worker 1513 is 1.407318
INFO:root:FL Epoch: 389 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :991
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384007
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433045
INFO:root:FL Epoch: 389 Norm Difference for worker 991 is 1.414525
INFO:root:FL Epoch: 389 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1679
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372378
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309985
INFO:root:FL Epoch: 389 Norm Difference for worker 1679 is 1.493418
INFO:root:FL Epoch: 389 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1102
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446847
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193901
INFO:root:FL Epoch: 389 Norm Difference for worker 1102 is 1.284121
INFO:root:FL Epoch: 389 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :716
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613181
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176953
INFO:root:FL Epoch: 389 Norm Difference for worker 716 is 1.357087
INFO:root:FL Epoch: 389 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :905
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298965
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359127
INFO:root:FL Epoch: 389 Norm Difference for worker 905 is 1.44762
INFO:root:FL Epoch: 389 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :546
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291632
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331403
INFO:root:FL Epoch: 389 Norm Difference for worker 546 is 1.47009
INFO:root:FL Epoch: 389 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :26
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 26 is 1.346958
INFO:root:FL Epoch: 389 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1404
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450865
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168538
INFO:root:FL Epoch: 389 Norm Difference for worker 1404 is 1.34789
INFO:root:FL Epoch: 389 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1045
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419254
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384723
INFO:root:FL Epoch: 389 Norm Difference for worker 1045 is 1.326671
INFO:root:FL Epoch: 389 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3171043372978262, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3169007366153105
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3168979329085722
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3168978809498593
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.4640559238546035 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.03704175787667433                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [481, 1862, 29, 100, 807, 1488, 787, 447, 839, 251]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 390 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :481
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653931
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278098
INFO:root:FL Epoch: 390 Norm Difference for worker 481 is 1.411039
INFO:root:FL Epoch: 390 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1862
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419429
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213826
INFO:root:FL Epoch: 390 Norm Difference for worker 1862 is 1.402562
INFO:root:FL Epoch: 390 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :29
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538518
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 29 is 1.494531
INFO:root:FL Epoch: 390 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :100
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.215464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 100 is 1.372389
INFO:root:FL Epoch: 390 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :807
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419443
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192854
INFO:root:FL Epoch: 390 Norm Difference for worker 807 is 1.451712
INFO:root:FL Epoch: 390 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1488
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314513
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203551
INFO:root:FL Epoch: 390 Norm Difference for worker 1488 is 1.463063
INFO:root:FL Epoch: 390 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :787
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410639
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701663
INFO:root:FL Epoch: 390 Norm Difference for worker 787 is 1.764611
INFO:root:FL Epoch: 390 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :447
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441482
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368773
INFO:root:FL Epoch: 390 Norm Difference for worker 447 is 1.55375
INFO:root:FL Epoch: 390 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :839
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320310
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374570
INFO:root:FL Epoch: 390 Norm Difference for worker 839 is 1.464014
INFO:root:FL Epoch: 390 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :251
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.194392
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 251 is 1.328595
INFO:root:FL Epoch: 390 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3882328642896045, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3876861777221001
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3876801026372745
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3876800385052648
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.47771290996495414 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.03639415092766285                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 586, 541, 389, 613, 1869, 1176, 937]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.030205
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.024527
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.023207650364687044 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.02083230670541525 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.301155
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.080477
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.039560
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.020743067221095163 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.020845810975879432 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.312726
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.041982
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.049780
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.022173645440489054 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.020758698135614394 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.331967
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :586
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312405
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219526
INFO:root:FL Epoch: 391 Norm Difference for worker 586 is 1.435765
INFO:root:FL Epoch: 391 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :541
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399288
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158144
INFO:root:FL Epoch: 391 Norm Difference for worker 541 is 1.449633
INFO:root:FL Epoch: 391 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :389
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744772
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353622
INFO:root:FL Epoch: 391 Norm Difference for worker 389 is 1.423803
INFO:root:FL Epoch: 391 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :613
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458905
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357274
INFO:root:FL Epoch: 391 Norm Difference for worker 613 is 1.545765
INFO:root:FL Epoch: 391 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1869
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596482
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247196
INFO:root:FL Epoch: 391 Norm Difference for worker 1869 is 1.378284
INFO:root:FL Epoch: 391 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1176
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317546
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260430
INFO:root:FL Epoch: 391 Norm Difference for worker 1176 is 1.367844
INFO:root:FL Epoch: 391 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :937
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389361
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206835
INFO:root:FL Epoch: 391 Norm Difference for worker 937 is 1.355502
INFO:root:FL Epoch: 391 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.0586710697704518, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.0342931788532532
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0289056843005402
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0273801074835855
INFO:root:#### Oracle Cals: 5, Objective Val: 1.026928484834925
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0267961097473486
INFO:root:#### Oracle Cals: 7, Objective Val: 1.026757871118758
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0267471164944562
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0267439455905043
INFO:root:#### Oracle Cals: 10, Objective Val: 1.026743068702535
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0267428397480651
INFO:root:#### Oracle Cals: 12, Objective Val: 1.0267427597065835
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.49308642219094667 and Test Accuracy:75.0 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.026615445812543232                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [70, 1309, 1645, 252, 695, 1298, 1816, 1469, 1559, 596]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 392 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :70
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 70 is 1.412477
INFO:root:FL Epoch: 392 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1309
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438980
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219162
INFO:root:FL Epoch: 392 Norm Difference for worker 1309 is 1.610468
INFO:root:FL Epoch: 392 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1645
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324368
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327680
INFO:root:FL Epoch: 392 Norm Difference for worker 1645 is 1.415184
INFO:root:FL Epoch: 392 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :252
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 252 is 1.517837
INFO:root:FL Epoch: 392 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :695
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767047
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317025
INFO:root:FL Epoch: 392 Norm Difference for worker 695 is 1.482402
INFO:root:FL Epoch: 392 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1298
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527250
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442929
INFO:root:FL Epoch: 392 Norm Difference for worker 1298 is 1.605658
INFO:root:FL Epoch: 392 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1816
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482375
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546083
INFO:root:FL Epoch: 392 Norm Difference for worker 1816 is 1.521639
INFO:root:FL Epoch: 392 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1469
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601994
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283033
INFO:root:FL Epoch: 392 Norm Difference for worker 1469 is 1.582094
INFO:root:FL Epoch: 392 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1559
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349649
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251873
INFO:root:FL Epoch: 392 Norm Difference for worker 1559 is 1.493055
INFO:root:FL Epoch: 392 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :596
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802862
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248895
INFO:root:FL Epoch: 392 Norm Difference for worker 596 is 1.497529
INFO:root:FL Epoch: 392 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.4301916924411004, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.430042315573661
INFO:root:#### Oracle Cals: 3, Objective Val: 1.4300402030367043
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4300401671532132
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.45493461980539207 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.030845109683771927                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [1910, 681, 119, 86, 1536, 40, 1747, 1300, 59, 902]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :1910
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543790
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224389
INFO:root:FL Epoch: 393 Norm Difference for worker 1910 is 1.524869
INFO:root:FL Epoch: 393 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :681
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450508
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334145
INFO:root:FL Epoch: 393 Norm Difference for worker 681 is 1.418771
INFO:root:FL Epoch: 393 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :119
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 119 is 1.363577
INFO:root:FL Epoch: 393 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :86
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.281111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.149221
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 86 is 1.31975
INFO:root:FL Epoch: 393 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1536
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483692
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175969
INFO:root:FL Epoch: 393 Norm Difference for worker 1536 is 1.415869
INFO:root:FL Epoch: 393 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :40
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348700
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 40 is 1.43925
INFO:root:FL Epoch: 393 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1747
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594340
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336590
INFO:root:FL Epoch: 393 Norm Difference for worker 1747 is 1.50924
INFO:root:FL Epoch: 393 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1300
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296409
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245497
INFO:root:FL Epoch: 393 Norm Difference for worker 1300 is 1.356212
INFO:root:FL Epoch: 393 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :59
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.195506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 59 is 1.283751
INFO:root:FL Epoch: 393 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :902
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624733
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292093
INFO:root:FL Epoch: 393 Norm Difference for worker 902 is 1.487645
INFO:root:FL Epoch: 393 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3327522497184479, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3325697054400423
INFO:root:#### Oracle Cals: 3, Objective Val: 1.332567291586944
INFO:root:#### Oracle Cals: 4, Objective Val: 1.332567372878454
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.45364733829217796 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.036234451457858086                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [774, 1926, 1801, 399, 1725, 1837, 123, 912, 1829, 387]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 394 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :774
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390157
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273385
INFO:root:FL Epoch: 394 Norm Difference for worker 774 is 1.404549
INFO:root:FL Epoch: 394 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1926
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455999
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175578
INFO:root:FL Epoch: 394 Norm Difference for worker 1926 is 1.405428
INFO:root:FL Epoch: 394 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1801
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434578
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252365
INFO:root:FL Epoch: 394 Norm Difference for worker 1801 is 1.494068
INFO:root:FL Epoch: 394 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :399
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349651
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221581
INFO:root:FL Epoch: 394 Norm Difference for worker 399 is 1.389331
INFO:root:FL Epoch: 394 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1725
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419020
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249654
INFO:root:FL Epoch: 394 Norm Difference for worker 1725 is 1.46141
INFO:root:FL Epoch: 394 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1837
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365919
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180119
INFO:root:FL Epoch: 394 Norm Difference for worker 1837 is 1.396503
INFO:root:FL Epoch: 394 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :123
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 123 is 1.423827
INFO:root:FL Epoch: 394 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :912
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657641
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227328
INFO:root:FL Epoch: 394 Norm Difference for worker 912 is 1.389691
INFO:root:FL Epoch: 394 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1829
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497089
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139468
INFO:root:FL Epoch: 394 Norm Difference for worker 1829 is 1.512103
INFO:root:FL Epoch: 394 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :387
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485016
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188006
INFO:root:FL Epoch: 394 Norm Difference for worker 387 is 1.609471
INFO:root:FL Epoch: 394 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.371492011019252, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.371354310386692
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3713527022103638
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3713526861846586
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.4660978737999411 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.03308810479938984                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [291, 813, 50, 1335, 830, 653, 483, 1654, 1248, 274]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 395 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :291
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 291 is 1.464621
INFO:root:FL Epoch: 395 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :813
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484230
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284960
INFO:root:FL Epoch: 395 Norm Difference for worker 813 is 1.386465
INFO:root:FL Epoch: 395 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :50
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397145
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 50 is 1.353113
INFO:root:FL Epoch: 395 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1335
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323937
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323591
INFO:root:FL Epoch: 395 Norm Difference for worker 1335 is 1.282437
INFO:root:FL Epoch: 395 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :830
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387304
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238187
INFO:root:FL Epoch: 395 Norm Difference for worker 830 is 1.306493
INFO:root:FL Epoch: 395 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :653
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255108
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246839
INFO:root:FL Epoch: 395 Norm Difference for worker 653 is 1.40329
INFO:root:FL Epoch: 395 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :483
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437276
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221853
INFO:root:FL Epoch: 395 Norm Difference for worker 483 is 1.348033
INFO:root:FL Epoch: 395 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1654
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637082
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262853
INFO:root:FL Epoch: 395 Norm Difference for worker 1654 is 1.45362
INFO:root:FL Epoch: 395 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1248
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658389
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170795
INFO:root:FL Epoch: 395 Norm Difference for worker 1248 is 1.472418
INFO:root:FL Epoch: 395 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :274
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 274 is 1.449871
INFO:root:FL Epoch: 395 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3093978493914507, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.309250959109313
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3092490562371744
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3092490329939535
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.4471342335729038 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.028932522982358932                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [1385, 108, 1824, 1767, 1165, 138, 227, 1226, 114, 486]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 201 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :1385
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540543
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190478
INFO:root:FL Epoch: 396 Norm Difference for worker 1385 is 1.311684
INFO:root:FL Epoch: 396 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :108
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.118612
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 108 is 1.33346
INFO:root:FL Epoch: 396 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1824
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745562
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271561
INFO:root:FL Epoch: 396 Norm Difference for worker 1824 is 1.51866
INFO:root:FL Epoch: 396 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1767
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494596
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216858
INFO:root:FL Epoch: 396 Norm Difference for worker 1767 is 1.351151
INFO:root:FL Epoch: 396 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1165
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584769
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191578
INFO:root:FL Epoch: 396 Norm Difference for worker 1165 is 1.619124
INFO:root:FL Epoch: 396 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :138
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433229
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 138 is 1.521647
INFO:root:FL Epoch: 396 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :227
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.372976
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 227 is 1.421144
INFO:root:FL Epoch: 396 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1226
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775132
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142413
INFO:root:FL Epoch: 396 Norm Difference for worker 1226 is 1.452768
INFO:root:FL Epoch: 396 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :114
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 114 is 1.58361
INFO:root:FL Epoch: 396 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :486
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744912
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379428
INFO:root:FL Epoch: 396 Norm Difference for worker 486 is 1.466207
INFO:root:FL Epoch: 396 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.364873947388691, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3645943637528821
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3645903533962738
INFO:root:#### Oracle Cals: 4, Objective Val: 1.364590285548562
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.4759283276165233 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.04933955396215121                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [337, 1927, 777, 117, 1379, 1198, 527, 1053, 1645, 917]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :337
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 337 is 1.256309
INFO:root:FL Epoch: 397 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1927
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601345
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235913
INFO:root:FL Epoch: 397 Norm Difference for worker 1927 is 1.347423
INFO:root:FL Epoch: 397 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :777
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412939
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229054
INFO:root:FL Epoch: 397 Norm Difference for worker 777 is 1.385566
INFO:root:FL Epoch: 397 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :117
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277975
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 117 is 1.316228
INFO:root:FL Epoch: 397 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1379
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263372
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190644
INFO:root:FL Epoch: 397 Norm Difference for worker 1379 is 1.350551
INFO:root:FL Epoch: 397 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1198
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425371
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210356
INFO:root:FL Epoch: 397 Norm Difference for worker 1198 is 1.229233
INFO:root:FL Epoch: 397 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :527
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522446
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254725
INFO:root:FL Epoch: 397 Norm Difference for worker 527 is 1.407148
INFO:root:FL Epoch: 397 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1053
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370808
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316138
INFO:root:FL Epoch: 397 Norm Difference for worker 1053 is 1.385806
INFO:root:FL Epoch: 397 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1645
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473947
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204004
INFO:root:FL Epoch: 397 Norm Difference for worker 1645 is 1.24395
INFO:root:FL Epoch: 397 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :917
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441624
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260378
INFO:root:FL Epoch: 397 Norm Difference for worker 917 is 1.394228
INFO:root:FL Epoch: 397 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2596184624764746, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2594674916702506
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2594657463774173
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2594657684616453
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.4732644785852993 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.03624151647090912                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1469, 1630, 1186, 1921, 1671, 732, 997, 506, 1188, 398]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 398 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1469
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486832
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152696
INFO:root:FL Epoch: 398 Norm Difference for worker 1469 is 1.429489
INFO:root:FL Epoch: 398 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1630
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733686
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265312
INFO:root:FL Epoch: 398 Norm Difference for worker 1630 is 1.482384
INFO:root:FL Epoch: 398 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1186
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532905
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186512
INFO:root:FL Epoch: 398 Norm Difference for worker 1186 is 1.499019
INFO:root:FL Epoch: 398 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1921
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538732
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225799
INFO:root:FL Epoch: 398 Norm Difference for worker 1921 is 1.387382
INFO:root:FL Epoch: 398 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1671
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529774
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205015
INFO:root:FL Epoch: 398 Norm Difference for worker 1671 is 1.382757
INFO:root:FL Epoch: 398 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :732
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564785
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296324
INFO:root:FL Epoch: 398 Norm Difference for worker 732 is 1.514935
INFO:root:FL Epoch: 398 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :997
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650758
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210317
INFO:root:FL Epoch: 398 Norm Difference for worker 997 is 1.3574
INFO:root:FL Epoch: 398 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :506
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474066
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431256
INFO:root:FL Epoch: 398 Norm Difference for worker 506 is 1.482215
INFO:root:FL Epoch: 398 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1188
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583709
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205037
INFO:root:FL Epoch: 398 Norm Difference for worker 1188 is 1.517279
INFO:root:FL Epoch: 398 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :398
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807044
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434353
INFO:root:FL Epoch: 398 Norm Difference for worker 398 is 1.483782
INFO:root:FL Epoch: 398 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.376464744924927, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3763669632830533
INFO:root:#### Oracle Cals: 3, Objective Val: 1.376365807183613
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3763658039117443
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.48408837002866406 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.03908252374579509                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [33, 656, 758, 379, 1800, 821, 1258, 725, 768, 46]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 399 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :33
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608771
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 33 is 1.383171
INFO:root:FL Epoch: 399 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :656
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553704
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411658
INFO:root:FL Epoch: 399 Norm Difference for worker 656 is 1.342181
INFO:root:FL Epoch: 399 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :758
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372961
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194921
INFO:root:FL Epoch: 399 Norm Difference for worker 758 is 1.391291
INFO:root:FL Epoch: 399 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :379
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230022
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254232
INFO:root:FL Epoch: 399 Norm Difference for worker 379 is 1.448707
INFO:root:FL Epoch: 399 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1800
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409415
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347720
INFO:root:FL Epoch: 399 Norm Difference for worker 1800 is 1.349463
INFO:root:FL Epoch: 399 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :821
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625121
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306102
INFO:root:FL Epoch: 399 Norm Difference for worker 821 is 1.361291
INFO:root:FL Epoch: 399 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1258
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501516
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342566
INFO:root:FL Epoch: 399 Norm Difference for worker 1258 is 1.352787
INFO:root:FL Epoch: 399 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :725
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588917
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191607
INFO:root:FL Epoch: 399 Norm Difference for worker 725 is 1.28695
INFO:root:FL Epoch: 399 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :768
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386159
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126798
INFO:root:FL Epoch: 399 Norm Difference for worker 768 is 1.271958
INFO:root:FL Epoch: 399 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :46
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472489
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.213277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 46 is 1.33231
INFO:root:FL Epoch: 399 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.281965187981587, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2818815434864337
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2818805153563162
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2818805031442435
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.4815465246929842 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.04222110410531362                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [1374, 653, 800, 738, 1855, 248, 298, 573, 1627, 1083]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :1374
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475343
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142492
INFO:root:FL Epoch: 400 Norm Difference for worker 1374 is 1.240376
INFO:root:FL Epoch: 400 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :653
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416108
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298791
INFO:root:FL Epoch: 400 Norm Difference for worker 653 is 1.221008
INFO:root:FL Epoch: 400 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :800
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454118
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157818
INFO:root:FL Epoch: 400 Norm Difference for worker 800 is 1.202838
INFO:root:FL Epoch: 400 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :738
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244214
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237866
INFO:root:FL Epoch: 400 Norm Difference for worker 738 is 1.413518
INFO:root:FL Epoch: 400 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1855
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744152
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250812
INFO:root:FL Epoch: 400 Norm Difference for worker 1855 is 1.377925
INFO:root:FL Epoch: 400 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :248
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 248 is 1.371312
INFO:root:FL Epoch: 400 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :298
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.090729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 298 is 1.310953
INFO:root:FL Epoch: 400 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :573
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436270
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397474
INFO:root:FL Epoch: 400 Norm Difference for worker 573 is 1.295261
INFO:root:FL Epoch: 400 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1627
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425134
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270113
INFO:root:FL Epoch: 400 Norm Difference for worker 1627 is 1.416853
INFO:root:FL Epoch: 400 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1083
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315799
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395339
INFO:root:FL Epoch: 400 Norm Difference for worker 1083 is 1.396869
INFO:root:FL Epoch: 400 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2507922267384215, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2505568464626686
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2505535618480008
INFO:root:#### Oracle Cals: 4, Objective Val: 1.250553492525311
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.47057246460634117 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.03415338508784771                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 163, 138, 1190, 701, 1254, 563, 1004]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.078582
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.027407
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.01911232139294346 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.0200055125169456 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.29073
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.039129
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.028506
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.019871595470855635 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.02091922201216221 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.281369
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.046278
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.035533
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.020790617757787306 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.020135352946817876 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.28986
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :163
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.255014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 163 is 1.361855
INFO:root:FL Epoch: 401 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :138
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.347037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 138 is 1.447167
INFO:root:FL Epoch: 401 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1190
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426051
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155254
INFO:root:FL Epoch: 401 Norm Difference for worker 1190 is 1.269474
INFO:root:FL Epoch: 401 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :701
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250053
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299117
INFO:root:FL Epoch: 401 Norm Difference for worker 701 is 1.457549
INFO:root:FL Epoch: 401 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1254
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333137
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234980
INFO:root:FL Epoch: 401 Norm Difference for worker 1254 is 1.348019
INFO:root:FL Epoch: 401 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :563
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453021
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206197
INFO:root:FL Epoch: 401 Norm Difference for worker 563 is 1.335661
INFO:root:FL Epoch: 401 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1004
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500778
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262887
INFO:root:FL Epoch: 401 Norm Difference for worker 1004 is 1.464076
INFO:root:FL Epoch: 401 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.0292527418914803, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.0046067610520855
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9989847069335426
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9973199007599327
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9968053970820274
INFO:root:#### Oracle Cals: 6, Objective Val: 0.9966491119400884
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9966029704547618
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9965898783088987
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9965858555753037
INFO:root:#### Oracle Cals: 10, Objective Val: 0.9965848504701078
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9965842582002362
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9965841860758968
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.4937444311731002 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.02238998127480348                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [607, 1517, 1264, 1385, 623, 1075, 1805, 731, 742, 1898]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :607
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408349
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206875
INFO:root:FL Epoch: 402 Norm Difference for worker 607 is 1.508154
INFO:root:FL Epoch: 402 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1517
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577057
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198824
INFO:root:FL Epoch: 402 Norm Difference for worker 1517 is 1.565529
INFO:root:FL Epoch: 402 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1264
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705985
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268614
INFO:root:FL Epoch: 402 Norm Difference for worker 1264 is 1.60867
INFO:root:FL Epoch: 402 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1385
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364761
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178071
INFO:root:FL Epoch: 402 Norm Difference for worker 1385 is 1.298631
INFO:root:FL Epoch: 402 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :623
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631310
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297555
INFO:root:FL Epoch: 402 Norm Difference for worker 623 is 1.499075
INFO:root:FL Epoch: 402 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1075
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505884
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.104267
INFO:root:FL Epoch: 402 Norm Difference for worker 1075 is 1.416211
INFO:root:FL Epoch: 402 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1805
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 1.217474
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239972
INFO:root:FL Epoch: 402 Norm Difference for worker 1805 is 1.507993
INFO:root:FL Epoch: 402 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :731
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683921
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240586
INFO:root:FL Epoch: 402 Norm Difference for worker 731 is 1.546837
INFO:root:FL Epoch: 402 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :742
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347351
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181171
INFO:root:FL Epoch: 402 Norm Difference for worker 742 is 1.372836
INFO:root:FL Epoch: 402 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1898
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308458
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155020
INFO:root:FL Epoch: 402 Norm Difference for worker 1898 is 1.423163
INFO:root:FL Epoch: 402 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.396892199674867, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3966372965886458
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3966336446326784
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3966335790405917
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.4955810869441313 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.02987230367337664                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1697, 438, 1000, 1152, 674, 1882, 1176, 1868, 78, 1171]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1697
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.202082
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233894
INFO:root:FL Epoch: 403 Norm Difference for worker 1697 is 1.546773
INFO:root:FL Epoch: 403 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :438
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370789
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414470
INFO:root:FL Epoch: 403 Norm Difference for worker 438 is 1.514923
INFO:root:FL Epoch: 403 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1000
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.991355
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300344
INFO:root:FL Epoch: 403 Norm Difference for worker 1000 is 1.493317
INFO:root:FL Epoch: 403 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1152
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799277
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145934
INFO:root:FL Epoch: 403 Norm Difference for worker 1152 is 1.697959
INFO:root:FL Epoch: 403 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :674
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393661
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226482
INFO:root:FL Epoch: 403 Norm Difference for worker 674 is 1.403882
INFO:root:FL Epoch: 403 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1882
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414341
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355905
INFO:root:FL Epoch: 403 Norm Difference for worker 1882 is 1.404218
INFO:root:FL Epoch: 403 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1176
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707906
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361035
INFO:root:FL Epoch: 403 Norm Difference for worker 1176 is 1.42734
INFO:root:FL Epoch: 403 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1868
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272076
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223111
INFO:root:FL Epoch: 403 Norm Difference for worker 1868 is 1.558973
INFO:root:FL Epoch: 403 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :78
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.251308
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 78 is 1.372478
INFO:root:FL Epoch: 403 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1171
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491754
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.114517
INFO:root:FL Epoch: 403 Norm Difference for worker 1171 is 1.339164
INFO:root:FL Epoch: 403 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3969445750618628, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3966163280315942
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3966122147346427
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3966121683024981
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.4977681479033302 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.02568056449914972                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [42, 1565, 994, 591, 1772, 1731, 767, 1854, 1609, 1682]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 404 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :42
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 42 is 1.426976
INFO:root:FL Epoch: 404 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1565
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484928
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351315
INFO:root:FL Epoch: 404 Norm Difference for worker 1565 is 1.588857
INFO:root:FL Epoch: 404 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :994
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729426
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261639
INFO:root:FL Epoch: 404 Norm Difference for worker 994 is 1.424164
INFO:root:FL Epoch: 404 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :591
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430402
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286262
INFO:root:FL Epoch: 404 Norm Difference for worker 591 is 1.548928
INFO:root:FL Epoch: 404 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1772
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755733
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196078
INFO:root:FL Epoch: 404 Norm Difference for worker 1772 is 1.374588
INFO:root:FL Epoch: 404 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1731
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332727
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170216
INFO:root:FL Epoch: 404 Norm Difference for worker 1731 is 1.354475
INFO:root:FL Epoch: 404 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :767
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387983
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201662
INFO:root:FL Epoch: 404 Norm Difference for worker 767 is 1.481229
INFO:root:FL Epoch: 404 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1854
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342352
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.132888
INFO:root:FL Epoch: 404 Norm Difference for worker 1854 is 1.575094
INFO:root:FL Epoch: 404 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1609
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720002
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380024
INFO:root:FL Epoch: 404 Norm Difference for worker 1609 is 1.47495
INFO:root:FL Epoch: 404 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1682
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285332
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288549
INFO:root:FL Epoch: 404 Norm Difference for worker 1682 is 1.39828
INFO:root:FL Epoch: 404 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3821322256105277, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.381902660143372
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3818996735872673
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3818996075742873
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.4854664206504822 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.030077646486461163                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1229, 1879, 783, 290, 1711, 787, 1366, 1837, 1562, 898]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1229
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762079
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292082
INFO:root:FL Epoch: 405 Norm Difference for worker 1229 is 1.423547
INFO:root:FL Epoch: 405 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1879
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776572
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330937
INFO:root:FL Epoch: 405 Norm Difference for worker 1879 is 1.458306
INFO:root:FL Epoch: 405 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :783
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330601
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195096
INFO:root:FL Epoch: 405 Norm Difference for worker 783 is 1.363471
INFO:root:FL Epoch: 405 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :290
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 290 is 1.44948
INFO:root:FL Epoch: 405 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1711
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557446
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214731
INFO:root:FL Epoch: 405 Norm Difference for worker 1711 is 1.476797
INFO:root:FL Epoch: 405 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :787
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425402
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235209
INFO:root:FL Epoch: 405 Norm Difference for worker 787 is 1.336574
INFO:root:FL Epoch: 405 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1366
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431720
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200786
INFO:root:FL Epoch: 405 Norm Difference for worker 1366 is 1.365841
INFO:root:FL Epoch: 405 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1837
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734515
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194229
INFO:root:FL Epoch: 405 Norm Difference for worker 1837 is 1.346819
INFO:root:FL Epoch: 405 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1562
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308253
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255502
INFO:root:FL Epoch: 405 Norm Difference for worker 1562 is 1.411509
INFO:root:FL Epoch: 405 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :898
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250367
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253294
INFO:root:FL Epoch: 405 Norm Difference for worker 898 is 1.446341
INFO:root:FL Epoch: 405 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.32856008279741, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3284812785198492
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3284802844893748
INFO:root:#### Oracle Cals: 4, Objective Val: 1.328480257903219
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.48239389412543354 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.028260610687235992                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [43, 1346, 1944, 1012, 832, 366, 1013, 1230, 475, 495]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 406 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :43
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.793681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 43 is 1.420349
INFO:root:FL Epoch: 406 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1346
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514298
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224979
INFO:root:FL Epoch: 406 Norm Difference for worker 1346 is 1.384614
INFO:root:FL Epoch: 406 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1944
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574513
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195457
INFO:root:FL Epoch: 406 Norm Difference for worker 1944 is 1.27449
INFO:root:FL Epoch: 406 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1012
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477829
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121538
INFO:root:FL Epoch: 406 Norm Difference for worker 1012 is 1.358476
INFO:root:FL Epoch: 406 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :832
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261209
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183822
INFO:root:FL Epoch: 406 Norm Difference for worker 832 is 1.293545
INFO:root:FL Epoch: 406 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :366
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590164
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262688
INFO:root:FL Epoch: 406 Norm Difference for worker 366 is 1.430652
INFO:root:FL Epoch: 406 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1013
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761018
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211028
INFO:root:FL Epoch: 406 Norm Difference for worker 1013 is 1.382927
INFO:root:FL Epoch: 406 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1230
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424004
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.118639
INFO:root:FL Epoch: 406 Norm Difference for worker 1230 is 1.420215
INFO:root:FL Epoch: 406 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :475
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574414
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246993
INFO:root:FL Epoch: 406 Norm Difference for worker 475 is 1.352054
INFO:root:FL Epoch: 406 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :495
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390655
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294320
INFO:root:FL Epoch: 406 Norm Difference for worker 495 is 1.442405
INFO:root:FL Epoch: 406 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2983448280111767, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2982266950317256
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2982252763699267
INFO:root:#### Oracle Cals: 4, Objective Val: 1.298225150198372
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.4826054520466748 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.02848656630764405                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1183, 943, 1373, 1473, 992, 757, 1475, 680, 491, 1743]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1183
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681928
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192382
INFO:root:FL Epoch: 407 Norm Difference for worker 1183 is 1.310353
INFO:root:FL Epoch: 407 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :943
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375797
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296932
INFO:root:FL Epoch: 407 Norm Difference for worker 943 is 1.426861
INFO:root:FL Epoch: 407 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1373
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473552
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218057
INFO:root:FL Epoch: 407 Norm Difference for worker 1373 is 1.446795
INFO:root:FL Epoch: 407 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1473
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512101
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219821
INFO:root:FL Epoch: 407 Norm Difference for worker 1473 is 1.461644
INFO:root:FL Epoch: 407 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :992
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370849
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299992
INFO:root:FL Epoch: 407 Norm Difference for worker 992 is 1.491042
INFO:root:FL Epoch: 407 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :757
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710985
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332701
INFO:root:FL Epoch: 407 Norm Difference for worker 757 is 1.430904
INFO:root:FL Epoch: 407 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1475
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582377
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228766
INFO:root:FL Epoch: 407 Norm Difference for worker 1475 is 1.306471
INFO:root:FL Epoch: 407 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :680
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671138
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379617
INFO:root:FL Epoch: 407 Norm Difference for worker 680 is 1.355557
INFO:root:FL Epoch: 407 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :491
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503315
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.119589
INFO:root:FL Epoch: 407 Norm Difference for worker 491 is 1.187656
INFO:root:FL Epoch: 407 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1743
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788968
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290156
INFO:root:FL Epoch: 407 Norm Difference for worker 1743 is 1.381373
INFO:root:FL Epoch: 407 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2998608806610032, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.299550832020387
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2995464419319573
INFO:root:#### Oracle Cals: 4, Objective Val: 1.299546349841377
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.49416812553125267 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.0330796679481864                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [1623, 1108, 1748, 150, 1450, 611, 673, 1016, 676, 1248]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :1623
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582520
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370563
INFO:root:FL Epoch: 408 Norm Difference for worker 1623 is 1.470351
INFO:root:FL Epoch: 408 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1108
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541291
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324855
INFO:root:FL Epoch: 408 Norm Difference for worker 1108 is 1.592659
INFO:root:FL Epoch: 408 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1748
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431100
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240529
INFO:root:FL Epoch: 408 Norm Difference for worker 1748 is 1.370188
INFO:root:FL Epoch: 408 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :150
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.178763
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 150 is 1.47094
INFO:root:FL Epoch: 408 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1450
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532800
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.146529
INFO:root:FL Epoch: 408 Norm Difference for worker 1450 is 1.389019
INFO:root:FL Epoch: 408 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :611
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325960
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.095500
INFO:root:FL Epoch: 408 Norm Difference for worker 611 is 1.315381
INFO:root:FL Epoch: 408 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :673
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468549
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107572
INFO:root:FL Epoch: 408 Norm Difference for worker 673 is 1.360032
INFO:root:FL Epoch: 408 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1016
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549035
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251909
INFO:root:FL Epoch: 408 Norm Difference for worker 1016 is 1.409691
INFO:root:FL Epoch: 408 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :676
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721717
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240919
INFO:root:FL Epoch: 408 Norm Difference for worker 676 is 1.446351
INFO:root:FL Epoch: 408 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1248
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450103
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268204
INFO:root:FL Epoch: 408 Norm Difference for worker 1248 is 1.396961
INFO:root:FL Epoch: 408 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.345558632497917, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3453828515160655
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3453808196160344
INFO:root:#### Oracle Cals: 4, Objective Val: 1.345380809562773
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.4653414505369523 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.033229099897046886                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1095, 1034, 884, 1106, 854, 1812, 1365, 1153, 368, 741]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1095
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745254
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324812
INFO:root:FL Epoch: 409 Norm Difference for worker 1095 is 1.499777
INFO:root:FL Epoch: 409 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1034
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345506
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336639
INFO:root:FL Epoch: 409 Norm Difference for worker 1034 is 1.395388
INFO:root:FL Epoch: 409 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :884
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541896
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276012
INFO:root:FL Epoch: 409 Norm Difference for worker 884 is 1.432762
INFO:root:FL Epoch: 409 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1106
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779834
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189231
INFO:root:FL Epoch: 409 Norm Difference for worker 1106 is 1.410529
INFO:root:FL Epoch: 409 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :854
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407611
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222367
INFO:root:FL Epoch: 409 Norm Difference for worker 854 is 1.329845
INFO:root:FL Epoch: 409 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1812
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650335
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186241
INFO:root:FL Epoch: 409 Norm Difference for worker 1812 is 1.418001
INFO:root:FL Epoch: 409 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1365
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256634
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195661
INFO:root:FL Epoch: 409 Norm Difference for worker 1365 is 1.307224
INFO:root:FL Epoch: 409 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1153
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748675
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315367
INFO:root:FL Epoch: 409 Norm Difference for worker 1153 is 1.470806
INFO:root:FL Epoch: 409 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :368
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287550
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221877
INFO:root:FL Epoch: 409 Norm Difference for worker 368 is 1.361373
INFO:root:FL Epoch: 409 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :741
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.233757
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235332
INFO:root:FL Epoch: 409 Norm Difference for worker 741 is 1.471362
INFO:root:FL Epoch: 409 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3322629185508235, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3321645754176572
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3321630717554516
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3321630213385567
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.4596720425521626 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.03126285194108883                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [1588, 1566, 1373, 38, 609, 48, 1939, 569, 905, 90]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :1588
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723379
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267835
INFO:root:FL Epoch: 410 Norm Difference for worker 1588 is 1.366517
INFO:root:FL Epoch: 410 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1566
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425079
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233290
INFO:root:FL Epoch: 410 Norm Difference for worker 1566 is 1.304802
INFO:root:FL Epoch: 410 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1373
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435077
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154876
INFO:root:FL Epoch: 410 Norm Difference for worker 1373 is 1.373518
INFO:root:FL Epoch: 410 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :38
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 38 is 1.270073
INFO:root:FL Epoch: 410 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :609
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760807
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381575
INFO:root:FL Epoch: 410 Norm Difference for worker 609 is 1.418553
INFO:root:FL Epoch: 410 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :48
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411322
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 48 is 1.379384
INFO:root:FL Epoch: 410 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1939
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507307
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553245
INFO:root:FL Epoch: 410 Norm Difference for worker 1939 is 1.499499
INFO:root:FL Epoch: 410 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :569
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509693
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308556
INFO:root:FL Epoch: 410 Norm Difference for worker 569 is 1.436699
INFO:root:FL Epoch: 410 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :905
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423198
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229446
INFO:root:FL Epoch: 410 Norm Difference for worker 905 is 1.28975
INFO:root:FL Epoch: 410 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :90
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 90 is 1.503576
INFO:root:FL Epoch: 410 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3099227131012268, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3097360762377563
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3097336042341894
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3097335855223178
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.47670310560394735 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.03478575963526964                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 1347, 1697, 1523, 1370, 1900, 1837, 1578]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.057504
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.036682
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.022135653843482334 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.02196990642696619 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.287274
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.036213
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.053179
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.02081939997151494 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.02228595707565546 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.272697
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.042043
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.036294
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.020399149041622877 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.021805671975016594 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.283742
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1347
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573520
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254661
INFO:root:FL Epoch: 411 Norm Difference for worker 1347 is 1.384259
INFO:root:FL Epoch: 411 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1697
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532772
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320975
INFO:root:FL Epoch: 411 Norm Difference for worker 1697 is 1.279217
INFO:root:FL Epoch: 411 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1523
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385849
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213195
INFO:root:FL Epoch: 411 Norm Difference for worker 1523 is 1.331525
INFO:root:FL Epoch: 411 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1370
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310989
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219986
INFO:root:FL Epoch: 411 Norm Difference for worker 1370 is 1.253742
INFO:root:FL Epoch: 411 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1900
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416099
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177688
INFO:root:FL Epoch: 411 Norm Difference for worker 1900 is 1.290287
INFO:root:FL Epoch: 411 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1837
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325377
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243930
INFO:root:FL Epoch: 411 Norm Difference for worker 1837 is 1.198478
INFO:root:FL Epoch: 411 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1578
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559186
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331837
INFO:root:FL Epoch: 411 Norm Difference for worker 1578 is 1.296619
INFO:root:FL Epoch: 411 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9561041046290293, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9331099675755177
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9278804233557568
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9263583368394487
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9259005023406953
INFO:root:#### Oracle Cals: 6, Objective Val: 0.92576577930339
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9257277229902121
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9257167149947778
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9257137896373638
INFO:root:#### Oracle Cals: 10, Objective Val: 0.9257129723301699
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9257129411738797
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.49434445360127616 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.022961039561778307                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1440, 141, 1453, 738, 655, 1904, 396, 1209, 903, 881]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 412 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1440
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301399
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184777
INFO:root:FL Epoch: 412 Norm Difference for worker 1440 is 1.529456
INFO:root:FL Epoch: 412 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :141
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.169145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 141 is 1.322089
INFO:root:FL Epoch: 412 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1453
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453792
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183165
INFO:root:FL Epoch: 412 Norm Difference for worker 1453 is 1.490222
INFO:root:FL Epoch: 412 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :738
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675280
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223575
INFO:root:FL Epoch: 412 Norm Difference for worker 738 is 1.414576
INFO:root:FL Epoch: 412 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :655
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552197
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378633
INFO:root:FL Epoch: 412 Norm Difference for worker 655 is 1.407626
INFO:root:FL Epoch: 412 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1904
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394318
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270630
INFO:root:FL Epoch: 412 Norm Difference for worker 1904 is 1.470795
INFO:root:FL Epoch: 412 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :396
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427034
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.086309
INFO:root:FL Epoch: 412 Norm Difference for worker 396 is 1.410434
INFO:root:FL Epoch: 412 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1209
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719764
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260289
INFO:root:FL Epoch: 412 Norm Difference for worker 1209 is 1.514299
INFO:root:FL Epoch: 412 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :903
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475385
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156542
INFO:root:FL Epoch: 412 Norm Difference for worker 903 is 1.419968
INFO:root:FL Epoch: 412 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :881
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452280
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196733
INFO:root:FL Epoch: 412 Norm Difference for worker 881 is 1.262469
INFO:root:FL Epoch: 412 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3417125336749347, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3414701588109048
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3414669648622777
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3414669299539974
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.47478567852693443 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.020167738509674866                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [459, 6, 1260, 1890, 606, 1654, 276, 718, 1641, 1195]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 413 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :459
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335120
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200211
INFO:root:FL Epoch: 413 Norm Difference for worker 459 is 1.445701
INFO:root:FL Epoch: 413 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :6
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.302833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 6 is 1.430607
INFO:root:FL Epoch: 413 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1260
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596320
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288154
INFO:root:FL Epoch: 413 Norm Difference for worker 1260 is 1.405129
INFO:root:FL Epoch: 413 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1890
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585207
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272325
INFO:root:FL Epoch: 413 Norm Difference for worker 1890 is 1.470673
INFO:root:FL Epoch: 413 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :606
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340328
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416320
INFO:root:FL Epoch: 413 Norm Difference for worker 606 is 1.364299
INFO:root:FL Epoch: 413 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1654
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417001
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237023
INFO:root:FL Epoch: 413 Norm Difference for worker 1654 is 1.461763
INFO:root:FL Epoch: 413 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :276
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 276 is 1.49458
INFO:root:FL Epoch: 413 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :718
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411461
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386157
INFO:root:FL Epoch: 413 Norm Difference for worker 718 is 1.508841
INFO:root:FL Epoch: 413 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1641
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327199
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213341
INFO:root:FL Epoch: 413 Norm Difference for worker 1641 is 1.468451
INFO:root:FL Epoch: 413 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1195
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292439
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245044
INFO:root:FL Epoch: 413 Norm Difference for worker 1195 is 1.387811
INFO:root:FL Epoch: 413 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3606005597065263, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3605598169717663
INFO:root:#### Oracle Cals: 3, Objective Val: 1.360559326590247
INFO:root:#### Oracle Cals: 4, Objective Val: 1.360559322452067
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.45935746764435487 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.027524509311964113                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [1250, 1532, 1790, 1295, 290, 1589, 1759, 1893, 1747, 1008]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :1250
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676342
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315907
INFO:root:FL Epoch: 414 Norm Difference for worker 1250 is 1.317285
INFO:root:FL Epoch: 414 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1532
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356349
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116736
INFO:root:FL Epoch: 414 Norm Difference for worker 1532 is 1.278098
INFO:root:FL Epoch: 414 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1790
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269180
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310748
INFO:root:FL Epoch: 414 Norm Difference for worker 1790 is 1.406141
INFO:root:FL Epoch: 414 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1295
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426267
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188193
INFO:root:FL Epoch: 414 Norm Difference for worker 1295 is 1.250097
INFO:root:FL Epoch: 414 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :290
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575003
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.296851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 290 is 1.364794
INFO:root:FL Epoch: 414 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1589
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219525
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231803
INFO:root:FL Epoch: 414 Norm Difference for worker 1589 is 1.423621
INFO:root:FL Epoch: 414 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1759
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594382
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235133
INFO:root:FL Epoch: 414 Norm Difference for worker 1759 is 1.399184
INFO:root:FL Epoch: 414 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1893
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687558
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369341
INFO:root:FL Epoch: 414 Norm Difference for worker 1893 is 1.45482
INFO:root:FL Epoch: 414 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1747
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381206
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428982
INFO:root:FL Epoch: 414 Norm Difference for worker 1747 is 1.307722
INFO:root:FL Epoch: 414 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1008
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382804
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418631
INFO:root:FL Epoch: 414 Norm Difference for worker 1008 is 1.486793
INFO:root:FL Epoch: 414 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.30004016469797, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2998817170442398
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2998797918486178
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2998797761767953
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.4678577745662016 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.03551131238540014                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [1413, 172, 86, 370, 1824, 1386, 472, 1000, 637, 1934]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 415 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :1413
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257401
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345381
INFO:root:FL Epoch: 415 Norm Difference for worker 1413 is 1.233981
INFO:root:FL Epoch: 415 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :172
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599525
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226144
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 172 is 1.345945
INFO:root:FL Epoch: 415 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :86
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.330428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 86 is 1.20628
INFO:root:FL Epoch: 415 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :370
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820192
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220762
INFO:root:FL Epoch: 415 Norm Difference for worker 370 is 1.329886
INFO:root:FL Epoch: 415 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1824
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678883
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271464
INFO:root:FL Epoch: 415 Norm Difference for worker 1824 is 1.423636
INFO:root:FL Epoch: 415 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1386
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543952
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156286
INFO:root:FL Epoch: 415 Norm Difference for worker 1386 is 1.327579
INFO:root:FL Epoch: 415 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :472
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613719
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156275
INFO:root:FL Epoch: 415 Norm Difference for worker 472 is 1.385235
INFO:root:FL Epoch: 415 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1000
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424474
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230219
INFO:root:FL Epoch: 415 Norm Difference for worker 1000 is 1.636005
INFO:root:FL Epoch: 415 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :637
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794821
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291012
INFO:root:FL Epoch: 415 Norm Difference for worker 637 is 1.492983
INFO:root:FL Epoch: 415 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1934
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608105
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359455
INFO:root:FL Epoch: 415 Norm Difference for worker 1934 is 1.383325
INFO:root:FL Epoch: 415 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3004453498768445, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2999252055653063
INFO:root:#### Oracle Cals: 3, Objective Val: 1.299919096400616
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2999189673641183
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.46811288419891806 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.035729191886881985                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [337, 431, 1785, 716, 52, 758, 1794, 162, 1203, 898]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 416 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :337
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 337 is 1.285962
INFO:root:FL Epoch: 416 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :431
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653928
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436594
INFO:root:FL Epoch: 416 Norm Difference for worker 431 is 1.511287
INFO:root:FL Epoch: 416 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1785
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408907
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295522
INFO:root:FL Epoch: 416 Norm Difference for worker 1785 is 1.366561
INFO:root:FL Epoch: 416 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :716
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657418
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137594
INFO:root:FL Epoch: 416 Norm Difference for worker 716 is 1.258523
INFO:root:FL Epoch: 416 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :52
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.146209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 52 is 1.380006
INFO:root:FL Epoch: 416 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :758
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634723
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386571
INFO:root:FL Epoch: 416 Norm Difference for worker 758 is 1.366489
INFO:root:FL Epoch: 416 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1794
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486755
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309346
INFO:root:FL Epoch: 416 Norm Difference for worker 1794 is 1.38651
INFO:root:FL Epoch: 416 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :162
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 162 is 1.330395
INFO:root:FL Epoch: 416 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1203
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898558
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300852
INFO:root:FL Epoch: 416 Norm Difference for worker 1203 is 1.43972
INFO:root:FL Epoch: 416 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :898
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264217
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335142
INFO:root:FL Epoch: 416 Norm Difference for worker 898 is 1.449519
INFO:root:FL Epoch: 416 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2948680069741403, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2946821825260806
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2946798040501604
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2946798094817515
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.4547134129440083 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.036496669674913086                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1578, 1877, 1722, 1440, 1829, 671, 994, 651, 1136, 1386]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1578
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513392
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199572
INFO:root:FL Epoch: 417 Norm Difference for worker 1578 is 1.252467
INFO:root:FL Epoch: 417 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1877
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575256
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351567
INFO:root:FL Epoch: 417 Norm Difference for worker 1877 is 1.256656
INFO:root:FL Epoch: 417 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1722
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457336
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189637
INFO:root:FL Epoch: 417 Norm Difference for worker 1722 is 1.272754
INFO:root:FL Epoch: 417 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1440
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560835
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192642
INFO:root:FL Epoch: 417 Norm Difference for worker 1440 is 1.303074
INFO:root:FL Epoch: 417 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1829
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442053
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198131
INFO:root:FL Epoch: 417 Norm Difference for worker 1829 is 1.406188
INFO:root:FL Epoch: 417 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :671
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756249
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122550
INFO:root:FL Epoch: 417 Norm Difference for worker 671 is 1.232887
INFO:root:FL Epoch: 417 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :994
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748460
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219196
INFO:root:FL Epoch: 417 Norm Difference for worker 994 is 1.308392
INFO:root:FL Epoch: 417 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :651
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303808
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.125287
INFO:root:FL Epoch: 417 Norm Difference for worker 651 is 1.281795
INFO:root:FL Epoch: 417 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1136
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291647
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269907
INFO:root:FL Epoch: 417 Norm Difference for worker 1136 is 1.451359
INFO:root:FL Epoch: 417 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1386
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391510
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321570
INFO:root:FL Epoch: 417 Norm Difference for worker 1386 is 1.246252
INFO:root:FL Epoch: 417 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.228999377199134, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2287860501713053
INFO:root:#### Oracle Cals: 3, Objective Val: 1.228783587851908
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2287835716129598
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.4664720051428851 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.038406488175193466                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [1394, 446, 1001, 597, 430, 98, 478, 1158, 171, 285]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :1394
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534140
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142625
INFO:root:FL Epoch: 418 Norm Difference for worker 1394 is 1.422283
INFO:root:FL Epoch: 418 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :446
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580201
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330815
INFO:root:FL Epoch: 418 Norm Difference for worker 446 is 1.524547
INFO:root:FL Epoch: 418 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1001
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464430
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463850
INFO:root:FL Epoch: 418 Norm Difference for worker 1001 is 1.4311
INFO:root:FL Epoch: 418 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :597
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644629
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256742
INFO:root:FL Epoch: 418 Norm Difference for worker 597 is 1.360075
INFO:root:FL Epoch: 418 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :430
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411856
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367968
INFO:root:FL Epoch: 418 Norm Difference for worker 430 is 1.405032
INFO:root:FL Epoch: 418 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :98
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.265951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 98 is 1.343486
INFO:root:FL Epoch: 418 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :478
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308924
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262339
INFO:root:FL Epoch: 418 Norm Difference for worker 478 is 1.34789
INFO:root:FL Epoch: 418 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1158
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499917
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248991
INFO:root:FL Epoch: 418 Norm Difference for worker 1158 is 1.384064
INFO:root:FL Epoch: 418 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :171
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 171 is 1.341378
INFO:root:FL Epoch: 418 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :285
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 285 is 1.290334
INFO:root:FL Epoch: 418 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3070668227742894, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3069142955768396
INFO:root:#### Oracle Cals: 3, Objective Val: 1.306912597904191
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3069125810951974
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.4635255003676695 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.03738137955466906                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [1565, 1770, 855, 807, 185, 421, 1904, 1529, 162, 1104]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :1565
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453477
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211984
INFO:root:FL Epoch: 419 Norm Difference for worker 1565 is 1.389268
INFO:root:FL Epoch: 419 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1770
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331750
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202918
INFO:root:FL Epoch: 419 Norm Difference for worker 1770 is 1.213469
INFO:root:FL Epoch: 419 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :855
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340735
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247226
INFO:root:FL Epoch: 419 Norm Difference for worker 855 is 1.343087
INFO:root:FL Epoch: 419 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :807
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381865
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228349
INFO:root:FL Epoch: 419 Norm Difference for worker 807 is 1.322608
INFO:root:FL Epoch: 419 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :185
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.286402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 185 is 1.11237
INFO:root:FL Epoch: 419 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :421
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711365
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220959
INFO:root:FL Epoch: 419 Norm Difference for worker 421 is 1.516454
INFO:root:FL Epoch: 419 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1904
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343242
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193860
INFO:root:FL Epoch: 419 Norm Difference for worker 1904 is 1.311797
INFO:root:FL Epoch: 419 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1529
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589004
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284091
INFO:root:FL Epoch: 419 Norm Difference for worker 1529 is 1.362292
INFO:root:FL Epoch: 419 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :162
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 162 is 1.262399
INFO:root:FL Epoch: 419 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1104
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497105
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256579
INFO:root:FL Epoch: 419 Norm Difference for worker 1104 is 1.378905
INFO:root:FL Epoch: 419 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.251337234256031, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2509572529177637
INFO:root:#### Oracle Cals: 3, Objective Val: 1.250951810102276
INFO:root:#### Oracle Cals: 4, Objective Val: 1.250951674614837
INFO:root:#### Oracle Cals: 5, Objective Val: 1.2509516543194197
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.461470118340324 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.03600870383282503                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1780, 132, 501, 1727, 1308, 1584, 1596, 1485, 854, 363]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 420 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1780
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350074
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249119
INFO:root:FL Epoch: 420 Norm Difference for worker 1780 is 1.19153
INFO:root:FL Epoch: 420 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :132
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.150365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 132 is 1.291589
INFO:root:FL Epoch: 420 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :501
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564232
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165044
INFO:root:FL Epoch: 420 Norm Difference for worker 501 is 1.331184
INFO:root:FL Epoch: 420 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1727
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857378
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287381
INFO:root:FL Epoch: 420 Norm Difference for worker 1727 is 1.273456
INFO:root:FL Epoch: 420 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1308
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738783
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189839
INFO:root:FL Epoch: 420 Norm Difference for worker 1308 is 1.391021
INFO:root:FL Epoch: 420 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1584
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518815
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142838
INFO:root:FL Epoch: 420 Norm Difference for worker 1584 is 1.220049
INFO:root:FL Epoch: 420 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1596
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422290
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181126
INFO:root:FL Epoch: 420 Norm Difference for worker 1596 is 1.290383
INFO:root:FL Epoch: 420 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1485
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440288
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187192
INFO:root:FL Epoch: 420 Norm Difference for worker 1485 is 1.305751
INFO:root:FL Epoch: 420 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :854
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411375
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333028
INFO:root:FL Epoch: 420 Norm Difference for worker 854 is 1.285586
INFO:root:FL Epoch: 420 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :363
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509258
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308859
INFO:root:FL Epoch: 420 Norm Difference for worker 363 is 1.477596
INFO:root:FL Epoch: 420 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2373539501088011, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2371729006741214
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2371705762404503
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2371705629500394
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.4548818381393657 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.0334825050085783                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 331, 252, 1598, 852, 1672, 738, 1413]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.030924
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.036114
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.02294210872302453 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.018970171641558408 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.265439
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.041303
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.018420
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.0231539582212766 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.01934478785842657 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.255541
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.035731
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.027768
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.02366713434457779 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.01939717698842287 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.256566
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :331
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 331 is 1.50859
INFO:root:FL Epoch: 421 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :252
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 252 is 1.34014
INFO:root:FL Epoch: 421 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1598
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464265
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302067
INFO:root:FL Epoch: 421 Norm Difference for worker 1598 is 1.268468
INFO:root:FL Epoch: 421 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :852
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275803
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162290
INFO:root:FL Epoch: 421 Norm Difference for worker 852 is 1.232956
INFO:root:FL Epoch: 421 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1672
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394897
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278701
INFO:root:FL Epoch: 421 Norm Difference for worker 1672 is 1.367576
INFO:root:FL Epoch: 421 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :738
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520748
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154292
INFO:root:FL Epoch: 421 Norm Difference for worker 738 is 1.305258
INFO:root:FL Epoch: 421 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1413
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269505
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248130
INFO:root:FL Epoch: 421 Norm Difference for worker 1413 is 1.22625
INFO:root:FL Epoch: 421 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9790359519374656, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9551027186282509
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9494668958898708
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9476731928907834
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9470591359311622
INFO:root:#### Oracle Cals: 6, Objective Val: 0.9468483194185193
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9467772913105981
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9467535110784814
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9467462303121261
INFO:root:#### Oracle Cals: 10, Objective Val: 0.9467433708320703
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9467424690845537
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9467421962466765
INFO:root:#### Oracle Cals: 13, Objective Val: 0.9467421839829055
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.4806079785613453 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.02388374600559473                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [265, 1432, 207, 1520, 890, 723, 1096, 1450, 440, 1471]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 422 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :265
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 265 is 1.68846
INFO:root:FL Epoch: 422 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1432
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407334
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.126747
INFO:root:FL Epoch: 422 Norm Difference for worker 1432 is 1.39133
INFO:root:FL Epoch: 422 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :207
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.194436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 207 is 1.462125
INFO:root:FL Epoch: 422 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1520
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262444
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.086068
INFO:root:FL Epoch: 422 Norm Difference for worker 1520 is 1.305332
INFO:root:FL Epoch: 422 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :890
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745723
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260146
INFO:root:FL Epoch: 422 Norm Difference for worker 890 is 1.449064
INFO:root:FL Epoch: 422 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :723
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379694
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203548
INFO:root:FL Epoch: 422 Norm Difference for worker 723 is 1.54167
INFO:root:FL Epoch: 422 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1096
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343867
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456645
INFO:root:FL Epoch: 422 Norm Difference for worker 1096 is 1.472621
INFO:root:FL Epoch: 422 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1450
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894841
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183316
INFO:root:FL Epoch: 422 Norm Difference for worker 1450 is 1.411271
INFO:root:FL Epoch: 422 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :440
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467947
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218171
INFO:root:FL Epoch: 422 Norm Difference for worker 440 is 1.420736
INFO:root:FL Epoch: 422 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1471
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465862
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136915
INFO:root:FL Epoch: 422 Norm Difference for worker 1471 is 1.438659
INFO:root:FL Epoch: 422 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3768239236137463, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3765342314986913
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3765305025640657
INFO:root:#### Oracle Cals: 4, Objective Val: 1.37653049931078
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.4679417329676011 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.029200871475040913                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [1477, 1688, 190, 1382, 1904, 742, 1629, 178, 1346, 1406]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 423 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :1477
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327626
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257458
INFO:root:FL Epoch: 423 Norm Difference for worker 1477 is 1.481089
INFO:root:FL Epoch: 423 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1688
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567843
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251056
INFO:root:FL Epoch: 423 Norm Difference for worker 1688 is 1.329884
INFO:root:FL Epoch: 423 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :190
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 190 is 1.442203
INFO:root:FL Epoch: 423 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1382
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489398
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224185
INFO:root:FL Epoch: 423 Norm Difference for worker 1382 is 1.396542
INFO:root:FL Epoch: 423 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1904
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252129
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131682
INFO:root:FL Epoch: 423 Norm Difference for worker 1904 is 1.238738
INFO:root:FL Epoch: 423 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :742
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354239
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183890
INFO:root:FL Epoch: 423 Norm Difference for worker 742 is 1.25492
INFO:root:FL Epoch: 423 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1629
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774183
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197420
INFO:root:FL Epoch: 423 Norm Difference for worker 1629 is 1.402718
INFO:root:FL Epoch: 423 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :178
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277642
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 178 is 1.439884
INFO:root:FL Epoch: 423 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1346
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642507
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166642
INFO:root:FL Epoch: 423 Norm Difference for worker 1346 is 1.394477
INFO:root:FL Epoch: 423 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1406
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405187
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189214
INFO:root:FL Epoch: 423 Norm Difference for worker 1406 is 1.368416
INFO:root:FL Epoch: 423 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2992936304742064, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2990626959837057
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2990596969088262
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2990596486550947
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.4720621959251516 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.027357605751603842                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [1005, 998, 1599, 1223, 719, 279, 1149, 66, 805, 1920]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :1005
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495084
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162913
INFO:root:FL Epoch: 424 Norm Difference for worker 1005 is 1.323779
INFO:root:FL Epoch: 424 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :998
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822947
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216871
INFO:root:FL Epoch: 424 Norm Difference for worker 998 is 1.397615
INFO:root:FL Epoch: 424 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1599
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299389
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218413
INFO:root:FL Epoch: 424 Norm Difference for worker 1599 is 1.309128
INFO:root:FL Epoch: 424 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1223
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563321
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290493
INFO:root:FL Epoch: 424 Norm Difference for worker 1223 is 1.534862
INFO:root:FL Epoch: 424 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :719
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.182096
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366788
INFO:root:FL Epoch: 424 Norm Difference for worker 719 is 1.374189
INFO:root:FL Epoch: 424 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :279
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314407
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 279 is 1.369413
INFO:root:FL Epoch: 424 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1149
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619681
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426012
INFO:root:FL Epoch: 424 Norm Difference for worker 1149 is 1.429639
INFO:root:FL Epoch: 424 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :66
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.089617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 66 is 1.369681
INFO:root:FL Epoch: 424 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :805
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572961
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175639
INFO:root:FL Epoch: 424 Norm Difference for worker 805 is 1.383678
INFO:root:FL Epoch: 424 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1920
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380974
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292024
INFO:root:FL Epoch: 424 Norm Difference for worker 1920 is 1.393572
INFO:root:FL Epoch: 424 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3146842739338573, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3145446760546962
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3145429631513974
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3145429537707187
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.4539242395583321 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.03176167234778404                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [125, 315, 593, 250, 1008, 1364, 824, 487, 695, 198]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 425 Num points on workers: [201 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :125
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.315261
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 125 is 1.354179
INFO:root:FL Epoch: 425 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :315
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 315 is 1.414548
INFO:root:FL Epoch: 425 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :593
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394036
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349525
INFO:root:FL Epoch: 425 Norm Difference for worker 593 is 1.521559
INFO:root:FL Epoch: 425 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :250
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.155673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 250 is 1.383317
INFO:root:FL Epoch: 425 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1008
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654261
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222893
INFO:root:FL Epoch: 425 Norm Difference for worker 1008 is 1.439473
INFO:root:FL Epoch: 425 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1364
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363652
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232365
INFO:root:FL Epoch: 425 Norm Difference for worker 1364 is 1.376605
INFO:root:FL Epoch: 425 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :824
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743226
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270588
INFO:root:FL Epoch: 425 Norm Difference for worker 824 is 1.238642
INFO:root:FL Epoch: 425 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :487
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274611
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316791
INFO:root:FL Epoch: 425 Norm Difference for worker 487 is 1.400477
INFO:root:FL Epoch: 425 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :695
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311191
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329869
INFO:root:FL Epoch: 425 Norm Difference for worker 695 is 1.294577
INFO:root:FL Epoch: 425 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :198
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230400
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 198 is 1.382309
INFO:root:FL Epoch: 425 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3109330066631568, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3107783619189683
INFO:root:#### Oracle Cals: 3, Objective Val: 1.310776228020218
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3107762401311442
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.445916804320672 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.03389569123586019                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [1053, 684, 410, 840, 477, 530, 660, 1267, 513, 296]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 426 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :1053
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476050
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230142
INFO:root:FL Epoch: 426 Norm Difference for worker 1053 is 1.31636
INFO:root:FL Epoch: 426 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :684
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584481
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301139
INFO:root:FL Epoch: 426 Norm Difference for worker 684 is 1.351025
INFO:root:FL Epoch: 426 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :410
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359880
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262590
INFO:root:FL Epoch: 426 Norm Difference for worker 410 is 1.298992
INFO:root:FL Epoch: 426 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :840
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525680
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341634
INFO:root:FL Epoch: 426 Norm Difference for worker 840 is 1.463395
INFO:root:FL Epoch: 426 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :477
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604123
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347477
INFO:root:FL Epoch: 426 Norm Difference for worker 477 is 1.408563
INFO:root:FL Epoch: 426 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :530
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374866
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433383
INFO:root:FL Epoch: 426 Norm Difference for worker 530 is 1.452944
INFO:root:FL Epoch: 426 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :660
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647205
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227230
INFO:root:FL Epoch: 426 Norm Difference for worker 660 is 1.400691
INFO:root:FL Epoch: 426 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1267
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399579
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312202
INFO:root:FL Epoch: 426 Norm Difference for worker 1267 is 1.356667
INFO:root:FL Epoch: 426 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :513
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364214
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163636
INFO:root:FL Epoch: 426 Norm Difference for worker 513 is 1.412417
INFO:root:FL Epoch: 426 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :296
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 296 is 1.373043
INFO:root:FL Epoch: 426 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.306506641387963, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3064293639795534
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3064282962909497
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3064283057072883
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.4517684964572682 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.037159086825946964                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [358, 1702, 890, 850, 371, 1285, 1450, 49, 1623, 1502]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :358
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.197835
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334348
INFO:root:FL Epoch: 427 Norm Difference for worker 358 is 1.192978
INFO:root:FL Epoch: 427 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1702
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262926
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232545
INFO:root:FL Epoch: 427 Norm Difference for worker 1702 is 1.2863
INFO:root:FL Epoch: 427 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :890
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504518
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257006
INFO:root:FL Epoch: 427 Norm Difference for worker 890 is 1.244097
INFO:root:FL Epoch: 427 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :850
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372175
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258102
INFO:root:FL Epoch: 427 Norm Difference for worker 850 is 1.328052
INFO:root:FL Epoch: 427 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :371
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524472
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174892
INFO:root:FL Epoch: 427 Norm Difference for worker 371 is 1.271738
INFO:root:FL Epoch: 427 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1285
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447995
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327632
INFO:root:FL Epoch: 427 Norm Difference for worker 1285 is 1.30855
INFO:root:FL Epoch: 427 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1450
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375891
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308106
INFO:root:FL Epoch: 427 Norm Difference for worker 1450 is 1.253777
INFO:root:FL Epoch: 427 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :49
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 49 is 1.361128
INFO:root:FL Epoch: 427 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1623
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407484
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188683
INFO:root:FL Epoch: 427 Norm Difference for worker 1623 is 1.286359
INFO:root:FL Epoch: 427 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1502
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352626
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245244
INFO:root:FL Epoch: 427 Norm Difference for worker 1502 is 1.336107
INFO:root:FL Epoch: 427 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2143426467198655, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.214247944167676
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2142466841584223
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2142466723461482
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.4537324572310728 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.039082665306826435                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [1496, 1175, 188, 1530, 250, 1880, 417, 73, 781, 931]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 428 Num points on workers: [200 200 201 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :1496
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449502
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.132542
INFO:root:FL Epoch: 428 Norm Difference for worker 1496 is 1.280325
INFO:root:FL Epoch: 428 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1175
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553909
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123005
INFO:root:FL Epoch: 428 Norm Difference for worker 1175 is 1.290526
INFO:root:FL Epoch: 428 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :188
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.302243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262375
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 188 is 1.323068
INFO:root:FL Epoch: 428 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1530
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628664
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185377
INFO:root:FL Epoch: 428 Norm Difference for worker 1530 is 1.46453
INFO:root:FL Epoch: 428 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :250
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641742
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 250 is 1.2527
INFO:root:FL Epoch: 428 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1880
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382961
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329799
INFO:root:FL Epoch: 428 Norm Difference for worker 1880 is 1.506184
INFO:root:FL Epoch: 428 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :417
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569301
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241397
INFO:root:FL Epoch: 428 Norm Difference for worker 417 is 1.418327
INFO:root:FL Epoch: 428 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :73
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.173083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 73 is 1.359221
INFO:root:FL Epoch: 428 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :781
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570800
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147954
INFO:root:FL Epoch: 428 Norm Difference for worker 781 is 1.325217
INFO:root:FL Epoch: 428 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :931
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578940
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219450
INFO:root:FL Epoch: 428 Norm Difference for worker 931 is 1.391935
INFO:root:FL Epoch: 428 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.285968690374827, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2857850911104614
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2857829231233135
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2857828633536212
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.44856991487390857 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.04109625052660704                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [573, 1218, 1481, 1222, 962, 866, 753, 639, 467, 1324]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :573
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695996
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287587
INFO:root:FL Epoch: 429 Norm Difference for worker 573 is 1.215631
INFO:root:FL Epoch: 429 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1218
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502991
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252614
INFO:root:FL Epoch: 429 Norm Difference for worker 1218 is 1.322507
INFO:root:FL Epoch: 429 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1481
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690139
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455504
INFO:root:FL Epoch: 429 Norm Difference for worker 1481 is 1.468657
INFO:root:FL Epoch: 429 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1222
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347082
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405259
INFO:root:FL Epoch: 429 Norm Difference for worker 1222 is 1.345681
INFO:root:FL Epoch: 429 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :962
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.183875
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250123
INFO:root:FL Epoch: 429 Norm Difference for worker 962 is 1.333411
INFO:root:FL Epoch: 429 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :866
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463039
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.120774
INFO:root:FL Epoch: 429 Norm Difference for worker 866 is 1.387683
INFO:root:FL Epoch: 429 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :753
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510365
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383424
INFO:root:FL Epoch: 429 Norm Difference for worker 753 is 1.353458
INFO:root:FL Epoch: 429 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :639
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415070
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258951
INFO:root:FL Epoch: 429 Norm Difference for worker 639 is 1.31138
INFO:root:FL Epoch: 429 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :467
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344207
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367699
INFO:root:FL Epoch: 429 Norm Difference for worker 467 is 1.266638
INFO:root:FL Epoch: 429 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1324
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544236
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321268
INFO:root:FL Epoch: 429 Norm Difference for worker 1324 is 1.365134
INFO:root:FL Epoch: 429 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2652567136214663, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2651330188718348
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2651316748826658
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2651317171104979
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.4610169705222635 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.042421335664888225                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [510, 1930, 1874, 1305, 567, 1866, 16, 1329, 1868, 483]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 430 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :510
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580220
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277056
INFO:root:FL Epoch: 430 Norm Difference for worker 510 is 1.310593
INFO:root:FL Epoch: 430 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1930
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586631
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215717
INFO:root:FL Epoch: 430 Norm Difference for worker 1930 is 1.411286
INFO:root:FL Epoch: 430 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1874
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321406
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195546
INFO:root:FL Epoch: 430 Norm Difference for worker 1874 is 1.263814
INFO:root:FL Epoch: 430 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1305
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800824
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115039
INFO:root:FL Epoch: 430 Norm Difference for worker 1305 is 1.346135
INFO:root:FL Epoch: 430 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :567
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546346
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339086
INFO:root:FL Epoch: 430 Norm Difference for worker 567 is 1.236017
INFO:root:FL Epoch: 430 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1866
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616324
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293556
INFO:root:FL Epoch: 430 Norm Difference for worker 1866 is 1.373498
INFO:root:FL Epoch: 430 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :16
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.162602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 16 is 1.47619
INFO:root:FL Epoch: 430 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1329
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291972
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317258
INFO:root:FL Epoch: 430 Norm Difference for worker 1329 is 1.309687
INFO:root:FL Epoch: 430 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1868
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464063
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337848
INFO:root:FL Epoch: 430 Norm Difference for worker 1868 is 1.406749
INFO:root:FL Epoch: 430 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :483
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383646
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279148
INFO:root:FL Epoch: 430 Norm Difference for worker 483 is 1.212108
INFO:root:FL Epoch: 430 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2663917649373806, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2661193867262805
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2661153416517252
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2661152523288082
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.4492850776980905 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.034155198683341347                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 1386, 1380, 347, 1315, 1866, 1628, 201]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.052461
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.051640
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.023405034095048904 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.019453402515500783 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.281237
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.055176
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.029850
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.02169225721930464 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.01936748893931508 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.248427
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.041131
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.038826
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.022261981076250475 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.019416210148483513 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.277846
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1386
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350069
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212681
INFO:root:FL Epoch: 431 Norm Difference for worker 1386 is 1.282342
INFO:root:FL Epoch: 431 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1380
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583653
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367061
INFO:root:FL Epoch: 431 Norm Difference for worker 1380 is 2.153437
INFO:root:FL Epoch: 431 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :347
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626374
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262839
INFO:root:FL Epoch: 431 Norm Difference for worker 347 is 1.389997
INFO:root:FL Epoch: 431 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1315
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575225
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303362
INFO:root:FL Epoch: 431 Norm Difference for worker 1315 is 1.361243
INFO:root:FL Epoch: 431 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1866
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366670
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265858
INFO:root:FL Epoch: 431 Norm Difference for worker 1866 is 1.336334
INFO:root:FL Epoch: 431 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1628
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456490
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237572
INFO:root:FL Epoch: 431 Norm Difference for worker 1628 is 1.324659
INFO:root:FL Epoch: 431 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :201
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.167801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 201 is 1.500571
INFO:root:FL Epoch: 431 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1085969135406828, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.077191055960772
INFO:root:#### Oracle Cals: 3, Objective Val: 1.0704963465334671
INFO:root:#### Oracle Cals: 4, Objective Val: 1.0684343502619196
INFO:root:#### Oracle Cals: 5, Objective Val: 1.067752534529986
INFO:root:#### Oracle Cals: 6, Objective Val: 1.0675280759998547
INFO:root:#### Oracle Cals: 7, Objective Val: 1.067455620698423
INFO:root:#### Oracle Cals: 8, Objective Val: 1.0674326911054535
INFO:root:#### Oracle Cals: 9, Objective Val: 1.0674255311133716
INFO:root:#### Oracle Cals: 10, Objective Val: 1.067423495228938
INFO:root:#### Oracle Cals: 11, Objective Val: 1.0674227759866937
INFO:root:#### Oracle Cals: 12, Objective Val: 1.0674224624182538
INFO:root:#### Oracle Cals: 13, Objective Val: 1.067422584527702
INFO:root:#### Oracle Cals: 14, Objective Val: 1.0674223962490024
INFO:root:#### Oracle Cals: 15, Objective Val: 1.0674223788008605
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.4729266832856571 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.02569411415606737                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1163, 172, 1453, 1739, 840, 1608, 371, 1040, 702, 1686]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 432 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1163
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559343
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402533
INFO:root:FL Epoch: 432 Norm Difference for worker 1163 is 1.463619
INFO:root:FL Epoch: 432 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :172
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.286792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 172 is 1.410872
INFO:root:FL Epoch: 432 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1453
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402374
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143082
INFO:root:FL Epoch: 432 Norm Difference for worker 1453 is 1.376271
INFO:root:FL Epoch: 432 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1739
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480279
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143706
INFO:root:FL Epoch: 432 Norm Difference for worker 1739 is 1.370925
INFO:root:FL Epoch: 432 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :840
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477131
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261331
INFO:root:FL Epoch: 432 Norm Difference for worker 840 is 1.436071
INFO:root:FL Epoch: 432 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1608
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427711
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210053
INFO:root:FL Epoch: 432 Norm Difference for worker 1608 is 1.511199
INFO:root:FL Epoch: 432 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :371
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433528
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216649
INFO:root:FL Epoch: 432 Norm Difference for worker 371 is 1.329516
INFO:root:FL Epoch: 432 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1040
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311016
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280810
INFO:root:FL Epoch: 432 Norm Difference for worker 1040 is 1.410043
INFO:root:FL Epoch: 432 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :702
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424211
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346882
INFO:root:FL Epoch: 432 Norm Difference for worker 702 is 1.467405
INFO:root:FL Epoch: 432 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1686
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377235
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492057
INFO:root:FL Epoch: 432 Norm Difference for worker 1686 is 1.320867
INFO:root:FL Epoch: 432 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3274348713509563, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3273231402914019
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3273216826126395
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3273216393088232
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.4389665363466038 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.023674840262780588                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [936, 1529, 428, 1022, 1797, 133, 96, 1201, 1407, 422]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :936
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204992
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286452
INFO:root:FL Epoch: 433 Norm Difference for worker 936 is 1.348312
INFO:root:FL Epoch: 433 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1529
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363265
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309314
INFO:root:FL Epoch: 433 Norm Difference for worker 1529 is 1.314814
INFO:root:FL Epoch: 433 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :428
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790152
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296561
INFO:root:FL Epoch: 433 Norm Difference for worker 428 is 1.299598
INFO:root:FL Epoch: 433 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1022
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328488
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347520
INFO:root:FL Epoch: 433 Norm Difference for worker 1022 is 1.282211
INFO:root:FL Epoch: 433 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1797
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893645
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180646
INFO:root:FL Epoch: 433 Norm Difference for worker 1797 is 1.426349
INFO:root:FL Epoch: 433 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :133
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181576
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 133 is 1.371013
INFO:root:FL Epoch: 433 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :96
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258747
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 96 is 1.534854
INFO:root:FL Epoch: 433 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1201
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406824
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259562
INFO:root:FL Epoch: 433 Norm Difference for worker 1201 is 1.409608
INFO:root:FL Epoch: 433 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1407
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499582
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376564
INFO:root:FL Epoch: 433 Norm Difference for worker 1407 is 1.396465
INFO:root:FL Epoch: 433 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :422
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400824
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217656
INFO:root:FL Epoch: 433 Norm Difference for worker 422 is 1.296086
INFO:root:FL Epoch: 433 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2913441704033908, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2912050393502308
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2912034803071764
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2912034749637966
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.4523719882263857 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.026264298396805923                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1767, 1620, 569, 55, 953, 253, 598, 295, 1199, 545]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1767
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347104
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205102
INFO:root:FL Epoch: 434 Norm Difference for worker 1767 is 1.324747
INFO:root:FL Epoch: 434 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1620
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421692
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349359
INFO:root:FL Epoch: 434 Norm Difference for worker 1620 is 1.397616
INFO:root:FL Epoch: 434 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :569
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352996
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374675
INFO:root:FL Epoch: 434 Norm Difference for worker 569 is 1.443025
INFO:root:FL Epoch: 434 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :55
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376895
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 55 is 1.297272
INFO:root:FL Epoch: 434 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :953
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271820
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141848
INFO:root:FL Epoch: 434 Norm Difference for worker 953 is 1.379293
INFO:root:FL Epoch: 434 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :253
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.185041
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.157139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 253 is 1.421553
INFO:root:FL Epoch: 434 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :598
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447845
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245933
INFO:root:FL Epoch: 434 Norm Difference for worker 598 is 1.404528
INFO:root:FL Epoch: 434 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :295
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.201964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 295 is 1.528197
INFO:root:FL Epoch: 434 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1199
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282806
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248852
INFO:root:FL Epoch: 434 Norm Difference for worker 1199 is 1.430174
INFO:root:FL Epoch: 434 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :545
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296013
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284221
INFO:root:FL Epoch: 434 Norm Difference for worker 545 is 1.355056
INFO:root:FL Epoch: 434 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.321438391876574, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3212993381368554
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3212974495081016
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3212974302288443
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.45522377245566426 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.03080199472606182                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [444, 1452, 461, 140, 1000, 1210, 747, 33, 1773, 375]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :444
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278252
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288139
INFO:root:FL Epoch: 435 Norm Difference for worker 444 is 1.327523
INFO:root:FL Epoch: 435 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1452
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513125
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325122
INFO:root:FL Epoch: 435 Norm Difference for worker 1452 is 1.42535
INFO:root:FL Epoch: 435 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :461
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464337
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244754
INFO:root:FL Epoch: 435 Norm Difference for worker 461 is 1.363185
INFO:root:FL Epoch: 435 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :140
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.315027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272273
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 140 is 1.406771
INFO:root:FL Epoch: 435 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1000
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583499
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342266
INFO:root:FL Epoch: 435 Norm Difference for worker 1000 is 1.363801
INFO:root:FL Epoch: 435 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1210
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351904
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344578
INFO:root:FL Epoch: 435 Norm Difference for worker 1210 is 1.378366
INFO:root:FL Epoch: 435 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :747
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474989
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325555
INFO:root:FL Epoch: 435 Norm Difference for worker 747 is 1.357125
INFO:root:FL Epoch: 435 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :33
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 33 is 1.303201
INFO:root:FL Epoch: 435 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1773
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457163
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299441
INFO:root:FL Epoch: 435 Norm Difference for worker 1773 is 1.345658
INFO:root:FL Epoch: 435 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :375
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274590
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252989
INFO:root:FL Epoch: 435 Norm Difference for worker 375 is 1.276152
INFO:root:FL Epoch: 435 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2843423563932521, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2842680706690404
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2842670909609224
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2842670635097018
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.4602792648708119 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.03688848577439785                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1596, 104, 1138, 367, 1834, 289, 475, 1888, 1798, 51]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 436 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1596
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525182
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171169
INFO:root:FL Epoch: 436 Norm Difference for worker 1596 is 1.239879
INFO:root:FL Epoch: 436 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :104
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 104 is 1.368689
INFO:root:FL Epoch: 436 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1138
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747909
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335145
INFO:root:FL Epoch: 436 Norm Difference for worker 1138 is 1.463092
INFO:root:FL Epoch: 436 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :367
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467706
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330088
INFO:root:FL Epoch: 436 Norm Difference for worker 367 is 1.318662
INFO:root:FL Epoch: 436 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1834
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.891873
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459693
INFO:root:FL Epoch: 436 Norm Difference for worker 1834 is 1.372849
INFO:root:FL Epoch: 436 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :289
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.149813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 289 is 1.237886
INFO:root:FL Epoch: 436 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :475
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433246
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149850
INFO:root:FL Epoch: 436 Norm Difference for worker 475 is 1.269257
INFO:root:FL Epoch: 436 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1888
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664825
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341233
INFO:root:FL Epoch: 436 Norm Difference for worker 1888 is 1.318747
INFO:root:FL Epoch: 436 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1798
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290987
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307684
INFO:root:FL Epoch: 436 Norm Difference for worker 1798 is 1.556235
INFO:root:FL Epoch: 436 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :51
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274449
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 51 is 1.368011
INFO:root:FL Epoch: 436 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2745158762138378, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.274229725961775
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2742265894147216
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2742265206495014
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.4504679502809749 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.02726883441209793                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [945, 15, 304, 957, 1361, 1848, 1090, 284, 1715, 208]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 437 Num points on workers: [200 201 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :945
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247560
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220274
INFO:root:FL Epoch: 437 Norm Difference for worker 945 is 1.172765
INFO:root:FL Epoch: 437 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :15
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 15 is 1.305738
INFO:root:FL Epoch: 437 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :304
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 304 is 1.331955
INFO:root:FL Epoch: 437 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :957
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487792
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272321
INFO:root:FL Epoch: 437 Norm Difference for worker 957 is 1.288123
INFO:root:FL Epoch: 437 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1361
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389875
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328310
INFO:root:FL Epoch: 437 Norm Difference for worker 1361 is 1.41961
INFO:root:FL Epoch: 437 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1848
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.215165
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358976
INFO:root:FL Epoch: 437 Norm Difference for worker 1848 is 1.524693
INFO:root:FL Epoch: 437 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1090
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407243
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134898
INFO:root:FL Epoch: 437 Norm Difference for worker 1090 is 1.306127
INFO:root:FL Epoch: 437 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :284
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.963300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 284 is 1.564763
INFO:root:FL Epoch: 437 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1715
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316804
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224464
INFO:root:FL Epoch: 437 Norm Difference for worker 1715 is 1.300299
INFO:root:FL Epoch: 437 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :208
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588605
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 208 is 1.448052
INFO:root:FL Epoch: 437 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.28862596738545, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2881852555108886
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2881794920343894
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2881794292377422
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.4579080360777238 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.029002503491938114                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [421, 1169, 907, 1176, 1511, 288, 1524, 1826, 1157, 919]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :421
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725749
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218587
INFO:root:FL Epoch: 438 Norm Difference for worker 421 is 1.357328
INFO:root:FL Epoch: 438 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1169
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213367
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165781
INFO:root:FL Epoch: 438 Norm Difference for worker 1169 is 1.266124
INFO:root:FL Epoch: 438 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :907
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585908
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368332
INFO:root:FL Epoch: 438 Norm Difference for worker 907 is 1.381899
INFO:root:FL Epoch: 438 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1176
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662934
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223676
INFO:root:FL Epoch: 438 Norm Difference for worker 1176 is 1.490895
INFO:root:FL Epoch: 438 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1511
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425740
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207831
INFO:root:FL Epoch: 438 Norm Difference for worker 1511 is 1.420978
INFO:root:FL Epoch: 438 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :288
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.730495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 288 is 1.348711
INFO:root:FL Epoch: 438 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1524
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780704
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414921
INFO:root:FL Epoch: 438 Norm Difference for worker 1524 is 1.435788
INFO:root:FL Epoch: 438 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1826
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344533
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243428
INFO:root:FL Epoch: 438 Norm Difference for worker 1826 is 1.207853
INFO:root:FL Epoch: 438 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1157
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674001
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373937
INFO:root:FL Epoch: 438 Norm Difference for worker 1157 is 1.353619
INFO:root:FL Epoch: 438 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :919
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629946
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439256
INFO:root:FL Epoch: 438 Norm Difference for worker 919 is 1.409605
INFO:root:FL Epoch: 438 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2876149176742255, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2874510844292368
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2874490605807651
INFO:root:#### Oracle Cals: 4, Objective Val: 1.287448955232112
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.46045485664816466 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.038242301593224205                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1124, 583, 333, 158, 126, 459, 786, 991, 1294, 367]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1124
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474050
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248231
INFO:root:FL Epoch: 439 Norm Difference for worker 1124 is 1.283811
INFO:root:FL Epoch: 439 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :583
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403120
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311239
INFO:root:FL Epoch: 439 Norm Difference for worker 583 is 1.179788
INFO:root:FL Epoch: 439 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :333
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451006
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 333 is 1.255339
INFO:root:FL Epoch: 439 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :158
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 158 is 1.233861
INFO:root:FL Epoch: 439 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :126
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 126 is 1.287234
INFO:root:FL Epoch: 439 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :459
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612565
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235465
INFO:root:FL Epoch: 439 Norm Difference for worker 459 is 1.174362
INFO:root:FL Epoch: 439 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :786
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562423
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480818
INFO:root:FL Epoch: 439 Norm Difference for worker 786 is 1.311974
INFO:root:FL Epoch: 439 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :991
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483920
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124795
INFO:root:FL Epoch: 439 Norm Difference for worker 991 is 1.166976
INFO:root:FL Epoch: 439 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1294
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384093
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278201
INFO:root:FL Epoch: 439 Norm Difference for worker 1294 is 1.309534
INFO:root:FL Epoch: 439 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :367
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366177
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294779
INFO:root:FL Epoch: 439 Norm Difference for worker 367 is 1.147439
INFO:root:FL Epoch: 439 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.166675805937839, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1665636800410357
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1665623965300054
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1665625121353393
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.4657779914491317 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.034528786626954876                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1829, 1217, 584, 1479, 451, 1313, 1673, 401, 885, 1525]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1829
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448195
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298507
INFO:root:FL Epoch: 440 Norm Difference for worker 1829 is 1.329214
INFO:root:FL Epoch: 440 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1217
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505475
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290841
INFO:root:FL Epoch: 440 Norm Difference for worker 1217 is 1.387603
INFO:root:FL Epoch: 440 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :584
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555662
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306506
INFO:root:FL Epoch: 440 Norm Difference for worker 584 is 1.348202
INFO:root:FL Epoch: 440 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1479
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500764
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270638
INFO:root:FL Epoch: 440 Norm Difference for worker 1479 is 1.227532
INFO:root:FL Epoch: 440 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :451
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438050
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298212
INFO:root:FL Epoch: 440 Norm Difference for worker 451 is 1.236169
INFO:root:FL Epoch: 440 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1313
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511256
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226732
INFO:root:FL Epoch: 440 Norm Difference for worker 1313 is 1.211263
INFO:root:FL Epoch: 440 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1673
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574134
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267713
INFO:root:FL Epoch: 440 Norm Difference for worker 1673 is 1.278179
INFO:root:FL Epoch: 440 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :401
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727856
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513951
INFO:root:FL Epoch: 440 Norm Difference for worker 401 is 1.388382
INFO:root:FL Epoch: 440 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :885
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516255
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178485
INFO:root:FL Epoch: 440 Norm Difference for worker 885 is 1.224114
INFO:root:FL Epoch: 440 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1525
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636799
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173822
INFO:root:FL Epoch: 440 Norm Difference for worker 1525 is 1.375801
INFO:root:FL Epoch: 440 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2291648321721753, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2289859146376856
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2289834870453447
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2289835048970323
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.43473778226796317 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.02951228649665912                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 1644, 1050, 1137, 72, 1710, 325, 74]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.073353
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.043661
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.01905307996397217 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.019164207205176354 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.30314
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.073088
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.027994
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.021300972749789555 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.01967053972184658 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.273061
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.029428
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.023616
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.020242411643266678 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.019229251705110074 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.275226
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1644
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356542
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297469
INFO:root:FL Epoch: 441 Norm Difference for worker 1644 is 1.337125
INFO:root:FL Epoch: 441 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1050
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351679
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403911
INFO:root:FL Epoch: 441 Norm Difference for worker 1050 is 1.374256
INFO:root:FL Epoch: 441 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1137
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518209
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400447
INFO:root:FL Epoch: 441 Norm Difference for worker 1137 is 1.395723
INFO:root:FL Epoch: 441 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :72
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.227282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 72 is 1.317894
INFO:root:FL Epoch: 441 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1710
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.234298
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228533
INFO:root:FL Epoch: 441 Norm Difference for worker 1710 is 1.284398
INFO:root:FL Epoch: 441 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :325
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432122
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.109582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 325 is 1.268161
INFO:root:FL Epoch: 441 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :74
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379385
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 74 is 1.34665
INFO:root:FL Epoch: 441 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9924032868352066, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9688452068837534
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9635912949726573
INFO:root:#### Oracle Cals: 4, Objective Val: 0.962114517407729
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9616910678385688
INFO:root:#### Oracle Cals: 6, Objective Val: 0.961572875701226
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9615407681872329
INFO:root:#### Oracle Cals: 8, Objective Val: 0.961532356185261
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9615304227255063
INFO:root:#### Oracle Cals: 10, Objective Val: 0.961529662850219
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9615294998642707
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9615294148284508
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.45740948705112233 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.022017880032459896                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1904, 830, 1706, 724, 105, 669, 1838, 1426, 1525, 348]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1904
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437552
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257938
INFO:root:FL Epoch: 442 Norm Difference for worker 1904 is 1.311618
INFO:root:FL Epoch: 442 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :830
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406578
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334827
INFO:root:FL Epoch: 442 Norm Difference for worker 830 is 1.203833
INFO:root:FL Epoch: 442 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1706
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592379
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320835
INFO:root:FL Epoch: 442 Norm Difference for worker 1706 is 1.408303
INFO:root:FL Epoch: 442 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :724
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219166
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415910
INFO:root:FL Epoch: 442 Norm Difference for worker 724 is 1.461185
INFO:root:FL Epoch: 442 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :105
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423461
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 105 is 1.306971
INFO:root:FL Epoch: 442 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :669
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511543
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.106490
INFO:root:FL Epoch: 442 Norm Difference for worker 669 is 1.302299
INFO:root:FL Epoch: 442 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1838
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481046
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440236
INFO:root:FL Epoch: 442 Norm Difference for worker 1838 is 1.48303
INFO:root:FL Epoch: 442 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1426
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638775
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251671
INFO:root:FL Epoch: 442 Norm Difference for worker 1426 is 1.534809
INFO:root:FL Epoch: 442 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1525
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574277
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428252
INFO:root:FL Epoch: 442 Norm Difference for worker 1525 is 1.334243
INFO:root:FL Epoch: 442 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :348
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525937
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377158
INFO:root:FL Epoch: 442 Norm Difference for worker 348 is 1.369103
INFO:root:FL Epoch: 442 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3032224533666743, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3029286326641574
INFO:root:#### Oracle Cals: 3, Objective Val: 1.302924585025503
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3029245379341603
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.4661055277375614 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.021801076053331297                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1577, 779, 512, 235, 243, 191, 1671, 634, 443, 1020]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1577
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405568
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324352
INFO:root:FL Epoch: 443 Norm Difference for worker 1577 is 1.382064
INFO:root:FL Epoch: 443 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :779
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470349
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154659
INFO:root:FL Epoch: 443 Norm Difference for worker 779 is 1.326112
INFO:root:FL Epoch: 443 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :512
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539211
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222406
INFO:root:FL Epoch: 443 Norm Difference for worker 512 is 1.416099
INFO:root:FL Epoch: 443 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :235
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 235 is 1.423047
INFO:root:FL Epoch: 443 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :243
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612650
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.175915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 243 is 1.275118
INFO:root:FL Epoch: 443 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :191
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485371
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.105371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 191 is 1.317027
INFO:root:FL Epoch: 443 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1671
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356820
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496450
INFO:root:FL Epoch: 443 Norm Difference for worker 1671 is 1.401264
INFO:root:FL Epoch: 443 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :634
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592868
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337535
INFO:root:FL Epoch: 443 Norm Difference for worker 634 is 1.347417
INFO:root:FL Epoch: 443 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :443
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782506
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528452
INFO:root:FL Epoch: 443 Norm Difference for worker 443 is 1.38027
INFO:root:FL Epoch: 443 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1020
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489848
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238544
INFO:root:FL Epoch: 443 Norm Difference for worker 1020 is 1.443371
INFO:root:FL Epoch: 443 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2965810780948914, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2964420171096132
INFO:root:#### Oracle Cals: 3, Objective Val: 1.296440230975139
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2964402074799266
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.49288801936542287 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.035300346091389656                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [563, 1407, 1882, 1071, 1689, 574, 1118, 399, 1608, 1747]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :563
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291549
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157044
INFO:root:FL Epoch: 444 Norm Difference for worker 563 is 1.178506
INFO:root:FL Epoch: 444 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1407
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437459
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272858
INFO:root:FL Epoch: 444 Norm Difference for worker 1407 is 1.325801
INFO:root:FL Epoch: 444 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1882
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477553
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285790
INFO:root:FL Epoch: 444 Norm Difference for worker 1882 is 1.326417
INFO:root:FL Epoch: 444 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1071
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719861
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307976
INFO:root:FL Epoch: 444 Norm Difference for worker 1071 is 1.380268
INFO:root:FL Epoch: 444 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1689
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522618
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207135
INFO:root:FL Epoch: 444 Norm Difference for worker 1689 is 1.425348
INFO:root:FL Epoch: 444 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :574
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537030
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343031
INFO:root:FL Epoch: 444 Norm Difference for worker 574 is 1.362835
INFO:root:FL Epoch: 444 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1118
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797634
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208763
INFO:root:FL Epoch: 444 Norm Difference for worker 1118 is 1.378532
INFO:root:FL Epoch: 444 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :399
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495836
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293916
INFO:root:FL Epoch: 444 Norm Difference for worker 399 is 1.267639
INFO:root:FL Epoch: 444 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1608
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471065
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155562
INFO:root:FL Epoch: 444 Norm Difference for worker 1608 is 1.39033
INFO:root:FL Epoch: 444 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1747
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301552
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308316
INFO:root:FL Epoch: 444 Norm Difference for worker 1747 is 1.307696
INFO:root:FL Epoch: 444 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2588602996459781, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2587092071527934
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2587073058518954
INFO:root:#### Oracle Cals: 4, Objective Val: 1.258707261640117
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.47300294742864724 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.025895871377239626                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [1111, 1878, 1505, 1084, 1040, 1173, 1446, 805, 871, 453]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 445 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :1111
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380671
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208981
INFO:root:FL Epoch: 445 Norm Difference for worker 1111 is 1.392403
INFO:root:FL Epoch: 445 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1878
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475615
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284972
INFO:root:FL Epoch: 445 Norm Difference for worker 1878 is 1.44052
INFO:root:FL Epoch: 445 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1505
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762276
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343121
INFO:root:FL Epoch: 445 Norm Difference for worker 1505 is 1.388587
INFO:root:FL Epoch: 445 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1084
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520200
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213709
INFO:root:FL Epoch: 445 Norm Difference for worker 1084 is 1.369398
INFO:root:FL Epoch: 445 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1040
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599686
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202191
INFO:root:FL Epoch: 445 Norm Difference for worker 1040 is 1.294794
INFO:root:FL Epoch: 445 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1173
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548786
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234612
INFO:root:FL Epoch: 445 Norm Difference for worker 1173 is 1.251922
INFO:root:FL Epoch: 445 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1446
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493093
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287743
INFO:root:FL Epoch: 445 Norm Difference for worker 1446 is 1.373682
INFO:root:FL Epoch: 445 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :805
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400202
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259754
INFO:root:FL Epoch: 445 Norm Difference for worker 805 is 1.416725
INFO:root:FL Epoch: 445 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :871
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533333
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246175
INFO:root:FL Epoch: 445 Norm Difference for worker 871 is 1.321609
INFO:root:FL Epoch: 445 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :453
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587256
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271992
INFO:root:FL Epoch: 445 Norm Difference for worker 453 is 1.472753
INFO:root:FL Epoch: 445 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2997668137842335, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2996520876223077
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2996507421208467
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2996507591330544
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.4579467054675607 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.026890459315230448                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [1056, 1824, 1566, 228, 917, 527, 169, 279, 1402, 1605]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :1056
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578217
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233807
INFO:root:FL Epoch: 446 Norm Difference for worker 1056 is 1.323674
INFO:root:FL Epoch: 446 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1824
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739588
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444950
INFO:root:FL Epoch: 446 Norm Difference for worker 1824 is 1.346129
INFO:root:FL Epoch: 446 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1566
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525632
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488035
INFO:root:FL Epoch: 446 Norm Difference for worker 1566 is 1.320952
INFO:root:FL Epoch: 446 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :228
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532586
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 228 is 1.34194
INFO:root:FL Epoch: 446 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :917
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436141
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344283
INFO:root:FL Epoch: 446 Norm Difference for worker 917 is 1.357636
INFO:root:FL Epoch: 446 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :527
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454007
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334835
INFO:root:FL Epoch: 446 Norm Difference for worker 527 is 1.281582
INFO:root:FL Epoch: 446 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :169
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 169 is 1.265789
INFO:root:FL Epoch: 446 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :279
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 279 is 1.346924
INFO:root:FL Epoch: 446 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1402
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434240
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413820
INFO:root:FL Epoch: 446 Norm Difference for worker 1402 is 1.415265
INFO:root:FL Epoch: 446 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1605
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494583
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441000
INFO:root:FL Epoch: 446 Norm Difference for worker 1605 is 1.292223
INFO:root:FL Epoch: 446 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.258533054813008, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2584670082380576
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2584661770184942
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2584661451283548
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.4719505134750815 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.02591957477852702                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [4, 146, 1929, 1862, 226, 1490, 914, 1000, 1175, 116]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 447 Num points on workers: [201 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :4
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447015
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 4 is 1.338905
INFO:root:FL Epoch: 447 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :146
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 146 is 1.499303
INFO:root:FL Epoch: 447 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1929
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.154582
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200240
INFO:root:FL Epoch: 447 Norm Difference for worker 1929 is 1.218184
INFO:root:FL Epoch: 447 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1862
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312659
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234028
INFO:root:FL Epoch: 447 Norm Difference for worker 1862 is 1.318604
INFO:root:FL Epoch: 447 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :226
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.247039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257715
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 226 is 1.337825
INFO:root:FL Epoch: 447 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1490
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543395
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275370
INFO:root:FL Epoch: 447 Norm Difference for worker 1490 is 1.359844
INFO:root:FL Epoch: 447 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :914
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480113
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278775
INFO:root:FL Epoch: 447 Norm Difference for worker 914 is 1.381099
INFO:root:FL Epoch: 447 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1000
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432521
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137744
INFO:root:FL Epoch: 447 Norm Difference for worker 1000 is 1.419873
INFO:root:FL Epoch: 447 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1175
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256850
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316170
INFO:root:FL Epoch: 447 Norm Difference for worker 1175 is 1.247432
INFO:root:FL Epoch: 447 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :116
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.163963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 116 is 1.350118
INFO:root:FL Epoch: 447 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2687712329695895, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2685875590700593
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2685853655065202
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2685853569718557
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.4852062358575709 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.025057022149364155                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [949, 1443, 890, 852, 689, 1895, 1574, 607, 277, 950]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :949
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375819
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429800
INFO:root:FL Epoch: 448 Norm Difference for worker 949 is 1.427427
INFO:root:FL Epoch: 448 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1443
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411924
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392477
INFO:root:FL Epoch: 448 Norm Difference for worker 1443 is 1.435133
INFO:root:FL Epoch: 448 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :890
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455450
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209631
INFO:root:FL Epoch: 448 Norm Difference for worker 890 is 1.304215
INFO:root:FL Epoch: 448 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :852
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534282
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176835
INFO:root:FL Epoch: 448 Norm Difference for worker 852 is 1.27067
INFO:root:FL Epoch: 448 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :689
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460297
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152180
INFO:root:FL Epoch: 448 Norm Difference for worker 689 is 1.363712
INFO:root:FL Epoch: 448 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1895
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482740
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209858
INFO:root:FL Epoch: 448 Norm Difference for worker 1895 is 1.528326
INFO:root:FL Epoch: 448 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1574
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275554
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290277
INFO:root:FL Epoch: 448 Norm Difference for worker 1574 is 1.475229
INFO:root:FL Epoch: 448 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :607
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677660
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214235
INFO:root:FL Epoch: 448 Norm Difference for worker 607 is 1.342385
INFO:root:FL Epoch: 448 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :277
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741616
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 277 is 1.415177
INFO:root:FL Epoch: 448 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :950
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319549
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176396
INFO:root:FL Epoch: 448 Norm Difference for worker 950 is 1.240577
INFO:root:FL Epoch: 448 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3092852080504755, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3090561635797133
INFO:root:#### Oracle Cals: 3, Objective Val: 1.309053255276114
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3090533361864536
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.4766625236062443 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.025224114923427503                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [1522, 782, 758, 912, 1379, 1210, 1104, 1023, 1212, 1352]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :1522
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606165
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202144
INFO:root:FL Epoch: 449 Norm Difference for worker 1522 is 1.294764
INFO:root:FL Epoch: 449 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :782
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603850
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293321
INFO:root:FL Epoch: 449 Norm Difference for worker 782 is 1.531731
INFO:root:FL Epoch: 449 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :758
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425155
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365240
INFO:root:FL Epoch: 449 Norm Difference for worker 758 is 1.333532
INFO:root:FL Epoch: 449 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :912
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524515
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193970
INFO:root:FL Epoch: 449 Norm Difference for worker 912 is 1.23378
INFO:root:FL Epoch: 449 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1379
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331335
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205890
INFO:root:FL Epoch: 449 Norm Difference for worker 1379 is 1.334137
INFO:root:FL Epoch: 449 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1210
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211969
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200765
INFO:root:FL Epoch: 449 Norm Difference for worker 1210 is 1.444031
INFO:root:FL Epoch: 449 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1104
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308350
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304134
INFO:root:FL Epoch: 449 Norm Difference for worker 1104 is 1.409257
INFO:root:FL Epoch: 449 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1023
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525771
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217355
INFO:root:FL Epoch: 449 Norm Difference for worker 1023 is 1.248611
INFO:root:FL Epoch: 449 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1212
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220805
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226259
INFO:root:FL Epoch: 449 Norm Difference for worker 1212 is 1.300596
INFO:root:FL Epoch: 449 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1352
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420664
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404518
INFO:root:FL Epoch: 449 Norm Difference for worker 1352 is 1.279426
INFO:root:FL Epoch: 449 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2720326686010397, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2717406439746113
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2717370116335243
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2717369770381133
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.4798046227763681 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.024827643763273954                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [389, 411, 375, 1747, 319, 522, 1311, 1796, 76, 1590]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :389
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529765
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373967
INFO:root:FL Epoch: 450 Norm Difference for worker 389 is 1.413243
INFO:root:FL Epoch: 450 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :411
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.231118
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274937
INFO:root:FL Epoch: 450 Norm Difference for worker 411 is 1.558327
INFO:root:FL Epoch: 450 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :375
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313393
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397665
INFO:root:FL Epoch: 450 Norm Difference for worker 375 is 1.302312
INFO:root:FL Epoch: 450 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1747
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252169
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261488
INFO:root:FL Epoch: 450 Norm Difference for worker 1747 is 1.312099
INFO:root:FL Epoch: 450 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :319
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.182706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 319 is 1.318114
INFO:root:FL Epoch: 450 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :522
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518902
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166834
INFO:root:FL Epoch: 450 Norm Difference for worker 522 is 1.231339
INFO:root:FL Epoch: 450 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1311
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629219
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231111
INFO:root:FL Epoch: 450 Norm Difference for worker 1311 is 1.452234
INFO:root:FL Epoch: 450 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1796
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276327
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236902
INFO:root:FL Epoch: 450 Norm Difference for worker 1796 is 1.315866
INFO:root:FL Epoch: 450 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :76
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.192390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 76 is 1.420985
INFO:root:FL Epoch: 450 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1590
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396774
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241206
INFO:root:FL Epoch: 450 Norm Difference for worker 1590 is 1.442502
INFO:root:FL Epoch: 450 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3006781392081905, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.300395496715874
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3003916798468325
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3003916361686354
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.44986289038377647 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.027129321669538815                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 1108, 1097, 1433, 1247, 1404, 1313, 684]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.030224
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.037309
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.018964786703387897 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.01887555969879031 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.24139
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.039449
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.060809
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.018323224037885666 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.019397070072591303 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.229593
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.038085
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.030960
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.019042208790779114 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.0188225862570107 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.24884
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1108
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583848
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262622
INFO:root:FL Epoch: 451 Norm Difference for worker 1108 is 1.413004
INFO:root:FL Epoch: 451 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1097
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419717
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200589
INFO:root:FL Epoch: 451 Norm Difference for worker 1097 is 1.402914
INFO:root:FL Epoch: 451 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1433
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397755
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214819
INFO:root:FL Epoch: 451 Norm Difference for worker 1433 is 1.249633
INFO:root:FL Epoch: 451 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1247
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507164
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173769
INFO:root:FL Epoch: 451 Norm Difference for worker 1247 is 1.261618
INFO:root:FL Epoch: 451 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1404
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439224
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281748
INFO:root:FL Epoch: 451 Norm Difference for worker 1404 is 1.198421
INFO:root:FL Epoch: 451 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1313
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570464
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211218
INFO:root:FL Epoch: 451 Norm Difference for worker 1313 is 1.20501
INFO:root:FL Epoch: 451 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :684
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366076
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219573
INFO:root:FL Epoch: 451 Norm Difference for worker 684 is 1.22962
INFO:root:FL Epoch: 451 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9467310039268879, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9232950076582416
INFO:root:#### Oracle Cals: 3, Objective Val: 0.917772280003947
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9160294484252345
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9154440342946341
INFO:root:#### Oracle Cals: 6, Objective Val: 0.915248960022483
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9151855983210201
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9151653427401083
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9151591065586918
INFO:root:#### Oracle Cals: 10, Objective Val: 0.9151571363222571
INFO:root:#### Oracle Cals: 11, Objective Val: 0.915156467921484
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9151567661898945
INFO:root:#### Oracle Cals: 13, Objective Val: 0.9151564464483116
INFO:root:#### Oracle Cals: 14, Objective Val: 0.9151562054502707
INFO:root:#### Oracle Cals: 15, Objective Val: 0.9151562564373377
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.4659852069966933 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.020425688320149977                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1459, 1133, 1333, 1274, 6, 1294, 853, 1204, 312, 111]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1459
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312244
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341637
INFO:root:FL Epoch: 452 Norm Difference for worker 1459 is 1.304413
INFO:root:FL Epoch: 452 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1133
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365551
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247212
INFO:root:FL Epoch: 452 Norm Difference for worker 1133 is 1.496462
INFO:root:FL Epoch: 452 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1333
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411060
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168125
INFO:root:FL Epoch: 452 Norm Difference for worker 1333 is 1.482488
INFO:root:FL Epoch: 452 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1274
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404754
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278881
INFO:root:FL Epoch: 452 Norm Difference for worker 1274 is 1.467877
INFO:root:FL Epoch: 452 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :6
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.183007
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 6 is 1.247959
INFO:root:FL Epoch: 452 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1294
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731489
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131803
INFO:root:FL Epoch: 452 Norm Difference for worker 1294 is 1.398121
INFO:root:FL Epoch: 452 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :853
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453979
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368612
INFO:root:FL Epoch: 452 Norm Difference for worker 853 is 1.501379
INFO:root:FL Epoch: 452 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1204
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462154
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164329
INFO:root:FL Epoch: 452 Norm Difference for worker 1204 is 1.484268
INFO:root:FL Epoch: 452 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :312
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445303
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 312 is 1.463465
INFO:root:FL Epoch: 452 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :111
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.163053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 111 is 1.452592
INFO:root:FL Epoch: 452 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.34649554763471, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3462688870468298
INFO:root:#### Oracle Cals: 3, Objective Val: 1.346265580043102
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3462655227349478
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.44704529993674336 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.02023818561186393                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1448, 287, 1140, 793, 1896, 421, 213, 1873, 1936, 764]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 453 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1448
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422419
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144656
INFO:root:FL Epoch: 453 Norm Difference for worker 1448 is 1.291888
INFO:root:FL Epoch: 453 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :287
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 287 is 1.380598
INFO:root:FL Epoch: 453 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1140
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562999
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346016
INFO:root:FL Epoch: 453 Norm Difference for worker 1140 is 1.335671
INFO:root:FL Epoch: 453 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :793
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807607
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121154
INFO:root:FL Epoch: 453 Norm Difference for worker 793 is 1.336563
INFO:root:FL Epoch: 453 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1896
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438011
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138570
INFO:root:FL Epoch: 453 Norm Difference for worker 1896 is 1.304661
INFO:root:FL Epoch: 453 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :421
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542074
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399925
INFO:root:FL Epoch: 453 Norm Difference for worker 421 is 1.326869
INFO:root:FL Epoch: 453 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :213
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 213 is 1.344334
INFO:root:FL Epoch: 453 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1873
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584130
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151888
INFO:root:FL Epoch: 453 Norm Difference for worker 1873 is 1.297262
INFO:root:FL Epoch: 453 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1936
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.207851
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147662
INFO:root:FL Epoch: 453 Norm Difference for worker 1936 is 1.349235
INFO:root:FL Epoch: 453 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :764
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421329
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172790
INFO:root:FL Epoch: 453 Norm Difference for worker 764 is 1.339493
INFO:root:FL Epoch: 453 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2569976637552602, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2569642288495024
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2569638455791337
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2569638211378333
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.4609214663505554 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.024222527941068012                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [20, 53, 1915, 859, 1637, 1037, 375, 528, 1448, 1070]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 454 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :20
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 20 is 1.335052
INFO:root:FL Epoch: 454 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :53
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 53 is 1.291387
INFO:root:FL Epoch: 454 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1915
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563754
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254528
INFO:root:FL Epoch: 454 Norm Difference for worker 1915 is 1.376277
INFO:root:FL Epoch: 454 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :859
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380868
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206434
INFO:root:FL Epoch: 454 Norm Difference for worker 859 is 1.388716
INFO:root:FL Epoch: 454 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1637
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403274
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343782
INFO:root:FL Epoch: 454 Norm Difference for worker 1637 is 1.446112
INFO:root:FL Epoch: 454 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1037
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314742
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290153
INFO:root:FL Epoch: 454 Norm Difference for worker 1037 is 1.378029
INFO:root:FL Epoch: 454 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :375
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455890
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288085
INFO:root:FL Epoch: 454 Norm Difference for worker 375 is 1.185238
INFO:root:FL Epoch: 454 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :528
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490161
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129743
INFO:root:FL Epoch: 454 Norm Difference for worker 528 is 1.401322
INFO:root:FL Epoch: 454 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1448
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441902
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261332
INFO:root:FL Epoch: 454 Norm Difference for worker 1448 is 1.26652
INFO:root:FL Epoch: 454 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1070
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702675
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157545
INFO:root:FL Epoch: 454 Norm Difference for worker 1070 is 1.444089
INFO:root:FL Epoch: 454 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2780062496691396, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2777788066505038
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2777759286354102
INFO:root:#### Oracle Cals: 4, Objective Val: 1.277775889180535
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.46280836182482105 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.02457400442411502                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [248, 1827, 377, 1118, 1287, 306, 1415, 336, 1237, 1124]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 455 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :248
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.291251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 248 is 1.278686
INFO:root:FL Epoch: 455 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1827
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488834
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423060
INFO:root:FL Epoch: 455 Norm Difference for worker 1827 is 1.378193
INFO:root:FL Epoch: 455 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :377
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359257
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533651
INFO:root:FL Epoch: 455 Norm Difference for worker 377 is 1.420581
INFO:root:FL Epoch: 455 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1118
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334711
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267082
INFO:root:FL Epoch: 455 Norm Difference for worker 1118 is 1.295477
INFO:root:FL Epoch: 455 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1287
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670023
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342033
INFO:root:FL Epoch: 455 Norm Difference for worker 1287 is 1.318019
INFO:root:FL Epoch: 455 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :306
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.171926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 306 is 1.211559
INFO:root:FL Epoch: 455 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1415
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330310
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357179
INFO:root:FL Epoch: 455 Norm Difference for worker 1415 is 1.434352
INFO:root:FL Epoch: 455 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :336
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.156254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 336 is 1.359533
INFO:root:FL Epoch: 455 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1237
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586379
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279271
INFO:root:FL Epoch: 455 Norm Difference for worker 1237 is 1.367798
INFO:root:FL Epoch: 455 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1124
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543284
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295144
INFO:root:FL Epoch: 455 Norm Difference for worker 1124 is 1.306183
INFO:root:FL Epoch: 455 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.264415925364812, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2642560594083312
INFO:root:#### Oracle Cals: 3, Objective Val: 1.264253861420924
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2642539193159859
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.44692765965181236 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.026368670475979645                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1208, 847, 1418, 97, 558, 674, 1098, 1624, 983, 1079]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1208
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604622
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233052
INFO:root:FL Epoch: 456 Norm Difference for worker 1208 is 1.266514
INFO:root:FL Epoch: 456 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :847
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776635
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282942
INFO:root:FL Epoch: 456 Norm Difference for worker 847 is 1.319582
INFO:root:FL Epoch: 456 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1418
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585588
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272277
INFO:root:FL Epoch: 456 Norm Difference for worker 1418 is 1.367573
INFO:root:FL Epoch: 456 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :97
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.243146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 97 is 1.279504
INFO:root:FL Epoch: 456 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :558
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527614
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205610
INFO:root:FL Epoch: 456 Norm Difference for worker 558 is 1.347678
INFO:root:FL Epoch: 456 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :674
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461812
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243819
INFO:root:FL Epoch: 456 Norm Difference for worker 674 is 1.214139
INFO:root:FL Epoch: 456 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1098
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489861
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247559
INFO:root:FL Epoch: 456 Norm Difference for worker 1098 is 1.248298
INFO:root:FL Epoch: 456 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1624
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464930
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351868
INFO:root:FL Epoch: 456 Norm Difference for worker 1624 is 1.305174
INFO:root:FL Epoch: 456 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :983
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385203
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213214
INFO:root:FL Epoch: 456 Norm Difference for worker 983 is 1.410581
INFO:root:FL Epoch: 456 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1079
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326111
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334385
INFO:root:FL Epoch: 456 Norm Difference for worker 1079 is 1.346685
INFO:root:FL Epoch: 456 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.238431361498145, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2382639497331351
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2382617697414067
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2382617247341825
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.48098771361743703 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.02894954103976488                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [301, 892, 1357, 946, 1812, 217, 198, 160, 97, 78]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.0997009 0.1001994 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 457 Num points on workers: [201 200 200 200 200 201 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :301
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 301 is 1.304155
INFO:root:FL Epoch: 457 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :892
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.218686
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333620
INFO:root:FL Epoch: 457 Norm Difference for worker 892 is 1.213722
INFO:root:FL Epoch: 457 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1357
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499812
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217634
INFO:root:FL Epoch: 457 Norm Difference for worker 1357 is 1.34793
INFO:root:FL Epoch: 457 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :946
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433345
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366116
INFO:root:FL Epoch: 457 Norm Difference for worker 946 is 1.282137
INFO:root:FL Epoch: 457 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1812
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306774
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230731
INFO:root:FL Epoch: 457 Norm Difference for worker 1812 is 1.311656
INFO:root:FL Epoch: 457 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :217
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.180951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 217 is 1.291313
INFO:root:FL Epoch: 457 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :198
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303843
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 198 is 1.278531
INFO:root:FL Epoch: 457 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :160
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.993572
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 160 is 1.324734
INFO:root:FL Epoch: 457 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :97
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210881
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 97 is 1.138886
INFO:root:FL Epoch: 457 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :78
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 78 is 1.149497
INFO:root:FL Epoch: 457 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.200463924010367, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.200313493771569
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2003112115757844
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2003111816831011
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.47800928704878864 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.024422157866259415                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [993, 92, 497, 26, 364, 1508, 1296, 1117, 1009, 867]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 458 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :993
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285722
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227167
INFO:root:FL Epoch: 458 Norm Difference for worker 993 is 1.276702
INFO:root:FL Epoch: 458 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :92
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 92 is 1.339369
INFO:root:FL Epoch: 458 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :497
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684782
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261185
INFO:root:FL Epoch: 458 Norm Difference for worker 497 is 1.20502
INFO:root:FL Epoch: 458 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :26
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 26 is 1.226167
INFO:root:FL Epoch: 458 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :364
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352983
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203684
INFO:root:FL Epoch: 458 Norm Difference for worker 364 is 1.247926
INFO:root:FL Epoch: 458 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1508
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449138
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170561
INFO:root:FL Epoch: 458 Norm Difference for worker 1508 is 1.197224
INFO:root:FL Epoch: 458 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1296
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583909
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214466
INFO:root:FL Epoch: 458 Norm Difference for worker 1296 is 1.376729
INFO:root:FL Epoch: 458 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1117
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608591
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185890
INFO:root:FL Epoch: 458 Norm Difference for worker 1117 is 1.258244
INFO:root:FL Epoch: 458 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1009
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484677
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509438
INFO:root:FL Epoch: 458 Norm Difference for worker 1009 is 1.419662
INFO:root:FL Epoch: 458 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :867
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318328
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136069
INFO:root:FL Epoch: 458 Norm Difference for worker 867 is 1.230984
INFO:root:FL Epoch: 458 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2077177999798736, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2075240562742355
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2075213044352602
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2075212570641232
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.48364340031848235 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.023786026674012344                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [1706, 1346, 133, 699, 374, 827, 367, 1408, 741, 952]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 459 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :1706
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307304
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216760
INFO:root:FL Epoch: 459 Norm Difference for worker 1706 is 1.251157
INFO:root:FL Epoch: 459 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1346
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.214343
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190973
INFO:root:FL Epoch: 459 Norm Difference for worker 1346 is 1.307854
INFO:root:FL Epoch: 459 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :133
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307034
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 133 is 1.239699
INFO:root:FL Epoch: 459 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :699
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528124
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162215
INFO:root:FL Epoch: 459 Norm Difference for worker 699 is 1.356403
INFO:root:FL Epoch: 459 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :374
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570558
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224514
INFO:root:FL Epoch: 459 Norm Difference for worker 374 is 1.28588
INFO:root:FL Epoch: 459 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :827
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702127
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193895
INFO:root:FL Epoch: 459 Norm Difference for worker 827 is 1.355535
INFO:root:FL Epoch: 459 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :367
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497172
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192540
INFO:root:FL Epoch: 459 Norm Difference for worker 367 is 1.246892
INFO:root:FL Epoch: 459 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1408
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420420
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302035
INFO:root:FL Epoch: 459 Norm Difference for worker 1408 is 1.207857
INFO:root:FL Epoch: 459 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :741
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410716
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451179
INFO:root:FL Epoch: 459 Norm Difference for worker 741 is 1.40557
INFO:root:FL Epoch: 459 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :952
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320003
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245526
INFO:root:FL Epoch: 459 Norm Difference for worker 952 is 1.3711
INFO:root:FL Epoch: 459 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2382569165114377, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2381170456437505
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2381149917311915
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2381150439274744
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.46895376373739805 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.02313327230513096                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [580, 445, 1191, 908, 25, 749, 812, 244, 593, 618]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :580
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443567
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199984
INFO:root:FL Epoch: 460 Norm Difference for worker 580 is 1.37857
INFO:root:FL Epoch: 460 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :445
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611649
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164218
INFO:root:FL Epoch: 460 Norm Difference for worker 445 is 1.327106
INFO:root:FL Epoch: 460 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1191
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765880
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260168
INFO:root:FL Epoch: 460 Norm Difference for worker 1191 is 1.321486
INFO:root:FL Epoch: 460 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :908
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483331
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187053
INFO:root:FL Epoch: 460 Norm Difference for worker 908 is 1.287891
INFO:root:FL Epoch: 460 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :25
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324303
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.136291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 25 is 1.226536
INFO:root:FL Epoch: 460 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :749
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351925
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.095992
INFO:root:FL Epoch: 460 Norm Difference for worker 749 is 1.259377
INFO:root:FL Epoch: 460 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :812
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451043
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425747
INFO:root:FL Epoch: 460 Norm Difference for worker 812 is 1.362688
INFO:root:FL Epoch: 460 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :244
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.154240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 244 is 1.244878
INFO:root:FL Epoch: 460 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :593
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672353
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259964
INFO:root:FL Epoch: 460 Norm Difference for worker 593 is 1.385401
INFO:root:FL Epoch: 460 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :618
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415792
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188838
INFO:root:FL Epoch: 460 Norm Difference for worker 618 is 1.360108
INFO:root:FL Epoch: 460 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2431999175224258, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2430686203690169
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2430669577794076
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2430669110140562
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.4681226076448665 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.02409185500194629                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 607, 837, 17, 896, 1404, 909, 1212]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.059236
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.045675
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.015839432133361697 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.018892682250589134 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.246164
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.057530
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.023381
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.016263467880586784 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.018338206596672534 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.250061
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.051098
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.025417
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.016318838034446042 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.0190604486502707 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.235644
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :607
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675750
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183325
INFO:root:FL Epoch: 461 Norm Difference for worker 607 is 1.234709
INFO:root:FL Epoch: 461 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :837
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640780
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271683
INFO:root:FL Epoch: 461 Norm Difference for worker 837 is 1.356335
INFO:root:FL Epoch: 461 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :17
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 17 is 1.316865
INFO:root:FL Epoch: 461 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :896
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696816
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.095501
INFO:root:FL Epoch: 461 Norm Difference for worker 896 is 1.180238
INFO:root:FL Epoch: 461 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1404
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772933
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292752
INFO:root:FL Epoch: 461 Norm Difference for worker 1404 is 1.2178
INFO:root:FL Epoch: 461 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :909
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388797
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222184
INFO:root:FL Epoch: 461 Norm Difference for worker 909 is 1.262928
INFO:root:FL Epoch: 461 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1212
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419051
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211425
INFO:root:FL Epoch: 461 Norm Difference for worker 1212 is 1.180164
INFO:root:FL Epoch: 461 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9295862878577725, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9075538275711191
INFO:root:#### Oracle Cals: 3, Objective Val: 0.902538329098019
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9010530494234121
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9005915325870849
INFO:root:#### Oracle Cals: 6, Objective Val: 0.9004496523458512
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9004071490649094
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9003947564503769
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9003907818341729
INFO:root:#### Oracle Cals: 10, Objective Val: 0.9003899678548504
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9003894199171025
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9003894056440667
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.4822223589700811 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.017812910334517557                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [1587, 831, 1744, 981, 535, 1490, 1495, 634, 1243, 571]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :1587
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440069
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212599
INFO:root:FL Epoch: 462 Norm Difference for worker 1587 is 1.347846
INFO:root:FL Epoch: 462 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :831
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496947
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124068
INFO:root:FL Epoch: 462 Norm Difference for worker 831 is 1.244867
INFO:root:FL Epoch: 462 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1744
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376939
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.862363
INFO:root:FL Epoch: 462 Norm Difference for worker 1744 is 1.728124
INFO:root:FL Epoch: 462 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :981
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386955
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213600
INFO:root:FL Epoch: 462 Norm Difference for worker 981 is 1.436025
INFO:root:FL Epoch: 462 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :535
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512318
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145462
INFO:root:FL Epoch: 462 Norm Difference for worker 535 is 1.292503
INFO:root:FL Epoch: 462 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1490
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248263
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211466
INFO:root:FL Epoch: 462 Norm Difference for worker 1490 is 1.319803
INFO:root:FL Epoch: 462 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1495
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.983467
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200412
INFO:root:FL Epoch: 462 Norm Difference for worker 1495 is 1.570407
INFO:root:FL Epoch: 462 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :634
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543399
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370980
INFO:root:FL Epoch: 462 Norm Difference for worker 634 is 1.324273
INFO:root:FL Epoch: 462 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1243
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691473
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171365
INFO:root:FL Epoch: 462 Norm Difference for worker 1243 is 1.364522
INFO:root:FL Epoch: 462 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :571
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.168766
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203361
INFO:root:FL Epoch: 462 Norm Difference for worker 571 is 1.401497
INFO:root:FL Epoch: 462 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.322688964937857, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.322143073285739
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3221364435706593
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3221364805673852
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.51317719150992 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.028293586025635403                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [335, 1320, 78, 417, 3, 371, 1139, 1410, 1867, 738]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 463 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :335
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.262540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 335 is 1.352483
INFO:root:FL Epoch: 463 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1320
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798638
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 1.721505
INFO:root:FL Epoch: 463 Norm Difference for worker 1320 is 2.847703
INFO:root:FL Epoch: 463 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :78
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 78 is 1.277161
INFO:root:FL Epoch: 463 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :417
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458231
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271281
INFO:root:FL Epoch: 463 Norm Difference for worker 417 is 1.320452
INFO:root:FL Epoch: 463 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :3
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.910215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.748467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 3 is 2.093313
INFO:root:FL Epoch: 463 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :371
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330743
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239866
INFO:root:FL Epoch: 463 Norm Difference for worker 371 is 1.325263
INFO:root:FL Epoch: 463 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1139
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512226
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355367
INFO:root:FL Epoch: 463 Norm Difference for worker 1139 is 1.292722
INFO:root:FL Epoch: 463 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1410
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488561
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150104
INFO:root:FL Epoch: 463 Norm Difference for worker 1410 is 1.40344
INFO:root:FL Epoch: 463 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1867
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465294
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346202
INFO:root:FL Epoch: 463 Norm Difference for worker 1867 is 1.447002
INFO:root:FL Epoch: 463 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :738
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444799
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134596
INFO:root:FL Epoch: 463 Norm Difference for worker 738 is 1.310081
INFO:root:FL Epoch: 463 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.482492572972141, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.4700467943082813
INFO:root:#### Oracle Cals: 3, Objective Val: 1.469757077919062
INFO:root:#### Oracle Cals: 4, Objective Val: 1.4697510908190308
INFO:root:#### Oracle Cals: 5, Objective Val: 1.4697509760757852
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.48056728699628043 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.04151345572123925                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [740, 258, 895, 807, 468, 1002, 239, 675, 1571, 1007]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 464 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :740
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381768
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405729
INFO:root:FL Epoch: 464 Norm Difference for worker 740 is 1.162376
INFO:root:FL Epoch: 464 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :258
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469800
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231459
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 258 is 1.258147
INFO:root:FL Epoch: 464 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :895
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573136
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274522
INFO:root:FL Epoch: 464 Norm Difference for worker 895 is 1.201523
INFO:root:FL Epoch: 464 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :807
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.226434
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304660
INFO:root:FL Epoch: 464 Norm Difference for worker 807 is 1.215511
INFO:root:FL Epoch: 464 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :468
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447178
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205032
INFO:root:FL Epoch: 464 Norm Difference for worker 468 is 1.172103
INFO:root:FL Epoch: 464 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1002
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416599
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211359
INFO:root:FL Epoch: 464 Norm Difference for worker 1002 is 1.192955
INFO:root:FL Epoch: 464 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :239
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 239 is 1.344665
INFO:root:FL Epoch: 464 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :675
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591375
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263991
INFO:root:FL Epoch: 464 Norm Difference for worker 675 is 1.331224
INFO:root:FL Epoch: 464 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1571
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256336
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418053
INFO:root:FL Epoch: 464 Norm Difference for worker 1571 is 1.212936
INFO:root:FL Epoch: 464 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1007
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303983
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420978
INFO:root:FL Epoch: 464 Norm Difference for worker 1007 is 1.20194
INFO:root:FL Epoch: 464 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.160494052818647, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1603647862536997
INFO:root:#### Oracle Cals: 3, Objective Val: 1.160363195897945
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1603631450857104
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.4739173966295579 and Test Accuracy:75.0 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.038312182761728764                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [81, 351, 1764, 1030, 751, 1163, 582, 323, 1265, 143]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 465 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :81
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 81 is 1.2752
INFO:root:FL Epoch: 465 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :351
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490573
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218856
INFO:root:FL Epoch: 465 Norm Difference for worker 351 is 1.228719
INFO:root:FL Epoch: 465 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1764
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686773
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369107
INFO:root:FL Epoch: 465 Norm Difference for worker 1764 is 1.411041
INFO:root:FL Epoch: 465 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1030
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722935
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218540
INFO:root:FL Epoch: 465 Norm Difference for worker 1030 is 1.366969
INFO:root:FL Epoch: 465 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :751
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466801
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247826
INFO:root:FL Epoch: 465 Norm Difference for worker 751 is 1.196791
INFO:root:FL Epoch: 465 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1163
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380797
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385314
INFO:root:FL Epoch: 465 Norm Difference for worker 1163 is 1.258657
INFO:root:FL Epoch: 465 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :582
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622112
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387655
INFO:root:FL Epoch: 465 Norm Difference for worker 582 is 1.438117
INFO:root:FL Epoch: 465 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :323
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 323 is 1.317597
INFO:root:FL Epoch: 465 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1265
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360970
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282970
INFO:root:FL Epoch: 465 Norm Difference for worker 1265 is 1.222927
INFO:root:FL Epoch: 465 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :143
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.163732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 143 is 1.260148
INFO:root:FL Epoch: 465 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.224208572024488, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2240184109270413
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2240155404328281
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2240154690725729
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.4753189858268289 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.03733529895544052                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1824, 1524, 512, 513, 1770, 173, 1460, 639, 1261, 1732]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1824
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416686
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374880
INFO:root:FL Epoch: 466 Norm Difference for worker 1824 is 1.264012
INFO:root:FL Epoch: 466 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1524
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592628
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187664
INFO:root:FL Epoch: 466 Norm Difference for worker 1524 is 1.254164
INFO:root:FL Epoch: 466 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :512
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541654
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371790
INFO:root:FL Epoch: 466 Norm Difference for worker 512 is 1.212693
INFO:root:FL Epoch: 466 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :513
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447615
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413458
INFO:root:FL Epoch: 466 Norm Difference for worker 513 is 1.384996
INFO:root:FL Epoch: 466 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1770
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360798
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299853
INFO:root:FL Epoch: 466 Norm Difference for worker 1770 is 1.093608
INFO:root:FL Epoch: 466 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :173
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403962
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 173 is 1.282614
INFO:root:FL Epoch: 466 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1460
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270658
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144539
INFO:root:FL Epoch: 466 Norm Difference for worker 1460 is 1.123641
INFO:root:FL Epoch: 466 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :639
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473827
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227693
INFO:root:FL Epoch: 466 Norm Difference for worker 639 is 1.156202
INFO:root:FL Epoch: 466 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1261
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585593
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379091
INFO:root:FL Epoch: 466 Norm Difference for worker 1261 is 1.314088
INFO:root:FL Epoch: 466 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1732
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662339
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354388
INFO:root:FL Epoch: 466 Norm Difference for worker 1732 is 1.178096
INFO:root:FL Epoch: 466 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.149293679766262, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.148900088384955
INFO:root:#### Oracle Cals: 3, Objective Val: 1.148894225922656
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1488940842281132
INFO:root:#### Oracle Cals: 5, Objective Val: 1.1488941103161852
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.476362489602145 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.036295698334773384                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1773, 938, 657, 1319, 1905, 21, 745, 488, 408, 1595]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 467 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1773
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536580
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206669
INFO:root:FL Epoch: 467 Norm Difference for worker 1773 is 1.222977
INFO:root:FL Epoch: 467 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :938
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618436
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450770
INFO:root:FL Epoch: 467 Norm Difference for worker 938 is 1.404386
INFO:root:FL Epoch: 467 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :657
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796688
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248869
INFO:root:FL Epoch: 467 Norm Difference for worker 657 is 1.331684
INFO:root:FL Epoch: 467 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1319
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436465
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325908
INFO:root:FL Epoch: 467 Norm Difference for worker 1319 is 1.379293
INFO:root:FL Epoch: 467 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1905
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278260
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170878
INFO:root:FL Epoch: 467 Norm Difference for worker 1905 is 1.128004
INFO:root:FL Epoch: 467 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :21
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 21 is 1.151643
INFO:root:FL Epoch: 467 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :745
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447911
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347058
INFO:root:FL Epoch: 467 Norm Difference for worker 745 is 1.308804
INFO:root:FL Epoch: 467 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :488
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298212
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240148
INFO:root:FL Epoch: 467 Norm Difference for worker 488 is 1.21259
INFO:root:FL Epoch: 467 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :408
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577017
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182534
INFO:root:FL Epoch: 467 Norm Difference for worker 408 is 1.217569
INFO:root:FL Epoch: 467 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1595
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294896
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268173
INFO:root:FL Epoch: 467 Norm Difference for worker 1595 is 1.201248
INFO:root:FL Epoch: 467 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1886104155974038, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1882460351664987
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1882415085218636
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1882414546545568
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.48253706448218403 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.044820212138195835                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1586, 1317, 626, 1406, 854, 1493, 724, 1905, 1504, 843]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1586
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704399
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250366
INFO:root:FL Epoch: 468 Norm Difference for worker 1586 is 1.283102
INFO:root:FL Epoch: 468 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1317
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425383
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295609
INFO:root:FL Epoch: 468 Norm Difference for worker 1317 is 1.242261
INFO:root:FL Epoch: 468 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :626
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.156242
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314789
INFO:root:FL Epoch: 468 Norm Difference for worker 626 is 1.212178
INFO:root:FL Epoch: 468 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1406
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514680
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301138
INFO:root:FL Epoch: 468 Norm Difference for worker 1406 is 1.274235
INFO:root:FL Epoch: 468 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :854
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346158
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292640
INFO:root:FL Epoch: 468 Norm Difference for worker 854 is 1.235231
INFO:root:FL Epoch: 468 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1493
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306263
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230104
INFO:root:FL Epoch: 468 Norm Difference for worker 1493 is 1.277262
INFO:root:FL Epoch: 468 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :724
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607874
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260373
INFO:root:FL Epoch: 468 Norm Difference for worker 724 is 1.202398
INFO:root:FL Epoch: 468 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1905
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324040
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.105902
INFO:root:FL Epoch: 468 Norm Difference for worker 1905 is 0.952748
INFO:root:FL Epoch: 468 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1504
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509739
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210371
INFO:root:FL Epoch: 468 Norm Difference for worker 1504 is 1.34
INFO:root:FL Epoch: 468 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :843
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566088
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329383
INFO:root:FL Epoch: 468 Norm Difference for worker 843 is 1.262336
INFO:root:FL Epoch: 468 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.158206574643383, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1578992388168743
INFO:root:#### Oracle Cals: 3, Objective Val: 1.157894205728251
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1578941712360624
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.4548199071603663 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.03262046414117018                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [554, 1448, 934, 1333, 217, 1698, 1453, 379, 1803, 488]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :554
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436662
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253306
INFO:root:FL Epoch: 469 Norm Difference for worker 554 is 1.355947
INFO:root:FL Epoch: 469 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1448
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402484
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244705
INFO:root:FL Epoch: 469 Norm Difference for worker 1448 is 1.179547
INFO:root:FL Epoch: 469 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :934
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648241
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309167
INFO:root:FL Epoch: 469 Norm Difference for worker 934 is 1.438356
INFO:root:FL Epoch: 469 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1333
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646714
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261668
INFO:root:FL Epoch: 469 Norm Difference for worker 1333 is 1.346741
INFO:root:FL Epoch: 469 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :217
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488843
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.200506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 217 is 1.190806
INFO:root:FL Epoch: 469 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1698
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429165
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296735
INFO:root:FL Epoch: 469 Norm Difference for worker 1698 is 1.360892
INFO:root:FL Epoch: 469 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1453
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392974
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280115
INFO:root:FL Epoch: 469 Norm Difference for worker 1453 is 1.192279
INFO:root:FL Epoch: 469 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :379
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567082
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175552
INFO:root:FL Epoch: 469 Norm Difference for worker 379 is 1.276494
INFO:root:FL Epoch: 469 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1803
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572718
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282168
INFO:root:FL Epoch: 469 Norm Difference for worker 1803 is 1.270488
INFO:root:FL Epoch: 469 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :488
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460850
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226050
INFO:root:FL Epoch: 469 Norm Difference for worker 488 is 1.175995
INFO:root:FL Epoch: 469 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2062772817112861, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2059700105656024
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2059662238785167
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2059662038703074
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.44787191468126636 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.027126064524054527                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [709, 1445, 1569, 618, 1559, 1202, 1010, 484, 1465, 613]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :709
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454069
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416492
INFO:root:FL Epoch: 470 Norm Difference for worker 709 is 1.378716
INFO:root:FL Epoch: 470 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1445
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733493
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332017
INFO:root:FL Epoch: 470 Norm Difference for worker 1445 is 1.376051
INFO:root:FL Epoch: 470 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1569
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472272
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278405
INFO:root:FL Epoch: 470 Norm Difference for worker 1569 is 1.374722
INFO:root:FL Epoch: 470 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :618
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621721
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144313
INFO:root:FL Epoch: 470 Norm Difference for worker 618 is 1.256626
INFO:root:FL Epoch: 470 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1559
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260989
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189717
INFO:root:FL Epoch: 470 Norm Difference for worker 1559 is 1.255133
INFO:root:FL Epoch: 470 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1202
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435520
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196075
INFO:root:FL Epoch: 470 Norm Difference for worker 1202 is 1.312521
INFO:root:FL Epoch: 470 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1010
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429876
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419873
INFO:root:FL Epoch: 470 Norm Difference for worker 1010 is 1.355276
INFO:root:FL Epoch: 470 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :484
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543158
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255747
INFO:root:FL Epoch: 470 Norm Difference for worker 484 is 1.355189
INFO:root:FL Epoch: 470 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1465
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446620
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406439
INFO:root:FL Epoch: 470 Norm Difference for worker 1465 is 1.364603
INFO:root:FL Epoch: 470 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :613
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601954
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312477
INFO:root:FL Epoch: 470 Norm Difference for worker 613 is 1.483962
INFO:root:FL Epoch: 470 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2669507248917489, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.266846962871923
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2668455046284224
INFO:root:#### Oracle Cals: 4, Objective Val: 1.266845527682737
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.4503746015184066 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.027659295592457056                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 151, 1654, 1080, 91, 1467, 1247, 1165]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.028765
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.021724
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.017820128705352545 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.018386015389114618 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.202479
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.028544
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.027605
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.018487643916159868 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.01818575831130147 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.210648
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.023275
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.031089
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.019130873183409374 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.018412933871150016 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.205241
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :151
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 151 is 1.338666
INFO:root:FL Epoch: 471 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1654
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844168
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.152738
INFO:root:FL Epoch: 471 Norm Difference for worker 1654 is 1.253932
INFO:root:FL Epoch: 471 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1080
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825328
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380941
INFO:root:FL Epoch: 471 Norm Difference for worker 1080 is 1.295737
INFO:root:FL Epoch: 471 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :91
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 91 is 1.308654
INFO:root:FL Epoch: 471 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1467
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528570
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.122327
INFO:root:FL Epoch: 471 Norm Difference for worker 1467 is 1.156326
INFO:root:FL Epoch: 471 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1247
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580288
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266617
INFO:root:FL Epoch: 471 Norm Difference for worker 1247 is 1.305047
INFO:root:FL Epoch: 471 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1165
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.176395
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258017
INFO:root:FL Epoch: 471 Norm Difference for worker 1165 is 1.242405
INFO:root:FL Epoch: 471 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9418031196841851, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9190020673332336
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9133515538221452
INFO:root:#### Oracle Cals: 4, Objective Val: 0.911435071419463
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9107191453802606
INFO:root:#### Oracle Cals: 6, Objective Val: 0.9104463100729513
INFO:root:#### Oracle Cals: 7, Objective Val: 0.9103428394100119
INFO:root:#### Oracle Cals: 8, Objective Val: 0.9103044066012395
INFO:root:#### Oracle Cals: 9, Objective Val: 0.9102904851945325
INFO:root:#### Oracle Cals: 10, Objective Val: 0.910284783903874
INFO:root:#### Oracle Cals: 11, Objective Val: 0.9102828670864976
INFO:root:#### Oracle Cals: 12, Objective Val: 0.9102823118203384
INFO:root:#### Oracle Cals: 13, Objective Val: 0.9102819595256018
INFO:root:#### Oracle Cals: 14, Objective Val: 0.9102822792391062
INFO:root:#### Oracle Cals: 15, Objective Val: 0.9102818316497956
INFO:root:#### Oracle Cals: 16, Objective Val: 0.910281924371895
INFO:root:#### Oracle Cals: 17, Objective Val: 0.9102819100223852
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.4574964502278496 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.020371088758111                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [55, 1275, 894, 1719, 433, 1880, 1000, 1374, 879, 853]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 472 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :55
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.239881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.141811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 55 is 1.220739
INFO:root:FL Epoch: 472 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1275
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353673
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144560
INFO:root:FL Epoch: 472 Norm Difference for worker 1275 is 1.257169
INFO:root:FL Epoch: 472 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :894
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272113
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205200
INFO:root:FL Epoch: 472 Norm Difference for worker 894 is 1.230314
INFO:root:FL Epoch: 472 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1719
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301704
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307316
INFO:root:FL Epoch: 472 Norm Difference for worker 1719 is 1.242757
INFO:root:FL Epoch: 472 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :433
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352307
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290761
INFO:root:FL Epoch: 472 Norm Difference for worker 433 is 1.381136
INFO:root:FL Epoch: 472 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1880
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681508
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367787
INFO:root:FL Epoch: 472 Norm Difference for worker 1880 is 1.340497
INFO:root:FL Epoch: 472 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1000
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347643
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121930
INFO:root:FL Epoch: 472 Norm Difference for worker 1000 is 1.300503
INFO:root:FL Epoch: 472 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1374
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432524
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166137
INFO:root:FL Epoch: 472 Norm Difference for worker 1374 is 1.189646
INFO:root:FL Epoch: 472 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :879
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508327
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493831
INFO:root:FL Epoch: 472 Norm Difference for worker 879 is 1.486185
INFO:root:FL Epoch: 472 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :853
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398470
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266881
INFO:root:FL Epoch: 472 Norm Difference for worker 853 is 1.405558
INFO:root:FL Epoch: 472 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2389391779850294, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2387013165200298
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2386985241691597
INFO:root:#### Oracle Cals: 4, Objective Val: 1.238698526475569
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.44884972712572885 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.024289014438788097                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [548, 1156, 785, 1590, 1674, 880, 1577, 662, 1528, 386]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :548
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457028
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398072
INFO:root:FL Epoch: 473 Norm Difference for worker 548 is 1.396799
INFO:root:FL Epoch: 473 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1156
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384283
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205397
INFO:root:FL Epoch: 473 Norm Difference for worker 1156 is 1.209214
INFO:root:FL Epoch: 473 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :785
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464838
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269801
INFO:root:FL Epoch: 473 Norm Difference for worker 785 is 1.333587
INFO:root:FL Epoch: 473 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1590
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620102
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277692
INFO:root:FL Epoch: 473 Norm Difference for worker 1590 is 1.346827
INFO:root:FL Epoch: 473 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1674
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395369
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272545
INFO:root:FL Epoch: 473 Norm Difference for worker 1674 is 1.315318
INFO:root:FL Epoch: 473 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :880
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546249
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315140
INFO:root:FL Epoch: 473 Norm Difference for worker 880 is 1.346154
INFO:root:FL Epoch: 473 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1577
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648490
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308785
INFO:root:FL Epoch: 473 Norm Difference for worker 1577 is 1.381282
INFO:root:FL Epoch: 473 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :662
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814273
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268980
INFO:root:FL Epoch: 473 Norm Difference for worker 662 is 1.491712
INFO:root:FL Epoch: 473 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1528
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411866
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216701
INFO:root:FL Epoch: 473 Norm Difference for worker 1528 is 1.173576
INFO:root:FL Epoch: 473 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :386
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390273
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138767
INFO:root:FL Epoch: 473 Norm Difference for worker 386 is 1.182902
INFO:root:FL Epoch: 473 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2417618764533314, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.241407480514011
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2414031054592942
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2414030536838483
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.4556113551644718 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.02524372562766075                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1866, 1598, 830, 460, 382, 1338, 838, 193, 457, 1938]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1866
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421799
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158945
INFO:root:FL Epoch: 474 Norm Difference for worker 1866 is 1.405793
INFO:root:FL Epoch: 474 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1598
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331746
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200140
INFO:root:FL Epoch: 474 Norm Difference for worker 1598 is 1.207292
INFO:root:FL Epoch: 474 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :830
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305812
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156417
INFO:root:FL Epoch: 474 Norm Difference for worker 830 is 1.154374
INFO:root:FL Epoch: 474 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :460
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433865
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274894
INFO:root:FL Epoch: 474 Norm Difference for worker 460 is 1.415004
INFO:root:FL Epoch: 474 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :382
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509279
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321946
INFO:root:FL Epoch: 474 Norm Difference for worker 382 is 1.397342
INFO:root:FL Epoch: 474 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1338
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770995
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458312
INFO:root:FL Epoch: 474 Norm Difference for worker 1338 is 1.23721
INFO:root:FL Epoch: 474 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :838
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232144
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219973
INFO:root:FL Epoch: 474 Norm Difference for worker 838 is 1.30396
INFO:root:FL Epoch: 474 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :193
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 1.058686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 193 is 1.476296
INFO:root:FL Epoch: 474 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :457
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585122
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365995
INFO:root:FL Epoch: 474 Norm Difference for worker 457 is 1.422215
INFO:root:FL Epoch: 474 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1938
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343950
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408704
INFO:root:FL Epoch: 474 Norm Difference for worker 1938 is 1.403463
INFO:root:FL Epoch: 474 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2656884071972627, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2653727812698932
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2653682140244458
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2653681595586277
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.4582654938978307 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.024599779552469652                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1290, 213, 1351, 1815, 282, 152, 1723, 1823, 752, 1239]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 475 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1290
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505309
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284256
INFO:root:FL Epoch: 475 Norm Difference for worker 1290 is 1.275602
INFO:root:FL Epoch: 475 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :213
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 213 is 1.343711
INFO:root:FL Epoch: 475 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1351
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297494
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330971
INFO:root:FL Epoch: 475 Norm Difference for worker 1351 is 1.29021
INFO:root:FL Epoch: 475 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1815
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734613
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225900
INFO:root:FL Epoch: 475 Norm Difference for worker 1815 is 1.283834
INFO:root:FL Epoch: 475 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :282
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 282 is 1.379951
INFO:root:FL Epoch: 475 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :152
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 152 is 1.316189
INFO:root:FL Epoch: 475 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1723
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785190
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216361
INFO:root:FL Epoch: 475 Norm Difference for worker 1723 is 1.306781
INFO:root:FL Epoch: 475 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1823
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329099
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228551
INFO:root:FL Epoch: 475 Norm Difference for worker 1823 is 1.347368
INFO:root:FL Epoch: 475 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :752
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569000
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539735
INFO:root:FL Epoch: 475 Norm Difference for worker 752 is 1.326409
INFO:root:FL Epoch: 475 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1239
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306992
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247320
INFO:root:FL Epoch: 475 Norm Difference for worker 1239 is 1.270865
INFO:root:FL Epoch: 475 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2434400365083584, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2433900816797034
INFO:root:#### Oracle Cals: 3, Objective Val: 1.243389475797782
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2433894822744418
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.4562650831306682 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.02607430253798763                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [1494, 1738, 1857, 453, 1466, 1132, 1586, 1646, 1059, 419]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 476 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :1494
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277346
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201745
INFO:root:FL Epoch: 476 Norm Difference for worker 1494 is 1.231686
INFO:root:FL Epoch: 476 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1738
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284482
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317214
INFO:root:FL Epoch: 476 Norm Difference for worker 1738 is 1.331744
INFO:root:FL Epoch: 476 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1857
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415789
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210465
INFO:root:FL Epoch: 476 Norm Difference for worker 1857 is 1.287358
INFO:root:FL Epoch: 476 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :453
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306084
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186359
INFO:root:FL Epoch: 476 Norm Difference for worker 453 is 1.395364
INFO:root:FL Epoch: 476 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1466
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555733
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465023
INFO:root:FL Epoch: 476 Norm Difference for worker 1466 is 1.33649
INFO:root:FL Epoch: 476 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1132
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422073
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334343
INFO:root:FL Epoch: 476 Norm Difference for worker 1132 is 1.309866
INFO:root:FL Epoch: 476 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1586
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625464
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225505
INFO:root:FL Epoch: 476 Norm Difference for worker 1586 is 1.23305
INFO:root:FL Epoch: 476 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1646
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258164
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332161
INFO:root:FL Epoch: 476 Norm Difference for worker 1646 is 1.255093
INFO:root:FL Epoch: 476 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1059
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257082
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267116
INFO:root:FL Epoch: 476 Norm Difference for worker 1059 is 1.124755
INFO:root:FL Epoch: 476 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :419
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196304
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229316
INFO:root:FL Epoch: 476 Norm Difference for worker 419 is 1.169214
INFO:root:FL Epoch: 476 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1985726955888043, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1983709919700138
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1983679892424097
INFO:root:#### Oracle Cals: 4, Objective Val: 1.19836798170978
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.4478434762533973 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.027787808949748676                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [952, 411, 415, 1448, 552, 1943, 679, 1277, 1416, 35]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 477 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :952
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725360
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298212
INFO:root:FL Epoch: 477 Norm Difference for worker 952 is 1.255733
INFO:root:FL Epoch: 477 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :411
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834162
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268879
INFO:root:FL Epoch: 477 Norm Difference for worker 411 is 1.387947
INFO:root:FL Epoch: 477 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :415
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522700
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206372
INFO:root:FL Epoch: 477 Norm Difference for worker 415 is 1.216724
INFO:root:FL Epoch: 477 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1448
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353449
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185865
INFO:root:FL Epoch: 477 Norm Difference for worker 1448 is 1.199205
INFO:root:FL Epoch: 477 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :552
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555636
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378133
INFO:root:FL Epoch: 477 Norm Difference for worker 552 is 1.410615
INFO:root:FL Epoch: 477 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1943
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672318
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330332
INFO:root:FL Epoch: 477 Norm Difference for worker 1943 is 1.419255
INFO:root:FL Epoch: 477 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :679
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398011
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377252
INFO:root:FL Epoch: 477 Norm Difference for worker 679 is 1.320285
INFO:root:FL Epoch: 477 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1277
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.203903
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153217
INFO:root:FL Epoch: 477 Norm Difference for worker 1277 is 1.232858
INFO:root:FL Epoch: 477 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1416
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459303
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115632
INFO:root:FL Epoch: 477 Norm Difference for worker 1416 is 1.247278
INFO:root:FL Epoch: 477 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :35
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 35 is 1.202551
INFO:root:FL Epoch: 477 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2197290515487815, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2193985242391183
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2193942299799174
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2193941722671167
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.4529957140193266 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.02303968012953798                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [1457, 196, 409, 1243, 850, 1688, 1945, 529, 1824, 301]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 478 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :1457
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622576
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257405
INFO:root:FL Epoch: 478 Norm Difference for worker 1457 is 1.275087
INFO:root:FL Epoch: 478 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :196
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 196 is 1.346752
INFO:root:FL Epoch: 478 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :409
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664265
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308643
INFO:root:FL Epoch: 478 Norm Difference for worker 409 is 1.327037
INFO:root:FL Epoch: 478 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1243
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643696
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187045
INFO:root:FL Epoch: 478 Norm Difference for worker 1243 is 1.219883
INFO:root:FL Epoch: 478 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :850
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313039
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257983
INFO:root:FL Epoch: 478 Norm Difference for worker 850 is 1.246176
INFO:root:FL Epoch: 478 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1688
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249660
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168834
INFO:root:FL Epoch: 478 Norm Difference for worker 1688 is 1.186995
INFO:root:FL Epoch: 478 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1945
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364470
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127807
INFO:root:FL Epoch: 478 Norm Difference for worker 1945 is 1.173586
INFO:root:FL Epoch: 478 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :529
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475500
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314521
INFO:root:FL Epoch: 478 Norm Difference for worker 529 is 1.287769
INFO:root:FL Epoch: 478 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1824
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749026
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237783
INFO:root:FL Epoch: 478 Norm Difference for worker 1824 is 1.238657
INFO:root:FL Epoch: 478 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :301
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 301 is 1.275443
INFO:root:FL Epoch: 478 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.190281007765619, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1901394152678288
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1901376667403323
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1901376367753804
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.47267795485608716 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.024441721538702648                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [1556, 1805, 396, 462, 693, 700, 492, 688, 164, 1734]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :1556
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530405
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349521
INFO:root:FL Epoch: 479 Norm Difference for worker 1556 is 1.191871
INFO:root:FL Epoch: 479 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1805
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397248
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155211
INFO:root:FL Epoch: 479 Norm Difference for worker 1805 is 1.212121
INFO:root:FL Epoch: 479 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :396
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594905
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141775
INFO:root:FL Epoch: 479 Norm Difference for worker 396 is 1.206679
INFO:root:FL Epoch: 479 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :462
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483964
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304593
INFO:root:FL Epoch: 479 Norm Difference for worker 462 is 1.33069
INFO:root:FL Epoch: 479 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :693
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433746
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277950
INFO:root:FL Epoch: 479 Norm Difference for worker 693 is 1.292188
INFO:root:FL Epoch: 479 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :700
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596125
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218052
INFO:root:FL Epoch: 479 Norm Difference for worker 700 is 1.291304
INFO:root:FL Epoch: 479 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :492
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571317
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.128355
INFO:root:FL Epoch: 479 Norm Difference for worker 492 is 1.248048
INFO:root:FL Epoch: 479 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :688
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582452
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257340
INFO:root:FL Epoch: 479 Norm Difference for worker 688 is 1.313322
INFO:root:FL Epoch: 479 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :164
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.166861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 164 is 1.346931
INFO:root:FL Epoch: 479 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1734
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.131908
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174600
INFO:root:FL Epoch: 479 Norm Difference for worker 1734 is 1.284991
INFO:root:FL Epoch: 479 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.204089626851988, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2039686209051499
INFO:root:#### Oracle Cals: 3, Objective Val: 1.203966928237655
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2039669412079643
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.4831540829995099 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.018524598175038893                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [616, 1015, 305, 191, 1119, 1854, 1670, 983, 1569, 980]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :616
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618705
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199318
INFO:root:FL Epoch: 480 Norm Difference for worker 616 is 1.367567
INFO:root:FL Epoch: 480 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1015
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567947
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167481
INFO:root:FL Epoch: 480 Norm Difference for worker 1015 is 1.290775
INFO:root:FL Epoch: 480 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :305
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427894
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 305 is 1.244289
INFO:root:FL Epoch: 480 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :191
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.315584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 191 is 1.252556
INFO:root:FL Epoch: 480 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1119
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394490
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236376
INFO:root:FL Epoch: 480 Norm Difference for worker 1119 is 1.182148
INFO:root:FL Epoch: 480 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1854
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581478
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266793
INFO:root:FL Epoch: 480 Norm Difference for worker 1854 is 1.408798
INFO:root:FL Epoch: 480 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1670
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568024
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189245
INFO:root:FL Epoch: 480 Norm Difference for worker 1670 is 1.286805
INFO:root:FL Epoch: 480 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :983
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590987
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224697
INFO:root:FL Epoch: 480 Norm Difference for worker 983 is 1.344659
INFO:root:FL Epoch: 480 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1569
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599434
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190229
INFO:root:FL Epoch: 480 Norm Difference for worker 1569 is 1.283225
INFO:root:FL Epoch: 480 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :980
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486436
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201955
INFO:root:FL Epoch: 480 Norm Difference for worker 980 is 1.359614
INFO:root:FL Epoch: 480 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2299678091140045, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2298098841165443
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2298079345088522
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2298078726937745
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.49527031533858357 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.025081090163439512                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 561, 481, 321, 674, 79, 14, 483]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.035767
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.019049
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.01702816318720579 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.017926628701388836 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.2057
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.029250
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.033030
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.015768338460475206 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.017554832529276608 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.215097
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.023848
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.031225
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.015863438912977774 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.017560074850916863 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.216111
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :561
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409897
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361920
INFO:root:FL Epoch: 481 Norm Difference for worker 561 is 1.415047
INFO:root:FL Epoch: 481 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :481
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523414
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180207
INFO:root:FL Epoch: 481 Norm Difference for worker 481 is 1.237862
INFO:root:FL Epoch: 481 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :321
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 321 is 1.309768
INFO:root:FL Epoch: 481 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :674
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493028
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170445
INFO:root:FL Epoch: 481 Norm Difference for worker 674 is 1.096918
INFO:root:FL Epoch: 481 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :79
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 79 is 1.239948
INFO:root:FL Epoch: 481 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :14
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.347327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.229190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 14 is 1.152609
INFO:root:FL Epoch: 481 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :483
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305858
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214208
INFO:root:FL Epoch: 481 Norm Difference for worker 483 is 1.095631
INFO:root:FL Epoch: 481 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9048186254449762, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.8819337180803738
INFO:root:#### Oracle Cals: 3, Objective Val: 0.8765838988435362
INFO:root:#### Oracle Cals: 4, Objective Val: 0.8748931598000642
INFO:root:#### Oracle Cals: 5, Objective Val: 0.8743256669976291
INFO:root:#### Oracle Cals: 6, Objective Val: 0.8741372893607384
INFO:root:#### Oracle Cals: 7, Objective Val: 0.8740766653537215
INFO:root:#### Oracle Cals: 8, Objective Val: 0.874057724366692
INFO:root:#### Oracle Cals: 9, Objective Val: 0.8740517338751239
INFO:root:#### Oracle Cals: 10, Objective Val: 0.8740502222631183
INFO:root:#### Oracle Cals: 11, Objective Val: 0.8740493896763916
INFO:root:#### Oracle Cals: 12, Objective Val: 0.8740492502190348
INFO:root:#### Oracle Cals: 13, Objective Val: 0.8740495777696995
INFO:root:#### Oracle Cals: 14, Objective Val: 0.8740492476538102
INFO:root:#### Oracle Cals: 15, Objective Val: 0.8740495193394825
INFO:root:#### Oracle Cals: 16, Objective Val: 0.8740491556178555
INFO:root:#### Oracle Cals: 17, Objective Val: 0.8740491680888967
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.5076544950990116 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.017890500215192635                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [949, 863, 340, 58, 1181, 242, 1945, 1451, 1473, 477]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :949
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398076
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282381
INFO:root:FL Epoch: 482 Norm Difference for worker 949 is 1.390874
INFO:root:FL Epoch: 482 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :863
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.868356
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248561
INFO:root:FL Epoch: 482 Norm Difference for worker 863 is 1.416926
INFO:root:FL Epoch: 482 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :340
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.227586
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169408
INFO:root:FL Epoch: 482 Norm Difference for worker 340 is 1.375164
INFO:root:FL Epoch: 482 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :58
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.353192
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 58 is 1.50197
INFO:root:FL Epoch: 482 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1181
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440935
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167490
INFO:root:FL Epoch: 482 Norm Difference for worker 1181 is 1.300671
INFO:root:FL Epoch: 482 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :242
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420623
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 242 is 1.430032
INFO:root:FL Epoch: 482 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1945
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492855
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.110723
INFO:root:FL Epoch: 482 Norm Difference for worker 1945 is 1.239661
INFO:root:FL Epoch: 482 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1451
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615816
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139210
INFO:root:FL Epoch: 482 Norm Difference for worker 1451 is 1.412095
INFO:root:FL Epoch: 482 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1473
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482469
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265515
INFO:root:FL Epoch: 482 Norm Difference for worker 1473 is 1.444494
INFO:root:FL Epoch: 482 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :477
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473135
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235747
INFO:root:FL Epoch: 482 Norm Difference for worker 477 is 1.403969
INFO:root:FL Epoch: 482 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.3142954372628843, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.3140735105279722
INFO:root:#### Oracle Cals: 3, Objective Val: 1.3140704691135705
INFO:root:#### Oracle Cals: 4, Objective Val: 1.3140704251339503
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.48038557347129374 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.020886756014078856                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [849, 1204, 1327, 924, 1031, 409, 912, 401, 117, 1136]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 483 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :849
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794894
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247012
INFO:root:FL Epoch: 483 Norm Difference for worker 849 is 1.354537
INFO:root:FL Epoch: 483 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1204
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315603
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168780
INFO:root:FL Epoch: 483 Norm Difference for worker 1204 is 1.305415
INFO:root:FL Epoch: 483 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1327
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402905
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346603
INFO:root:FL Epoch: 483 Norm Difference for worker 1327 is 1.209263
INFO:root:FL Epoch: 483 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :924
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375736
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192192
INFO:root:FL Epoch: 483 Norm Difference for worker 924 is 1.321579
INFO:root:FL Epoch: 483 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1031
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373577
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263494
INFO:root:FL Epoch: 483 Norm Difference for worker 1031 is 1.447405
INFO:root:FL Epoch: 483 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :409
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764878
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301780
INFO:root:FL Epoch: 483 Norm Difference for worker 409 is 1.203341
INFO:root:FL Epoch: 483 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :912
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398724
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265581
INFO:root:FL Epoch: 483 Norm Difference for worker 912 is 1.225862
INFO:root:FL Epoch: 483 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :401
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278849
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404905
INFO:root:FL Epoch: 483 Norm Difference for worker 401 is 1.274242
INFO:root:FL Epoch: 483 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :117
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.368506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.207354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 117 is 1.288027
INFO:root:FL Epoch: 483 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1136
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679711
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286563
INFO:root:FL Epoch: 483 Norm Difference for worker 1136 is 1.368121
INFO:root:FL Epoch: 483 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2328253877977038, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2326603401627014
INFO:root:#### Oracle Cals: 3, Objective Val: 1.232657941321265
INFO:root:#### Oracle Cals: 4, Objective Val: 1.232657926464608
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.4750460351214689 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.02028268699844678                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [528, 141, 406, 1149, 639, 932, 865, 1944, 1827, 1174]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 484 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :528
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841710
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245842
INFO:root:FL Epoch: 484 Norm Difference for worker 528 is 1.364629
INFO:root:FL Epoch: 484 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :141
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.089884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 141 is 1.139022
INFO:root:FL Epoch: 484 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :406
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649952
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522990
INFO:root:FL Epoch: 484 Norm Difference for worker 406 is 1.394212
INFO:root:FL Epoch: 484 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1149
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533490
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306639
INFO:root:FL Epoch: 484 Norm Difference for worker 1149 is 1.288597
INFO:root:FL Epoch: 484 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :639
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354124
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182499
INFO:root:FL Epoch: 484 Norm Difference for worker 639 is 1.238441
INFO:root:FL Epoch: 484 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :932
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453798
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216076
INFO:root:FL Epoch: 484 Norm Difference for worker 932 is 1.347934
INFO:root:FL Epoch: 484 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :865
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348787
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198295
INFO:root:FL Epoch: 484 Norm Difference for worker 865 is 1.188751
INFO:root:FL Epoch: 484 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1944
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488386
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180538
INFO:root:FL Epoch: 484 Norm Difference for worker 1944 is 1.125255
INFO:root:FL Epoch: 484 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1827
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705964
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438140
INFO:root:FL Epoch: 484 Norm Difference for worker 1827 is 1.346844
INFO:root:FL Epoch: 484 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1174
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570700
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149459
INFO:root:FL Epoch: 484 Norm Difference for worker 1174 is 1.340176
INFO:root:FL Epoch: 484 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2107029174971826, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2103804698865774
INFO:root:#### Oracle Cals: 3, Objective Val: 1.210375769891116
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2103757164491964
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.4589765825692345 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.02056951231012742                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [496, 203, 42, 22, 915, 382, 62, 1040, 29, 779]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 485 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :496
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486525
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176384
INFO:root:FL Epoch: 485 Norm Difference for worker 496 is 1.282627
INFO:root:FL Epoch: 485 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :203
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 203 is 1.403085
INFO:root:FL Epoch: 485 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :42
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 42 is 1.245038
INFO:root:FL Epoch: 485 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :22
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.145723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 22 is 1.33393
INFO:root:FL Epoch: 485 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :915
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514966
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283909
INFO:root:FL Epoch: 485 Norm Difference for worker 915 is 1.269188
INFO:root:FL Epoch: 485 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :382
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307495
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579897
INFO:root:FL Epoch: 485 Norm Difference for worker 382 is 1.194838
INFO:root:FL Epoch: 485 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :62
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.237358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 62 is 1.283176
INFO:root:FL Epoch: 485 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1040
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290588
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241462
INFO:root:FL Epoch: 485 Norm Difference for worker 1040 is 1.26228
INFO:root:FL Epoch: 485 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :29
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 29 is 1.337056
INFO:root:FL Epoch: 485 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :779
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411531
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313805
INFO:root:FL Epoch: 485 Norm Difference for worker 779 is 1.201887
INFO:root:FL Epoch: 485 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2020504669674836, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2019511907678346
INFO:root:#### Oracle Cals: 3, Objective Val: 1.20194997597992
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2019499703498495
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.46992375657838936 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.021165120570609968                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1637, 577, 971, 1234, 1712, 1120, 733, 1188, 1270, 393]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1637
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499088
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474618
INFO:root:FL Epoch: 486 Norm Difference for worker 1637 is 1.382839
INFO:root:FL Epoch: 486 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :577
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593585
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269736
INFO:root:FL Epoch: 486 Norm Difference for worker 577 is 1.417198
INFO:root:FL Epoch: 486 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :971
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557020
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281686
INFO:root:FL Epoch: 486 Norm Difference for worker 971 is 1.387904
INFO:root:FL Epoch: 486 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1234
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907456
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248310
INFO:root:FL Epoch: 486 Norm Difference for worker 1234 is 1.342244
INFO:root:FL Epoch: 486 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1712
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528620
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247820
INFO:root:FL Epoch: 486 Norm Difference for worker 1712 is 1.265352
INFO:root:FL Epoch: 486 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1120
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792658
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253522
INFO:root:FL Epoch: 486 Norm Difference for worker 1120 is 1.261355
INFO:root:FL Epoch: 486 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :733
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575904
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226980
INFO:root:FL Epoch: 486 Norm Difference for worker 733 is 1.253893
INFO:root:FL Epoch: 486 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1188
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390178
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302277
INFO:root:FL Epoch: 486 Norm Difference for worker 1188 is 1.351311
INFO:root:FL Epoch: 486 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1270
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450566
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168809
INFO:root:FL Epoch: 486 Norm Difference for worker 1270 is 1.149804
INFO:root:FL Epoch: 486 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :393
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501025
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454033
INFO:root:FL Epoch: 486 Norm Difference for worker 393 is 1.312194
INFO:root:FL Epoch: 486 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2355807281476163, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2353915047010702
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2353890864052162
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2353890663736893
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.466185063123703 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.02642821427434683                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1318, 1307, 1255, 86, 1583, 73, 1774, 1361, 1191, 72]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1318
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587085
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233573
INFO:root:FL Epoch: 487 Norm Difference for worker 1318 is 1.118416
INFO:root:FL Epoch: 487 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1307
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495114
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143057
INFO:root:FL Epoch: 487 Norm Difference for worker 1307 is 1.182055
INFO:root:FL Epoch: 487 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1255
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600338
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252619
INFO:root:FL Epoch: 487 Norm Difference for worker 1255 is 1.367164
INFO:root:FL Epoch: 487 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :86
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.374103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 86 is 1.170175
INFO:root:FL Epoch: 487 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1583
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497179
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251480
INFO:root:FL Epoch: 487 Norm Difference for worker 1583 is 1.269948
INFO:root:FL Epoch: 487 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :73
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519193
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 73 is 1.203526
INFO:root:FL Epoch: 487 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1774
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485835
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420399
INFO:root:FL Epoch: 487 Norm Difference for worker 1774 is 1.091744
INFO:root:FL Epoch: 487 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1361
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438599
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355282
INFO:root:FL Epoch: 487 Norm Difference for worker 1361 is 1.327345
INFO:root:FL Epoch: 487 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1191
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495590
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306430
INFO:root:FL Epoch: 487 Norm Difference for worker 1191 is 1.183316
INFO:root:FL Epoch: 487 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :72
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.327478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.181713
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 72 is 1.152098
INFO:root:FL Epoch: 487 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1359222390055885, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1356575099748172
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1356544870380672
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1356544395307637
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.47887421530835766 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.02387148840352893                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [1497, 860, 1140, 427, 1056, 1259, 134, 1401, 937, 1377]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 488 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :1497
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426824
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326655
INFO:root:FL Epoch: 488 Norm Difference for worker 1497 is 1.195645
INFO:root:FL Epoch: 488 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :860
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853417
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337412
INFO:root:FL Epoch: 488 Norm Difference for worker 860 is 1.348616
INFO:root:FL Epoch: 488 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1140
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.184217
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245708
INFO:root:FL Epoch: 488 Norm Difference for worker 1140 is 1.227256
INFO:root:FL Epoch: 488 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :427
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370153
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232796
INFO:root:FL Epoch: 488 Norm Difference for worker 427 is 1.2187
INFO:root:FL Epoch: 488 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1056
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504504
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.093534
INFO:root:FL Epoch: 488 Norm Difference for worker 1056 is 1.215351
INFO:root:FL Epoch: 488 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1259
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450300
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367153
INFO:root:FL Epoch: 488 Norm Difference for worker 1259 is 1.295072
INFO:root:FL Epoch: 488 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :134
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.160582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 134 is 1.179283
INFO:root:FL Epoch: 488 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1401
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592933
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233277
INFO:root:FL Epoch: 488 Norm Difference for worker 1401 is 1.306875
INFO:root:FL Epoch: 488 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :937
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573051
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205471
INFO:root:FL Epoch: 488 Norm Difference for worker 937 is 1.229377
INFO:root:FL Epoch: 488 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1377
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506191
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289408
INFO:root:FL Epoch: 488 Norm Difference for worker 1377 is 1.293784
INFO:root:FL Epoch: 488 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1812829445847608, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1811796867459865
INFO:root:#### Oracle Cals: 3, Objective Val: 1.181178537669704
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1811785282322391
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.4631969402818119 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.018574233632534742                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [858, 1611, 442, 1751, 1626, 1430, 557, 6, 1406, 1934]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :858
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527459
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.125150
INFO:root:FL Epoch: 489 Norm Difference for worker 858 is 1.285759
INFO:root:FL Epoch: 489 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1611
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387913
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172516
INFO:root:FL Epoch: 489 Norm Difference for worker 1611 is 1.228536
INFO:root:FL Epoch: 489 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :442
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512532
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237024
INFO:root:FL Epoch: 489 Norm Difference for worker 442 is 1.287851
INFO:root:FL Epoch: 489 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1751
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642728
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304792
INFO:root:FL Epoch: 489 Norm Difference for worker 1751 is 1.361124
INFO:root:FL Epoch: 489 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1626
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585612
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326041
INFO:root:FL Epoch: 489 Norm Difference for worker 1626 is 1.483904
INFO:root:FL Epoch: 489 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1430
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461003
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404612
INFO:root:FL Epoch: 489 Norm Difference for worker 1430 is 1.331526
INFO:root:FL Epoch: 489 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :557
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259058
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393844
INFO:root:FL Epoch: 489 Norm Difference for worker 557 is 1.320663
INFO:root:FL Epoch: 489 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :6
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 6 is 1.163546
INFO:root:FL Epoch: 489 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1406
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531844
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380706
INFO:root:FL Epoch: 489 Norm Difference for worker 1406 is 1.180153
INFO:root:FL Epoch: 489 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1934
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511910
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159594
INFO:root:FL Epoch: 489 Norm Difference for worker 1934 is 1.23616
INFO:root:FL Epoch: 489 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2140557116111554, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2137051860013095
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2137008466302093
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2137007752565403
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.4769185150370878 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.021162191250671942                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [406, 1256, 1544, 894, 738, 923, 1701, 1105, 182, 95]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 490 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :406
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283253
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253057
INFO:root:FL Epoch: 490 Norm Difference for worker 406 is 1.282119
INFO:root:FL Epoch: 490 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1256
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364313
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212752
INFO:root:FL Epoch: 490 Norm Difference for worker 1256 is 1.076516
INFO:root:FL Epoch: 490 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1544
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580548
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229485
INFO:root:FL Epoch: 490 Norm Difference for worker 1544 is 1.333796
INFO:root:FL Epoch: 490 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :894
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296469
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219677
INFO:root:FL Epoch: 490 Norm Difference for worker 894 is 1.075884
INFO:root:FL Epoch: 490 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :738
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640852
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256388
INFO:root:FL Epoch: 490 Norm Difference for worker 738 is 1.104236
INFO:root:FL Epoch: 490 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :923
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521841
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235583
INFO:root:FL Epoch: 490 Norm Difference for worker 923 is 1.292611
INFO:root:FL Epoch: 490 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1701
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456470
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448394
INFO:root:FL Epoch: 490 Norm Difference for worker 1701 is 1.240874
INFO:root:FL Epoch: 490 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1105
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420099
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165597
INFO:root:FL Epoch: 490 Norm Difference for worker 1105 is 1.108297
INFO:root:FL Epoch: 490 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :182
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 182 is 1.242794
INFO:root:FL Epoch: 490 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :95
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371382
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 95 is 1.21126
INFO:root:FL Epoch: 490 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.135435349072142, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1350449474019972
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1350394477609174
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1350393807973596
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.47414889230447654 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.02270945409933726                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 1088, 523, 382, 1677, 98, 89, 290]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.028038
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.022066
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.016380457983662684 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.016878217551857234 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.195969
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.027170
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.024751
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.016587419124941032 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.017036889772862197 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.201909
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.028486
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.022607
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.016707857605069876 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.016758965514600276 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.2045
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1088
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413313
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220736
INFO:root:FL Epoch: 491 Norm Difference for worker 1088 is 1.225574
INFO:root:FL Epoch: 491 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :523
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712595
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422946
INFO:root:FL Epoch: 491 Norm Difference for worker 523 is 1.337902
INFO:root:FL Epoch: 491 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :382
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382902
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366968
INFO:root:FL Epoch: 491 Norm Difference for worker 382 is 1.262374
INFO:root:FL Epoch: 491 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1677
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707985
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365518
INFO:root:FL Epoch: 491 Norm Difference for worker 1677 is 1.311591
INFO:root:FL Epoch: 491 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :98
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 98 is 1.220956
INFO:root:FL Epoch: 491 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :89
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 89 is 1.233629
INFO:root:FL Epoch: 491 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :290
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359294
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 290 is 1.234654
INFO:root:FL Epoch: 491 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 0.9313628799311094, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 0.9083224511102282
INFO:root:#### Oracle Cals: 3, Objective Val: 0.9026414691145526
INFO:root:#### Oracle Cals: 4, Objective Val: 0.9007550913385352
INFO:root:#### Oracle Cals: 5, Objective Val: 0.9000848314040125
INFO:root:#### Oracle Cals: 6, Objective Val: 0.8998479364848055
INFO:root:#### Oracle Cals: 7, Objective Val: 0.8997668851882062
INFO:root:#### Oracle Cals: 8, Objective Val: 0.8997398253392019
INFO:root:#### Oracle Cals: 9, Objective Val: 0.8997309936206008
INFO:root:#### Oracle Cals: 10, Objective Val: 0.8997285459914766
INFO:root:#### Oracle Cals: 11, Objective Val: 0.8997274285877574
INFO:root:#### Oracle Cals: 12, Objective Val: 0.8997269783423774
INFO:root:#### Oracle Cals: 13, Objective Val: 0.8997270646299517
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.493897161063026 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.01683017595981558                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [331, 1080, 1356, 698, 1944, 796, 259, 384, 392, 19]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 492 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :331
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.810917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 331 is 1.485574
INFO:root:FL Epoch: 492 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1080
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350687
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143527
INFO:root:FL Epoch: 492 Norm Difference for worker 1080 is 1.351281
INFO:root:FL Epoch: 492 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1356
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 1.045678
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346334
INFO:root:FL Epoch: 492 Norm Difference for worker 1356 is 1.455872
INFO:root:FL Epoch: 492 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :698
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835675
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294466
INFO:root:FL Epoch: 492 Norm Difference for worker 698 is 1.450565
INFO:root:FL Epoch: 492 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1944
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264358
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158884
INFO:root:FL Epoch: 492 Norm Difference for worker 1944 is 1.136883
INFO:root:FL Epoch: 492 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :796
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378856
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140611
INFO:root:FL Epoch: 492 Norm Difference for worker 796 is 1.234649
INFO:root:FL Epoch: 492 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :259
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470070
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 259 is 1.443175
INFO:root:FL Epoch: 492 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :384
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439352
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250928
INFO:root:FL Epoch: 492 Norm Difference for worker 384 is 1.342444
INFO:root:FL Epoch: 492 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :392
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262438
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.103551
INFO:root:FL Epoch: 492 Norm Difference for worker 392 is 1.225474
INFO:root:FL Epoch: 492 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :19
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 19 is 1.381042
INFO:root:FL Epoch: 492 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2737291645678195, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2733561149998829
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2733508485926706
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2733507419918493
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.47126363656100106 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.02139520738273859                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [1392, 707, 927, 1825, 923, 1449, 169, 1319, 496, 681]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :1392
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492067
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195075
INFO:root:FL Epoch: 493 Norm Difference for worker 1392 is 1.255001
INFO:root:FL Epoch: 493 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :707
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 1.104907
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164268
INFO:root:FL Epoch: 493 Norm Difference for worker 707 is 1.254152
INFO:root:FL Epoch: 493 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :927
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363447
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216505
INFO:root:FL Epoch: 493 Norm Difference for worker 927 is 1.053489
INFO:root:FL Epoch: 493 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1825
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350796
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359920
INFO:root:FL Epoch: 493 Norm Difference for worker 1825 is 1.278475
INFO:root:FL Epoch: 493 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :923
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338049
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280930
INFO:root:FL Epoch: 493 Norm Difference for worker 923 is 1.297356
INFO:root:FL Epoch: 493 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1449
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858031
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134927
INFO:root:FL Epoch: 493 Norm Difference for worker 1449 is 1.358839
INFO:root:FL Epoch: 493 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :169
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.221887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.154603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 169 is 1.128943
INFO:root:FL Epoch: 493 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1319
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580250
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268937
INFO:root:FL Epoch: 493 Norm Difference for worker 1319 is 1.236983
INFO:root:FL Epoch: 493 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :496
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256007
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269417
INFO:root:FL Epoch: 493 Norm Difference for worker 496 is 1.13834
INFO:root:FL Epoch: 493 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :681
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512223
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183752
INFO:root:FL Epoch: 493 Norm Difference for worker 681 is 1.31749
INFO:root:FL Epoch: 493 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1622481756777123, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.161901853572134
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1618973672034765
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1618973085388984
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.4591903037884656 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.01938960701227188                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [999, 311, 1767, 1021, 1187, 1460, 822, 1804, 711, 228]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 494 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :999
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415683
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341408
INFO:root:FL Epoch: 494 Norm Difference for worker 999 is 1.235367
INFO:root:FL Epoch: 494 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :311
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 311 is 1.258286
INFO:root:FL Epoch: 494 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1767
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428568
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246487
INFO:root:FL Epoch: 494 Norm Difference for worker 1767 is 1.27068
INFO:root:FL Epoch: 494 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1021
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481497
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198630
INFO:root:FL Epoch: 494 Norm Difference for worker 1021 is 1.22384
INFO:root:FL Epoch: 494 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1187
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620483
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360985
INFO:root:FL Epoch: 494 Norm Difference for worker 1187 is 1.297929
INFO:root:FL Epoch: 494 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1460
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519670
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207735
INFO:root:FL Epoch: 494 Norm Difference for worker 1460 is 1.173292
INFO:root:FL Epoch: 494 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :822
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499923
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.145609
INFO:root:FL Epoch: 494 Norm Difference for worker 822 is 1.332839
INFO:root:FL Epoch: 494 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1804
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489249
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447189
INFO:root:FL Epoch: 494 Norm Difference for worker 1804 is 1.328951
INFO:root:FL Epoch: 494 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :711
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343534
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286216
INFO:root:FL Epoch: 494 Norm Difference for worker 711 is 1.228442
INFO:root:FL Epoch: 494 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :228
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.274284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.260709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 228 is 1.207721
INFO:root:FL Epoch: 494 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1913081974785982, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1912419764755946
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1912412181466079
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1912412014471319
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.47720633797785816 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.0225880426975588                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [780, 63, 1298, 1777, 1947, 227, 1603, 1502, 1894, 1344]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 495 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :780
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522314
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289498
INFO:root:FL Epoch: 495 Norm Difference for worker 780 is 1.135427
INFO:root:FL Epoch: 495 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :63
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 63 is 1.362569
INFO:root:FL Epoch: 495 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1298
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487695
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252717
INFO:root:FL Epoch: 495 Norm Difference for worker 1298 is 1.236553
INFO:root:FL Epoch: 495 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1777
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.183033
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221348
INFO:root:FL Epoch: 495 Norm Difference for worker 1777 is 1.357185
INFO:root:FL Epoch: 495 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1947
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558472
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347406
INFO:root:FL Epoch: 495 Norm Difference for worker 1947 is 1.106238
INFO:root:FL Epoch: 495 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :227
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 227 is 1.263535
INFO:root:FL Epoch: 495 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1603
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406131
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195211
INFO:root:FL Epoch: 495 Norm Difference for worker 1603 is 1.252308
INFO:root:FL Epoch: 495 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1502
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496941
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245806
INFO:root:FL Epoch: 495 Norm Difference for worker 1502 is 1.338119
INFO:root:FL Epoch: 495 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1894
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706931
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192010
INFO:root:FL Epoch: 495 Norm Difference for worker 1894 is 1.302231
INFO:root:FL Epoch: 495 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1344
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376402
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306925
INFO:root:FL Epoch: 495 Norm Difference for worker 1344 is 1.341772
INFO:root:FL Epoch: 495 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1988046344444088, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.198548434933278
INFO:root:#### Oracle Cals: 3, Objective Val: 1.198544644427361
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1985445781214865
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.4694325888858122 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.027445836768796045                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [83, 593, 676, 1241, 405, 1473, 912, 335, 726, 15]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 496 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :83
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 83 is 1.377524
INFO:root:FL Epoch: 496 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :593
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559602
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226101
INFO:root:FL Epoch: 496 Norm Difference for worker 593 is 1.30346
INFO:root:FL Epoch: 496 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :676
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529521
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195850
INFO:root:FL Epoch: 496 Norm Difference for worker 676 is 1.379588
INFO:root:FL Epoch: 496 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1241
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554372
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383726
INFO:root:FL Epoch: 496 Norm Difference for worker 1241 is 1.279428
INFO:root:FL Epoch: 496 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :405
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475256
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130203
INFO:root:FL Epoch: 496 Norm Difference for worker 405 is 1.229138
INFO:root:FL Epoch: 496 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1473
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499324
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297401
INFO:root:FL Epoch: 496 Norm Difference for worker 1473 is 1.281905
INFO:root:FL Epoch: 496 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :912
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328392
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287260
INFO:root:FL Epoch: 496 Norm Difference for worker 912 is 1.151442
INFO:root:FL Epoch: 496 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :335
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546419
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364043
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 335 is 1.31469
INFO:root:FL Epoch: 496 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :726
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350165
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121387
INFO:root:FL Epoch: 496 Norm Difference for worker 726 is 1.278471
INFO:root:FL Epoch: 496 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :15
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498555
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.173463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 15 is 1.228253
INFO:root:FL Epoch: 496 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2124704731266456, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.2123250317647742
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2123230816163564
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2123230539945005
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.4644038712277132 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.027205999940633774                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [733, 220, 907, 1530, 605, 307, 873, 1496, 391, 607]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 497 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :733
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228929
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356297
INFO:root:FL Epoch: 497 Norm Difference for worker 733 is 1.156224
INFO:root:FL Epoch: 497 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :220
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.846082
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 220 is 1.293979
INFO:root:FL Epoch: 497 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :907
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327519
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305589
INFO:root:FL Epoch: 497 Norm Difference for worker 907 is 1.285873
INFO:root:FL Epoch: 497 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1530
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869602
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296298
INFO:root:FL Epoch: 497 Norm Difference for worker 1530 is 1.337978
INFO:root:FL Epoch: 497 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :605
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646302
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200210
INFO:root:FL Epoch: 497 Norm Difference for worker 605 is 1.270164
INFO:root:FL Epoch: 497 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :307
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.186377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 307 is 1.310718
INFO:root:FL Epoch: 497 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :873
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307704
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345446
INFO:root:FL Epoch: 497 Norm Difference for worker 873 is 1.346974
INFO:root:FL Epoch: 497 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1496
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253619
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305012
INFO:root:FL Epoch: 497 Norm Difference for worker 1496 is 1.146222
INFO:root:FL Epoch: 497 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :391
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700820
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342658
INFO:root:FL Epoch: 497 Norm Difference for worker 391 is 1.37015
INFO:root:FL Epoch: 497 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :607
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378050
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255850
INFO:root:FL Epoch: 497 Norm Difference for worker 607 is 1.176228
INFO:root:FL Epoch: 497 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.2011189819865034, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.200901759271543
INFO:root:#### Oracle Cals: 3, Objective Val: 1.2008985077090606
INFO:root:#### Oracle Cals: 4, Objective Val: 1.2008984560394915
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.48513797626775856 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.0364550839488705                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [1400, 441, 67, 585, 632, 280, 890, 1637, 897, 1319]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :1400
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241676
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347161
INFO:root:FL Epoch: 498 Norm Difference for worker 1400 is 1.241513
INFO:root:FL Epoch: 498 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :441
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895550
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249555
INFO:root:FL Epoch: 498 Norm Difference for worker 441 is 1.314102
INFO:root:FL Epoch: 498 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :67
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 67 is 1.206671
INFO:root:FL Epoch: 498 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :585
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584011
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336016
INFO:root:FL Epoch: 498 Norm Difference for worker 585 is 1.217161
INFO:root:FL Epoch: 498 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :632
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432867
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339235
INFO:root:FL Epoch: 498 Norm Difference for worker 632 is 1.222074
INFO:root:FL Epoch: 498 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :280
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439049
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 280 is 1.298473
INFO:root:FL Epoch: 498 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :890
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501052
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188787
INFO:root:FL Epoch: 498 Norm Difference for worker 890 is 1.218334
INFO:root:FL Epoch: 498 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1637
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512555
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268722
INFO:root:FL Epoch: 498 Norm Difference for worker 1637 is 1.295812
INFO:root:FL Epoch: 498 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :897
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509724
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332827
INFO:root:FL Epoch: 498 Norm Difference for worker 897 is 1.355716
INFO:root:FL Epoch: 498 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1319
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302063
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177832
INFO:root:FL Epoch: 498 Norm Difference for worker 1319 is 1.190974
INFO:root:FL Epoch: 498 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1778721033180417, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.177768319423798
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1777671873817268
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1777671616898915
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.4605111900497885 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.028818799803654354                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1014, 1779, 1466, 1440, 1234, 808, 479, 1215, 188, 1752]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1014
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561656
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325199
INFO:root:FL Epoch: 499 Norm Difference for worker 1014 is 1.285492
INFO:root:FL Epoch: 499 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1779
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289853
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249679
INFO:root:FL Epoch: 499 Norm Difference for worker 1779 is 1.185512
INFO:root:FL Epoch: 499 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1466
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445260
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381411
INFO:root:FL Epoch: 499 Norm Difference for worker 1466 is 1.215995
INFO:root:FL Epoch: 499 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1440
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550527
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215187
INFO:root:FL Epoch: 499 Norm Difference for worker 1440 is 1.203914
INFO:root:FL Epoch: 499 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1234
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552689
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.176431
INFO:root:FL Epoch: 499 Norm Difference for worker 1234 is 1.179325
INFO:root:FL Epoch: 499 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :808
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616690
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309516
INFO:root:FL Epoch: 499 Norm Difference for worker 808 is 1.306965
INFO:root:FL Epoch: 499 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :479
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545444
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369628
INFO:root:FL Epoch: 499 Norm Difference for worker 479 is 1.3586
INFO:root:FL Epoch: 499 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1215
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902802
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403696
INFO:root:FL Epoch: 499 Norm Difference for worker 1215 is 1.201385
INFO:root:FL Epoch: 499 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :188
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480757
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.281989
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 188 is 1.126562
INFO:root:FL Epoch: 499 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1752
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526331
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206408
INFO:root:FL Epoch: 499 Norm Difference for worker 1752 is 1.276714
INFO:root:FL Epoch: 499 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1670478619905666, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1668583301278956
INFO:root:#### Oracle Cals: 3, Objective Val: 1.166856006638741
INFO:root:#### Oracle Cals: 4, Objective Val: 1.1668559963129872
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.4526883539031534 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.02967135328799486                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [465, 1676, 1137, 1286, 1292, 469, 679, 551, 1025, 1649]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :465
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295996
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382969
INFO:root:FL Epoch: 500 Norm Difference for worker 465 is 1.264341
INFO:root:FL Epoch: 500 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1676
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369534
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281411
INFO:root:FL Epoch: 500 Norm Difference for worker 1676 is 1.365114
INFO:root:FL Epoch: 500 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1137
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418732
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474686
INFO:root:FL Epoch: 500 Norm Difference for worker 1137 is 1.269691
INFO:root:FL Epoch: 500 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1286
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411318
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204774
INFO:root:FL Epoch: 500 Norm Difference for worker 1286 is 1.234001
INFO:root:FL Epoch: 500 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1292
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526525
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212978
INFO:root:FL Epoch: 500 Norm Difference for worker 1292 is 1.31714
INFO:root:FL Epoch: 500 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :469
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282761
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171192
INFO:root:FL Epoch: 500 Norm Difference for worker 469 is 1.138852
INFO:root:FL Epoch: 500 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :679
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212556
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265089
INFO:root:FL Epoch: 500 Norm Difference for worker 679 is 1.211149
INFO:root:FL Epoch: 500 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :551
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437914
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139320
INFO:root:FL Epoch: 500 Norm Difference for worker 551 is 1.238696
INFO:root:FL Epoch: 500 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1025
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485466
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281026
INFO:root:FL Epoch: 500 Norm Difference for worker 1025 is 1.180037
INFO:root:FL Epoch: 500 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1649
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556609
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276670
INFO:root:FL Epoch: 500 Norm Difference for worker 1649 is 1.24761
INFO:root:FL Epoch: 500 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Starting Weiszfeld algorithm
INFO:root:[0, 1.1771603965032031, 0, 0]
INFO:root:#### Oracle Cals: 2, Objective Val: 1.1770260025324686
INFO:root:#### Oracle Cals: 3, Objective Val: 1.1770244126650724
INFO:root:#### Oracle Cals: 4, Objective Val: 1.177024403625077
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.4602828078410205 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.028785263498624165                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/single-character-rfa//stats.csv ******
